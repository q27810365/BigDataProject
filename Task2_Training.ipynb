{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of rooms</th>\n",
       "      <th>security level of the community</th>\n",
       "      <th>residence space</th>\n",
       "      <th>building space</th>\n",
       "      <th>noise level</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>air quality level</th>\n",
       "      <th>aboveground space</th>\n",
       "      <th>basement space</th>\n",
       "      <th>...</th>\n",
       "      <th>zip code_WA 98155</th>\n",
       "      <th>zip code_WA 98166</th>\n",
       "      <th>zip code_WA 98168</th>\n",
       "      <th>zip code_WA 98177</th>\n",
       "      <th>zip code_WA 98178</th>\n",
       "      <th>zip code_WA 98188</th>\n",
       "      <th>zip code_WA 98198</th>\n",
       "      <th>zip code_WA 98199</th>\n",
       "      <th>zip code_WA 98288</th>\n",
       "      <th>zip code_WA 98354</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2820</td>\n",
       "      <td>67518</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2820</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1210</td>\n",
       "      <td>9400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1210</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2200</td>\n",
       "      <td>9397</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1200</td>\n",
       "      <td>9720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1370</td>\n",
       "      <td>5858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1370</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3840</td>\n",
       "      <td>85728</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3840</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2310</td>\n",
       "      <td>13430</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3360</td>\n",
       "      <td>22111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3360</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>6</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2640</td>\n",
       "      <td>3680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1760</td>\n",
       "      <td>880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>5</td>\n",
       "      <td>4.25</td>\n",
       "      <td>6070</td>\n",
       "      <td>171626</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6070</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number of rooms  security level of the community  residence space  \\\n",
       "0                   5                             2.50             2820   \n",
       "1                   2                             1.00             1210   \n",
       "2                   4                             2.50             2200   \n",
       "3                   3                             1.50             1200   \n",
       "4                   3                             1.75             1370   \n",
       "...               ...                              ...              ...   \n",
       "3995                4                             3.50             3840   \n",
       "3996                5                             2.00             2310   \n",
       "3997                4                             2.50             3360   \n",
       "3998                6                             2.50             2640   \n",
       "3999                5                             4.25             6070   \n",
       "\n",
       "      building space  noise level  waterfront  view  air quality level  \\\n",
       "0              67518          2.0           0     0                  3   \n",
       "1               9400          1.0           0     0                  2   \n",
       "2               9397          2.0           0     0                  3   \n",
       "3               9720          1.0           0     0                  4   \n",
       "4               5858          1.0           0     0                  3   \n",
       "...              ...          ...         ...   ...                ...   \n",
       "3995           85728          2.0           0     0                  3   \n",
       "3996           13430          1.5           0     0                  4   \n",
       "3997           22111          2.0           0     0                  3   \n",
       "3998            3680          2.0           0     0                  5   \n",
       "3999          171626          2.0           0     0                  3   \n",
       "\n",
       "      aboveground space   basement space  ...  zip code_WA 98155  \\\n",
       "0                   2820               0  ...                0.0   \n",
       "1                   1210               0  ...                0.0   \n",
       "2                   2200               0  ...                0.0   \n",
       "3                   1200               0  ...                0.0   \n",
       "4                   1370               0  ...                0.0   \n",
       "...                  ...             ...  ...                ...   \n",
       "3995                3840               0  ...                0.0   \n",
       "3996                2310               0  ...                0.0   \n",
       "3997                3360               0  ...                0.0   \n",
       "3998                1760             880  ...                0.0   \n",
       "3999                6070               0  ...                0.0   \n",
       "\n",
       "      zip code_WA 98166  zip code_WA 98168  zip code_WA 98177  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "3995                0.0                0.0                0.0   \n",
       "3996                0.0                0.0                0.0   \n",
       "3997                0.0                0.0                0.0   \n",
       "3998                0.0                0.0                0.0   \n",
       "3999                0.0                0.0                0.0   \n",
       "\n",
       "      zip code_WA 98178  zip code_WA 98188  zip code_WA 98198  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                1.0   \n",
       "...                 ...                ...                ...   \n",
       "3995                0.0                0.0                0.0   \n",
       "3996                0.0                0.0                0.0   \n",
       "3997                0.0                0.0                0.0   \n",
       "3998                0.0                0.0                0.0   \n",
       "3999                0.0                0.0                0.0   \n",
       "\n",
       "      zip code_WA 98199  zip code_WA 98288  zip code_WA 98354  \n",
       "0                   0.0                0.0                0.0  \n",
       "1                   0.0                0.0                0.0  \n",
       "2                   0.0                0.0                0.0  \n",
       "3                   0.0                0.0                0.0  \n",
       "4                   0.0                0.0                0.0  \n",
       "...                 ...                ...                ...  \n",
       "3995                0.0                0.0                0.0  \n",
       "3996                0.0                0.0                0.0  \n",
       "3997                0.0                0.0                0.0  \n",
       "3998                0.0                0.0                0.0  \n",
       "3999                0.0                0.0                0.0  \n",
       "\n",
       "[4000 rows x 137 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Train_Data_final.csv\")\n",
    "# LongTensor should start from 0, we used to define from 1 to 4, now 0 to 3\n",
    "df['total cost'] = df['total cost'] - 1\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training set\n",
    "train_features = torch.tensor(train_data.drop('total cost', axis=1).values, dtype=torch.float).to(device)\n",
    "train_labels = torch.LongTensor(train_data['total cost'].values).to(device)\n",
    "\n",
    "# Validation set\n",
    "val_features = torch.tensor(val_data.drop('total cost', axis=1).values, dtype=torch.float).to(device)\n",
    "val_labels = torch.LongTensor(val_data['total cost'].values).to(device)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP \n",
    "# Reference: https://blog.csdn.net/jclian91/article/details/121708431 (Multiclass classification, Iris Dataset, MLP)\n",
    "# Reference: https://www.jianshu.com/p/65aed5b33cf2 (Pytorch MLP)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(features.shape[1], 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = nn.functional.relu(self.layer1(x))\n",
    "        y_pred = nn.functional.relu(self.layer2(y_pred))\n",
    "        y_pred = nn.functional.relu(self.layer3(y_pred))\n",
    "        y_pred = self.output(y_pred)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layer1): Linear(in_features=136, out_features=256, bias=True)\n",
      "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(train_features).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Fuction\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,     Training Loss: 19.29322052001953, Training Acc: 19.69%\n",
      "              Val Loss: 25.982803344726562, Val Acc: 39.75%\n",
      "Epoch: 2,     Training Loss: 23.581275939941406, Training Acc: 28.59%\n",
      "              Val Loss: 42.27552795410156, Val Acc: 33.31%\n",
      "Epoch: 3,     Training Loss: 39.19352722167969, Training Acc: 27.48%\n",
      "              Val Loss: 39.879520416259766, Val Acc: 30.33%\n",
      "Epoch: 4,     Training Loss: 35.878211975097656, Training Acc: 27.15%\n",
      "              Val Loss: 26.747020721435547, Val Acc: 30.38%\n",
      "Epoch: 5,     Training Loss: 24.070222854614258, Training Acc: 27.73%\n",
      "              Val Loss: 20.579015731811523, Val Acc: 31.62%\n",
      "Epoch: 6,     Training Loss: 19.20761489868164, Training Acc: 28.98%\n",
      "              Val Loss: 18.06261444091797, Val Acc: 32.27%\n",
      "Epoch: 7,     Training Loss: 17.266347885131836, Training Acc: 29.62%\n",
      "              Val Loss: 12.744467735290527, Val Acc: 32.62%\n",
      "Epoch: 8,     Training Loss: 12.617815017700195, Training Acc: 30.03%\n",
      "              Val Loss: 6.897873401641846, Val Acc: 33.30%\n",
      "Epoch: 9,     Training Loss: 7.1656599044799805, Training Acc: 30.69%\n",
      "              Val Loss: 10.524848937988281, Val Acc: 32.00%\n",
      "Epoch: 10,     Training Loss: 10.465209007263184, Training Acc: 29.94%\n",
      "              Val Loss: 11.030098915100098, Val Acc: 30.85%\n",
      "Epoch: 11,     Training Loss: 10.83877944946289, Training Acc: 29.20%\n",
      "              Val Loss: 6.273280620574951, Val Acc: 30.08%\n",
      "Epoch: 12,     Training Loss: 6.127413749694824, Training Acc: 28.86%\n",
      "              Val Loss: 6.697021007537842, Val Acc: 29.72%\n",
      "Epoch: 13,     Training Loss: 6.192418098449707, Training Acc: 28.71%\n",
      "              Val Loss: 7.515148162841797, Val Acc: 29.56%\n",
      "Epoch: 14,     Training Loss: 7.000178813934326, Training Acc: 28.68%\n",
      "              Val Loss: 8.024212837219238, Val Acc: 29.82%\n",
      "Epoch: 15,     Training Loss: 7.664968967437744, Training Acc: 28.97%\n",
      "              Val Loss: 7.179143905639648, Val Acc: 30.19%\n",
      "Epoch: 16,     Training Loss: 6.933833599090576, Training Acc: 29.33%\n",
      "              Val Loss: 6.348476409912109, Val Acc: 30.01%\n",
      "Epoch: 17,     Training Loss: 5.918429374694824, Training Acc: 29.24%\n",
      "              Val Loss: 6.10502815246582, Val Acc: 29.79%\n",
      "Epoch: 18,     Training Loss: 5.743584632873535, Training Acc: 29.06%\n",
      "              Val Loss: 2.6717734336853027, Val Acc: 29.81%\n",
      "Epoch: 19,     Training Loss: 2.6418862342834473, Training Acc: 29.18%\n",
      "              Val Loss: 4.272045135498047, Val Acc: 29.91%\n",
      "Epoch: 20,     Training Loss: 4.073939800262451, Training Acc: 29.41%\n",
      "              Val Loss: 5.251305103302002, Val Acc: 30.31%\n",
      "Epoch: 21,     Training Loss: 4.9166579246521, Training Acc: 29.91%\n",
      "              Val Loss: 5.818682670593262, Val Acc: 30.61%\n",
      "Epoch: 22,     Training Loss: 5.48330020904541, Training Acc: 30.28%\n",
      "              Val Loss: 5.996453762054443, Val Acc: 31.03%\n",
      "Epoch: 23,     Training Loss: 5.696902275085449, Training Acc: 30.81%\n",
      "              Val Loss: 4.888627529144287, Val Acc: 31.49%\n",
      "Epoch: 24,     Training Loss: 4.613348484039307, Training Acc: 31.35%\n",
      "              Val Loss: 3.989016532897949, Val Acc: 31.83%\n",
      "Epoch: 25,     Training Loss: 3.7393131256103516, Training Acc: 31.85%\n",
      "              Val Loss: 2.741375207901001, Val Acc: 32.20%\n",
      "Epoch: 26,     Training Loss: 2.653860092163086, Training Acc: 32.28%\n",
      "              Val Loss: 2.055201768875122, Val Acc: 32.29%\n",
      "Epoch: 27,     Training Loss: 2.139055013656616, Training Acc: 32.35%\n",
      "              Val Loss: 2.923643112182617, Val Acc: 32.30%\n",
      "Epoch: 28,     Training Loss: 2.89997935295105, Training Acc: 32.32%\n",
      "              Val Loss: 2.590836763381958, Val Acc: 32.60%\n",
      "Epoch: 29,     Training Loss: 2.6189255714416504, Training Acc: 32.52%\n",
      "              Val Loss: 1.7543644905090332, Val Acc: 33.00%\n",
      "Epoch: 30,     Training Loss: 1.8144667148590088, Training Acc: 32.81%\n",
      "              Val Loss: 1.9793881177902222, Val Acc: 33.27%\n",
      "Epoch: 31,     Training Loss: 1.905221700668335, Training Acc: 33.14%\n",
      "              Val Loss: 2.3786940574645996, Val Acc: 33.52%\n",
      "Epoch: 32,     Training Loss: 2.2464234828948975, Training Acc: 33.47%\n",
      "              Val Loss: 2.1938438415527344, Val Acc: 33.75%\n",
      "Epoch: 33,     Training Loss: 2.0873541831970215, Training Acc: 33.77%\n",
      "              Val Loss: 1.8968825340270996, Val Acc: 34.04%\n",
      "Epoch: 34,     Training Loss: 1.797576904296875, Training Acc: 34.04%\n",
      "              Val Loss: 1.6301912069320679, Val Acc: 34.36%\n",
      "Epoch: 35,     Training Loss: 1.596401333808899, Training Acc: 34.42%\n",
      "              Val Loss: 2.120720863342285, Val Acc: 34.60%\n",
      "Epoch: 36,     Training Loss: 2.118361473083496, Training Acc: 34.63%\n",
      "              Val Loss: 1.4832899570465088, Val Acc: 34.88%\n",
      "Epoch: 37,     Training Loss: 1.4296965599060059, Training Acc: 34.95%\n",
      "              Val Loss: 1.807178020477295, Val Acc: 34.97%\n",
      "Epoch: 38,     Training Loss: 1.7047169208526611, Training Acc: 35.14%\n",
      "              Val Loss: 1.7196060419082642, Val Acc: 35.13%\n",
      "Epoch: 39,     Training Loss: 1.6305121183395386, Training Acc: 35.35%\n",
      "              Val Loss: 1.5472915172576904, Val Acc: 35.34%\n",
      "Epoch: 40,     Training Loss: 1.505983829498291, Training Acc: 35.56%\n",
      "              Val Loss: 1.313879370689392, Val Acc: 35.58%\n",
      "Epoch: 41,     Training Loss: 1.2942951917648315, Training Acc: 35.86%\n",
      "              Val Loss: 1.4866443872451782, Val Acc: 35.79%\n",
      "Epoch: 42,     Training Loss: 1.4383915662765503, Training Acc: 36.09%\n",
      "              Val Loss: 1.4152402877807617, Val Acc: 36.04%\n",
      "Epoch: 43,     Training Loss: 1.2998727560043335, Training Acc: 36.34%\n",
      "              Val Loss: 1.2879256010055542, Val Acc: 36.17%\n",
      "Epoch: 44,     Training Loss: 1.2310817241668701, Training Acc: 36.55%\n",
      "              Val Loss: 1.3121516704559326, Val Acc: 36.43%\n",
      "Epoch: 45,     Training Loss: 1.2626820802688599, Training Acc: 36.85%\n",
      "              Val Loss: 1.3805867433547974, Val Acc: 36.71%\n",
      "Epoch: 46,     Training Loss: 1.3467800617218018, Training Acc: 37.14%\n",
      "              Val Loss: 1.1828614473342896, Val Acc: 36.97%\n",
      "Epoch: 47,     Training Loss: 1.1790279150009155, Training Acc: 37.41%\n",
      "              Val Loss: 1.3972400426864624, Val Acc: 37.06%\n",
      "Epoch: 48,     Training Loss: 1.372840166091919, Training Acc: 37.48%\n",
      "              Val Loss: 1.0916532278060913, Val Acc: 37.27%\n",
      "Epoch: 49,     Training Loss: 1.0954113006591797, Training Acc: 37.67%\n",
      "              Val Loss: 1.1991748809814453, Val Acc: 37.50%\n",
      "Epoch: 50,     Training Loss: 1.1749732494354248, Training Acc: 37.91%\n",
      "              Val Loss: 1.2385625839233398, Val Acc: 37.71%\n",
      "Epoch: 51,     Training Loss: 1.2082951068878174, Training Acc: 38.16%\n",
      "              Val Loss: 1.072913646697998, Val Acc: 37.94%\n",
      "Epoch: 52,     Training Loss: 1.0722241401672363, Training Acc: 38.39%\n",
      "              Val Loss: 1.248220682144165, Val Acc: 38.10%\n",
      "Epoch: 53,     Training Loss: 1.2229690551757812, Training Acc: 38.54%\n",
      "              Val Loss: 1.2547115087509155, Val Acc: 38.27%\n",
      "Epoch: 54,     Training Loss: 1.221828818321228, Training Acc: 38.70%\n",
      "              Val Loss: 1.0712382793426514, Val Acc: 38.46%\n",
      "Epoch: 55,     Training Loss: 1.064771056175232, Training Acc: 38.93%\n",
      "              Val Loss: 1.1979899406433105, Val Acc: 38.59%\n",
      "Epoch: 56,     Training Loss: 1.1716341972351074, Training Acc: 39.13%\n",
      "              Val Loss: 1.0852946043014526, Val Acc: 38.72%\n",
      "Epoch: 57,     Training Loss: 1.059559941291809, Training Acc: 39.36%\n",
      "              Val Loss: 1.264391303062439, Val Acc: 38.91%\n",
      "Epoch: 58,     Training Loss: 1.1912105083465576, Training Acc: 39.55%\n",
      "              Val Loss: 1.1303153038024902, Val Acc: 39.07%\n",
      "Epoch: 59,     Training Loss: 1.0779943466186523, Training Acc: 39.77%\n",
      "              Val Loss: 1.0737025737762451, Val Acc: 39.24%\n",
      "Epoch: 60,     Training Loss: 1.050971269607544, Training Acc: 39.98%\n",
      "              Val Loss: 1.0724282264709473, Val Acc: 39.40%\n",
      "Epoch: 61,     Training Loss: 1.047108769416809, Training Acc: 40.18%\n",
      "              Val Loss: 1.074427604675293, Val Acc: 39.56%\n",
      "Epoch: 62,     Training Loss: 1.0282762050628662, Training Acc: 40.39%\n",
      "              Val Loss: 1.129246711730957, Val Acc: 39.70%\n",
      "Epoch: 63,     Training Loss: 1.0724151134490967, Training Acc: 40.56%\n",
      "              Val Loss: 1.1024771928787231, Val Acc: 39.86%\n",
      "Epoch: 64,     Training Loss: 1.0608965158462524, Training Acc: 40.75%\n",
      "              Val Loss: 1.0998375415802002, Val Acc: 40.01%\n",
      "Epoch: 65,     Training Loss: 1.0689914226531982, Training Acc: 40.92%\n",
      "              Val Loss: 1.0747586488723755, Val Acc: 40.17%\n",
      "Epoch: 66,     Training Loss: 1.050857663154602, Training Acc: 41.07%\n",
      "              Val Loss: 1.0772217512130737, Val Acc: 40.32%\n",
      "Epoch: 67,     Training Loss: 1.0385856628417969, Training Acc: 41.24%\n",
      "              Val Loss: 1.0097180604934692, Val Acc: 40.49%\n",
      "Epoch: 68,     Training Loss: 0.9938961863517761, Training Acc: 41.41%\n",
      "              Val Loss: 1.0437793731689453, Val Acc: 40.62%\n",
      "Epoch: 69,     Training Loss: 1.0258567333221436, Training Acc: 41.57%\n",
      "              Val Loss: 1.0147534608840942, Val Acc: 40.78%\n",
      "Epoch: 70,     Training Loss: 0.9998877644538879, Training Acc: 41.73%\n",
      "              Val Loss: 1.04643976688385, Val Acc: 40.93%\n",
      "Epoch: 71,     Training Loss: 1.0280157327651978, Training Acc: 41.86%\n",
      "              Val Loss: 1.0757970809936523, Val Acc: 41.05%\n",
      "Epoch: 72,     Training Loss: 1.0476926565170288, Training Acc: 41.99%\n",
      "              Val Loss: 1.076797366142273, Val Acc: 41.18%\n",
      "Epoch: 73,     Training Loss: 1.049368143081665, Training Acc: 42.13%\n",
      "              Val Loss: 1.046653151512146, Val Acc: 41.31%\n",
      "Epoch: 74,     Training Loss: 1.0250189304351807, Training Acc: 42.27%\n",
      "              Val Loss: 1.085344910621643, Val Acc: 41.42%\n",
      "Epoch: 75,     Training Loss: 1.0467545986175537, Training Acc: 42.39%\n",
      "              Val Loss: 1.0507792234420776, Val Acc: 41.56%\n",
      "Epoch: 76,     Training Loss: 1.0167734622955322, Training Acc: 42.53%\n",
      "              Val Loss: 1.0319583415985107, Val Acc: 41.66%\n",
      "Epoch: 77,     Training Loss: 1.0139150619506836, Training Acc: 42.66%\n",
      "              Val Loss: 1.0238850116729736, Val Acc: 41.79%\n",
      "Epoch: 78,     Training Loss: 1.0065776109695435, Training Acc: 42.78%\n",
      "              Val Loss: 1.0651971101760864, Val Acc: 41.91%\n",
      "Epoch: 79,     Training Loss: 1.0254969596862793, Training Acc: 42.91%\n",
      "              Val Loss: 1.0668272972106934, Val Acc: 42.01%\n",
      "Epoch: 80,     Training Loss: 1.0284714698791504, Training Acc: 43.02%\n",
      "              Val Loss: 1.0467617511749268, Val Acc: 42.12%\n",
      "Epoch: 81,     Training Loss: 1.024878740310669, Training Acc: 43.15%\n",
      "              Val Loss: 1.0182790756225586, Val Acc: 42.24%\n",
      "Epoch: 82,     Training Loss: 0.9984198808670044, Training Acc: 43.27%\n",
      "              Val Loss: 1.1187412738800049, Val Acc: 42.33%\n",
      "Epoch: 83,     Training Loss: 1.0676624774932861, Training Acc: 43.37%\n",
      "              Val Loss: 1.0662829875946045, Val Acc: 42.42%\n",
      "Epoch: 84,     Training Loss: 1.0334038734436035, Training Acc: 43.48%\n",
      "              Val Loss: 1.0387775897979736, Val Acc: 42.50%\n",
      "Epoch: 85,     Training Loss: 1.015124797821045, Training Acc: 43.59%\n",
      "              Val Loss: 1.0543142557144165, Val Acc: 42.58%\n",
      "Epoch: 86,     Training Loss: 1.0273072719573975, Training Acc: 43.70%\n",
      "              Val Loss: 1.0412288904190063, Val Acc: 42.68%\n",
      "Epoch: 87,     Training Loss: 1.0203605890274048, Training Acc: 43.80%\n",
      "              Val Loss: 0.9948980212211609, Val Acc: 42.79%\n",
      "Epoch: 88,     Training Loss: 0.9752365946769714, Training Acc: 43.92%\n",
      "              Val Loss: 1.0159589052200317, Val Acc: 42.87%\n",
      "Epoch: 89,     Training Loss: 0.9915485382080078, Training Acc: 44.03%\n",
      "              Val Loss: 1.047593116760254, Val Acc: 42.97%\n",
      "Epoch: 90,     Training Loss: 1.022039532661438, Training Acc: 44.12%\n",
      "              Val Loss: 1.0059112310409546, Val Acc: 43.06%\n",
      "Epoch: 91,     Training Loss: 0.9828670024871826, Training Acc: 44.24%\n",
      "              Val Loss: 1.061661958694458, Val Acc: 43.14%\n",
      "Epoch: 92,     Training Loss: 1.0267544984817505, Training Acc: 44.32%\n",
      "              Val Loss: 1.1610612869262695, Val Acc: 43.21%\n",
      "Epoch: 93,     Training Loss: 1.1091856956481934, Training Acc: 44.40%\n",
      "              Val Loss: 1.1091691255569458, Val Acc: 43.27%\n",
      "Epoch: 94,     Training Loss: 1.068921685218811, Training Acc: 44.48%\n",
      "              Val Loss: 1.1375676393508911, Val Acc: 43.31%\n",
      "Epoch: 95,     Training Loss: 1.098318099975586, Training Acc: 44.53%\n",
      "              Val Loss: 1.08542799949646, Val Acc: 43.38%\n",
      "Epoch: 96,     Training Loss: 1.0481438636779785, Training Acc: 44.61%\n",
      "              Val Loss: 1.0027344226837158, Val Acc: 43.47%\n",
      "Epoch: 97,     Training Loss: 0.9791742563247681, Training Acc: 44.72%\n",
      "              Val Loss: 1.1075470447540283, Val Acc: 43.52%\n",
      "Epoch: 98,     Training Loss: 1.0640977621078491, Training Acc: 44.79%\n",
      "              Val Loss: 1.0651922225952148, Val Acc: 43.60%\n",
      "Epoch: 99,     Training Loss: 1.032382607460022, Training Acc: 44.87%\n",
      "              Val Loss: 1.034713864326477, Val Acc: 43.68%\n",
      "Epoch: 100,     Training Loss: 1.0059767961502075, Training Acc: 44.95%\n",
      "              Val Loss: 1.1586332321166992, Val Acc: 43.72%\n",
      "Epoch: 101,     Training Loss: 1.1055949926376343, Training Acc: 45.01%\n",
      "              Val Loss: 1.0188504457473755, Val Acc: 43.80%\n",
      "Epoch: 102,     Training Loss: 0.9924119710922241, Training Acc: 45.10%\n",
      "              Val Loss: 1.0309959650039673, Val Acc: 43.88%\n",
      "Epoch: 103,     Training Loss: 1.0016764402389526, Training Acc: 45.18%\n",
      "              Val Loss: 1.0824748277664185, Val Acc: 43.93%\n",
      "Epoch: 104,     Training Loss: 1.04110586643219, Training Acc: 45.25%\n",
      "              Val Loss: 1.0272681713104248, Val Acc: 44.01%\n",
      "Epoch: 105,     Training Loss: 0.9980000257492065, Training Acc: 45.33%\n",
      "              Val Loss: 1.004382610321045, Val Acc: 44.10%\n",
      "Epoch: 106,     Training Loss: 0.9785578846931458, Training Acc: 45.42%\n",
      "              Val Loss: 1.0811030864715576, Val Acc: 44.16%\n",
      "Epoch: 107,     Training Loss: 1.0400663614273071, Training Acc: 45.48%\n",
      "              Val Loss: 1.104161024093628, Val Acc: 44.21%\n",
      "Epoch: 108,     Training Loss: 1.0590015649795532, Training Acc: 45.55%\n",
      "              Val Loss: 1.0784016847610474, Val Acc: 44.26%\n",
      "Epoch: 109,     Training Loss: 1.0392277240753174, Training Acc: 45.61%\n",
      "              Val Loss: 1.1023906469345093, Val Acc: 44.31%\n",
      "Epoch: 110,     Training Loss: 1.0611662864685059, Training Acc: 45.66%\n",
      "              Val Loss: 1.1502588987350464, Val Acc: 44.35%\n",
      "Epoch: 111,     Training Loss: 1.0986241102218628, Training Acc: 45.71%\n",
      "              Val Loss: 1.048445463180542, Val Acc: 44.40%\n",
      "Epoch: 112,     Training Loss: 1.0142865180969238, Training Acc: 45.78%\n",
      "              Val Loss: 1.125948429107666, Val Acc: 44.42%\n",
      "Epoch: 113,     Training Loss: 1.079899549484253, Training Acc: 45.82%\n",
      "              Val Loss: 1.0870001316070557, Val Acc: 44.47%\n",
      "Epoch: 114,     Training Loss: 1.052872657775879, Training Acc: 45.88%\n",
      "              Val Loss: 1.0262194871902466, Val Acc: 44.54%\n",
      "Epoch: 115,     Training Loss: 0.994172990322113, Training Acc: 45.95%\n",
      "              Val Loss: 1.1539934873580933, Val Acc: 44.57%\n",
      "Epoch: 116,     Training Loss: 1.097029685974121, Training Acc: 45.99%\n",
      "              Val Loss: 1.0569360256195068, Val Acc: 44.63%\n",
      "Epoch: 117,     Training Loss: 1.021438479423523, Training Acc: 46.05%\n",
      "              Val Loss: 1.0510941743850708, Val Acc: 44.68%\n",
      "Epoch: 118,     Training Loss: 1.0136237144470215, Training Acc: 46.12%\n",
      "              Val Loss: 1.068588376045227, Val Acc: 44.73%\n",
      "Epoch: 119,     Training Loss: 1.0272328853607178, Training Acc: 46.17%\n",
      "              Val Loss: 1.121466040611267, Val Acc: 44.77%\n",
      "Epoch: 120,     Training Loss: 1.067077875137329, Training Acc: 46.21%\n",
      "              Val Loss: 1.0539356470108032, Val Acc: 44.81%\n",
      "Epoch: 121,     Training Loss: 1.0169905424118042, Training Acc: 46.27%\n",
      "              Val Loss: 1.0839223861694336, Val Acc: 44.84%\n",
      "Epoch: 122,     Training Loss: 1.0436208248138428, Training Acc: 46.31%\n",
      "              Val Loss: 1.1397110223770142, Val Acc: 44.88%\n",
      "Epoch: 123,     Training Loss: 1.0961674451828003, Training Acc: 46.35%\n",
      "              Val Loss: 1.0316026210784912, Val Acc: 44.92%\n",
      "Epoch: 124,     Training Loss: 0.9973593354225159, Training Acc: 46.41%\n",
      "              Val Loss: 1.1575509309768677, Val Acc: 44.93%\n",
      "Epoch: 125,     Training Loss: 1.1003475189208984, Training Acc: 46.44%\n",
      "              Val Loss: 1.0968836545944214, Val Acc: 44.98%\n",
      "Epoch: 126,     Training Loss: 1.0588244199752808, Training Acc: 46.49%\n",
      "              Val Loss: 1.059953212738037, Val Acc: 45.02%\n",
      "Epoch: 127,     Training Loss: 1.0205557346343994, Training Acc: 46.54%\n",
      "              Val Loss: 1.1176979541778564, Val Acc: 45.05%\n",
      "Epoch: 128,     Training Loss: 1.0675021409988403, Training Acc: 46.58%\n",
      "              Val Loss: 1.0864158868789673, Val Acc: 45.09%\n",
      "Epoch: 129,     Training Loss: 1.041353702545166, Training Acc: 46.63%\n",
      "              Val Loss: 1.0414053201675415, Val Acc: 45.13%\n",
      "Epoch: 130,     Training Loss: 1.002931833267212, Training Acc: 46.68%\n",
      "              Val Loss: 1.075191617012024, Val Acc: 45.16%\n",
      "Epoch: 131,     Training Loss: 1.032401204109192, Training Acc: 46.72%\n",
      "              Val Loss: 1.139653205871582, Val Acc: 45.20%\n",
      "Epoch: 132,     Training Loss: 1.0844943523406982, Training Acc: 46.76%\n",
      "              Val Loss: 1.0638960599899292, Val Acc: 45.23%\n",
      "Epoch: 133,     Training Loss: 1.0216405391693115, Training Acc: 46.81%\n",
      "              Val Loss: 1.1243473291397095, Val Acc: 45.24%\n",
      "Epoch: 134,     Training Loss: 1.0739120244979858, Training Acc: 46.84%\n",
      "              Val Loss: 1.1349411010742188, Val Acc: 45.27%\n",
      "Epoch: 135,     Training Loss: 1.0884881019592285, Training Acc: 46.87%\n",
      "              Val Loss: 1.0561867952346802, Val Acc: 45.31%\n",
      "Epoch: 136,     Training Loss: 1.015087366104126, Training Acc: 46.93%\n",
      "              Val Loss: 1.148005485534668, Val Acc: 45.32%\n",
      "Epoch: 137,     Training Loss: 1.0912998914718628, Training Acc: 46.95%\n",
      "              Val Loss: 1.0720148086547852, Val Acc: 45.36%\n",
      "Epoch: 138,     Training Loss: 1.0347970724105835, Training Acc: 46.99%\n",
      "              Val Loss: 1.0346579551696777, Val Acc: 45.40%\n",
      "Epoch: 139,     Training Loss: 0.9976152777671814, Training Acc: 47.04%\n",
      "              Val Loss: 1.0936874151229858, Val Acc: 45.43%\n",
      "Epoch: 140,     Training Loss: 1.0444804430007935, Training Acc: 47.08%\n",
      "              Val Loss: 1.0994844436645508, Val Acc: 45.47%\n",
      "Epoch: 141,     Training Loss: 1.0536365509033203, Training Acc: 47.12%\n",
      "              Val Loss: 1.0571807622909546, Val Acc: 45.50%\n",
      "Epoch: 142,     Training Loss: 1.0149493217468262, Training Acc: 47.17%\n",
      "              Val Loss: 1.1017524003982544, Val Acc: 45.52%\n",
      "Epoch: 143,     Training Loss: 1.0530887842178345, Training Acc: 47.19%\n",
      "              Val Loss: 1.1514297723770142, Val Acc: 45.56%\n",
      "Epoch: 144,     Training Loss: 1.095630168914795, Training Acc: 47.22%\n",
      "              Val Loss: 1.0758553743362427, Val Acc: 45.59%\n",
      "Epoch: 145,     Training Loss: 1.0307037830352783, Training Acc: 47.27%\n",
      "              Val Loss: 1.1338317394256592, Val Acc: 45.60%\n",
      "Epoch: 146,     Training Loss: 1.0810472965240479, Training Acc: 47.28%\n",
      "              Val Loss: 1.1039332151412964, Val Acc: 45.63%\n",
      "Epoch: 147,     Training Loss: 1.061139702796936, Training Acc: 47.31%\n",
      "              Val Loss: 1.03361976146698, Val Acc: 45.66%\n",
      "Epoch: 148,     Training Loss: 0.9950999617576599, Training Acc: 47.36%\n",
      "              Val Loss: 1.1203601360321045, Val Acc: 45.67%\n",
      "Epoch: 149,     Training Loss: 1.066166639328003, Training Acc: 47.39%\n",
      "              Val Loss: 1.0830926895141602, Val Acc: 45.71%\n",
      "Epoch: 150,     Training Loss: 1.0414338111877441, Training Acc: 47.42%\n",
      "              Val Loss: 1.0503262281417847, Val Acc: 45.75%\n",
      "Epoch: 151,     Training Loss: 1.0076347589492798, Training Acc: 47.47%\n",
      "              Val Loss: 1.0993998050689697, Val Acc: 45.77%\n",
      "Epoch: 152,     Training Loss: 1.0481007099151611, Training Acc: 47.50%\n",
      "              Val Loss: 1.130095362663269, Val Acc: 45.80%\n",
      "Epoch: 153,     Training Loss: 1.0721461772918701, Training Acc: 47.53%\n",
      "              Val Loss: 1.076015830039978, Val Acc: 45.82%\n",
      "Epoch: 154,     Training Loss: 1.028746485710144, Training Acc: 47.57%\n",
      "              Val Loss: 1.108689546585083, Val Acc: 45.84%\n",
      "Epoch: 155,     Training Loss: 1.0584213733673096, Training Acc: 47.58%\n",
      "              Val Loss: 1.1302132606506348, Val Acc: 45.87%\n",
      "Epoch: 156,     Training Loss: 1.0778218507766724, Training Acc: 47.61%\n",
      "              Val Loss: 1.0410115718841553, Val Acc: 45.90%\n",
      "Epoch: 157,     Training Loss: 0.99861741065979, Training Acc: 47.65%\n",
      "              Val Loss: 1.1218069791793823, Val Acc: 45.91%\n",
      "Epoch: 158,     Training Loss: 1.066371202468872, Training Acc: 47.67%\n",
      "              Val Loss: 1.094138741493225, Val Acc: 45.94%\n",
      "Epoch: 159,     Training Loss: 1.0535612106323242, Training Acc: 47.70%\n",
      "              Val Loss: 1.0465701818466187, Val Acc: 45.98%\n",
      "Epoch: 160,     Training Loss: 1.0037221908569336, Training Acc: 47.75%\n",
      "              Val Loss: 1.1223301887512207, Val Acc: 45.99%\n",
      "Epoch: 161,     Training Loss: 1.0659024715423584, Training Acc: 47.76%\n",
      "              Val Loss: 1.099635124206543, Val Acc: 46.02%\n",
      "Epoch: 162,     Training Loss: 1.0483043193817139, Training Acc: 47.80%\n",
      "              Val Loss: 1.0628105401992798, Val Acc: 46.05%\n",
      "Epoch: 163,     Training Loss: 1.0166001319885254, Training Acc: 47.84%\n",
      "              Val Loss: 1.0877121686935425, Val Acc: 46.06%\n",
      "Epoch: 164,     Training Loss: 1.03874671459198, Training Acc: 47.85%\n",
      "              Val Loss: 1.1297268867492676, Val Acc: 46.09%\n",
      "Epoch: 165,     Training Loss: 1.0705068111419678, Training Acc: 47.88%\n",
      "              Val Loss: 1.0525825023651123, Val Acc: 46.11%\n",
      "Epoch: 166,     Training Loss: 1.0070981979370117, Training Acc: 47.92%\n",
      "              Val Loss: 1.1006431579589844, Val Acc: 46.12%\n",
      "Epoch: 167,     Training Loss: 1.0487823486328125, Training Acc: 47.93%\n",
      "              Val Loss: 1.1156808137893677, Val Acc: 46.14%\n",
      "Epoch: 168,     Training Loss: 1.0693726539611816, Training Acc: 47.96%\n",
      "              Val Loss: 1.0426195859909058, Val Acc: 46.17%\n",
      "Epoch: 169,     Training Loss: 0.9983677864074707, Training Acc: 48.00%\n",
      "              Val Loss: 1.1325784921646118, Val Acc: 46.18%\n",
      "Epoch: 170,     Training Loss: 1.072399377822876, Training Acc: 48.01%\n",
      "              Val Loss: 1.0951335430145264, Val Acc: 46.21%\n",
      "Epoch: 171,     Training Loss: 1.048246145248413, Training Acc: 48.04%\n",
      "              Val Loss: 1.0575461387634277, Val Acc: 46.24%\n",
      "Epoch: 172,     Training Loss: 1.0109665393829346, Training Acc: 48.08%\n",
      "              Val Loss: 1.1023386716842651, Val Acc: 46.25%\n",
      "Epoch: 173,     Training Loss: 1.0472230911254883, Training Acc: 48.09%\n",
      "              Val Loss: 1.113364815711975, Val Acc: 46.28%\n",
      "Epoch: 174,     Training Loss: 1.0559759140014648, Training Acc: 48.12%\n",
      "              Val Loss: 1.0565783977508545, Val Acc: 46.30%\n",
      "Epoch: 175,     Training Loss: 1.009041428565979, Training Acc: 48.16%\n",
      "              Val Loss: 1.0929003953933716, Val Acc: 46.31%\n",
      "Epoch: 176,     Training Loss: 1.041030764579773, Training Acc: 48.17%\n",
      "              Val Loss: 1.1192748546600342, Val Acc: 46.34%\n",
      "Epoch: 177,     Training Loss: 1.066176414489746, Training Acc: 48.20%\n",
      "              Val Loss: 1.0487982034683228, Val Acc: 46.35%\n",
      "Epoch: 178,     Training Loss: 1.0019915103912354, Training Acc: 48.23%\n",
      "              Val Loss: 1.113206386566162, Val Acc: 46.36%\n",
      "Epoch: 179,     Training Loss: 1.0560442209243774, Training Acc: 48.25%\n",
      "              Val Loss: 1.102399230003357, Val Acc: 46.39%\n",
      "Epoch: 180,     Training Loss: 1.0569889545440674, Training Acc: 48.27%\n",
      "              Val Loss: 1.0490946769714355, Val Acc: 46.42%\n",
      "Epoch: 181,     Training Loss: 1.0025542974472046, Training Acc: 48.31%\n",
      "              Val Loss: 1.1192848682403564, Val Acc: 46.42%\n",
      "Epoch: 182,     Training Loss: 1.0594086647033691, Training Acc: 48.32%\n",
      "              Val Loss: 1.1007757186889648, Val Acc: 46.45%\n",
      "Epoch: 183,     Training Loss: 1.0470877885818481, Training Acc: 48.35%\n",
      "              Val Loss: 1.0574284791946411, Val Acc: 46.48%\n",
      "Epoch: 184,     Training Loss: 1.0090965032577515, Training Acc: 48.38%\n",
      "              Val Loss: 1.0922651290893555, Val Acc: 46.49%\n",
      "Epoch: 185,     Training Loss: 1.0379958152770996, Training Acc: 48.40%\n",
      "              Val Loss: 1.1180305480957031, Val Acc: 46.51%\n",
      "Epoch: 186,     Training Loss: 1.0581477880477905, Training Acc: 48.42%\n",
      "              Val Loss: 1.0519787073135376, Val Acc: 46.53%\n",
      "Epoch: 187,     Training Loss: 1.0029696226119995, Training Acc: 48.45%\n",
      "              Val Loss: 1.0960502624511719, Val Acc: 46.54%\n",
      "Epoch: 188,     Training Loss: 1.0413262844085693, Training Acc: 48.47%\n",
      "              Val Loss: 1.1085466146469116, Val Acc: 46.56%\n",
      "Epoch: 189,     Training Loss: 1.0579516887664795, Training Acc: 48.49%\n",
      "              Val Loss: 1.0441582202911377, Val Acc: 46.58%\n",
      "Epoch: 190,     Training Loss: 0.9958568811416626, Training Acc: 48.52%\n",
      "              Val Loss: 1.1139883995056152, Val Acc: 46.59%\n",
      "Epoch: 191,     Training Loss: 1.0534840822219849, Training Acc: 48.54%\n",
      "              Val Loss: 1.0989655256271362, Val Acc: 46.61%\n",
      "Epoch: 192,     Training Loss: 1.0490416288375854, Training Acc: 48.56%\n",
      "              Val Loss: 1.054433822631836, Val Acc: 46.63%\n",
      "Epoch: 193,     Training Loss: 1.005043387413025, Training Acc: 48.59%\n",
      "              Val Loss: 1.1058684587478638, Val Acc: 46.64%\n",
      "Epoch: 194,     Training Loss: 1.046453595161438, Training Acc: 48.60%\n",
      "              Val Loss: 1.1093356609344482, Val Acc: 46.67%\n",
      "Epoch: 195,     Training Loss: 1.050262451171875, Training Acc: 48.63%\n",
      "              Val Loss: 1.0555590391159058, Val Acc: 46.69%\n",
      "Epoch: 196,     Training Loss: 1.0054692029953003, Training Acc: 48.65%\n",
      "              Val Loss: 1.0912425518035889, Val Acc: 46.70%\n",
      "Epoch: 197,     Training Loss: 1.0360792875289917, Training Acc: 48.67%\n",
      "              Val Loss: 1.1045268774032593, Val Acc: 46.72%\n",
      "Epoch: 198,     Training Loss: 1.0493979454040527, Training Acc: 48.69%\n",
      "              Val Loss: 1.041536808013916, Val Acc: 46.74%\n",
      "Epoch: 199,     Training Loss: 0.9928164482116699, Training Acc: 48.72%\n",
      "              Val Loss: 1.0926138162612915, Val Acc: 46.75%\n",
      "Epoch: 200,     Training Loss: 1.0354593992233276, Training Acc: 48.74%\n",
      "              Val Loss: 1.09734308719635, Val Acc: 46.77%\n",
      "Epoch: 201,     Training Loss: 1.0484966039657593, Training Acc: 48.76%\n",
      "              Val Loss: 1.0449457168579102, Val Acc: 46.79%\n",
      "Epoch: 202,     Training Loss: 0.9955831170082092, Training Acc: 48.79%\n",
      "              Val Loss: 1.1066737174987793, Val Acc: 46.80%\n",
      "Epoch: 203,     Training Loss: 1.0456616878509521, Training Acc: 48.80%\n",
      "              Val Loss: 1.1085593700408936, Val Acc: 46.82%\n",
      "Epoch: 204,     Training Loss: 1.0513020753860474, Training Acc: 48.82%\n",
      "              Val Loss: 1.0613328218460083, Val Acc: 46.84%\n",
      "Epoch: 205,     Training Loss: 1.0095906257629395, Training Acc: 48.85%\n",
      "              Val Loss: 1.097731590270996, Val Acc: 46.85%\n",
      "Epoch: 206,     Training Loss: 1.0397613048553467, Training Acc: 48.86%\n",
      "              Val Loss: 1.1068391799926758, Val Acc: 46.87%\n",
      "Epoch: 207,     Training Loss: 1.0466688871383667, Training Acc: 48.88%\n",
      "              Val Loss: 1.0430102348327637, Val Acc: 46.89%\n",
      "Epoch: 208,     Training Loss: 0.9932438135147095, Training Acc: 48.91%\n",
      "              Val Loss: 1.0837547779083252, Val Acc: 46.90%\n",
      "Epoch: 209,     Training Loss: 1.0280303955078125, Training Acc: 48.93%\n",
      "              Val Loss: 1.0896316766738892, Val Acc: 46.92%\n",
      "Epoch: 210,     Training Loss: 1.038597583770752, Training Acc: 48.95%\n",
      "              Val Loss: 1.0337902307510376, Val Acc: 46.94%\n",
      "Epoch: 211,     Training Loss: 0.9847457408905029, Training Acc: 48.98%\n",
      "              Val Loss: 1.0916191339492798, Val Acc: 46.95%\n",
      "Epoch: 212,     Training Loss: 1.0314756631851196, Training Acc: 48.99%\n",
      "              Val Loss: 1.102013111114502, Val Acc: 46.97%\n",
      "Epoch: 213,     Training Loss: 1.0485310554504395, Training Acc: 49.01%\n",
      "              Val Loss: 1.0573554039001465, Val Acc: 46.99%\n",
      "Epoch: 214,     Training Loss: 1.004740834236145, Training Acc: 49.04%\n",
      "              Val Loss: 1.1051665544509888, Val Acc: 47.00%\n",
      "Epoch: 215,     Training Loss: 1.0433323383331299, Training Acc: 49.05%\n",
      "              Val Loss: 1.1110917329788208, Val Acc: 47.02%\n",
      "Epoch: 216,     Training Loss: 1.0496541261672974, Training Acc: 49.07%\n",
      "              Val Loss: 1.0549850463867188, Val Acc: 47.04%\n",
      "Epoch: 217,     Training Loss: 1.002465844154358, Training Acc: 49.09%\n",
      "              Val Loss: 1.0887898206710815, Val Acc: 47.04%\n",
      "Epoch: 218,     Training Loss: 1.031546950340271, Training Acc: 49.10%\n",
      "              Val Loss: 1.08762526512146, Val Acc: 47.07%\n",
      "Epoch: 219,     Training Loss: 1.0320125818252563, Training Acc: 49.12%\n",
      "              Val Loss: 1.0282816886901855, Val Acc: 47.09%\n",
      "Epoch: 220,     Training Loss: 0.9788802862167358, Training Acc: 49.15%\n",
      "              Val Loss: 1.0729707479476929, Val Acc: 47.10%\n",
      "Epoch: 221,     Training Loss: 1.0157802104949951, Training Acc: 49.17%\n",
      "              Val Loss: 1.0862313508987427, Val Acc: 47.12%\n",
      "Epoch: 222,     Training Loss: 1.0340145826339722, Training Acc: 49.19%\n",
      "              Val Loss: 1.040200114250183, Val Acc: 47.14%\n",
      "Epoch: 223,     Training Loss: 0.9884144067764282, Training Acc: 49.22%\n",
      "              Val Loss: 1.092057228088379, Val Acc: 47.15%\n",
      "Epoch: 224,     Training Loss: 1.029981255531311, Training Acc: 49.23%\n",
      "              Val Loss: 1.1151734590530396, Val Acc: 47.16%\n",
      "Epoch: 225,     Training Loss: 1.054184079170227, Training Acc: 49.25%\n",
      "              Val Loss: 1.065673828125, Val Acc: 47.18%\n",
      "Epoch: 226,     Training Loss: 1.0101709365844727, Training Acc: 49.27%\n",
      "              Val Loss: 1.1034340858459473, Val Acc: 47.19%\n",
      "Epoch: 227,     Training Loss: 1.0411012172698975, Training Acc: 49.28%\n",
      "              Val Loss: 1.0961509943008423, Val Acc: 47.21%\n",
      "Epoch: 228,     Training Loss: 1.0374500751495361, Training Acc: 49.30%\n",
      "              Val Loss: 1.0351531505584717, Val Acc: 47.22%\n",
      "Epoch: 229,     Training Loss: 0.9836781024932861, Training Acc: 49.32%\n",
      "              Val Loss: 1.0780928134918213, Val Acc: 47.23%\n",
      "Epoch: 230,     Training Loss: 1.0187830924987793, Training Acc: 49.34%\n",
      "              Val Loss: 1.0768400430679321, Val Acc: 47.26%\n",
      "Epoch: 231,     Training Loss: 1.023007869720459, Training Acc: 49.35%\n",
      "              Val Loss: 1.0300837755203247, Val Acc: 47.27%\n",
      "Epoch: 232,     Training Loss: 0.9787278771400452, Training Acc: 49.38%\n",
      "              Val Loss: 1.0749638080596924, Val Acc: 47.29%\n",
      "Epoch: 233,     Training Loss: 1.0141868591308594, Training Acc: 49.40%\n",
      "              Val Loss: 1.1030480861663818, Val Acc: 47.30%\n",
      "Epoch: 234,     Training Loss: 1.0421116352081299, Training Acc: 49.41%\n",
      "              Val Loss: 1.0573177337646484, Val Acc: 47.32%\n",
      "Epoch: 235,     Training Loss: 1.001552700996399, Training Acc: 49.44%\n",
      "              Val Loss: 1.0957080125808716, Val Acc: 47.33%\n",
      "Epoch: 236,     Training Loss: 1.0329571962356567, Training Acc: 49.45%\n",
      "              Val Loss: 1.1047234535217285, Val Acc: 47.34%\n",
      "Epoch: 237,     Training Loss: 1.0434564352035522, Training Acc: 49.46%\n",
      "              Val Loss: 1.0452053546905518, Val Acc: 47.36%\n",
      "Epoch: 238,     Training Loss: 0.9904766082763672, Training Acc: 49.49%\n",
      "              Val Loss: 1.0872793197631836, Val Acc: 47.37%\n",
      "Epoch: 239,     Training Loss: 1.0254454612731934, Training Acc: 49.50%\n",
      "              Val Loss: 1.0772066116333008, Val Acc: 47.39%\n",
      "Epoch: 240,     Training Loss: 1.0228312015533447, Training Acc: 49.52%\n",
      "              Val Loss: 1.027759313583374, Val Acc: 47.40%\n",
      "Epoch: 241,     Training Loss: 0.9756314158439636, Training Acc: 49.54%\n",
      "              Val Loss: 1.0734156370162964, Val Acc: 47.42%\n",
      "Epoch: 242,     Training Loss: 1.0114033222198486, Training Acc: 49.56%\n",
      "              Val Loss: 1.0914149284362793, Val Acc: 47.43%\n",
      "Epoch: 243,     Training Loss: 1.0309468507766724, Training Acc: 49.58%\n",
      "              Val Loss: 1.0472427606582642, Val Acc: 47.45%\n",
      "Epoch: 244,     Training Loss: 0.992469310760498, Training Acc: 49.60%\n",
      "              Val Loss: 1.0843627452850342, Val Acc: 47.46%\n",
      "Epoch: 245,     Training Loss: 1.0217020511627197, Training Acc: 49.61%\n",
      "              Val Loss: 1.1039351224899292, Val Acc: 47.48%\n",
      "Epoch: 246,     Training Loss: 1.0399465560913086, Training Acc: 49.62%\n",
      "              Val Loss: 1.0461636781692505, Val Acc: 47.49%\n",
      "Epoch: 247,     Training Loss: 0.990582287311554, Training Acc: 49.65%\n",
      "              Val Loss: 1.0860670804977417, Val Acc: 47.50%\n",
      "Epoch: 248,     Training Loss: 1.023755669593811, Training Acc: 49.66%\n",
      "              Val Loss: 1.0762828588485718, Val Acc: 47.52%\n",
      "Epoch: 249,     Training Loss: 1.0215002298355103, Training Acc: 49.67%\n",
      "              Val Loss: 1.0262012481689453, Val Acc: 47.54%\n",
      "Epoch: 250,     Training Loss: 0.9726307392120361, Training Acc: 49.70%\n",
      "              Val Loss: 1.0734341144561768, Val Acc: 47.55%\n",
      "Epoch: 251,     Training Loss: 1.0098191499710083, Training Acc: 49.71%\n",
      "              Val Loss: 1.0824975967407227, Val Acc: 47.56%\n",
      "Epoch: 252,     Training Loss: 1.0246838331222534, Training Acc: 49.73%\n",
      "              Val Loss: 1.0437519550323486, Val Acc: 47.58%\n",
      "Epoch: 253,     Training Loss: 0.9882599115371704, Training Acc: 49.75%\n",
      "              Val Loss: 1.0817068815231323, Val Acc: 47.59%\n",
      "Epoch: 254,     Training Loss: 1.0169973373413086, Training Acc: 49.76%\n",
      "              Val Loss: 1.1046255826950073, Val Acc: 47.60%\n",
      "Epoch: 255,     Training Loss: 1.038160800933838, Training Acc: 49.78%\n",
      "              Val Loss: 1.049032211303711, Val Acc: 47.62%\n",
      "Epoch: 256,     Training Loss: 0.9925452470779419, Training Acc: 49.80%\n",
      "              Val Loss: 1.0847675800323486, Val Acc: 47.63%\n",
      "Epoch: 257,     Training Loss: 1.0216495990753174, Training Acc: 49.81%\n",
      "              Val Loss: 1.0751174688339233, Val Acc: 47.65%\n",
      "Epoch: 258,     Training Loss: 1.0173033475875854, Training Acc: 49.83%\n",
      "              Val Loss: 1.0208299160003662, Val Acc: 47.66%\n",
      "Epoch: 259,     Training Loss: 0.9671148061752319, Training Acc: 49.85%\n",
      "              Val Loss: 1.067091941833496, Val Acc: 47.68%\n",
      "Epoch: 260,     Training Loss: 1.0035964250564575, Training Acc: 49.87%\n",
      "              Val Loss: 1.0697251558303833, Val Acc: 47.69%\n",
      "Epoch: 261,     Training Loss: 1.0140193700790405, Training Acc: 49.88%\n",
      "              Val Loss: 1.0343362092971802, Val Acc: 47.71%\n",
      "Epoch: 262,     Training Loss: 0.9785755276679993, Training Acc: 49.90%\n",
      "              Val Loss: 1.075326681137085, Val Acc: 47.72%\n",
      "Epoch: 263,     Training Loss: 1.0094530582427979, Training Acc: 49.92%\n",
      "              Val Loss: 1.1026605367660522, Val Acc: 47.73%\n",
      "Epoch: 264,     Training Loss: 1.036250114440918, Training Acc: 49.93%\n",
      "              Val Loss: 1.0563373565673828, Val Acc: 47.75%\n",
      "Epoch: 265,     Training Loss: 0.9977501034736633, Training Acc: 49.95%\n",
      "              Val Loss: 1.0885560512542725, Val Acc: 47.75%\n",
      "Epoch: 266,     Training Loss: 1.023014783859253, Training Acc: 49.96%\n",
      "              Val Loss: 1.0815653800964355, Val Acc: 47.77%\n",
      "Epoch: 267,     Training Loss: 1.0199354887008667, Training Acc: 49.97%\n",
      "              Val Loss: 1.022057056427002, Val Acc: 47.78%\n",
      "Epoch: 268,     Training Loss: 0.9673652052879333, Training Acc: 50.00%\n",
      "              Val Loss: 1.0666389465332031, Val Acc: 47.79%\n",
      "Epoch: 269,     Training Loss: 1.0022886991500854, Training Acc: 50.01%\n",
      "              Val Loss: 1.059550404548645, Val Acc: 47.81%\n",
      "Epoch: 270,     Training Loss: 1.0040922164916992, Training Acc: 50.03%\n",
      "              Val Loss: 1.0218727588653564, Val Acc: 47.83%\n",
      "Epoch: 271,     Training Loss: 0.9668850898742676, Training Acc: 50.05%\n",
      "              Val Loss: 1.0662813186645508, Val Acc: 47.84%\n",
      "Epoch: 272,     Training Loss: 0.9998893141746521, Training Acc: 50.06%\n",
      "              Val Loss: 1.0897215604782104, Val Acc: 47.85%\n",
      "Epoch: 273,     Training Loss: 1.0255675315856934, Training Acc: 50.08%\n",
      "              Val Loss: 1.0533215999603271, Val Acc: 47.87%\n",
      "Epoch: 274,     Training Loss: 0.994316577911377, Training Acc: 50.10%\n",
      "              Val Loss: 1.0847164392471313, Val Acc: 47.88%\n",
      "Epoch: 275,     Training Loss: 1.0178085565567017, Training Acc: 50.10%\n",
      "              Val Loss: 1.089176058769226, Val Acc: 47.89%\n",
      "Epoch: 276,     Training Loss: 1.0250043869018555, Training Acc: 50.12%\n",
      "              Val Loss: 1.0323705673217773, Val Acc: 47.90%\n",
      "Epoch: 277,     Training Loss: 0.9753955602645874, Training Acc: 50.14%\n",
      "              Val Loss: 1.0718882083892822, Val Acc: 47.91%\n",
      "Epoch: 278,     Training Loss: 1.0066124200820923, Training Acc: 50.15%\n",
      "              Val Loss: 1.0588607788085938, Val Acc: 47.93%\n",
      "Epoch: 279,     Training Loss: 1.0022802352905273, Training Acc: 50.17%\n",
      "              Val Loss: 1.016628384590149, Val Acc: 47.94%\n",
      "Epoch: 280,     Training Loss: 0.9612820148468018, Training Acc: 50.19%\n",
      "              Val Loss: 1.0603914260864258, Val Acc: 47.96%\n",
      "Epoch: 281,     Training Loss: 0.9939724802970886, Training Acc: 50.20%\n",
      "              Val Loss: 1.0782486200332642, Val Acc: 47.97%\n",
      "Epoch: 282,     Training Loss: 1.014991283416748, Training Acc: 50.22%\n",
      "              Val Loss: 1.044000506401062, Val Acc: 47.99%\n",
      "Epoch: 283,     Training Loss: 0.9851225018501282, Training Acc: 50.24%\n",
      "              Val Loss: 1.0754942893981934, Val Acc: 48.00%\n",
      "Epoch: 284,     Training Loss: 1.0079847574234009, Training Acc: 50.25%\n",
      "              Val Loss: 1.0938975811004639, Val Acc: 48.01%\n",
      "Epoch: 285,     Training Loss: 1.0255606174468994, Training Acc: 50.26%\n",
      "              Val Loss: 1.0390658378601074, Val Acc: 48.02%\n",
      "Epoch: 286,     Training Loss: 0.9802377223968506, Training Acc: 50.28%\n",
      "              Val Loss: 1.0745478868484497, Val Acc: 48.03%\n",
      "Epoch: 287,     Training Loss: 1.0081079006195068, Training Acc: 50.29%\n",
      "              Val Loss: 1.0607504844665527, Val Acc: 48.05%\n",
      "Epoch: 288,     Training Loss: 1.0010755062103271, Training Acc: 50.30%\n",
      "              Val Loss: 1.0136902332305908, Val Acc: 48.06%\n",
      "Epoch: 289,     Training Loss: 0.956983745098114, Training Acc: 50.33%\n",
      "              Val Loss: 1.0558135509490967, Val Acc: 48.08%\n",
      "Epoch: 290,     Training Loss: 0.9887439608573914, Training Acc: 50.34%\n",
      "              Val Loss: 1.0659805536270142, Val Acc: 48.09%\n",
      "Epoch: 291,     Training Loss: 1.00380277633667, Training Acc: 50.35%\n",
      "              Val Loss: 1.0341774225234985, Val Acc: 48.11%\n",
      "Epoch: 292,     Training Loss: 0.9746332764625549, Training Acc: 50.37%\n",
      "              Val Loss: 1.0651403665542603, Val Acc: 48.12%\n",
      "Epoch: 293,     Training Loss: 0.9964261651039124, Training Acc: 50.38%\n",
      "              Val Loss: 1.0986806154251099, Val Acc: 48.13%\n",
      "Epoch: 294,     Training Loss: 1.026391863822937, Training Acc: 50.39%\n",
      "              Val Loss: 1.0471389293670654, Val Acc: 48.14%\n",
      "Epoch: 295,     Training Loss: 0.9861275553703308, Training Acc: 50.41%\n",
      "              Val Loss: 1.0768892765045166, Val Acc: 48.15%\n",
      "Epoch: 296,     Training Loss: 1.0094138383865356, Training Acc: 50.42%\n",
      "              Val Loss: 1.0655688047409058, Val Acc: 48.17%\n",
      "Epoch: 297,     Training Loss: 1.0027570724487305, Training Acc: 50.43%\n",
      "              Val Loss: 1.0102813243865967, Val Acc: 48.18%\n",
      "Epoch: 298,     Training Loss: 0.9535524249076843, Training Acc: 50.46%\n",
      "              Val Loss: 1.0529743432998657, Val Acc: 48.20%\n",
      "Epoch: 299,     Training Loss: 0.9860820174217224, Training Acc: 50.47%\n",
      "              Val Loss: 1.0522122383117676, Val Acc: 48.21%\n",
      "Epoch: 300,     Training Loss: 0.9919254183769226, Training Acc: 50.48%\n",
      "              Val Loss: 1.0210216045379639, Val Acc: 48.23%\n",
      "Epoch: 301,     Training Loss: 0.9619024395942688, Training Acc: 50.50%\n",
      "              Val Loss: 1.0550650358200073, Val Acc: 48.24%\n",
      "Epoch: 302,     Training Loss: 0.9857540130615234, Training Acc: 50.52%\n",
      "              Val Loss: 1.093916654586792, Val Acc: 48.25%\n",
      "Epoch: 303,     Training Loss: 1.0202287435531616, Training Acc: 50.53%\n",
      "              Val Loss: 1.0521541833877563, Val Acc: 48.27%\n",
      "Epoch: 304,     Training Loss: 0.9891479015350342, Training Acc: 50.55%\n",
      "              Val Loss: 1.0757763385772705, Val Acc: 48.27%\n",
      "Epoch: 305,     Training Loss: 1.0067009925842285, Training Acc: 50.56%\n",
      "              Val Loss: 1.0767199993133545, Val Acc: 48.29%\n",
      "Epoch: 306,     Training Loss: 1.008436918258667, Training Acc: 50.57%\n",
      "              Val Loss: 1.014379620552063, Val Acc: 48.30%\n",
      "Epoch: 307,     Training Loss: 0.9555811285972595, Training Acc: 50.59%\n",
      "              Val Loss: 1.054183006286621, Val Acc: 48.31%\n",
      "Epoch: 308,     Training Loss: 0.9862375855445862, Training Acc: 50.60%\n",
      "              Val Loss: 1.04454505443573, Val Acc: 48.33%\n",
      "Epoch: 309,     Training Loss: 0.9846459031105042, Training Acc: 50.62%\n",
      "              Val Loss: 1.0089877843856812, Val Acc: 48.34%\n",
      "Epoch: 310,     Training Loss: 0.9502383470535278, Training Acc: 50.64%\n",
      "              Val Loss: 1.047829270362854, Val Acc: 48.36%\n",
      "Epoch: 311,     Training Loss: 0.9778187274932861, Training Acc: 50.65%\n",
      "              Val Loss: 1.0795624256134033, Val Acc: 48.37%\n",
      "Epoch: 312,     Training Loss: 1.008448600769043, Training Acc: 50.66%\n",
      "              Val Loss: 1.0474152565002441, Val Acc: 48.39%\n",
      "Epoch: 313,     Training Loss: 0.984006941318512, Training Acc: 50.68%\n",
      "              Val Loss: 1.0698046684265137, Val Acc: 48.40%\n",
      "Epoch: 314,     Training Loss: 0.9994850158691406, Training Acc: 50.69%\n",
      "              Val Loss: 1.0878113508224487, Val Acc: 48.41%\n",
      "Epoch: 315,     Training Loss: 1.0145511627197266, Training Acc: 50.70%\n",
      "              Val Loss: 1.025727391242981, Val Acc: 48.42%\n",
      "Epoch: 316,     Training Loss: 0.9644979238510132, Training Acc: 50.72%\n",
      "              Val Loss: 1.058279037475586, Val Acc: 48.43%\n",
      "Epoch: 317,     Training Loss: 0.9902823567390442, Training Acc: 50.73%\n",
      "              Val Loss: 1.0453377962112427, Val Acc: 48.44%\n",
      "Epoch: 318,     Training Loss: 0.9829340577125549, Training Acc: 50.74%\n",
      "              Val Loss: 1.0021594762802124, Val Acc: 48.46%\n",
      "Epoch: 319,     Training Loss: 0.9430626034736633, Training Acc: 50.76%\n",
      "              Val Loss: 1.0394182205200195, Val Acc: 48.47%\n",
      "Epoch: 320,     Training Loss: 0.9704436659812927, Training Acc: 50.78%\n",
      "              Val Loss: 1.0595042705535889, Val Acc: 48.49%\n",
      "Epoch: 321,     Training Loss: 0.9922544956207275, Training Acc: 50.79%\n",
      "              Val Loss: 1.0308122634887695, Val Acc: 48.50%\n",
      "Epoch: 322,     Training Loss: 0.9680832028388977, Training Acc: 50.81%\n",
      "              Val Loss: 1.0561882257461548, Val Acc: 48.51%\n",
      "Epoch: 323,     Training Loss: 0.9849640727043152, Training Acc: 50.82%\n",
      "              Val Loss: 1.0931603908538818, Val Acc: 48.52%\n",
      "Epoch: 324,     Training Loss: 1.0168750286102295, Training Acc: 50.83%\n",
      "              Val Loss: 1.0383354425430298, Val Acc: 48.53%\n",
      "Epoch: 325,     Training Loss: 0.9746910929679871, Training Acc: 50.85%\n",
      "              Val Loss: 1.0681203603744507, Val Acc: 48.54%\n",
      "Epoch: 326,     Training Loss: 0.9974277019500732, Training Acc: 50.86%\n",
      "              Val Loss: 1.0563253164291382, Val Acc: 48.56%\n",
      "Epoch: 327,     Training Loss: 0.9894100427627563, Training Acc: 50.87%\n",
      "              Val Loss: 1.003269076347351, Val Acc: 48.57%\n",
      "Epoch: 328,     Training Loss: 0.9435433745384216, Training Acc: 50.89%\n",
      "              Val Loss: 1.0422892570495605, Val Acc: 48.58%\n",
      "Epoch: 329,     Training Loss: 0.9727563261985779, Training Acc: 50.91%\n",
      "              Val Loss: 1.0412098169326782, Val Acc: 48.60%\n",
      "Epoch: 330,     Training Loss: 0.9782969951629639, Training Acc: 50.92%\n",
      "              Val Loss: 1.0138673782348633, Val Acc: 48.61%\n",
      "Epoch: 331,     Training Loss: 0.9521901607513428, Training Acc: 50.94%\n",
      "              Val Loss: 1.0427192449569702, Val Acc: 48.62%\n",
      "Epoch: 332,     Training Loss: 0.9714271426200867, Training Acc: 50.95%\n",
      "              Val Loss: 1.0812232494354248, Val Acc: 48.63%\n",
      "Epoch: 333,     Training Loss: 1.0055636167526245, Training Acc: 50.96%\n",
      "              Val Loss: 1.0405972003936768, Val Acc: 48.64%\n",
      "Epoch: 334,     Training Loss: 0.9757630228996277, Training Acc: 50.98%\n",
      "              Val Loss: 1.0622875690460205, Val Acc: 48.65%\n",
      "Epoch: 335,     Training Loss: 0.9912082552909851, Training Acc: 50.99%\n",
      "              Val Loss: 1.0764927864074707, Val Acc: 48.67%\n",
      "Epoch: 336,     Training Loss: 1.0012731552124023, Training Acc: 51.00%\n",
      "              Val Loss: 1.0123018026351929, Val Acc: 48.68%\n",
      "Epoch: 337,     Training Loss: 0.9507187008857727, Training Acc: 51.02%\n",
      "              Val Loss: 1.0470236539840698, Val Acc: 48.69%\n",
      "Epoch: 338,     Training Loss: 0.9771336317062378, Training Acc: 51.03%\n",
      "              Val Loss: 1.0408998727798462, Val Acc: 48.70%\n",
      "Epoch: 339,     Training Loss: 0.9763744473457336, Training Acc: 51.04%\n",
      "              Val Loss: 1.0024173259735107, Val Acc: 48.72%\n",
      "Epoch: 340,     Training Loss: 0.9415390491485596, Training Acc: 51.07%\n",
      "              Val Loss: 1.0386654138565063, Val Acc: 48.73%\n",
      "Epoch: 341,     Training Loss: 0.9670497179031372, Training Acc: 51.08%\n",
      "              Val Loss: 1.0559672117233276, Val Acc: 48.75%\n",
      "Epoch: 342,     Training Loss: 0.9871686697006226, Training Acc: 51.09%\n",
      "              Val Loss: 1.0259580612182617, Val Acc: 48.76%\n",
      "Epoch: 343,     Training Loss: 0.9619902968406677, Training Acc: 51.11%\n",
      "              Val Loss: 1.052116870880127, Val Acc: 48.77%\n",
      "Epoch: 344,     Training Loss: 0.9792518615722656, Training Acc: 51.12%\n",
      "              Val Loss: 1.0828455686569214, Val Acc: 48.78%\n",
      "Epoch: 345,     Training Loss: 1.0052577257156372, Training Acc: 51.13%\n",
      "              Val Loss: 1.0306552648544312, Val Acc: 48.79%\n",
      "Epoch: 346,     Training Loss: 0.9658532738685608, Training Acc: 51.15%\n",
      "              Val Loss: 1.0556645393371582, Val Acc: 48.80%\n",
      "Epoch: 347,     Training Loss: 0.984061598777771, Training Acc: 51.16%\n",
      "              Val Loss: 1.0548033714294434, Val Acc: 48.82%\n",
      "Epoch: 348,     Training Loss: 0.9838182926177979, Training Acc: 51.17%\n",
      "              Val Loss: 1.0025385618209839, Val Acc: 48.83%\n",
      "Epoch: 349,     Training Loss: 0.940582275390625, Training Acc: 51.19%\n",
      "              Val Loss: 1.0346379280090332, Val Acc: 48.84%\n",
      "Epoch: 350,     Training Loss: 0.9641010761260986, Training Acc: 51.20%\n",
      "              Val Loss: 1.0389204025268555, Val Acc: 48.85%\n",
      "Epoch: 351,     Training Loss: 0.9721938371658325, Training Acc: 51.21%\n",
      "              Val Loss: 1.0044817924499512, Val Acc: 48.87%\n",
      "Epoch: 352,     Training Loss: 0.9423134326934814, Training Acc: 51.23%\n",
      "              Val Loss: 1.0350658893585205, Val Acc: 48.88%\n",
      "Epoch: 353,     Training Loss: 0.9625890254974365, Training Acc: 51.24%\n",
      "              Val Loss: 1.0690044164657593, Val Acc: 48.89%\n",
      "Epoch: 354,     Training Loss: 0.99308180809021, Training Acc: 51.25%\n",
      "              Val Loss: 1.0288166999816895, Val Acc: 48.90%\n",
      "Epoch: 355,     Training Loss: 0.9635154604911804, Training Acc: 51.27%\n",
      "              Val Loss: 1.0547767877578735, Val Acc: 48.91%\n",
      "Epoch: 356,     Training Loss: 0.9808933734893799, Training Acc: 51.28%\n",
      "              Val Loss: 1.0725796222686768, Val Acc: 48.93%\n",
      "Epoch: 357,     Training Loss: 0.9952364563941956, Training Acc: 51.29%\n",
      "              Val Loss: 1.016291618347168, Val Acc: 48.94%\n",
      "Epoch: 358,     Training Loss: 0.951612651348114, Training Acc: 51.31%\n",
      "              Val Loss: 1.0466855764389038, Val Acc: 48.95%\n",
      "Epoch: 359,     Training Loss: 0.9740387201309204, Training Acc: 51.32%\n",
      "              Val Loss: 1.0412917137145996, Val Acc: 48.96%\n",
      "Epoch: 360,     Training Loss: 0.9719812273979187, Training Acc: 51.33%\n",
      "              Val Loss: 0.9998956322669983, Val Acc: 48.97%\n",
      "Epoch: 361,     Training Loss: 0.9369394183158875, Training Acc: 51.35%\n",
      "              Val Loss: 1.0290182828903198, Val Acc: 48.99%\n",
      "Epoch: 362,     Training Loss: 0.9573510885238647, Training Acc: 51.36%\n",
      "              Val Loss: 1.0469129085540771, Val Acc: 49.00%\n",
      "Epoch: 363,     Training Loss: 0.9751695394515991, Training Acc: 51.37%\n",
      "              Val Loss: 1.012853980064392, Val Acc: 49.01%\n",
      "Epoch: 364,     Training Loss: 0.9485926032066345, Training Acc: 51.39%\n",
      "              Val Loss: 1.0352625846862793, Val Acc: 49.03%\n",
      "Epoch: 365,     Training Loss: 0.9630248546600342, Training Acc: 51.40%\n",
      "              Val Loss: 1.0732207298278809, Val Acc: 49.04%\n",
      "Epoch: 366,     Training Loss: 0.993943989276886, Training Acc: 51.41%\n",
      "              Val Loss: 1.0208854675292969, Val Acc: 49.05%\n",
      "Epoch: 367,     Training Loss: 0.9559289813041687, Training Acc: 51.43%\n",
      "              Val Loss: 1.048762559890747, Val Acc: 49.06%\n",
      "Epoch: 368,     Training Loss: 0.9753140807151794, Training Acc: 51.44%\n",
      "              Val Loss: 1.05377995967865, Val Acc: 49.07%\n",
      "Epoch: 369,     Training Loss: 0.9803169965744019, Training Acc: 51.45%\n",
      "              Val Loss: 1.0015642642974854, Val Acc: 49.08%\n",
      "Epoch: 370,     Training Loss: 0.9380060434341431, Training Acc: 51.47%\n",
      "              Val Loss: 1.037139654159546, Val Acc: 49.10%\n",
      "Epoch: 371,     Training Loss: 0.9634093642234802, Training Acc: 51.48%\n",
      "              Val Loss: 1.0344197750091553, Val Acc: 49.11%\n",
      "Epoch: 372,     Training Loss: 0.9655633568763733, Training Acc: 51.49%\n",
      "              Val Loss: 1.0019704103469849, Val Acc: 49.12%\n",
      "Epoch: 373,     Training Loss: 0.9379676580429077, Training Acc: 51.51%\n",
      "              Val Loss: 1.0295482873916626, Val Acc: 49.13%\n",
      "Epoch: 374,     Training Loss: 0.9558719396591187, Training Acc: 51.52%\n",
      "              Val Loss: 1.0586124658584595, Val Acc: 49.14%\n",
      "Epoch: 375,     Training Loss: 0.9810136556625366, Training Acc: 51.53%\n",
      "              Val Loss: 1.0204750299453735, Val Acc: 49.16%\n",
      "Epoch: 376,     Training Loss: 0.9548443555831909, Training Acc: 51.55%\n",
      "              Val Loss: 1.0391871929168701, Val Acc: 49.17%\n",
      "Epoch: 377,     Training Loss: 0.9658088088035583, Training Acc: 51.56%\n",
      "              Val Loss: 1.0705357789993286, Val Acc: 49.18%\n",
      "Epoch: 378,     Training Loss: 0.9890623688697815, Training Acc: 51.57%\n",
      "              Val Loss: 1.0094270706176758, Val Acc: 49.19%\n",
      "Epoch: 379,     Training Loss: 0.9445275068283081, Training Acc: 51.59%\n",
      "              Val Loss: 1.0398197174072266, Val Acc: 49.20%\n",
      "Epoch: 380,     Training Loss: 0.9658697247505188, Training Acc: 51.60%\n",
      "              Val Loss: 1.0387272834777832, Val Acc: 49.21%\n",
      "Epoch: 381,     Training Loss: 0.9666689038276672, Training Acc: 51.61%\n",
      "              Val Loss: 0.9924894571304321, Val Acc: 49.23%\n",
      "Epoch: 382,     Training Loss: 0.9288867712020874, Training Acc: 51.63%\n",
      "              Val Loss: 1.0286253690719604, Val Acc: 49.24%\n",
      "Epoch: 383,     Training Loss: 0.9536663293838501, Training Acc: 51.64%\n",
      "              Val Loss: 1.0376321077346802, Val Acc: 49.25%\n",
      "Epoch: 384,     Training Loss: 0.9653830528259277, Training Acc: 51.65%\n",
      "              Val Loss: 1.0080370903015137, Val Acc: 49.26%\n",
      "Epoch: 385,     Training Loss: 0.942596971988678, Training Acc: 51.67%\n",
      "              Val Loss: 1.031780481338501, Val Acc: 49.28%\n",
      "Epoch: 386,     Training Loss: 0.9565575122833252, Training Acc: 51.68%\n",
      "              Val Loss: 1.067255973815918, Val Acc: 49.28%\n",
      "Epoch: 387,     Training Loss: 0.9851840138435364, Training Acc: 51.69%\n",
      "              Val Loss: 1.0216485261917114, Val Acc: 49.30%\n",
      "Epoch: 388,     Training Loss: 0.9544609189033508, Training Acc: 51.71%\n",
      "              Val Loss: 1.0408225059509277, Val Acc: 49.31%\n",
      "Epoch: 389,     Training Loss: 0.9663814306259155, Training Acc: 51.72%\n",
      "              Val Loss: 1.0531715154647827, Val Acc: 49.32%\n",
      "Epoch: 390,     Training Loss: 0.9745466709136963, Training Acc: 51.73%\n",
      "              Val Loss: 0.995089590549469, Val Acc: 49.33%\n",
      "Epoch: 391,     Training Loss: 0.9305371642112732, Training Acc: 51.75%\n",
      "              Val Loss: 1.0262075662612915, Val Acc: 49.34%\n",
      "Epoch: 392,     Training Loss: 0.9524304270744324, Training Acc: 51.76%\n",
      "              Val Loss: 1.0259606838226318, Val Acc: 49.35%\n",
      "Epoch: 393,     Training Loss: 0.9557418823242188, Training Acc: 51.77%\n",
      "              Val Loss: 0.9901479482650757, Val Acc: 49.37%\n",
      "Epoch: 394,     Training Loss: 0.9261705279350281, Training Acc: 51.79%\n",
      "              Val Loss: 1.0218473672866821, Val Acc: 49.38%\n",
      "Epoch: 395,     Training Loss: 0.946433424949646, Training Acc: 51.80%\n",
      "              Val Loss: 1.0478099584579468, Val Acc: 49.39%\n",
      "Epoch: 396,     Training Loss: 0.9699989557266235, Training Acc: 51.81%\n",
      "              Val Loss: 1.0148942470550537, Val Acc: 49.40%\n",
      "Epoch: 397,     Training Loss: 0.9479568004608154, Training Acc: 51.83%\n",
      "              Val Loss: 1.0362693071365356, Val Acc: 49.41%\n",
      "Epoch: 398,     Training Loss: 0.9592511057853699, Training Acc: 51.84%\n",
      "              Val Loss: 1.0694973468780518, Val Acc: 49.42%\n",
      "Epoch: 399,     Training Loss: 0.9846339225769043, Training Acc: 51.85%\n",
      "              Val Loss: 1.0124869346618652, Val Acc: 49.44%\n",
      "Epoch: 400,     Training Loss: 0.9456267356872559, Training Acc: 51.86%\n",
      "              Val Loss: 1.0375269651412964, Val Acc: 49.45%\n",
      "Epoch: 401,     Training Loss: 0.9617673754692078, Training Acc: 51.88%\n",
      "              Val Loss: 1.0360559225082397, Val Acc: 49.45%\n",
      "Epoch: 402,     Training Loss: 0.9605761766433716, Training Acc: 51.89%\n",
      "              Val Loss: 0.9864738583564758, Val Acc: 49.47%\n",
      "Epoch: 403,     Training Loss: 0.9222277998924255, Training Acc: 51.90%\n",
      "              Val Loss: 1.018378496170044, Val Acc: 49.48%\n",
      "Epoch: 404,     Training Loss: 0.9435365796089172, Training Acc: 51.92%\n",
      "              Val Loss: 1.0229970216751099, Val Acc: 49.49%\n",
      "Epoch: 405,     Training Loss: 0.9515250325202942, Training Acc: 51.93%\n",
      "              Val Loss: 0.993274986743927, Val Acc: 49.50%\n",
      "Epoch: 406,     Training Loss: 0.9282247424125671, Training Acc: 51.94%\n",
      "              Val Loss: 1.018889307975769, Val Acc: 49.52%\n",
      "Epoch: 407,     Training Loss: 0.9427326917648315, Training Acc: 51.96%\n",
      "              Val Loss: 1.0574910640716553, Val Acc: 49.53%\n",
      "Epoch: 408,     Training Loss: 0.974709689617157, Training Acc: 51.97%\n",
      "              Val Loss: 1.0170670747756958, Val Acc: 49.54%\n",
      "Epoch: 409,     Training Loss: 0.9492617845535278, Training Acc: 51.98%\n",
      "              Val Loss: 1.0367693901062012, Val Acc: 49.55%\n",
      "Epoch: 410,     Training Loss: 0.9598246216773987, Training Acc: 51.99%\n",
      "              Val Loss: 1.060319423675537, Val Acc: 49.56%\n",
      "Epoch: 411,     Training Loss: 0.9761409163475037, Training Acc: 52.00%\n",
      "              Val Loss: 0.9995826482772827, Val Acc: 49.57%\n",
      "Epoch: 412,     Training Loss: 0.9329279065132141, Training Acc: 52.02%\n",
      "              Val Loss: 1.0287033319473267, Val Acc: 49.58%\n",
      "Epoch: 413,     Training Loss: 0.9523928165435791, Training Acc: 52.03%\n",
      "              Val Loss: 1.022616982460022, Val Acc: 49.59%\n",
      "Epoch: 414,     Training Loss: 0.9493456482887268, Training Acc: 52.04%\n",
      "              Val Loss: 0.9829127788543701, Val Acc: 49.60%\n",
      "Epoch: 415,     Training Loss: 0.9180466532707214, Training Acc: 52.06%\n",
      "              Val Loss: 1.0133962631225586, Val Acc: 49.62%\n",
      "Epoch: 416,     Training Loss: 0.9369188547134399, Training Acc: 52.07%\n",
      "              Val Loss: 1.0283790826797485, Val Acc: 49.62%\n",
      "Epoch: 417,     Training Loss: 0.9521201252937317, Training Acc: 52.08%\n",
      "              Val Loss: 0.9997530579566956, Val Acc: 49.64%\n",
      "Epoch: 418,     Training Loss: 0.9326981902122498, Training Acc: 52.10%\n",
      "              Val Loss: 1.0198290348052979, Val Acc: 49.65%\n",
      "Epoch: 419,     Training Loss: 0.9421847462654114, Training Acc: 52.11%\n",
      "              Val Loss: 1.0650800466537476, Val Acc: 49.66%\n",
      "Epoch: 420,     Training Loss: 0.9773196578025818, Training Acc: 52.12%\n",
      "              Val Loss: 1.0138875246047974, Val Acc: 49.67%\n",
      "Epoch: 421,     Training Loss: 0.9453463554382324, Training Acc: 52.13%\n",
      "              Val Loss: 1.0354013442993164, Val Acc: 49.68%\n",
      "Epoch: 422,     Training Loss: 0.9574894905090332, Training Acc: 52.14%\n",
      "              Val Loss: 1.0445799827575684, Val Acc: 49.69%\n",
      "Epoch: 423,     Training Loss: 0.9632521271705627, Training Acc: 52.15%\n",
      "              Val Loss: 0.987067461013794, Val Acc: 49.70%\n",
      "Epoch: 424,     Training Loss: 0.9211923480033875, Training Acc: 52.17%\n",
      "              Val Loss: 1.0197968482971191, Val Acc: 49.71%\n",
      "Epoch: 425,     Training Loss: 0.9426655769348145, Training Acc: 52.18%\n",
      "              Val Loss: 1.0152534246444702, Val Acc: 49.72%\n",
      "Epoch: 426,     Training Loss: 0.9418271780014038, Training Acc: 52.19%\n",
      "              Val Loss: 0.983815610408783, Val Acc: 49.74%\n",
      "Epoch: 427,     Training Loss: 0.9178569316864014, Training Acc: 52.21%\n",
      "              Val Loss: 1.0092949867248535, Val Acc: 49.75%\n",
      "Epoch: 428,     Training Loss: 0.9318957328796387, Training Acc: 52.22%\n",
      "              Val Loss: 1.0395629405975342, Val Acc: 49.76%\n",
      "Epoch: 429,     Training Loss: 0.9570631980895996, Training Acc: 52.23%\n",
      "              Val Loss: 1.0079119205474854, Val Acc: 49.77%\n",
      "Epoch: 430,     Training Loss: 0.9394789934158325, Training Acc: 52.25%\n",
      "              Val Loss: 1.0209428071975708, Val Acc: 49.78%\n",
      "Epoch: 431,     Training Loss: 0.943088173866272, Training Acc: 52.26%\n",
      "              Val Loss: 1.066957950592041, Val Acc: 49.79%\n",
      "Epoch: 432,     Training Loss: 0.9758192300796509, Training Acc: 52.27%\n",
      "              Val Loss: 1.0037269592285156, Val Acc: 49.81%\n",
      "Epoch: 433,     Training Loss: 0.9349689483642578, Training Acc: 52.28%\n",
      "              Val Loss: 1.0289138555526733, Val Acc: 49.82%\n",
      "Epoch: 434,     Training Loss: 0.9503423571586609, Training Acc: 52.29%\n",
      "              Val Loss: 1.028136134147644, Val Acc: 49.83%\n",
      "Epoch: 435,     Training Loss: 0.9494429230690002, Training Acc: 52.30%\n",
      "              Val Loss: 0.9781284928321838, Val Acc: 49.84%\n",
      "Epoch: 436,     Training Loss: 0.9121494293212891, Training Acc: 52.32%\n",
      "              Val Loss: 1.0143908262252808, Val Acc: 49.85%\n",
      "Epoch: 437,     Training Loss: 0.9351792335510254, Training Acc: 52.33%\n",
      "              Val Loss: 1.0121986865997314, Val Acc: 49.86%\n",
      "Epoch: 438,     Training Loss: 0.9373030662536621, Training Acc: 52.34%\n",
      "              Val Loss: 0.9875988960266113, Val Acc: 49.87%\n",
      "Epoch: 439,     Training Loss: 0.9200831651687622, Training Acc: 52.36%\n",
      "              Val Loss: 1.0099507570266724, Val Acc: 49.89%\n",
      "Epoch: 440,     Training Loss: 0.930523693561554, Training Acc: 52.37%\n",
      "              Val Loss: 1.0522085428237915, Val Acc: 49.90%\n",
      "Epoch: 441,     Training Loss: 0.9628562331199646, Training Acc: 52.38%\n",
      "              Val Loss: 1.0152983665466309, Val Acc: 49.91%\n",
      "Epoch: 442,     Training Loss: 0.9450225830078125, Training Acc: 52.39%\n",
      "              Val Loss: 1.0240558385849, Val Acc: 49.92%\n",
      "Epoch: 443,     Training Loss: 0.9451950788497925, Training Acc: 52.40%\n",
      "              Val Loss: 1.0602285861968994, Val Acc: 49.93%\n",
      "Epoch: 444,     Training Loss: 0.9691285490989685, Training Acc: 52.41%\n",
      "              Val Loss: 0.9909449219703674, Val Acc: 49.94%\n",
      "Epoch: 445,     Training Loss: 0.9230052828788757, Training Acc: 52.43%\n",
      "              Val Loss: 1.0199371576309204, Val Acc: 49.95%\n",
      "Epoch: 446,     Training Loss: 0.941142737865448, Training Acc: 52.44%\n",
      "              Val Loss: 1.0122857093811035, Val Acc: 49.96%\n",
      "Epoch: 447,     Training Loss: 0.9366270303726196, Training Acc: 52.45%\n",
      "              Val Loss: 0.971310019493103, Val Acc: 49.97%\n",
      "Epoch: 448,     Training Loss: 0.9052446484565735, Training Acc: 52.47%\n",
      "              Val Loss: 1.008863091468811, Val Acc: 49.98%\n",
      "Epoch: 449,     Training Loss: 0.9276461601257324, Training Acc: 52.48%\n",
      "              Val Loss: 1.0140981674194336, Val Acc: 49.99%\n",
      "Epoch: 450,     Training Loss: 0.9365605711936951, Training Acc: 52.49%\n",
      "              Val Loss: 0.9937823414802551, Val Acc: 50.00%\n",
      "Epoch: 451,     Training Loss: 0.9250221252441406, Training Acc: 52.51%\n",
      "              Val Loss: 1.0126789808273315, Val Acc: 50.02%\n",
      "Epoch: 452,     Training Loss: 0.9310745000839233, Training Acc: 52.52%\n",
      "              Val Loss: 1.0635126829147339, Val Acc: 50.02%\n",
      "Epoch: 453,     Training Loss: 0.9693635702133179, Training Acc: 52.53%\n",
      "              Val Loss: 1.0176551342010498, Val Acc: 50.04%\n",
      "Epoch: 454,     Training Loss: 0.9465787410736084, Training Acc: 52.54%\n",
      "              Val Loss: 1.028186321258545, Val Acc: 50.04%\n",
      "Epoch: 455,     Training Loss: 0.9482038021087646, Training Acc: 52.55%\n",
      "              Val Loss: 1.046675443649292, Val Acc: 50.05%\n",
      "Epoch: 456,     Training Loss: 0.9575889706611633, Training Acc: 52.56%\n",
      "              Val Loss: 0.9780691266059875, Val Acc: 50.06%\n",
      "Epoch: 457,     Training Loss: 0.910859227180481, Training Acc: 52.57%\n",
      "              Val Loss: 1.0099107027053833, Val Acc: 50.07%\n",
      "Epoch: 458,     Training Loss: 0.9307308197021484, Training Acc: 52.59%\n",
      "              Val Loss: 0.9992162585258484, Val Acc: 50.08%\n",
      "Epoch: 459,     Training Loss: 0.9253619313240051, Training Acc: 52.60%\n",
      "              Val Loss: 0.9687710404396057, Val Acc: 50.09%\n",
      "Epoch: 460,     Training Loss: 0.9020835161209106, Training Acc: 52.61%\n",
      "              Val Loss: 1.0021843910217285, Val Acc: 50.11%\n",
      "Epoch: 461,     Training Loss: 0.9199761152267456, Training Acc: 52.63%\n",
      "              Val Loss: 1.0218183994293213, Val Acc: 50.11%\n",
      "Epoch: 462,     Training Loss: 0.9387866854667664, Training Acc: 52.64%\n",
      "              Val Loss: 1.0021954774856567, Val Acc: 50.13%\n",
      "Epoch: 463,     Training Loss: 0.931682825088501, Training Acc: 52.65%\n",
      "              Val Loss: 1.0143444538116455, Val Acc: 50.14%\n",
      "Epoch: 464,     Training Loss: 0.9311556220054626, Training Acc: 52.66%\n",
      "              Val Loss: 1.0737240314483643, Val Acc: 50.15%\n",
      "Epoch: 465,     Training Loss: 0.974333643913269, Training Acc: 52.67%\n",
      "              Val Loss: 1.0144768953323364, Val Acc: 50.16%\n",
      "Epoch: 466,     Training Loss: 0.9424957036972046, Training Acc: 52.68%\n",
      "              Val Loss: 1.0301012992858887, Val Acc: 50.16%\n",
      "Epoch: 467,     Training Loss: 0.9483281970024109, Training Acc: 52.69%\n",
      "              Val Loss: 1.0278966426849365, Val Acc: 50.17%\n",
      "Epoch: 468,     Training Loss: 0.9429471492767334, Training Acc: 52.70%\n",
      "              Val Loss: 0.9679434895515442, Val Acc: 50.18%\n",
      "Epoch: 469,     Training Loss: 0.9011827707290649, Training Acc: 52.72%\n",
      "              Val Loss: 1.0040539503097534, Val Acc: 50.19%\n",
      "Epoch: 470,     Training Loss: 0.9228577613830566, Training Acc: 52.73%\n",
      "              Val Loss: 0.9887722134590149, Val Acc: 50.20%\n",
      "Epoch: 471,     Training Loss: 0.9151464700698853, Training Acc: 52.74%\n",
      "              Val Loss: 0.9684625864028931, Val Acc: 50.22%\n",
      "Epoch: 472,     Training Loss: 0.9012195467948914, Training Acc: 52.76%\n",
      "              Val Loss: 0.9981117844581604, Val Acc: 50.23%\n",
      "Epoch: 473,     Training Loss: 0.9140952229499817, Training Acc: 52.77%\n",
      "              Val Loss: 1.0315682888031006, Val Acc: 50.24%\n",
      "Epoch: 474,     Training Loss: 0.9423272609710693, Training Acc: 52.78%\n",
      "              Val Loss: 1.012696385383606, Val Acc: 50.25%\n",
      "Epoch: 475,     Training Loss: 0.9409171938896179, Training Acc: 52.79%\n",
      "              Val Loss: 1.0173921585083008, Val Acc: 50.26%\n",
      "Epoch: 476,     Training Loss: 0.9328727126121521, Training Acc: 52.80%\n",
      "              Val Loss: 1.0796114206314087, Val Acc: 50.27%\n",
      "Epoch: 477,     Training Loss: 0.9768030047416687, Training Acc: 52.81%\n",
      "              Val Loss: 1.0074107646942139, Val Acc: 50.28%\n",
      "Epoch: 478,     Training Loss: 0.9355152249336243, Training Acc: 52.82%\n",
      "              Val Loss: 1.0304089784622192, Val Acc: 50.29%\n",
      "Epoch: 479,     Training Loss: 0.9459794759750366, Training Acc: 52.83%\n",
      "              Val Loss: 1.012021780014038, Val Acc: 50.30%\n",
      "Epoch: 480,     Training Loss: 0.9296683669090271, Training Acc: 52.84%\n",
      "              Val Loss: 0.9618674516677856, Val Acc: 50.31%\n",
      "Epoch: 481,     Training Loss: 0.8951736688613892, Training Acc: 52.86%\n",
      "              Val Loss: 1.0015007257461548, Val Acc: 50.32%\n",
      "Epoch: 482,     Training Loss: 0.917061448097229, Training Acc: 52.87%\n",
      "              Val Loss: 0.9835383892059326, Val Acc: 50.33%\n",
      "Epoch: 483,     Training Loss: 0.908316433429718, Training Acc: 52.88%\n",
      "              Val Loss: 0.9714742302894592, Val Acc: 50.34%\n",
      "Epoch: 484,     Training Loss: 0.9039259552955627, Training Acc: 52.89%\n",
      "              Val Loss: 0.9952080249786377, Val Acc: 50.35%\n",
      "Epoch: 485,     Training Loss: 0.90997713804245, Training Acc: 52.91%\n",
      "              Val Loss: 1.041749358177185, Val Acc: 50.36%\n",
      "Epoch: 486,     Training Loss: 0.9449977278709412, Training Acc: 52.92%\n",
      "              Val Loss: 1.022377371788025, Val Acc: 50.37%\n",
      "Epoch: 487,     Training Loss: 0.9491742849349976, Training Acc: 52.93%\n",
      "              Val Loss: 1.016909122467041, Val Acc: 50.38%\n",
      "Epoch: 488,     Training Loss: 0.9324941039085388, Training Acc: 52.94%\n",
      "              Val Loss: 1.0820984840393066, Val Acc: 50.39%\n",
      "Epoch: 489,     Training Loss: 0.9754894971847534, Training Acc: 52.94%\n",
      "              Val Loss: 0.9981999397277832, Val Acc: 50.40%\n",
      "Epoch: 490,     Training Loss: 0.9270740747451782, Training Acc: 52.96%\n",
      "              Val Loss: 1.0235339403152466, Val Acc: 50.41%\n",
      "Epoch: 491,     Training Loss: 0.9392489790916443, Training Acc: 52.97%\n",
      "              Val Loss: 1.000596284866333, Val Acc: 50.42%\n",
      "Epoch: 492,     Training Loss: 0.9206133484840393, Training Acc: 52.98%\n",
      "              Val Loss: 0.9567335247993469, Val Acc: 50.43%\n",
      "Epoch: 493,     Training Loss: 0.8922578692436218, Training Acc: 52.99%\n",
      "              Val Loss: 1.0007305145263672, Val Acc: 50.44%\n",
      "Epoch: 494,     Training Loss: 0.9142805337905884, Training Acc: 53.01%\n",
      "              Val Loss: 0.9786050319671631, Val Acc: 50.45%\n",
      "Epoch: 495,     Training Loss: 0.9027366042137146, Training Acc: 53.02%\n",
      "              Val Loss: 0.9720189571380615, Val Acc: 50.46%\n",
      "Epoch: 496,     Training Loss: 0.9051761627197266, Training Acc: 53.03%\n",
      "              Val Loss: 0.9952472448348999, Val Acc: 50.47%\n",
      "Epoch: 497,     Training Loss: 0.9080358743667603, Training Acc: 53.04%\n",
      "              Val Loss: 1.0367282629013062, Val Acc: 50.48%\n",
      "Epoch: 498,     Training Loss: 0.939083456993103, Training Acc: 53.05%\n",
      "              Val Loss: 1.0251291990280151, Val Acc: 50.49%\n",
      "Epoch: 499,     Training Loss: 0.9525949358940125, Training Acc: 53.06%\n",
      "              Val Loss: 1.0091246366500854, Val Acc: 50.50%\n",
      "Epoch: 500,     Training Loss: 0.9261353015899658, Training Acc: 53.07%\n",
      "              Val Loss: 1.0858759880065918, Val Acc: 50.51%\n",
      "Epoch: 501,     Training Loss: 0.9764617085456848, Training Acc: 53.08%\n",
      "              Val Loss: 0.9992959499359131, Val Acc: 50.52%\n",
      "Epoch: 502,     Training Loss: 0.9289571642875671, Training Acc: 53.09%\n",
      "              Val Loss: 1.0180877447128296, Val Acc: 50.53%\n",
      "Epoch: 503,     Training Loss: 0.9356485605239868, Training Acc: 53.10%\n",
      "              Val Loss: 1.0008260011672974, Val Acc: 50.53%\n",
      "Epoch: 504,     Training Loss: 0.9191398620605469, Training Acc: 53.11%\n",
      "              Val Loss: 0.9554855227470398, Val Acc: 50.55%\n",
      "Epoch: 505,     Training Loss: 0.8920850157737732, Training Acc: 53.12%\n",
      "              Val Loss: 0.9967316389083862, Val Acc: 50.56%\n",
      "Epoch: 506,     Training Loss: 0.9104002118110657, Training Acc: 53.14%\n",
      "              Val Loss: 0.9784554243087769, Val Acc: 50.57%\n",
      "Epoch: 507,     Training Loss: 0.8993425965309143, Training Acc: 53.15%\n",
      "              Val Loss: 0.9724537134170532, Val Acc: 50.58%\n",
      "Epoch: 508,     Training Loss: 0.9084083437919617, Training Acc: 53.16%\n",
      "              Val Loss: 0.9930638074874878, Val Acc: 50.59%\n",
      "Epoch: 509,     Training Loss: 0.9052121043205261, Training Acc: 53.17%\n",
      "              Val Loss: 1.0332192182540894, Val Acc: 50.60%\n",
      "Epoch: 510,     Training Loss: 0.9322163462638855, Training Acc: 53.18%\n",
      "              Val Loss: 1.0298675298690796, Val Acc: 50.61%\n",
      "Epoch: 511,     Training Loss: 0.960296630859375, Training Acc: 53.19%\n",
      "              Val Loss: 0.9934589266777039, Val Acc: 50.62%\n",
      "Epoch: 512,     Training Loss: 0.9119958281517029, Training Acc: 53.20%\n",
      "              Val Loss: 1.1165655851364136, Val Acc: 50.62%\n",
      "Epoch: 513,     Training Loss: 0.9948982000350952, Training Acc: 53.21%\n",
      "              Val Loss: 1.0300246477127075, Val Acc: 50.63%\n",
      "Epoch: 514,     Training Loss: 0.9611178636550903, Training Acc: 53.22%\n",
      "              Val Loss: 1.02187180519104, Val Acc: 50.65%\n",
      "Epoch: 515,     Training Loss: 0.9432721138000488, Training Acc: 53.23%\n",
      "              Val Loss: 1.043027400970459, Val Acc: 50.65%\n",
      "Epoch: 516,     Training Loss: 0.9505833983421326, Training Acc: 53.23%\n",
      "              Val Loss: 0.9874112010002136, Val Acc: 50.65%\n",
      "Epoch: 517,     Training Loss: 0.939729630947113, Training Acc: 53.24%\n",
      "              Val Loss: 1.00371253490448, Val Acc: 50.66%\n",
      "Epoch: 518,     Training Loss: 0.9291657209396362, Training Acc: 53.25%\n",
      "              Val Loss: 1.107640266418457, Val Acc: 50.66%\n",
      "Epoch: 519,     Training Loss: 1.0034821033477783, Training Acc: 53.25%\n",
      "              Val Loss: 1.1587040424346924, Val Acc: 50.66%\n",
      "Epoch: 520,     Training Loss: 1.1357383728027344, Training Acc: 53.25%\n",
      "              Val Loss: 1.1698092222213745, Val Acc: 50.66%\n",
      "Epoch: 521,     Training Loss: 1.1245718002319336, Training Acc: 53.25%\n",
      "              Val Loss: 1.1181702613830566, Val Acc: 50.65%\n",
      "Epoch: 522,     Training Loss: 1.0240654945373535, Training Acc: 53.24%\n",
      "              Val Loss: 1.056828498840332, Val Acc: 50.65%\n",
      "Epoch: 523,     Training Loss: 0.9665404558181763, Training Acc: 53.25%\n",
      "              Val Loss: 1.0941574573516846, Val Acc: 50.65%\n",
      "Epoch: 524,     Training Loss: 1.0420039892196655, Training Acc: 53.25%\n",
      "              Val Loss: 1.0314793586730957, Val Acc: 50.66%\n",
      "Epoch: 525,     Training Loss: 0.9834016561508179, Training Acc: 53.25%\n",
      "              Val Loss: 1.1382156610488892, Val Acc: 50.66%\n",
      "Epoch: 526,     Training Loss: 1.0247868299484253, Training Acc: 53.25%\n",
      "              Val Loss: 1.0367375612258911, Val Acc: 50.66%\n",
      "Epoch: 527,     Training Loss: 0.9549918174743652, Training Acc: 53.26%\n",
      "              Val Loss: 1.0600794553756714, Val Acc: 50.67%\n",
      "Epoch: 528,     Training Loss: 1.007218837738037, Training Acc: 53.27%\n",
      "              Val Loss: 1.0067638158798218, Val Acc: 50.68%\n",
      "Epoch: 529,     Training Loss: 0.9467655420303345, Training Acc: 53.27%\n",
      "              Val Loss: 1.0920568704605103, Val Acc: 50.68%\n",
      "Epoch: 530,     Training Loss: 0.9953582882881165, Training Acc: 53.28%\n",
      "              Val Loss: 0.9980666637420654, Val Acc: 50.69%\n",
      "Epoch: 531,     Training Loss: 0.9275599122047424, Training Acc: 53.29%\n",
      "              Val Loss: 0.9991337060928345, Val Acc: 50.70%\n",
      "Epoch: 532,     Training Loss: 0.9407914876937866, Training Acc: 53.30%\n",
      "              Val Loss: 0.9943291544914246, Val Acc: 50.71%\n",
      "Epoch: 533,     Training Loss: 0.9189023375511169, Training Acc: 53.30%\n",
      "              Val Loss: 0.976064920425415, Val Acc: 50.71%\n",
      "Epoch: 534,     Training Loss: 0.9024016857147217, Training Acc: 53.32%\n",
      "              Val Loss: 0.9625991582870483, Val Acc: 50.72%\n",
      "Epoch: 535,     Training Loss: 0.901847779750824, Training Acc: 53.33%\n",
      "              Val Loss: 0.9561394453048706, Val Acc: 50.74%\n",
      "Epoch: 536,     Training Loss: 0.8939667344093323, Training Acc: 53.34%\n",
      "              Val Loss: 0.9549242258071899, Val Acc: 50.75%\n",
      "Epoch: 537,     Training Loss: 0.8838747143745422, Training Acc: 53.35%\n",
      "              Val Loss: 0.954954206943512, Val Acc: 50.75%\n",
      "Epoch: 538,     Training Loss: 0.8894512057304382, Training Acc: 53.36%\n",
      "              Val Loss: 0.9358431100845337, Val Acc: 50.77%\n",
      "Epoch: 539,     Training Loss: 0.876086413860321, Training Acc: 53.37%\n",
      "              Val Loss: 0.9647844433784485, Val Acc: 50.78%\n",
      "Epoch: 540,     Training Loss: 0.887800931930542, Training Acc: 53.39%\n",
      "              Val Loss: 0.9759804606437683, Val Acc: 50.78%\n",
      "Epoch: 541,     Training Loss: 0.9032595157623291, Training Acc: 53.40%\n",
      "              Val Loss: 0.9472601413726807, Val Acc: 50.80%\n",
      "Epoch: 542,     Training Loss: 0.881557285785675, Training Acc: 53.41%\n",
      "              Val Loss: 1.0135704278945923, Val Acc: 50.81%\n",
      "Epoch: 543,     Training Loss: 0.9265498518943787, Training Acc: 53.42%\n",
      "              Val Loss: 1.0225306749343872, Val Acc: 50.82%\n",
      "Epoch: 544,     Training Loss: 0.9301564693450928, Training Acc: 53.43%\n",
      "              Val Loss: 1.0595989227294922, Val Acc: 50.82%\n",
      "Epoch: 545,     Training Loss: 0.9806646704673767, Training Acc: 53.44%\n",
      "              Val Loss: 1.0089644193649292, Val Acc: 50.84%\n",
      "Epoch: 546,     Training Loss: 0.9303465485572815, Training Acc: 53.45%\n",
      "              Val Loss: 1.0730854272842407, Val Acc: 50.84%\n",
      "Epoch: 547,     Training Loss: 0.9684099555015564, Training Acc: 53.45%\n",
      "              Val Loss: 0.9759215712547302, Val Acc: 50.85%\n",
      "Epoch: 548,     Training Loss: 0.9026108384132385, Training Acc: 53.46%\n",
      "              Val Loss: 0.993804931640625, Val Acc: 50.86%\n",
      "Epoch: 549,     Training Loss: 0.9150385856628418, Training Acc: 53.48%\n",
      "              Val Loss: 0.9723917245864868, Val Acc: 50.87%\n",
      "Epoch: 550,     Training Loss: 0.8929086327552795, Training Acc: 53.48%\n",
      "              Val Loss: 0.9324564337730408, Val Acc: 50.88%\n",
      "Epoch: 551,     Training Loss: 0.8643600344657898, Training Acc: 53.50%\n",
      "              Val Loss: 0.9514217972755432, Val Acc: 50.89%\n",
      "Epoch: 552,     Training Loss: 0.8765681385993958, Training Acc: 53.51%\n",
      "              Val Loss: 0.9433683156967163, Val Acc: 50.90%\n",
      "Epoch: 553,     Training Loss: 0.8686750531196594, Training Acc: 53.53%\n",
      "              Val Loss: 0.9300337433815002, Val Acc: 50.92%\n",
      "Epoch: 554,     Training Loss: 0.8617777228355408, Training Acc: 53.54%\n",
      "              Val Loss: 0.9372247457504272, Val Acc: 50.93%\n",
      "Epoch: 555,     Training Loss: 0.8641806840896606, Training Acc: 53.56%\n",
      "              Val Loss: 0.9504820108413696, Val Acc: 50.94%\n",
      "Epoch: 556,     Training Loss: 0.8746070861816406, Training Acc: 53.57%\n",
      "              Val Loss: 0.9359805583953857, Val Acc: 50.95%\n",
      "Epoch: 557,     Training Loss: 0.8651649355888367, Training Acc: 53.58%\n",
      "              Val Loss: 0.9391634464263916, Val Acc: 50.96%\n",
      "Epoch: 558,     Training Loss: 0.8647090792655945, Training Acc: 53.60%\n",
      "              Val Loss: 0.9480767846107483, Val Acc: 50.97%\n",
      "Epoch: 559,     Training Loss: 0.8717538714408875, Training Acc: 53.61%\n",
      "              Val Loss: 0.9640026688575745, Val Acc: 50.98%\n",
      "Epoch: 560,     Training Loss: 0.889376163482666, Training Acc: 53.62%\n",
      "              Val Loss: 0.9438121914863586, Val Acc: 50.99%\n",
      "Epoch: 561,     Training Loss: 0.8665671348571777, Training Acc: 53.64%\n",
      "              Val Loss: 1.0151313543319702, Val Acc: 51.00%\n",
      "Epoch: 562,     Training Loss: 0.920674204826355, Training Acc: 53.64%\n",
      "              Val Loss: 1.0159724950790405, Val Acc: 51.01%\n",
      "Epoch: 563,     Training Loss: 0.9375255107879639, Training Acc: 53.65%\n",
      "              Val Loss: 0.9968923926353455, Val Acc: 51.01%\n",
      "Epoch: 564,     Training Loss: 0.9127479791641235, Training Acc: 53.67%\n",
      "              Val Loss: 1.0650869607925415, Val Acc: 51.02%\n",
      "Epoch: 565,     Training Loss: 0.9676527976989746, Training Acc: 53.67%\n",
      "              Val Loss: 0.9735499024391174, Val Acc: 51.03%\n",
      "Epoch: 566,     Training Loss: 0.8971462249755859, Training Acc: 53.68%\n",
      "              Val Loss: 1.0402030944824219, Val Acc: 51.04%\n",
      "Epoch: 567,     Training Loss: 0.9420670866966248, Training Acc: 53.69%\n",
      "              Val Loss: 0.973121702671051, Val Acc: 51.05%\n",
      "Epoch: 568,     Training Loss: 0.8944708108901978, Training Acc: 53.70%\n",
      "              Val Loss: 0.9552353024482727, Val Acc: 51.06%\n",
      "Epoch: 569,     Training Loss: 0.8820271492004395, Training Acc: 53.71%\n",
      "              Val Loss: 1.0137076377868652, Val Acc: 51.07%\n",
      "Epoch: 570,     Training Loss: 0.9156323075294495, Training Acc: 53.72%\n",
      "              Val Loss: 0.9523547887802124, Val Acc: 51.07%\n",
      "Epoch: 571,     Training Loss: 0.8746923804283142, Training Acc: 53.74%\n",
      "              Val Loss: 0.9641151428222656, Val Acc: 51.09%\n",
      "Epoch: 572,     Training Loss: 0.889636754989624, Training Acc: 53.75%\n",
      "              Val Loss: 0.9722205400466919, Val Acc: 51.10%\n",
      "Epoch: 573,     Training Loss: 0.8826855421066284, Training Acc: 53.76%\n",
      "              Val Loss: 0.998246431350708, Val Acc: 51.10%\n",
      "Epoch: 574,     Training Loss: 0.9045354723930359, Training Acc: 53.77%\n",
      "              Val Loss: 1.0063992738723755, Val Acc: 51.12%\n",
      "Epoch: 575,     Training Loss: 0.9276812672615051, Training Acc: 53.78%\n",
      "              Val Loss: 0.9771496057510376, Val Acc: 51.12%\n",
      "Epoch: 576,     Training Loss: 0.8919829726219177, Training Acc: 53.79%\n",
      "              Val Loss: 1.0768753290176392, Val Acc: 51.13%\n",
      "Epoch: 577,     Training Loss: 0.9639490246772766, Training Acc: 53.80%\n",
      "              Val Loss: 0.9916123151779175, Val Acc: 51.14%\n",
      "Epoch: 578,     Training Loss: 0.9127902388572693, Training Acc: 53.81%\n",
      "              Val Loss: 1.0137505531311035, Val Acc: 51.15%\n",
      "Epoch: 579,     Training Loss: 0.9219785332679749, Training Acc: 53.82%\n",
      "              Val Loss: 1.0015989542007446, Val Acc: 51.15%\n",
      "Epoch: 580,     Training Loss: 0.912973940372467, Training Acc: 53.83%\n",
      "              Val Loss: 0.9478800296783447, Val Acc: 51.16%\n",
      "Epoch: 581,     Training Loss: 0.8765918016433716, Training Acc: 53.84%\n",
      "              Val Loss: 1.0083757638931274, Val Acc: 51.18%\n",
      "Epoch: 582,     Training Loss: 0.9085944890975952, Training Acc: 53.85%\n",
      "              Val Loss: 0.9738502502441406, Val Acc: 51.18%\n",
      "Epoch: 583,     Training Loss: 0.8880305290222168, Training Acc: 53.86%\n",
      "              Val Loss: 0.9757851362228394, Val Acc: 51.19%\n",
      "Epoch: 584,     Training Loss: 0.9029289484024048, Training Acc: 53.87%\n",
      "              Val Loss: 0.9925335645675659, Val Acc: 51.21%\n",
      "Epoch: 585,     Training Loss: 0.8959677219390869, Training Acc: 53.88%\n",
      "              Val Loss: 1.0276738405227661, Val Acc: 51.21%\n",
      "Epoch: 586,     Training Loss: 0.9196631908416748, Training Acc: 53.89%\n",
      "              Val Loss: 1.0235768556594849, Val Acc: 51.22%\n",
      "Epoch: 587,     Training Loss: 0.9461844563484192, Training Acc: 53.90%\n",
      "              Val Loss: 0.9764783382415771, Val Acc: 51.23%\n",
      "Epoch: 588,     Training Loss: 0.8924661874771118, Training Acc: 53.91%\n",
      "              Val Loss: 1.092026948928833, Val Acc: 51.24%\n",
      "Epoch: 589,     Training Loss: 0.9707080721855164, Training Acc: 53.92%\n",
      "              Val Loss: 0.9965793490409851, Val Acc: 51.25%\n",
      "Epoch: 590,     Training Loss: 0.9220995903015137, Training Acc: 53.93%\n",
      "              Val Loss: 0.9976477026939392, Val Acc: 51.26%\n",
      "Epoch: 591,     Training Loss: 0.9137777090072632, Training Acc: 53.94%\n",
      "              Val Loss: 1.0175706148147583, Val Acc: 51.26%\n",
      "Epoch: 592,     Training Loss: 0.9244296550750732, Training Acc: 53.94%\n",
      "              Val Loss: 0.9574780464172363, Val Acc: 51.27%\n",
      "Epoch: 593,     Training Loss: 0.8930359482765198, Training Acc: 53.95%\n",
      "              Val Loss: 0.9922347068786621, Val Acc: 51.28%\n",
      "Epoch: 594,     Training Loss: 0.9018327593803406, Training Acc: 53.96%\n",
      "              Val Loss: 1.0152596235275269, Val Acc: 51.28%\n",
      "Epoch: 595,     Training Loss: 0.9189436435699463, Training Acc: 53.97%\n",
      "              Val Loss: 1.001296877861023, Val Acc: 51.28%\n",
      "Epoch: 596,     Training Loss: 0.9444438219070435, Training Acc: 53.97%\n",
      "              Val Loss: 1.0066429376602173, Val Acc: 51.29%\n",
      "Epoch: 597,     Training Loss: 0.9201734662055969, Training Acc: 53.98%\n",
      "              Val Loss: 1.0897046327590942, Val Acc: 51.29%\n",
      "Epoch: 598,     Training Loss: 0.9815804362297058, Training Acc: 53.98%\n",
      "              Val Loss: 1.079153299331665, Val Acc: 51.29%\n",
      "Epoch: 599,     Training Loss: 1.0225303173065186, Training Acc: 53.98%\n",
      "              Val Loss: 1.010216236114502, Val Acc: 51.30%\n",
      "Epoch: 600,     Training Loss: 0.9452875256538391, Training Acc: 53.99%\n",
      "              Val Loss: 1.1618316173553467, Val Acc: 51.30%\n",
      "Epoch: 601,     Training Loss: 1.0308945178985596, Training Acc: 53.99%\n",
      "              Val Loss: 1.0266578197479248, Val Acc: 51.30%\n",
      "Epoch: 602,     Training Loss: 0.9475797414779663, Training Acc: 53.99%\n",
      "              Val Loss: 1.02639639377594, Val Acc: 51.31%\n",
      "Epoch: 603,     Training Loss: 0.9579214453697205, Training Acc: 54.00%\n",
      "              Val Loss: 1.0559139251708984, Val Acc: 51.32%\n",
      "Epoch: 604,     Training Loss: 0.9481320977210999, Training Acc: 54.01%\n",
      "              Val Loss: 0.9937141537666321, Val Acc: 51.32%\n",
      "Epoch: 605,     Training Loss: 0.9003897905349731, Training Acc: 54.02%\n",
      "              Val Loss: 1.03178071975708, Val Acc: 51.32%\n",
      "Epoch: 606,     Training Loss: 0.959547221660614, Training Acc: 54.02%\n",
      "              Val Loss: 0.9403392672538757, Val Acc: 51.33%\n",
      "Epoch: 607,     Training Loss: 0.8690016269683838, Training Acc: 54.03%\n",
      "              Val Loss: 1.0417405366897583, Val Acc: 51.33%\n",
      "Epoch: 608,     Training Loss: 0.931571900844574, Training Acc: 54.04%\n",
      "              Val Loss: 0.9498866200447083, Val Acc: 51.35%\n",
      "Epoch: 609,     Training Loss: 0.879941463470459, Training Acc: 54.05%\n",
      "              Val Loss: 0.9376966953277588, Val Acc: 51.36%\n",
      "Epoch: 610,     Training Loss: 0.8671450018882751, Training Acc: 54.06%\n",
      "              Val Loss: 1.016456961631775, Val Acc: 51.36%\n",
      "Epoch: 611,     Training Loss: 0.9122791290283203, Training Acc: 54.07%\n",
      "              Val Loss: 0.9285923838615417, Val Acc: 51.38%\n",
      "Epoch: 612,     Training Loss: 0.8602084517478943, Training Acc: 54.08%\n",
      "              Val Loss: 0.9627754092216492, Val Acc: 51.39%\n",
      "Epoch: 613,     Training Loss: 0.8915727138519287, Training Acc: 54.09%\n",
      "              Val Loss: 0.9828950762748718, Val Acc: 51.39%\n",
      "Epoch: 614,     Training Loss: 0.8888636827468872, Training Acc: 54.10%\n",
      "              Val Loss: 0.9617944955825806, Val Acc: 51.40%\n",
      "Epoch: 615,     Training Loss: 0.8779282569885254, Training Acc: 54.11%\n",
      "              Val Loss: 0.9720112681388855, Val Acc: 51.41%\n",
      "Epoch: 616,     Training Loss: 0.9003958106040955, Training Acc: 54.12%\n",
      "              Val Loss: 0.9597984552383423, Val Acc: 51.41%\n",
      "Epoch: 617,     Training Loss: 0.8738149404525757, Training Acc: 54.13%\n",
      "              Val Loss: 1.0059442520141602, Val Acc: 51.42%\n",
      "Epoch: 618,     Training Loss: 0.9071111083030701, Training Acc: 54.14%\n",
      "              Val Loss: 0.9771281480789185, Val Acc: 51.43%\n",
      "Epoch: 619,     Training Loss: 0.8987197279930115, Training Acc: 54.15%\n",
      "              Val Loss: 0.9952664375305176, Val Acc: 51.44%\n",
      "Epoch: 620,     Training Loss: 0.9078648090362549, Training Acc: 54.16%\n",
      "              Val Loss: 0.9883998036384583, Val Acc: 51.44%\n",
      "Epoch: 621,     Training Loss: 0.8890865445137024, Training Acc: 54.17%\n",
      "              Val Loss: 1.0409789085388184, Val Acc: 51.45%\n",
      "Epoch: 622,     Training Loss: 0.9362571835517883, Training Acc: 54.17%\n",
      "              Val Loss: 0.9919847846031189, Val Acc: 51.46%\n",
      "Epoch: 623,     Training Loss: 0.9091829657554626, Training Acc: 54.18%\n",
      "              Val Loss: 1.0139878988265991, Val Acc: 51.46%\n",
      "Epoch: 624,     Training Loss: 0.9147770404815674, Training Acc: 54.19%\n",
      "              Val Loss: 0.9851734042167664, Val Acc: 51.47%\n",
      "Epoch: 625,     Training Loss: 0.8969873785972595, Training Acc: 54.20%\n",
      "              Val Loss: 0.9371541738510132, Val Acc: 51.48%\n",
      "Epoch: 626,     Training Loss: 0.8599558472633362, Training Acc: 54.21%\n",
      "              Val Loss: 0.9674657583236694, Val Acc: 51.49%\n",
      "Epoch: 627,     Training Loss: 0.8727662563323975, Training Acc: 54.22%\n",
      "              Val Loss: 0.9350811243057251, Val Acc: 51.49%\n",
      "Epoch: 628,     Training Loss: 0.8569688200950623, Training Acc: 54.23%\n",
      "              Val Loss: 0.9418466687202454, Val Acc: 51.51%\n",
      "Epoch: 629,     Training Loss: 0.8615034222602844, Training Acc: 54.24%\n",
      "              Val Loss: 0.9575124382972717, Val Acc: 51.51%\n",
      "Epoch: 630,     Training Loss: 0.8670461177825928, Training Acc: 54.25%\n",
      "              Val Loss: 0.9246987104415894, Val Acc: 51.52%\n",
      "Epoch: 631,     Training Loss: 0.8469376564025879, Training Acc: 54.27%\n",
      "              Val Loss: 0.9772711396217346, Val Acc: 51.53%\n",
      "Epoch: 632,     Training Loss: 0.8862217664718628, Training Acc: 54.28%\n",
      "              Val Loss: 0.956125795841217, Val Acc: 51.54%\n",
      "Epoch: 633,     Training Loss: 0.8674842715263367, Training Acc: 54.29%\n",
      "              Val Loss: 0.9376201033592224, Val Acc: 51.55%\n",
      "Epoch: 634,     Training Loss: 0.8560678362846375, Training Acc: 54.30%\n",
      "              Val Loss: 0.9977119565010071, Val Acc: 51.56%\n",
      "Epoch: 635,     Training Loss: 0.9031116962432861, Training Acc: 54.31%\n",
      "              Val Loss: 0.9393607378005981, Val Acc: 51.56%\n",
      "Epoch: 636,     Training Loss: 0.8528377413749695, Training Acc: 54.32%\n",
      "              Val Loss: 0.9632770419120789, Val Acc: 51.57%\n",
      "Epoch: 637,     Training Loss: 0.8796159625053406, Training Acc: 54.33%\n",
      "              Val Loss: 0.9940159320831299, Val Acc: 51.58%\n",
      "Epoch: 638,     Training Loss: 0.9049426913261414, Training Acc: 54.33%\n",
      "              Val Loss: 0.958644688129425, Val Acc: 51.59%\n",
      "Epoch: 639,     Training Loss: 0.8671761155128479, Training Acc: 54.35%\n",
      "              Val Loss: 1.0332396030426025, Val Acc: 51.59%\n",
      "Epoch: 640,     Training Loss: 0.9282900094985962, Training Acc: 54.35%\n",
      "              Val Loss: 1.0053287744522095, Val Acc: 51.60%\n",
      "Epoch: 641,     Training Loss: 0.9118452668190002, Training Acc: 54.36%\n",
      "              Val Loss: 1.0101853609085083, Val Acc: 51.60%\n",
      "Epoch: 642,     Training Loss: 0.914269208908081, Training Acc: 54.37%\n",
      "              Val Loss: 0.9707578420639038, Val Acc: 51.61%\n",
      "Epoch: 643,     Training Loss: 0.8824125528335571, Training Acc: 54.38%\n",
      "              Val Loss: 0.9825195074081421, Val Acc: 51.62%\n",
      "Epoch: 644,     Training Loss: 0.883510947227478, Training Acc: 54.39%\n",
      "              Val Loss: 0.9574581384658813, Val Acc: 51.63%\n",
      "Epoch: 645,     Training Loss: 0.8671809434890747, Training Acc: 54.40%\n",
      "              Val Loss: 0.9382683634757996, Val Acc: 51.64%\n",
      "Epoch: 646,     Training Loss: 0.8544004559516907, Training Acc: 54.41%\n",
      "              Val Loss: 0.9761276841163635, Val Acc: 51.65%\n",
      "Epoch: 647,     Training Loss: 0.881202220916748, Training Acc: 54.42%\n",
      "              Val Loss: 0.9295030236244202, Val Acc: 51.66%\n",
      "Epoch: 648,     Training Loss: 0.8445875644683838, Training Acc: 54.43%\n",
      "              Val Loss: 0.9344157576560974, Val Acc: 51.66%\n",
      "Epoch: 649,     Training Loss: 0.8510918617248535, Training Acc: 54.44%\n",
      "              Val Loss: 0.9618312120437622, Val Acc: 51.67%\n",
      "Epoch: 650,     Training Loss: 0.8760689496994019, Training Acc: 54.45%\n",
      "              Val Loss: 0.9239956140518188, Val Acc: 51.68%\n",
      "Epoch: 651,     Training Loss: 0.8384073376655579, Training Acc: 54.47%\n",
      "              Val Loss: 0.9599149823188782, Val Acc: 51.69%\n",
      "Epoch: 652,     Training Loss: 0.8685809373855591, Training Acc: 54.48%\n",
      "              Val Loss: 0.985349178314209, Val Acc: 51.70%\n",
      "Epoch: 653,     Training Loss: 0.8973199725151062, Training Acc: 54.49%\n",
      "              Val Loss: 0.9515337347984314, Val Acc: 51.71%\n",
      "Epoch: 654,     Training Loss: 0.8613970875740051, Training Acc: 54.50%\n",
      "              Val Loss: 1.0382237434387207, Val Acc: 51.71%\n",
      "Epoch: 655,     Training Loss: 0.9214928150177002, Training Acc: 54.50%\n",
      "              Val Loss: 1.016923189163208, Val Acc: 51.72%\n",
      "Epoch: 656,     Training Loss: 0.9190693497657776, Training Acc: 54.51%\n",
      "              Val Loss: 1.0005801916122437, Val Acc: 51.73%\n",
      "Epoch: 657,     Training Loss: 0.9088143706321716, Training Acc: 54.52%\n",
      "              Val Loss: 0.9831509590148926, Val Acc: 51.73%\n",
      "Epoch: 658,     Training Loss: 0.8880969285964966, Training Acc: 54.53%\n",
      "              Val Loss: 0.9844479560852051, Val Acc: 51.75%\n",
      "Epoch: 659,     Training Loss: 0.8871030211448669, Training Acc: 54.54%\n",
      "              Val Loss: 0.9423137903213501, Val Acc: 51.75%\n",
      "Epoch: 660,     Training Loss: 0.8542032837867737, Training Acc: 54.55%\n",
      "              Val Loss: 0.9595628380775452, Val Acc: 51.76%\n",
      "Epoch: 661,     Training Loss: 0.8664370775222778, Training Acc: 54.56%\n",
      "              Val Loss: 0.9702630639076233, Val Acc: 51.77%\n",
      "Epoch: 662,     Training Loss: 0.887870192527771, Training Acc: 54.57%\n",
      "              Val Loss: 0.9177554845809937, Val Acc: 51.78%\n",
      "Epoch: 663,     Training Loss: 0.8329818844795227, Training Acc: 54.58%\n",
      "              Val Loss: 0.9872675538063049, Val Acc: 51.78%\n",
      "Epoch: 664,     Training Loss: 0.8855966925621033, Training Acc: 54.59%\n",
      "              Val Loss: 1.0101351737976074, Val Acc: 51.79%\n",
      "Epoch: 665,     Training Loss: 0.9406111836433411, Training Acc: 54.59%\n",
      "              Val Loss: 0.9160304069519043, Val Acc: 51.80%\n",
      "Epoch: 666,     Training Loss: 0.8372509479522705, Training Acc: 54.61%\n",
      "              Val Loss: 1.1513104438781738, Val Acc: 51.79%\n",
      "Epoch: 667,     Training Loss: 1.0186553001403809, Training Acc: 54.60%\n",
      "              Val Loss: 1.1780591011047363, Val Acc: 51.79%\n",
      "Epoch: 668,     Training Loss: 1.1329255104064941, Training Acc: 54.60%\n",
      "              Val Loss: 1.1054308414459229, Val Acc: 51.80%\n",
      "Epoch: 669,     Training Loss: 1.0381193161010742, Training Acc: 54.60%\n",
      "              Val Loss: 1.2839961051940918, Val Acc: 51.78%\n",
      "Epoch: 670,     Training Loss: 1.1454280614852905, Training Acc: 54.59%\n",
      "              Val Loss: 1.0184922218322754, Val Acc: 51.79%\n",
      "Epoch: 671,     Training Loss: 0.9463222026824951, Training Acc: 54.60%\n",
      "              Val Loss: 1.0854547023773193, Val Acc: 51.79%\n",
      "Epoch: 672,     Training Loss: 1.009588360786438, Training Acc: 54.60%\n",
      "              Val Loss: 0.9825658202171326, Val Acc: 51.80%\n",
      "Epoch: 673,     Training Loss: 0.89195716381073, Training Acc: 54.61%\n",
      "              Val Loss: 1.019504189491272, Val Acc: 51.80%\n",
      "Epoch: 674,     Training Loss: 0.9230436682701111, Training Acc: 54.61%\n",
      "              Val Loss: 0.9851415753364563, Val Acc: 51.81%\n",
      "Epoch: 675,     Training Loss: 0.9157576560974121, Training Acc: 54.62%\n",
      "              Val Loss: 0.992764413356781, Val Acc: 51.82%\n",
      "Epoch: 676,     Training Loss: 0.9112538695335388, Training Acc: 54.63%\n",
      "              Val Loss: 1.089289903640747, Val Acc: 51.82%\n",
      "Epoch: 677,     Training Loss: 0.961408257484436, Training Acc: 54.63%\n",
      "              Val Loss: 1.077852487564087, Val Acc: 51.82%\n",
      "Epoch: 678,     Training Loss: 0.9758121371269226, Training Acc: 54.64%\n",
      "              Val Loss: 1.0574259757995605, Val Acc: 51.83%\n",
      "Epoch: 679,     Training Loss: 0.9701300859451294, Training Acc: 54.64%\n",
      "              Val Loss: 0.9872478246688843, Val Acc: 51.83%\n",
      "Epoch: 680,     Training Loss: 0.9092521071434021, Training Acc: 54.65%\n",
      "              Val Loss: 0.9487113356590271, Val Acc: 51.84%\n",
      "Epoch: 681,     Training Loss: 0.8612439036369324, Training Acc: 54.65%\n",
      "              Val Loss: 0.9677734971046448, Val Acc: 51.85%\n",
      "Epoch: 682,     Training Loss: 0.8795116543769836, Training Acc: 54.66%\n",
      "              Val Loss: 0.9226055145263672, Val Acc: 51.86%\n",
      "Epoch: 683,     Training Loss: 0.8444510102272034, Training Acc: 54.68%\n",
      "              Val Loss: 1.0420191287994385, Val Acc: 51.86%\n",
      "Epoch: 684,     Training Loss: 0.9269118309020996, Training Acc: 54.68%\n",
      "              Val Loss: 1.005693793296814, Val Acc: 51.87%\n",
      "Epoch: 685,     Training Loss: 0.9158769845962524, Training Acc: 54.69%\n",
      "              Val Loss: 1.000458836555481, Val Acc: 51.88%\n",
      "Epoch: 686,     Training Loss: 0.917258083820343, Training Acc: 54.70%\n",
      "              Val Loss: 0.9902800917625427, Val Acc: 51.88%\n",
      "Epoch: 687,     Training Loss: 0.8931611776351929, Training Acc: 54.70%\n",
      "              Val Loss: 0.9603307247161865, Val Acc: 51.89%\n",
      "Epoch: 688,     Training Loss: 0.8602403402328491, Training Acc: 54.71%\n",
      "              Val Loss: 0.9613450765609741, Val Acc: 51.90%\n",
      "Epoch: 689,     Training Loss: 0.8777955770492554, Training Acc: 54.72%\n",
      "              Val Loss: 0.9187648892402649, Val Acc: 51.91%\n",
      "Epoch: 690,     Training Loss: 0.8322469592094421, Training Acc: 54.74%\n",
      "              Val Loss: 0.970507025718689, Val Acc: 51.92%\n",
      "Epoch: 691,     Training Loss: 0.8657551407814026, Training Acc: 54.75%\n",
      "              Val Loss: 0.9149704575538635, Val Acc: 51.93%\n",
      "Epoch: 692,     Training Loss: 0.8346443772315979, Training Acc: 54.76%\n",
      "              Val Loss: 0.9511955380439758, Val Acc: 51.94%\n",
      "Epoch: 693,     Training Loss: 0.8586677312850952, Training Acc: 54.77%\n",
      "              Val Loss: 0.9268583655357361, Val Acc: 51.95%\n",
      "Epoch: 694,     Training Loss: 0.835827112197876, Training Acc: 54.78%\n",
      "              Val Loss: 0.9231709837913513, Val Acc: 51.96%\n",
      "Epoch: 695,     Training Loss: 0.8404112458229065, Training Acc: 54.79%\n",
      "              Val Loss: 0.936940610408783, Val Acc: 51.96%\n",
      "Epoch: 696,     Training Loss: 0.846701979637146, Training Acc: 54.81%\n",
      "              Val Loss: 0.9155756235122681, Val Acc: 51.97%\n",
      "Epoch: 697,     Training Loss: 0.8264462947845459, Training Acc: 54.82%\n",
      "              Val Loss: 0.9324079155921936, Val Acc: 51.98%\n",
      "Epoch: 698,     Training Loss: 0.8457157015800476, Training Acc: 54.83%\n",
      "              Val Loss: 0.9195805191993713, Val Acc: 51.99%\n",
      "Epoch: 699,     Training Loss: 0.8317918181419373, Training Acc: 54.84%\n",
      "              Val Loss: 0.9477383494377136, Val Acc: 52.00%\n",
      "Epoch: 700,     Training Loss: 0.8534835577011108, Training Acc: 54.85%\n",
      "              Val Loss: 0.9173869490623474, Val Acc: 52.01%\n",
      "Epoch: 701,     Training Loss: 0.8348179459571838, Training Acc: 54.86%\n",
      "              Val Loss: 0.990549623966217, Val Acc: 52.02%\n",
      "Epoch: 702,     Training Loss: 0.8857778906822205, Training Acc: 54.87%\n",
      "              Val Loss: 0.9489037990570068, Val Acc: 52.02%\n",
      "Epoch: 703,     Training Loss: 0.8558054566383362, Training Acc: 54.88%\n",
      "              Val Loss: 0.9522462487220764, Val Acc: 52.03%\n",
      "Epoch: 704,     Training Loss: 0.8615351319313049, Training Acc: 54.89%\n",
      "              Val Loss: 0.9881240725517273, Val Acc: 52.04%\n",
      "Epoch: 705,     Training Loss: 0.8905547261238098, Training Acc: 54.90%\n",
      "              Val Loss: 0.9184709191322327, Val Acc: 52.05%\n",
      "Epoch: 706,     Training Loss: 0.8273898363113403, Training Acc: 54.91%\n",
      "              Val Loss: 1.0284125804901123, Val Acc: 52.05%\n",
      "Epoch: 707,     Training Loss: 0.9122085571289062, Training Acc: 54.92%\n",
      "              Val Loss: 0.9701237678527832, Val Acc: 52.06%\n",
      "Epoch: 708,     Training Loss: 0.8801205158233643, Training Acc: 54.93%\n",
      "              Val Loss: 0.9710226655006409, Val Acc: 52.07%\n",
      "Epoch: 709,     Training Loss: 0.872854471206665, Training Acc: 54.94%\n",
      "              Val Loss: 1.0019173622131348, Val Acc: 52.08%\n",
      "Epoch: 710,     Training Loss: 0.9014483690261841, Training Acc: 54.94%\n",
      "              Val Loss: 0.9303992986679077, Val Acc: 52.08%\n",
      "Epoch: 711,     Training Loss: 0.8428164720535278, Training Acc: 54.96%\n",
      "              Val Loss: 1.0080287456512451, Val Acc: 52.09%\n",
      "Epoch: 712,     Training Loss: 0.8944585919380188, Training Acc: 54.97%\n",
      "              Val Loss: 0.9271262884140015, Val Acc: 52.10%\n",
      "Epoch: 713,     Training Loss: 0.8404572010040283, Training Acc: 54.98%\n",
      "              Val Loss: 0.932386577129364, Val Acc: 52.11%\n",
      "Epoch: 714,     Training Loss: 0.8411041498184204, Training Acc: 54.99%\n",
      "              Val Loss: 0.955157458782196, Val Acc: 52.12%\n",
      "Epoch: 715,     Training Loss: 0.8472617268562317, Training Acc: 55.00%\n",
      "              Val Loss: 0.9296882748603821, Val Acc: 52.13%\n",
      "Epoch: 716,     Training Loss: 0.8373000621795654, Training Acc: 55.01%\n",
      "              Val Loss: 0.9339101910591125, Val Acc: 52.14%\n",
      "Epoch: 717,     Training Loss: 0.840239405632019, Training Acc: 55.02%\n",
      "              Val Loss: 0.9160311818122864, Val Acc: 52.15%\n",
      "Epoch: 718,     Training Loss: 0.8222730755805969, Training Acc: 55.03%\n",
      "              Val Loss: 0.9718747138977051, Val Acc: 52.16%\n",
      "Epoch: 719,     Training Loss: 0.8660439848899841, Training Acc: 55.04%\n",
      "              Val Loss: 0.9567999243736267, Val Acc: 52.17%\n",
      "Epoch: 720,     Training Loss: 0.8601693511009216, Training Acc: 55.05%\n",
      "              Val Loss: 0.9340225458145142, Val Acc: 52.18%\n",
      "Epoch: 721,     Training Loss: 0.8392160534858704, Training Acc: 55.07%\n",
      "              Val Loss: 1.0180370807647705, Val Acc: 52.18%\n",
      "Epoch: 722,     Training Loss: 0.9007360339164734, Training Acc: 55.07%\n",
      "              Val Loss: 0.9470229148864746, Val Acc: 52.19%\n",
      "Epoch: 723,     Training Loss: 0.8505002856254578, Training Acc: 55.08%\n",
      "              Val Loss: 0.9501349925994873, Val Acc: 52.20%\n",
      "Epoch: 724,     Training Loss: 0.8514701724052429, Training Acc: 55.09%\n",
      "              Val Loss: 0.9662258625030518, Val Acc: 52.21%\n",
      "Epoch: 725,     Training Loss: 0.862989604473114, Training Acc: 55.10%\n",
      "              Val Loss: 0.9311335682868958, Val Acc: 52.22%\n",
      "Epoch: 726,     Training Loss: 0.8353972434997559, Training Acc: 55.11%\n",
      "              Val Loss: 0.9358024001121521, Val Acc: 52.22%\n",
      "Epoch: 727,     Training Loss: 0.8382704257965088, Training Acc: 55.13%\n",
      "              Val Loss: 0.9410563111305237, Val Acc: 52.23%\n",
      "Epoch: 728,     Training Loss: 0.84140944480896, Training Acc: 55.14%\n",
      "              Val Loss: 0.9636107087135315, Val Acc: 52.24%\n",
      "Epoch: 729,     Training Loss: 0.8622562289237976, Training Acc: 55.15%\n",
      "              Val Loss: 0.9271692037582397, Val Acc: 52.25%\n",
      "Epoch: 730,     Training Loss: 0.8325952887535095, Training Acc: 55.16%\n",
      "              Val Loss: 0.9651386141777039, Val Acc: 52.26%\n",
      "Epoch: 731,     Training Loss: 0.8593254089355469, Training Acc: 55.17%\n",
      "              Val Loss: 0.9778275489807129, Val Acc: 52.26%\n",
      "Epoch: 732,     Training Loss: 0.8800981044769287, Training Acc: 55.18%\n",
      "              Val Loss: 0.9285560846328735, Val Acc: 52.27%\n",
      "Epoch: 733,     Training Loss: 0.8350889682769775, Training Acc: 55.19%\n",
      "              Val Loss: 1.0043272972106934, Val Acc: 52.28%\n",
      "Epoch: 734,     Training Loss: 0.8892230987548828, Training Acc: 55.20%\n",
      "              Val Loss: 0.9620367288589478, Val Acc: 52.29%\n",
      "Epoch: 735,     Training Loss: 0.8690340518951416, Training Acc: 55.21%\n",
      "              Val Loss: 0.948078453540802, Val Acc: 52.30%\n",
      "Epoch: 736,     Training Loss: 0.8484513759613037, Training Acc: 55.22%\n",
      "              Val Loss: 0.9747692942619324, Val Acc: 52.30%\n",
      "Epoch: 737,     Training Loss: 0.8668814301490784, Training Acc: 55.23%\n",
      "              Val Loss: 0.9475618600845337, Val Acc: 52.31%\n",
      "Epoch: 738,     Training Loss: 0.8543180823326111, Training Acc: 55.24%\n",
      "              Val Loss: 0.9336591958999634, Val Acc: 52.32%\n",
      "Epoch: 739,     Training Loss: 0.8334982395172119, Training Acc: 55.25%\n",
      "              Val Loss: 0.949471116065979, Val Acc: 52.33%\n",
      "Epoch: 740,     Training Loss: 0.8449788689613342, Training Acc: 55.26%\n",
      "              Val Loss: 0.9526870250701904, Val Acc: 52.33%\n",
      "Epoch: 741,     Training Loss: 0.8640363812446594, Training Acc: 55.27%\n",
      "              Val Loss: 0.9120982885360718, Val Acc: 52.34%\n",
      "Epoch: 742,     Training Loss: 0.8179677724838257, Training Acc: 55.28%\n",
      "              Val Loss: 0.9672644138336182, Val Acc: 52.35%\n",
      "Epoch: 743,     Training Loss: 0.8575873374938965, Training Acc: 55.29%\n",
      "              Val Loss: 0.9836392998695374, Val Acc: 52.35%\n",
      "Epoch: 744,     Training Loss: 0.9039566516876221, Training Acc: 55.29%\n",
      "              Val Loss: 0.906226396560669, Val Acc: 52.36%\n",
      "Epoch: 745,     Training Loss: 0.8157997131347656, Training Acc: 55.31%\n",
      "              Val Loss: 1.0836623907089233, Val Acc: 52.36%\n",
      "Epoch: 746,     Training Loss: 0.9479780793190002, Training Acc: 55.31%\n",
      "              Val Loss: 1.110607624053955, Val Acc: 52.36%\n",
      "Epoch: 747,     Training Loss: 1.0537532567977905, Training Acc: 55.30%\n",
      "              Val Loss: 0.9678906202316284, Val Acc: 52.37%\n",
      "Epoch: 748,     Training Loss: 0.8909435272216797, Training Acc: 55.31%\n",
      "              Val Loss: 1.4682204723358154, Val Acc: 52.35%\n",
      "Epoch: 749,     Training Loss: 1.2773618698120117, Training Acc: 55.30%\n",
      "              Val Loss: 1.4722639322280884, Val Acc: 52.35%\n",
      "Epoch: 750,     Training Loss: 1.479455590248108, Training Acc: 55.30%\n",
      "              Val Loss: 1.755234956741333, Val Acc: 52.35%\n",
      "Epoch: 751,     Training Loss: 1.7754220962524414, Training Acc: 55.29%\n",
      "              Val Loss: 1.2026076316833496, Val Acc: 52.35%\n",
      "Epoch: 752,     Training Loss: 1.1711187362670898, Training Acc: 55.29%\n",
      "              Val Loss: 1.833911418914795, Val Acc: 52.33%\n",
      "Epoch: 753,     Training Loss: 1.6693978309631348, Training Acc: 55.27%\n",
      "              Val Loss: 1.1202936172485352, Val Acc: 52.33%\n",
      "Epoch: 754,     Training Loss: 1.0376595258712769, Training Acc: 55.27%\n",
      "              Val Loss: 1.246945858001709, Val Acc: 52.33%\n",
      "Epoch: 755,     Training Loss: 1.2377272844314575, Training Acc: 55.27%\n",
      "              Val Loss: 1.4592307806015015, Val Acc: 52.33%\n",
      "Epoch: 756,     Training Loss: 1.391502857208252, Training Acc: 55.26%\n",
      "              Val Loss: 1.1088083982467651, Val Acc: 52.33%\n",
      "Epoch: 757,     Training Loss: 1.0330076217651367, Training Acc: 55.26%\n",
      "              Val Loss: 1.4180896282196045, Val Acc: 52.32%\n",
      "Epoch: 758,     Training Loss: 1.316593885421753, Training Acc: 55.25%\n",
      "              Val Loss: 1.0916478633880615, Val Acc: 52.32%\n",
      "Epoch: 759,     Training Loss: 1.027919888496399, Training Acc: 55.25%\n",
      "              Val Loss: 1.2123371362686157, Val Acc: 52.32%\n",
      "Epoch: 760,     Training Loss: 1.1478885412216187, Training Acc: 55.25%\n",
      "              Val Loss: 1.2603908777236938, Val Acc: 52.32%\n",
      "Epoch: 761,     Training Loss: 1.210960865020752, Training Acc: 55.25%\n",
      "              Val Loss: 1.0926443338394165, Val Acc: 52.33%\n",
      "Epoch: 762,     Training Loss: 1.0450674295425415, Training Acc: 55.25%\n",
      "              Val Loss: 1.240571141242981, Val Acc: 52.32%\n",
      "Epoch: 763,     Training Loss: 1.1263957023620605, Training Acc: 55.25%\n",
      "              Val Loss: 1.0416991710662842, Val Acc: 52.32%\n",
      "Epoch: 764,     Training Loss: 0.9664691686630249, Training Acc: 55.26%\n",
      "              Val Loss: 1.098544716835022, Val Acc: 52.33%\n",
      "Epoch: 765,     Training Loss: 1.041571855545044, Training Acc: 55.26%\n",
      "              Val Loss: 1.0649744272232056, Val Acc: 52.33%\n",
      "Epoch: 766,     Training Loss: 1.039015769958496, Training Acc: 55.26%\n",
      "              Val Loss: 1.0219085216522217, Val Acc: 52.33%\n",
      "Epoch: 767,     Training Loss: 0.9723621606826782, Training Acc: 55.26%\n",
      "              Val Loss: 1.128925085067749, Val Acc: 52.33%\n",
      "Epoch: 768,     Training Loss: 1.043837070465088, Training Acc: 55.26%\n",
      "              Val Loss: 1.0782406330108643, Val Acc: 52.33%\n",
      "Epoch: 769,     Training Loss: 1.0049959421157837, Training Acc: 55.26%\n",
      "              Val Loss: 0.9733672142028809, Val Acc: 52.34%\n",
      "Epoch: 770,     Training Loss: 0.9239398241043091, Training Acc: 55.26%\n",
      "              Val Loss: 1.017744541168213, Val Acc: 52.34%\n",
      "Epoch: 771,     Training Loss: 0.9639251232147217, Training Acc: 55.27%\n",
      "              Val Loss: 1.028406023979187, Val Acc: 52.35%\n",
      "Epoch: 772,     Training Loss: 0.9534633755683899, Training Acc: 55.27%\n",
      "              Val Loss: 1.0467725992202759, Val Acc: 52.35%\n",
      "Epoch: 773,     Training Loss: 0.970212459564209, Training Acc: 55.27%\n",
      "              Val Loss: 1.0228540897369385, Val Acc: 52.35%\n",
      "Epoch: 774,     Training Loss: 0.9517158269882202, Training Acc: 55.27%\n",
      "              Val Loss: 0.9522042870521545, Val Acc: 52.35%\n",
      "Epoch: 775,     Training Loss: 0.8944324254989624, Training Acc: 55.28%\n",
      "              Val Loss: 0.9607049822807312, Val Acc: 52.36%\n",
      "Epoch: 776,     Training Loss: 0.912617564201355, Training Acc: 55.28%\n",
      "              Val Loss: 0.9585389494895935, Val Acc: 52.36%\n",
      "Epoch: 777,     Training Loss: 0.8949282169342041, Training Acc: 55.29%\n",
      "              Val Loss: 0.9982746839523315, Val Acc: 52.37%\n",
      "Epoch: 778,     Training Loss: 0.9210388660430908, Training Acc: 55.29%\n",
      "              Val Loss: 0.9433035254478455, Val Acc: 52.38%\n",
      "Epoch: 779,     Training Loss: 0.8866530656814575, Training Acc: 55.30%\n",
      "              Val Loss: 0.9552388787269592, Val Acc: 52.38%\n",
      "Epoch: 780,     Training Loss: 0.908413290977478, Training Acc: 55.31%\n",
      "              Val Loss: 0.9145016670227051, Val Acc: 52.39%\n",
      "Epoch: 781,     Training Loss: 0.8590192198753357, Training Acc: 55.32%\n",
      "              Val Loss: 0.9696581959724426, Val Acc: 52.39%\n",
      "Epoch: 782,     Training Loss: 0.8945291638374329, Training Acc: 55.32%\n",
      "              Val Loss: 0.906741201877594, Val Acc: 52.40%\n",
      "Epoch: 783,     Training Loss: 0.8478839993476868, Training Acc: 55.33%\n",
      "              Val Loss: 0.9246259927749634, Val Acc: 52.41%\n",
      "Epoch: 784,     Training Loss: 0.8749508857727051, Training Acc: 55.34%\n",
      "              Val Loss: 0.91368567943573, Val Acc: 52.42%\n",
      "Epoch: 785,     Training Loss: 0.8488317728042603, Training Acc: 55.34%\n",
      "              Val Loss: 0.941270112991333, Val Acc: 52.42%\n",
      "Epoch: 786,     Training Loss: 0.8679215908050537, Training Acc: 55.35%\n",
      "              Val Loss: 0.9273172616958618, Val Acc: 52.43%\n",
      "Epoch: 787,     Training Loss: 0.8637256622314453, Training Acc: 55.36%\n",
      "              Val Loss: 0.9089572429656982, Val Acc: 52.44%\n",
      "Epoch: 788,     Training Loss: 0.8505193591117859, Training Acc: 55.37%\n",
      "              Val Loss: 0.929760754108429, Val Acc: 52.45%\n",
      "Epoch: 789,     Training Loss: 0.8632057905197144, Training Acc: 55.37%\n",
      "              Val Loss: 0.9399833679199219, Val Acc: 52.45%\n",
      "Epoch: 790,     Training Loss: 0.867770791053772, Training Acc: 55.38%\n",
      "              Val Loss: 0.9279303550720215, Val Acc: 52.46%\n",
      "Epoch: 791,     Training Loss: 0.8550598621368408, Training Acc: 55.39%\n",
      "              Val Loss: 0.9656936526298523, Val Acc: 52.47%\n",
      "Epoch: 792,     Training Loss: 0.8818950057029724, Training Acc: 55.40%\n",
      "              Val Loss: 0.940569281578064, Val Acc: 52.48%\n",
      "Epoch: 793,     Training Loss: 0.8674001097679138, Training Acc: 55.40%\n",
      "              Val Loss: 0.9299933910369873, Val Acc: 52.48%\n",
      "Epoch: 794,     Training Loss: 0.8595858216285706, Training Acc: 55.41%\n",
      "              Val Loss: 0.959129273891449, Val Acc: 52.49%\n",
      "Epoch: 795,     Training Loss: 0.877733588218689, Training Acc: 55.42%\n",
      "              Val Loss: 0.9285327792167664, Val Acc: 52.50%\n",
      "Epoch: 796,     Training Loss: 0.8589236736297607, Training Acc: 55.43%\n",
      "              Val Loss: 0.9140777587890625, Val Acc: 52.51%\n",
      "Epoch: 797,     Training Loss: 0.8546298742294312, Training Acc: 55.44%\n",
      "              Val Loss: 0.9423431158065796, Val Acc: 52.51%\n",
      "Epoch: 798,     Training Loss: 0.863691508769989, Training Acc: 55.44%\n",
      "              Val Loss: 0.9317036271095276, Val Acc: 52.52%\n",
      "Epoch: 799,     Training Loss: 0.8537690043449402, Training Acc: 55.45%\n",
      "              Val Loss: 0.9203128218650818, Val Acc: 52.53%\n",
      "Epoch: 800,     Training Loss: 0.8535028100013733, Training Acc: 55.46%\n",
      "              Val Loss: 0.9399195909500122, Val Acc: 52.54%\n",
      "Epoch: 801,     Training Loss: 0.8624525666236877, Training Acc: 55.47%\n",
      "              Val Loss: 0.9375405311584473, Val Acc: 52.55%\n",
      "Epoch: 802,     Training Loss: 0.854555606842041, Training Acc: 55.48%\n",
      "              Val Loss: 0.9282501339912415, Val Acc: 52.55%\n",
      "Epoch: 803,     Training Loss: 0.8525813817977905, Training Acc: 55.49%\n",
      "              Val Loss: 0.9256081581115723, Val Acc: 52.56%\n",
      "Epoch: 804,     Training Loss: 0.8504180908203125, Training Acc: 55.49%\n",
      "              Val Loss: 0.9263371229171753, Val Acc: 52.57%\n",
      "Epoch: 805,     Training Loss: 0.8487737774848938, Training Acc: 55.50%\n",
      "              Val Loss: 0.9021244049072266, Val Acc: 52.58%\n",
      "Epoch: 806,     Training Loss: 0.8292775750160217, Training Acc: 55.51%\n",
      "              Val Loss: 0.9286534786224365, Val Acc: 52.59%\n",
      "Epoch: 807,     Training Loss: 0.8478049635887146, Training Acc: 55.52%\n",
      "              Val Loss: 0.9146768450737, Val Acc: 52.59%\n",
      "Epoch: 808,     Training Loss: 0.8369660973548889, Training Acc: 55.53%\n",
      "              Val Loss: 0.9035923480987549, Val Acc: 52.60%\n",
      "Epoch: 809,     Training Loss: 0.8287667632102966, Training Acc: 55.54%\n",
      "              Val Loss: 0.9309996962547302, Val Acc: 52.61%\n",
      "Epoch: 810,     Training Loss: 0.850874662399292, Training Acc: 55.55%\n",
      "              Val Loss: 0.9163873195648193, Val Acc: 52.62%\n",
      "Epoch: 811,     Training Loss: 0.83673495054245, Training Acc: 55.56%\n",
      "              Val Loss: 0.9167481064796448, Val Acc: 52.63%\n",
      "Epoch: 812,     Training Loss: 0.8351810574531555, Training Acc: 55.57%\n",
      "              Val Loss: 0.9353142380714417, Val Acc: 52.63%\n",
      "Epoch: 813,     Training Loss: 0.8548686504364014, Training Acc: 55.58%\n",
      "              Val Loss: 0.9106791615486145, Val Acc: 52.64%\n",
      "Epoch: 814,     Training Loss: 0.8347129225730896, Training Acc: 55.59%\n",
      "              Val Loss: 0.9312701225280762, Val Acc: 52.65%\n",
      "Epoch: 815,     Training Loss: 0.8441358804702759, Training Acc: 55.60%\n",
      "              Val Loss: 0.9282874464988708, Val Acc: 52.66%\n",
      "Epoch: 816,     Training Loss: 0.8486234545707703, Training Acc: 55.61%\n",
      "              Val Loss: 0.9190851449966431, Val Acc: 52.67%\n",
      "Epoch: 817,     Training Loss: 0.8442287445068359, Training Acc: 55.62%\n",
      "              Val Loss: 0.9295287132263184, Val Acc: 52.67%\n",
      "Epoch: 818,     Training Loss: 0.8423178791999817, Training Acc: 55.63%\n",
      "              Val Loss: 0.9311791062355042, Val Acc: 52.68%\n",
      "Epoch: 819,     Training Loss: 0.8483260869979858, Training Acc: 55.63%\n",
      "              Val Loss: 0.9230175614356995, Val Acc: 52.69%\n",
      "Epoch: 820,     Training Loss: 0.8468707203865051, Training Acc: 55.64%\n",
      "              Val Loss: 0.9156410694122314, Val Acc: 52.70%\n",
      "Epoch: 821,     Training Loss: 0.8321565985679626, Training Acc: 55.65%\n",
      "              Val Loss: 0.9464250206947327, Val Acc: 52.70%\n",
      "Epoch: 822,     Training Loss: 0.855729877948761, Training Acc: 55.66%\n",
      "              Val Loss: 0.9189000725746155, Val Acc: 52.71%\n",
      "Epoch: 823,     Training Loss: 0.8409740924835205, Training Acc: 55.67%\n",
      "              Val Loss: 0.9146766662597656, Val Acc: 52.72%\n",
      "Epoch: 824,     Training Loss: 0.831035315990448, Training Acc: 55.68%\n",
      "              Val Loss: 0.9494874477386475, Val Acc: 52.73%\n",
      "Epoch: 825,     Training Loss: 0.8579704761505127, Training Acc: 55.69%\n",
      "              Val Loss: 0.9144262671470642, Val Acc: 52.73%\n",
      "Epoch: 826,     Training Loss: 0.8342335224151611, Training Acc: 55.70%\n",
      "              Val Loss: 0.9199933409690857, Val Acc: 52.74%\n",
      "Epoch: 827,     Training Loss: 0.834088146686554, Training Acc: 55.71%\n",
      "              Val Loss: 0.9395667314529419, Val Acc: 52.75%\n",
      "Epoch: 828,     Training Loss: 0.8511987924575806, Training Acc: 55.72%\n",
      "              Val Loss: 0.9100376963615417, Val Acc: 52.76%\n",
      "Epoch: 829,     Training Loss: 0.8294441103935242, Training Acc: 55.73%\n",
      "              Val Loss: 0.9200631976127625, Val Acc: 52.77%\n",
      "Epoch: 830,     Training Loss: 0.8327995538711548, Training Acc: 55.74%\n",
      "              Val Loss: 0.9278193116188049, Val Acc: 52.77%\n",
      "Epoch: 831,     Training Loss: 0.8417581915855408, Training Acc: 55.75%\n",
      "              Val Loss: 0.9079570174217224, Val Acc: 52.78%\n",
      "Epoch: 832,     Training Loss: 0.8274433612823486, Training Acc: 55.76%\n",
      "              Val Loss: 0.9158620238304138, Val Acc: 52.79%\n",
      "Epoch: 833,     Training Loss: 0.8272797465324402, Training Acc: 55.77%\n",
      "              Val Loss: 0.9189289808273315, Val Acc: 52.80%\n",
      "Epoch: 834,     Training Loss: 0.8343144059181213, Training Acc: 55.78%\n",
      "              Val Loss: 0.9061638116836548, Val Acc: 52.81%\n",
      "Epoch: 835,     Training Loss: 0.8262889981269836, Training Acc: 55.79%\n",
      "              Val Loss: 0.9124756455421448, Val Acc: 52.81%\n",
      "Epoch: 836,     Training Loss: 0.8229866623878479, Training Acc: 55.80%\n",
      "              Val Loss: 0.9169538021087646, Val Acc: 52.82%\n",
      "Epoch: 837,     Training Loss: 0.8306551575660706, Training Acc: 55.81%\n",
      "              Val Loss: 0.9092066287994385, Val Acc: 52.83%\n",
      "Epoch: 838,     Training Loss: 0.8280208706855774, Training Acc: 55.82%\n",
      "              Val Loss: 0.9117789268493652, Val Acc: 52.84%\n",
      "Epoch: 839,     Training Loss: 0.8199922442436218, Training Acc: 55.83%\n",
      "              Val Loss: 0.9225651025772095, Val Acc: 52.85%\n",
      "Epoch: 840,     Training Loss: 0.8340997099876404, Training Acc: 55.84%\n",
      "              Val Loss: 0.9169532060623169, Val Acc: 52.86%\n",
      "Epoch: 841,     Training Loss: 0.8342427015304565, Training Acc: 55.85%\n",
      "              Val Loss: 0.9152333736419678, Val Acc: 52.86%\n",
      "Epoch: 842,     Training Loss: 0.821968674659729, Training Acc: 55.86%\n",
      "              Val Loss: 0.946430504322052, Val Acc: 52.87%\n",
      "Epoch: 843,     Training Loss: 0.849425733089447, Training Acc: 55.87%\n",
      "              Val Loss: 0.9273251295089722, Val Acc: 52.88%\n",
      "Epoch: 844,     Training Loss: 0.8433843851089478, Training Acc: 55.88%\n",
      "              Val Loss: 0.9287928938865662, Val Acc: 52.89%\n",
      "Epoch: 845,     Training Loss: 0.8327678442001343, Training Acc: 55.89%\n",
      "              Val Loss: 0.957029402256012, Val Acc: 52.89%\n",
      "Epoch: 846,     Training Loss: 0.8567845821380615, Training Acc: 55.90%\n",
      "              Val Loss: 0.9228641986846924, Val Acc: 52.90%\n",
      "Epoch: 847,     Training Loss: 0.8389229774475098, Training Acc: 55.91%\n",
      "              Val Loss: 0.9317511916160583, Val Acc: 52.91%\n",
      "Epoch: 848,     Training Loss: 0.8336069583892822, Training Acc: 55.92%\n",
      "              Val Loss: 0.9407097101211548, Val Acc: 52.92%\n",
      "Epoch: 849,     Training Loss: 0.843976616859436, Training Acc: 55.92%\n",
      "              Val Loss: 0.9117379188537598, Val Acc: 52.92%\n",
      "Epoch: 850,     Training Loss: 0.8276265859603882, Training Acc: 55.93%\n",
      "              Val Loss: 0.917084813117981, Val Acc: 52.93%\n",
      "Epoch: 851,     Training Loss: 0.822002112865448, Training Acc: 55.95%\n",
      "              Val Loss: 0.9302562475204468, Val Acc: 52.94%\n",
      "Epoch: 852,     Training Loss: 0.8350748419761658, Training Acc: 55.95%\n",
      "              Val Loss: 0.9079427123069763, Val Acc: 52.95%\n",
      "Epoch: 853,     Training Loss: 0.8227484226226807, Training Acc: 55.96%\n",
      "              Val Loss: 0.9085693359375, Val Acc: 52.96%\n",
      "Epoch: 854,     Training Loss: 0.8153831362724304, Training Acc: 55.98%\n",
      "              Val Loss: 0.9265720248222351, Val Acc: 52.96%\n",
      "Epoch: 855,     Training Loss: 0.8311383128166199, Training Acc: 55.98%\n",
      "              Val Loss: 0.9089303016662598, Val Acc: 52.97%\n",
      "Epoch: 856,     Training Loss: 0.8217945098876953, Training Acc: 55.99%\n",
      "              Val Loss: 0.9076182842254639, Val Acc: 52.98%\n",
      "Epoch: 857,     Training Loss: 0.8125965595245361, Training Acc: 56.01%\n",
      "              Val Loss: 0.9311150908470154, Val Acc: 52.99%\n",
      "Epoch: 858,     Training Loss: 0.833037793636322, Training Acc: 56.01%\n",
      "              Val Loss: 0.9150518774986267, Val Acc: 53.00%\n",
      "Epoch: 859,     Training Loss: 0.826496958732605, Training Acc: 56.03%\n",
      "              Val Loss: 0.9131683111190796, Val Acc: 53.00%\n",
      "Epoch: 860,     Training Loss: 0.8140929937362671, Training Acc: 56.04%\n",
      "              Val Loss: 0.9421247839927673, Val Acc: 53.01%\n",
      "Epoch: 861,     Training Loss: 0.8415666818618774, Training Acc: 56.04%\n",
      "              Val Loss: 0.923504114151001, Val Acc: 53.02%\n",
      "Epoch: 862,     Training Loss: 0.8344006538391113, Training Acc: 56.05%\n",
      "              Val Loss: 0.9282090067863464, Val Acc: 53.03%\n",
      "Epoch: 863,     Training Loss: 0.8242877721786499, Training Acc: 56.06%\n",
      "              Val Loss: 0.9533772468566895, Val Acc: 53.03%\n",
      "Epoch: 864,     Training Loss: 0.8491954803466797, Training Acc: 56.07%\n",
      "              Val Loss: 0.9297164678573608, Val Acc: 53.04%\n",
      "Epoch: 865,     Training Loss: 0.8413338661193848, Training Acc: 56.08%\n",
      "              Val Loss: 0.9358303546905518, Val Acc: 53.05%\n",
      "Epoch: 866,     Training Loss: 0.8294323682785034, Training Acc: 56.09%\n",
      "              Val Loss: 0.9557769894599915, Val Acc: 53.05%\n",
      "Epoch: 867,     Training Loss: 0.848222017288208, Training Acc: 56.10%\n",
      "              Val Loss: 0.9273613691329956, Val Acc: 53.06%\n",
      "Epoch: 868,     Training Loss: 0.8393707871437073, Training Acc: 56.11%\n",
      "              Val Loss: 0.9233526587486267, Val Acc: 53.07%\n",
      "Epoch: 869,     Training Loss: 0.8203961253166199, Training Acc: 56.12%\n",
      "              Val Loss: 0.9530317783355713, Val Acc: 53.08%\n",
      "Epoch: 870,     Training Loss: 0.8453570604324341, Training Acc: 56.12%\n",
      "              Val Loss: 0.9177581667900085, Val Acc: 53.09%\n",
      "Epoch: 871,     Training Loss: 0.829806923866272, Training Acc: 56.13%\n",
      "              Val Loss: 0.9111862182617188, Val Acc: 53.10%\n",
      "Epoch: 872,     Training Loss: 0.8116967082023621, Training Acc: 56.15%\n",
      "              Val Loss: 0.9463299512863159, Val Acc: 53.10%\n",
      "Epoch: 873,     Training Loss: 0.8397724628448486, Training Acc: 56.15%\n",
      "              Val Loss: 0.9145945906639099, Val Acc: 53.11%\n",
      "Epoch: 874,     Training Loss: 0.8248593807220459, Training Acc: 56.16%\n",
      "              Val Loss: 0.907634973526001, Val Acc: 53.12%\n",
      "Epoch: 875,     Training Loss: 0.8081495761871338, Training Acc: 56.17%\n",
      "              Val Loss: 0.9501566886901855, Val Acc: 53.12%\n",
      "Epoch: 876,     Training Loss: 0.8409151434898376, Training Acc: 56.18%\n",
      "              Val Loss: 0.9220048785209656, Val Acc: 53.13%\n",
      "Epoch: 877,     Training Loss: 0.8294045329093933, Training Acc: 56.19%\n",
      "              Val Loss: 0.9131115674972534, Val Acc: 53.14%\n",
      "Epoch: 878,     Training Loss: 0.8115656971931458, Training Acc: 56.20%\n",
      "              Val Loss: 0.9666388630867004, Val Acc: 53.14%\n",
      "Epoch: 879,     Training Loss: 0.8522464632987976, Training Acc: 56.21%\n",
      "              Val Loss: 0.9303311705589294, Val Acc: 53.15%\n",
      "Epoch: 880,     Training Loss: 0.8360565304756165, Training Acc: 56.22%\n",
      "              Val Loss: 0.9290913343429565, Val Acc: 53.16%\n",
      "Epoch: 881,     Training Loss: 0.8227934241294861, Training Acc: 56.23%\n",
      "              Val Loss: 0.9631938934326172, Val Acc: 53.17%\n",
      "Epoch: 882,     Training Loss: 0.8501096963882446, Training Acc: 56.23%\n",
      "              Val Loss: 0.9201803803443909, Val Acc: 53.18%\n",
      "Epoch: 883,     Training Loss: 0.8272716999053955, Training Acc: 56.24%\n",
      "              Val Loss: 0.9263545274734497, Val Acc: 53.18%\n",
      "Epoch: 884,     Training Loss: 0.8185425400733948, Training Acc: 56.25%\n",
      "              Val Loss: 0.9399321675300598, Val Acc: 53.19%\n",
      "Epoch: 885,     Training Loss: 0.8339653015136719, Training Acc: 56.26%\n",
      "              Val Loss: 0.9114473462104797, Val Acc: 53.20%\n",
      "Epoch: 886,     Training Loss: 0.8192039728164673, Training Acc: 56.27%\n",
      "              Val Loss: 0.9135722517967224, Val Acc: 53.21%\n",
      "Epoch: 887,     Training Loss: 0.808246374130249, Training Acc: 56.28%\n",
      "              Val Loss: 0.9280954003334045, Val Acc: 53.21%\n",
      "Epoch: 888,     Training Loss: 0.8238095045089722, Training Acc: 56.29%\n",
      "              Val Loss: 0.910129725933075, Val Acc: 53.22%\n",
      "Epoch: 889,     Training Loss: 0.8173381090164185, Training Acc: 56.30%\n",
      "              Val Loss: 0.9054698348045349, Val Acc: 53.23%\n",
      "Epoch: 890,     Training Loss: 0.8014810085296631, Training Acc: 56.31%\n",
      "              Val Loss: 0.9315169453620911, Val Acc: 53.24%\n",
      "Epoch: 891,     Training Loss: 0.8236086964607239, Training Acc: 56.32%\n",
      "              Val Loss: 0.9211214184761047, Val Acc: 53.25%\n",
      "Epoch: 892,     Training Loss: 0.8263084292411804, Training Acc: 56.33%\n",
      "              Val Loss: 0.9080870151519775, Val Acc: 53.25%\n",
      "Epoch: 893,     Training Loss: 0.8018592596054077, Training Acc: 56.34%\n",
      "              Val Loss: 0.9546283483505249, Val Acc: 53.26%\n",
      "Epoch: 894,     Training Loss: 0.8387858867645264, Training Acc: 56.35%\n",
      "              Val Loss: 0.9383726716041565, Val Acc: 53.27%\n",
      "Epoch: 895,     Training Loss: 0.8416712880134583, Training Acc: 56.36%\n",
      "              Val Loss: 0.9239267110824585, Val Acc: 53.28%\n",
      "Epoch: 896,     Training Loss: 0.8127649426460266, Training Acc: 56.37%\n",
      "              Val Loss: 0.970257043838501, Val Acc: 53.28%\n",
      "Epoch: 897,     Training Loss: 0.8534172773361206, Training Acc: 56.37%\n",
      "              Val Loss: 0.9347593188285828, Val Acc: 53.29%\n",
      "Epoch: 898,     Training Loss: 0.8393261432647705, Training Acc: 56.38%\n",
      "              Val Loss: 0.9370989203453064, Val Acc: 53.30%\n",
      "Epoch: 899,     Training Loss: 0.8221749067306519, Training Acc: 56.39%\n",
      "              Val Loss: 0.9585529565811157, Val Acc: 53.30%\n",
      "Epoch: 900,     Training Loss: 0.8444415330886841, Training Acc: 56.40%\n",
      "              Val Loss: 0.9262537956237793, Val Acc: 53.31%\n",
      "Epoch: 901,     Training Loss: 0.8322991132736206, Training Acc: 56.41%\n",
      "              Val Loss: 0.9274532794952393, Val Acc: 53.32%\n",
      "Epoch: 902,     Training Loss: 0.8137015700340271, Training Acc: 56.42%\n",
      "              Val Loss: 0.9507449865341187, Val Acc: 53.32%\n",
      "Epoch: 903,     Training Loss: 0.8353284597396851, Training Acc: 56.42%\n",
      "              Val Loss: 0.9273858070373535, Val Acc: 53.33%\n",
      "Epoch: 904,     Training Loss: 0.8333140015602112, Training Acc: 56.43%\n",
      "              Val Loss: 0.9099259972572327, Val Acc: 53.34%\n",
      "Epoch: 905,     Training Loss: 0.8009924292564392, Training Acc: 56.44%\n",
      "              Val Loss: 0.9528725147247314, Val Acc: 53.34%\n",
      "Epoch: 906,     Training Loss: 0.8343484401702881, Training Acc: 56.45%\n",
      "              Val Loss: 0.928781270980835, Val Acc: 53.35%\n",
      "Epoch: 907,     Training Loss: 0.8343854546546936, Training Acc: 56.46%\n",
      "              Val Loss: 0.9007241725921631, Val Acc: 53.36%\n",
      "Epoch: 908,     Training Loss: 0.7938310503959656, Training Acc: 56.47%\n",
      "              Val Loss: 0.9650142192840576, Val Acc: 53.36%\n",
      "Epoch: 909,     Training Loss: 0.8424121737480164, Training Acc: 56.47%\n",
      "              Val Loss: 0.9380576610565186, Val Acc: 53.37%\n",
      "Epoch: 910,     Training Loss: 0.8413711786270142, Training Acc: 56.48%\n",
      "              Val Loss: 0.9061862230300903, Val Acc: 53.38%\n",
      "Epoch: 911,     Training Loss: 0.7975772619247437, Training Acc: 56.49%\n",
      "              Val Loss: 0.9976951479911804, Val Acc: 53.38%\n",
      "Epoch: 912,     Training Loss: 0.8679750561714172, Training Acc: 56.50%\n",
      "              Val Loss: 0.9508013129234314, Val Acc: 53.39%\n",
      "Epoch: 913,     Training Loss: 0.8523244261741638, Training Acc: 56.50%\n",
      "              Val Loss: 0.9352089166641235, Val Acc: 53.40%\n",
      "Epoch: 914,     Training Loss: 0.8204869627952576, Training Acc: 56.51%\n",
      "              Val Loss: 1.0045275688171387, Val Acc: 53.40%\n",
      "Epoch: 915,     Training Loss: 0.8736512064933777, Training Acc: 56.52%\n",
      "              Val Loss: 0.9431686401367188, Val Acc: 53.41%\n",
      "Epoch: 916,     Training Loss: 0.8451826572418213, Training Acc: 56.53%\n",
      "              Val Loss: 0.9320585131645203, Val Acc: 53.42%\n",
      "Epoch: 917,     Training Loss: 0.8182893991470337, Training Acc: 56.54%\n",
      "              Val Loss: 0.9788766503334045, Val Acc: 53.42%\n",
      "Epoch: 918,     Training Loss: 0.8539477586746216, Training Acc: 56.54%\n",
      "              Val Loss: 0.9243520498275757, Val Acc: 53.43%\n",
      "Epoch: 919,     Training Loss: 0.8286746740341187, Training Acc: 56.55%\n",
      "              Val Loss: 0.9050030708312988, Val Acc: 53.44%\n",
      "Epoch: 920,     Training Loss: 0.7996021509170532, Training Acc: 56.56%\n",
      "              Val Loss: 0.9596801996231079, Val Acc: 53.44%\n",
      "Epoch: 921,     Training Loss: 0.8394524455070496, Training Acc: 56.57%\n",
      "              Val Loss: 0.9135554432868958, Val Acc: 53.45%\n",
      "Epoch: 922,     Training Loss: 0.8169742822647095, Training Acc: 56.57%\n",
      "              Val Loss: 0.8951336145401001, Val Acc: 53.46%\n",
      "Epoch: 923,     Training Loss: 0.7921204566955566, Training Acc: 56.59%\n",
      "              Val Loss: 0.9510445594787598, Val Acc: 53.46%\n",
      "Epoch: 924,     Training Loss: 0.8307951092720032, Training Acc: 56.59%\n",
      "              Val Loss: 0.9114515781402588, Val Acc: 53.47%\n",
      "Epoch: 925,     Training Loss: 0.8120198249816895, Training Acc: 56.60%\n",
      "              Val Loss: 0.8903626203536987, Val Acc: 53.48%\n",
      "Epoch: 926,     Training Loss: 0.7859676480293274, Training Acc: 56.61%\n",
      "              Val Loss: 0.949006199836731, Val Acc: 53.49%\n",
      "Epoch: 927,     Training Loss: 0.8268306851387024, Training Acc: 56.62%\n",
      "              Val Loss: 0.9245004057884216, Val Acc: 53.50%\n",
      "Epoch: 928,     Training Loss: 0.8212469220161438, Training Acc: 56.63%\n",
      "              Val Loss: 0.8975076079368591, Val Acc: 53.50%\n",
      "Epoch: 929,     Training Loss: 0.7882412672042847, Training Acc: 56.64%\n",
      "              Val Loss: 0.9814489483833313, Val Acc: 53.51%\n",
      "Epoch: 930,     Training Loss: 0.8523657321929932, Training Acc: 56.65%\n",
      "              Val Loss: 0.9406894445419312, Val Acc: 53.52%\n",
      "Epoch: 931,     Training Loss: 0.835856556892395, Training Acc: 56.65%\n",
      "              Val Loss: 0.9334298968315125, Val Acc: 53.52%\n",
      "Epoch: 932,     Training Loss: 0.8147047162055969, Training Acc: 56.66%\n",
      "              Val Loss: 0.9711331725120544, Val Acc: 53.53%\n",
      "Epoch: 933,     Training Loss: 0.8494880795478821, Training Acc: 56.67%\n",
      "              Val Loss: 0.9234038591384888, Val Acc: 53.53%\n",
      "Epoch: 934,     Training Loss: 0.8218738436698914, Training Acc: 56.68%\n",
      "              Val Loss: 0.9388778209686279, Val Acc: 53.54%\n",
      "Epoch: 935,     Training Loss: 0.8155146241188049, Training Acc: 56.69%\n",
      "              Val Loss: 0.9319068789482117, Val Acc: 53.55%\n",
      "Epoch: 936,     Training Loss: 0.8164424896240234, Training Acc: 56.70%\n",
      "              Val Loss: 0.9137459397315979, Val Acc: 53.55%\n",
      "Epoch: 937,     Training Loss: 0.8128458261489868, Training Acc: 56.70%\n",
      "              Val Loss: 0.9084863066673279, Val Acc: 53.56%\n",
      "Epoch: 938,     Training Loss: 0.790787935256958, Training Acc: 56.71%\n",
      "              Val Loss: 0.9203031063079834, Val Acc: 53.57%\n",
      "Epoch: 939,     Training Loss: 0.8034512996673584, Training Acc: 56.72%\n",
      "              Val Loss: 0.9093563556671143, Val Acc: 53.58%\n",
      "Epoch: 940,     Training Loss: 0.8083926439285278, Training Acc: 56.73%\n",
      "              Val Loss: 0.8896283507347107, Val Acc: 53.59%\n",
      "Epoch: 941,     Training Loss: 0.7784985899925232, Training Acc: 56.74%\n",
      "              Val Loss: 0.916717529296875, Val Acc: 53.59%\n",
      "Epoch: 942,     Training Loss: 0.7989382743835449, Training Acc: 56.75%\n",
      "              Val Loss: 0.9128192067146301, Val Acc: 53.60%\n",
      "Epoch: 943,     Training Loss: 0.8114579916000366, Training Acc: 56.76%\n",
      "              Val Loss: 0.8870230913162231, Val Acc: 53.61%\n",
      "Epoch: 944,     Training Loss: 0.7755175232887268, Training Acc: 56.77%\n",
      "              Val Loss: 0.9157258868217468, Val Acc: 53.61%\n",
      "Epoch: 945,     Training Loss: 0.7978288531303406, Training Acc: 56.78%\n",
      "              Val Loss: 0.9304039478302002, Val Acc: 53.62%\n",
      "Epoch: 946,     Training Loss: 0.8261464834213257, Training Acc: 56.79%\n",
      "              Val Loss: 0.8940669894218445, Val Acc: 53.63%\n",
      "Epoch: 947,     Training Loss: 0.7768080234527588, Training Acc: 56.80%\n",
      "              Val Loss: 0.951859712600708, Val Acc: 53.63%\n",
      "Epoch: 948,     Training Loss: 0.8265956044197083, Training Acc: 56.80%\n",
      "              Val Loss: 0.9603177905082703, Val Acc: 53.64%\n",
      "Epoch: 949,     Training Loss: 0.8528844714164734, Training Acc: 56.81%\n",
      "              Val Loss: 0.9363790154457092, Val Acc: 53.65%\n",
      "Epoch: 950,     Training Loss: 0.8076619505882263, Training Acc: 56.82%\n",
      "              Val Loss: 0.9839364886283875, Val Acc: 53.65%\n",
      "Epoch: 951,     Training Loss: 0.8549350500106812, Training Acc: 56.83%\n",
      "              Val Loss: 0.9573012590408325, Val Acc: 53.66%\n",
      "Epoch: 952,     Training Loss: 0.8512682318687439, Training Acc: 56.83%\n",
      "              Val Loss: 0.9633015394210815, Val Acc: 53.67%\n",
      "Epoch: 953,     Training Loss: 0.8272691965103149, Training Acc: 56.84%\n",
      "              Val Loss: 0.9401582479476929, Val Acc: 53.67%\n",
      "Epoch: 954,     Training Loss: 0.8189136981964111, Training Acc: 56.85%\n",
      "              Val Loss: 0.9325511455535889, Val Acc: 53.68%\n",
      "Epoch: 955,     Training Loss: 0.8302288055419922, Training Acc: 56.85%\n",
      "              Val Loss: 0.9138931035995483, Val Acc: 53.69%\n",
      "Epoch: 956,     Training Loss: 0.7888491749763489, Training Acc: 56.86%\n",
      "              Val Loss: 0.9363600015640259, Val Acc: 53.69%\n",
      "Epoch: 957,     Training Loss: 0.8114373683929443, Training Acc: 56.87%\n",
      "              Val Loss: 0.9318728446960449, Val Acc: 53.70%\n",
      "Epoch: 958,     Training Loss: 0.8327085375785828, Training Acc: 56.88%\n",
      "              Val Loss: 0.8895266652107239, Val Acc: 53.71%\n",
      "Epoch: 959,     Training Loss: 0.7748211622238159, Training Acc: 56.89%\n",
      "              Val Loss: 0.9539926052093506, Val Acc: 53.71%\n",
      "Epoch: 960,     Training Loss: 0.8242083787918091, Training Acc: 56.89%\n",
      "              Val Loss: 0.9513735771179199, Val Acc: 53.72%\n",
      "Epoch: 961,     Training Loss: 0.8543236255645752, Training Acc: 56.90%\n",
      "              Val Loss: 0.8869423866271973, Val Acc: 53.72%\n",
      "Epoch: 962,     Training Loss: 0.7756102085113525, Training Acc: 56.91%\n",
      "              Val Loss: 0.9806911945343018, Val Acc: 53.73%\n",
      "Epoch: 963,     Training Loss: 0.8447829484939575, Training Acc: 56.91%\n",
      "              Val Loss: 0.9822466373443604, Val Acc: 53.73%\n",
      "Epoch: 964,     Training Loss: 0.8842456936836243, Training Acc: 56.92%\n",
      "              Val Loss: 0.8864827156066895, Val Acc: 53.74%\n",
      "Epoch: 965,     Training Loss: 0.7744539380073547, Training Acc: 56.93%\n",
      "              Val Loss: 1.0627528429031372, Val Acc: 53.74%\n",
      "Epoch: 966,     Training Loss: 0.9101788997650146, Training Acc: 56.93%\n",
      "              Val Loss: 1.0333857536315918, Val Acc: 53.74%\n",
      "Epoch: 967,     Training Loss: 0.93059241771698, Training Acc: 56.93%\n",
      "              Val Loss: 0.9376155138015747, Val Acc: 53.75%\n",
      "Epoch: 968,     Training Loss: 0.8220195174217224, Training Acc: 56.94%\n",
      "              Val Loss: 1.1613589525222778, Val Acc: 53.75%\n",
      "Epoch: 969,     Training Loss: 0.9977357387542725, Training Acc: 56.94%\n",
      "              Val Loss: 1.0043065547943115, Val Acc: 53.75%\n",
      "Epoch: 970,     Training Loss: 0.9020262360572815, Training Acc: 56.94%\n",
      "              Val Loss: 0.9928880929946899, Val Acc: 53.76%\n",
      "Epoch: 971,     Training Loss: 0.875730037689209, Training Acc: 56.95%\n",
      "              Val Loss: 1.0350641012191772, Val Acc: 53.76%\n",
      "Epoch: 972,     Training Loss: 0.8981105089187622, Training Acc: 56.95%\n",
      "              Val Loss: 0.9127635955810547, Val Acc: 53.76%\n",
      "Epoch: 973,     Training Loss: 0.8077167272567749, Training Acc: 56.96%\n",
      "              Val Loss: 0.9307079911231995, Val Acc: 53.77%\n",
      "Epoch: 974,     Training Loss: 0.830007016658783, Training Acc: 56.96%\n",
      "              Val Loss: 0.9576095342636108, Val Acc: 53.78%\n",
      "Epoch: 975,     Training Loss: 0.8176699280738831, Training Acc: 56.97%\n",
      "              Val Loss: 0.9239292144775391, Val Acc: 53.78%\n",
      "Epoch: 976,     Training Loss: 0.8076425790786743, Training Acc: 56.98%\n",
      "              Val Loss: 0.9522254467010498, Val Acc: 53.79%\n",
      "Epoch: 977,     Training Loss: 0.84183669090271, Training Acc: 56.99%\n",
      "              Val Loss: 0.9478370547294617, Val Acc: 53.79%\n",
      "Epoch: 978,     Training Loss: 0.8105661273002625, Training Acc: 56.99%\n",
      "              Val Loss: 0.9608376026153564, Val Acc: 53.80%\n",
      "Epoch: 979,     Training Loss: 0.8296326994895935, Training Acc: 57.00%\n",
      "              Val Loss: 0.9341452121734619, Val Acc: 53.81%\n",
      "Epoch: 980,     Training Loss: 0.8244579434394836, Training Acc: 57.01%\n",
      "              Val Loss: 0.9064022302627563, Val Acc: 53.81%\n",
      "Epoch: 981,     Training Loss: 0.7838557362556458, Training Acc: 57.02%\n",
      "              Val Loss: 0.947011411190033, Val Acc: 53.82%\n",
      "Epoch: 982,     Training Loss: 0.8143132925033569, Training Acc: 57.02%\n",
      "              Val Loss: 0.9024831652641296, Val Acc: 53.83%\n",
      "Epoch: 983,     Training Loss: 0.7992295622825623, Training Acc: 57.03%\n",
      "              Val Loss: 0.8850873708724976, Val Acc: 53.83%\n",
      "Epoch: 984,     Training Loss: 0.7682161927223206, Training Acc: 57.04%\n",
      "              Val Loss: 0.9394187927246094, Val Acc: 53.84%\n",
      "Epoch: 985,     Training Loss: 0.8094967603683472, Training Acc: 57.05%\n",
      "              Val Loss: 0.9073895215988159, Val Acc: 53.85%\n",
      "Epoch: 986,     Training Loss: 0.802693247795105, Training Acc: 57.06%\n",
      "              Val Loss: 0.8838775753974915, Val Acc: 53.86%\n",
      "Epoch: 987,     Training Loss: 0.7683950662612915, Training Acc: 57.07%\n",
      "              Val Loss: 0.9588201642036438, Val Acc: 53.86%\n",
      "Epoch: 988,     Training Loss: 0.8233741521835327, Training Acc: 57.07%\n",
      "              Val Loss: 0.9354368448257446, Val Acc: 53.87%\n",
      "Epoch: 989,     Training Loss: 0.8287423849105835, Training Acc: 57.08%\n",
      "              Val Loss: 0.9039849042892456, Val Acc: 53.88%\n",
      "Epoch: 990,     Training Loss: 0.7818756699562073, Training Acc: 57.09%\n",
      "              Val Loss: 1.0053520202636719, Val Acc: 53.88%\n",
      "Epoch: 991,     Training Loss: 0.8587778210639954, Training Acc: 57.09%\n",
      "              Val Loss: 0.9754952192306519, Val Acc: 53.89%\n",
      "Epoch: 992,     Training Loss: 0.8627853393554688, Training Acc: 57.10%\n",
      "              Val Loss: 0.9238331317901611, Val Acc: 53.90%\n",
      "Epoch: 993,     Training Loss: 0.7970547676086426, Training Acc: 57.11%\n",
      "              Val Loss: 1.0298194885253906, Val Acc: 53.90%\n",
      "Epoch: 994,     Training Loss: 0.8807948231697083, Training Acc: 57.11%\n",
      "              Val Loss: 0.9293196201324463, Val Acc: 53.90%\n",
      "Epoch: 995,     Training Loss: 0.8168697953224182, Training Acc: 57.12%\n",
      "              Val Loss: 0.9178965091705322, Val Acc: 53.91%\n",
      "Epoch: 996,     Training Loss: 0.7982891798019409, Training Acc: 57.13%\n",
      "              Val Loss: 0.9788191318511963, Val Acc: 53.91%\n",
      "Epoch: 997,     Training Loss: 0.8411952257156372, Training Acc: 57.13%\n",
      "              Val Loss: 0.8933451175689697, Val Acc: 53.92%\n",
      "Epoch: 998,     Training Loss: 0.7837750315666199, Training Acc: 57.14%\n",
      "              Val Loss: 0.9068995118141174, Val Acc: 53.93%\n",
      "Epoch: 999,     Training Loss: 0.7911478281021118, Training Acc: 57.15%\n",
      "              Val Loss: 0.9355327486991882, Val Acc: 53.93%\n",
      "Epoch: 1000,     Training Loss: 0.8034190535545349, Training Acc: 57.16%\n",
      "              Val Loss: 0.8851391673088074, Val Acc: 53.94%\n",
      "Epoch: 1001,     Training Loss: 0.7748229503631592, Training Acc: 57.17%\n",
      "              Val Loss: 0.8895418047904968, Val Acc: 53.95%\n",
      "Epoch: 1002,     Training Loss: 0.7746378183364868, Training Acc: 57.18%\n",
      "              Val Loss: 0.9122871160507202, Val Acc: 53.96%\n",
      "Epoch: 1003,     Training Loss: 0.7812617421150208, Training Acc: 57.19%\n",
      "              Val Loss: 0.8808588981628418, Val Acc: 53.97%\n",
      "Epoch: 1004,     Training Loss: 0.7660380601882935, Training Acc: 57.20%\n",
      "              Val Loss: 0.8754865527153015, Val Acc: 53.97%\n",
      "Epoch: 1005,     Training Loss: 0.7592836618423462, Training Acc: 57.21%\n",
      "              Val Loss: 0.9003483653068542, Val Acc: 53.98%\n",
      "Epoch: 1006,     Training Loss: 0.769468367099762, Training Acc: 57.22%\n",
      "              Val Loss: 0.8817324042320251, Val Acc: 53.99%\n",
      "Epoch: 1007,     Training Loss: 0.7634375691413879, Training Acc: 57.23%\n",
      "              Val Loss: 0.8719624280929565, Val Acc: 54.00%\n",
      "Epoch: 1008,     Training Loss: 0.7519904971122742, Training Acc: 57.24%\n",
      "              Val Loss: 0.9002612233161926, Val Acc: 54.00%\n",
      "Epoch: 1009,     Training Loss: 0.7646342515945435, Training Acc: 57.25%\n",
      "              Val Loss: 0.8785383701324463, Val Acc: 54.01%\n",
      "Epoch: 1010,     Training Loss: 0.7597154378890991, Training Acc: 57.26%\n",
      "              Val Loss: 0.8723514676094055, Val Acc: 54.02%\n",
      "Epoch: 1011,     Training Loss: 0.7494992017745972, Training Acc: 57.27%\n",
      "              Val Loss: 0.8940598964691162, Val Acc: 54.03%\n",
      "Epoch: 1012,     Training Loss: 0.7599080801010132, Training Acc: 57.28%\n",
      "              Val Loss: 0.8745613098144531, Val Acc: 54.04%\n",
      "Epoch: 1013,     Training Loss: 0.7565637230873108, Training Acc: 57.29%\n",
      "              Val Loss: 0.8716487884521484, Val Acc: 54.04%\n",
      "Epoch: 1014,     Training Loss: 0.7484590411186218, Training Acc: 57.30%\n",
      "              Val Loss: 0.8903659582138062, Val Acc: 54.05%\n",
      "Epoch: 1015,     Training Loss: 0.7576571702957153, Training Acc: 57.31%\n",
      "              Val Loss: 0.874565601348877, Val Acc: 54.06%\n",
      "Epoch: 1016,     Training Loss: 0.7564312815666199, Training Acc: 57.32%\n",
      "              Val Loss: 0.870482861995697, Val Acc: 54.07%\n",
      "Epoch: 1017,     Training Loss: 0.7459834218025208, Training Acc: 57.33%\n",
      "              Val Loss: 0.8930885195732117, Val Acc: 54.08%\n",
      "Epoch: 1018,     Training Loss: 0.7578339576721191, Training Acc: 57.34%\n",
      "              Val Loss: 0.8778842687606812, Val Acc: 54.08%\n",
      "Epoch: 1019,     Training Loss: 0.7578883171081543, Training Acc: 57.35%\n",
      "              Val Loss: 0.8715454936027527, Val Acc: 54.09%\n",
      "Epoch: 1020,     Training Loss: 0.7440959811210632, Training Acc: 57.36%\n",
      "              Val Loss: 0.8960424065589905, Val Acc: 54.10%\n",
      "Epoch: 1021,     Training Loss: 0.7579959034919739, Training Acc: 57.37%\n",
      "              Val Loss: 0.8798010349273682, Val Acc: 54.11%\n",
      "Epoch: 1022,     Training Loss: 0.7603512406349182, Training Acc: 57.38%\n",
      "              Val Loss: 0.8688461780548096, Val Acc: 54.12%\n",
      "Epoch: 1023,     Training Loss: 0.743152379989624, Training Acc: 57.39%\n",
      "              Val Loss: 0.8993868231773376, Val Acc: 54.12%\n",
      "Epoch: 1024,     Training Loss: 0.7607141137123108, Training Acc: 57.40%\n",
      "              Val Loss: 0.8821001648902893, Val Acc: 54.13%\n",
      "Epoch: 1025,     Training Loss: 0.7632650136947632, Training Acc: 57.41%\n",
      "              Val Loss: 0.8721809387207031, Val Acc: 54.14%\n",
      "Epoch: 1026,     Training Loss: 0.7442173957824707, Training Acc: 57.42%\n",
      "              Val Loss: 0.9105832576751709, Val Acc: 54.14%\n",
      "Epoch: 1027,     Training Loss: 0.7657013535499573, Training Acc: 57.43%\n",
      "              Val Loss: 0.8891658782958984, Val Acc: 54.15%\n",
      "Epoch: 1028,     Training Loss: 0.7697007060050964, Training Acc: 57.44%\n",
      "              Val Loss: 0.8773944973945618, Val Acc: 54.16%\n",
      "Epoch: 1029,     Training Loss: 0.7456403374671936, Training Acc: 57.45%\n",
      "              Val Loss: 0.9243229031562805, Val Acc: 54.17%\n",
      "Epoch: 1030,     Training Loss: 0.7743018269538879, Training Acc: 57.46%\n",
      "              Val Loss: 0.9012740850448608, Val Acc: 54.17%\n",
      "Epoch: 1031,     Training Loss: 0.7862556576728821, Training Acc: 57.47%\n",
      "              Val Loss: 0.8736616373062134, Val Acc: 54.18%\n",
      "Epoch: 1032,     Training Loss: 0.7429777383804321, Training Acc: 57.48%\n",
      "              Val Loss: 0.9518238306045532, Val Acc: 54.19%\n",
      "Epoch: 1033,     Training Loss: 0.7969398498535156, Training Acc: 57.48%\n",
      "              Val Loss: 0.9455947279930115, Val Acc: 54.19%\n",
      "Epoch: 1034,     Training Loss: 0.8365289568901062, Training Acc: 57.49%\n",
      "              Val Loss: 0.8864192962646484, Val Acc: 54.20%\n",
      "Epoch: 1035,     Training Loss: 0.7583267092704773, Training Acc: 57.50%\n",
      "              Val Loss: 1.0228705406188965, Val Acc: 54.20%\n",
      "Epoch: 1036,     Training Loss: 0.8606857061386108, Training Acc: 57.50%\n",
      "              Val Loss: 1.004066824913025, Val Acc: 54.20%\n",
      "Epoch: 1037,     Training Loss: 0.8912674188613892, Training Acc: 57.50%\n",
      "              Val Loss: 1.0102648735046387, Val Acc: 54.20%\n",
      "Epoch: 1038,     Training Loss: 0.8594949841499329, Training Acc: 57.51%\n",
      "              Val Loss: 1.057267665863037, Val Acc: 54.21%\n",
      "Epoch: 1039,     Training Loss: 0.889712929725647, Training Acc: 57.51%\n",
      "              Val Loss: 1.0618172883987427, Val Acc: 54.21%\n",
      "Epoch: 1040,     Training Loss: 0.9207281470298767, Training Acc: 57.51%\n",
      "              Val Loss: 0.9162831902503967, Val Acc: 54.21%\n",
      "Epoch: 1041,     Training Loss: 0.7866976261138916, Training Acc: 57.52%\n",
      "              Val Loss: 0.9412679076194763, Val Acc: 54.22%\n",
      "Epoch: 1042,     Training Loss: 0.7877523303031921, Training Acc: 57.53%\n",
      "              Val Loss: 0.9235915541648865, Val Acc: 54.22%\n",
      "Epoch: 1043,     Training Loss: 0.7923362255096436, Training Acc: 57.53%\n",
      "              Val Loss: 0.8957474231719971, Val Acc: 54.23%\n",
      "Epoch: 1044,     Training Loss: 0.7585946917533875, Training Acc: 57.54%\n",
      "              Val Loss: 0.9622412323951721, Val Acc: 54.24%\n",
      "Epoch: 1045,     Training Loss: 0.8099046349525452, Training Acc: 57.55%\n",
      "              Val Loss: 0.9962082505226135, Val Acc: 54.24%\n",
      "Epoch: 1046,     Training Loss: 0.8559741973876953, Training Acc: 57.56%\n",
      "              Val Loss: 0.9838509559631348, Val Acc: 54.25%\n",
      "Epoch: 1047,     Training Loss: 0.8361225128173828, Training Acc: 57.56%\n",
      "              Val Loss: 0.9379860758781433, Val Acc: 54.25%\n",
      "Epoch: 1048,     Training Loss: 0.8042062520980835, Training Acc: 57.57%\n",
      "              Val Loss: 0.9626516103744507, Val Acc: 54.26%\n",
      "Epoch: 1049,     Training Loss: 0.8266797661781311, Training Acc: 57.58%\n",
      "              Val Loss: 0.8988463878631592, Val Acc: 54.27%\n",
      "Epoch: 1050,     Training Loss: 0.7562108039855957, Training Acc: 57.58%\n",
      "              Val Loss: 0.9157770276069641, Val Acc: 54.27%\n",
      "Epoch: 1051,     Training Loss: 0.7818319797515869, Training Acc: 57.59%\n",
      "              Val Loss: 0.8919010162353516, Val Acc: 54.28%\n",
      "Epoch: 1052,     Training Loss: 0.7721396088600159, Training Acc: 57.60%\n",
      "              Val Loss: 0.9538010358810425, Val Acc: 54.29%\n",
      "Epoch: 1053,     Training Loss: 0.7970517873764038, Training Acc: 57.61%\n",
      "              Val Loss: 0.9024751782417297, Val Acc: 54.29%\n",
      "Epoch: 1054,     Training Loss: 0.7648007273674011, Training Acc: 57.62%\n",
      "              Val Loss: 0.9772007465362549, Val Acc: 54.30%\n",
      "Epoch: 1055,     Training Loss: 0.8363178968429565, Training Acc: 57.63%\n",
      "              Val Loss: 0.9382542371749878, Val Acc: 54.31%\n",
      "Epoch: 1056,     Training Loss: 0.7774943709373474, Training Acc: 57.63%\n",
      "              Val Loss: 0.9353290796279907, Val Acc: 54.32%\n",
      "Epoch: 1057,     Training Loss: 0.7860676050186157, Training Acc: 57.64%\n",
      "              Val Loss: 0.903367817401886, Val Acc: 54.32%\n",
      "Epoch: 1058,     Training Loss: 0.7714176177978516, Training Acc: 57.65%\n",
      "              Val Loss: 0.9578111171722412, Val Acc: 54.33%\n",
      "Epoch: 1059,     Training Loss: 0.8023577928543091, Training Acc: 57.66%\n",
      "              Val Loss: 0.9263438582420349, Val Acc: 54.33%\n",
      "Epoch: 1060,     Training Loss: 0.8077588677406311, Training Acc: 57.66%\n",
      "              Val Loss: 0.8884535431861877, Val Acc: 54.34%\n",
      "Epoch: 1061,     Training Loss: 0.7539827227592468, Training Acc: 57.67%\n",
      "              Val Loss: 1.0181528329849243, Val Acc: 54.34%\n",
      "Epoch: 1062,     Training Loss: 0.8525799512863159, Training Acc: 57.67%\n",
      "              Val Loss: 0.9880306720733643, Val Acc: 54.34%\n",
      "Epoch: 1063,     Training Loss: 0.875072717666626, Training Acc: 57.68%\n",
      "              Val Loss: 0.9570260047912598, Val Acc: 54.35%\n",
      "Epoch: 1064,     Training Loss: 0.813466489315033, Training Acc: 57.68%\n",
      "              Val Loss: 1.0278258323669434, Val Acc: 54.35%\n",
      "Epoch: 1065,     Training Loss: 0.8587705492973328, Training Acc: 57.68%\n",
      "              Val Loss: 1.0335999727249146, Val Acc: 54.35%\n",
      "Epoch: 1066,     Training Loss: 0.9023767709732056, Training Acc: 57.69%\n",
      "              Val Loss: 0.9308792948722839, Val Acc: 54.36%\n",
      "Epoch: 1067,     Training Loss: 0.7889312505722046, Training Acc: 57.69%\n",
      "              Val Loss: 1.0075989961624146, Val Acc: 54.36%\n",
      "Epoch: 1068,     Training Loss: 0.8343203663825989, Training Acc: 57.70%\n",
      "              Val Loss: 0.9144160747528076, Val Acc: 54.37%\n",
      "Epoch: 1069,     Training Loss: 0.7816311717033386, Training Acc: 57.71%\n",
      "              Val Loss: 0.912401556968689, Val Acc: 54.38%\n",
      "Epoch: 1070,     Training Loss: 0.7743539214134216, Training Acc: 57.71%\n",
      "              Val Loss: 0.8939533829689026, Val Acc: 54.38%\n",
      "Epoch: 1071,     Training Loss: 0.7454887628555298, Training Acc: 57.72%\n",
      "              Val Loss: 0.9098824262619019, Val Acc: 54.39%\n",
      "Epoch: 1072,     Training Loss: 0.7716056704521179, Training Acc: 57.73%\n",
      "              Val Loss: 0.9115844964981079, Val Acc: 54.40%\n",
      "Epoch: 1073,     Training Loss: 0.7666203379631042, Training Acc: 57.74%\n",
      "              Val Loss: 0.8952886462211609, Val Acc: 54.40%\n",
      "Epoch: 1074,     Training Loss: 0.7473454475402832, Training Acc: 57.75%\n",
      "              Val Loss: 0.9136842489242554, Val Acc: 54.41%\n",
      "Epoch: 1075,     Training Loss: 0.7574453949928284, Training Acc: 57.76%\n",
      "              Val Loss: 0.9061400890350342, Val Acc: 54.42%\n",
      "Epoch: 1076,     Training Loss: 0.7545903921127319, Training Acc: 57.77%\n",
      "              Val Loss: 0.9063669443130493, Val Acc: 54.43%\n",
      "Epoch: 1077,     Training Loss: 0.7624108791351318, Training Acc: 57.78%\n",
      "              Val Loss: 0.903277575969696, Val Acc: 54.43%\n",
      "Epoch: 1078,     Training Loss: 0.7453678846359253, Training Acc: 57.79%\n",
      "              Val Loss: 0.9180777072906494, Val Acc: 54.44%\n",
      "Epoch: 1079,     Training Loss: 0.769036054611206, Training Acc: 57.80%\n",
      "              Val Loss: 0.8903423547744751, Val Acc: 54.45%\n",
      "Epoch: 1080,     Training Loss: 0.7495308518409729, Training Acc: 57.81%\n",
      "              Val Loss: 0.9308103919029236, Val Acc: 54.45%\n",
      "Epoch: 1081,     Training Loss: 0.7732118368148804, Training Acc: 57.81%\n",
      "              Val Loss: 0.8994348645210266, Val Acc: 54.46%\n",
      "Epoch: 1082,     Training Loss: 0.7733845710754395, Training Acc: 57.82%\n",
      "              Val Loss: 0.872374415397644, Val Acc: 54.47%\n",
      "Epoch: 1083,     Training Loss: 0.7346959114074707, Training Acc: 57.83%\n",
      "              Val Loss: 0.9700055122375488, Val Acc: 54.47%\n",
      "Epoch: 1084,     Training Loss: 0.8062585592269897, Training Acc: 57.84%\n",
      "              Val Loss: 0.9721472263336182, Val Acc: 54.47%\n",
      "Epoch: 1085,     Training Loss: 0.8526903390884399, Training Acc: 57.84%\n",
      "              Val Loss: 0.9397299289703369, Val Acc: 54.48%\n",
      "Epoch: 1086,     Training Loss: 0.7866025567054749, Training Acc: 57.85%\n",
      "              Val Loss: 1.0228259563446045, Val Acc: 54.48%\n",
      "Epoch: 1087,     Training Loss: 0.8435909152030945, Training Acc: 57.85%\n",
      "              Val Loss: 1.035577416419983, Val Acc: 54.49%\n",
      "Epoch: 1088,     Training Loss: 0.8966723084449768, Training Acc: 57.85%\n",
      "              Val Loss: 0.9820417165756226, Val Acc: 54.49%\n",
      "Epoch: 1089,     Training Loss: 0.8151822090148926, Training Acc: 57.86%\n",
      "              Val Loss: 0.9676204919815063, Val Acc: 54.49%\n",
      "Epoch: 1090,     Training Loss: 0.7969484925270081, Training Acc: 57.86%\n",
      "              Val Loss: 0.9338991641998291, Val Acc: 54.50%\n",
      "Epoch: 1091,     Training Loss: 0.7894737124443054, Training Acc: 57.87%\n",
      "              Val Loss: 0.9347074031829834, Val Acc: 54.51%\n",
      "Epoch: 1092,     Training Loss: 0.7754465341567993, Training Acc: 57.88%\n",
      "              Val Loss: 0.8665244579315186, Val Acc: 54.51%\n",
      "Epoch: 1093,     Training Loss: 0.7204459309577942, Training Acc: 57.89%\n",
      "              Val Loss: 0.8922350406646729, Val Acc: 54.52%\n",
      "Epoch: 1094,     Training Loss: 0.743014395236969, Training Acc: 57.90%\n",
      "              Val Loss: 0.8865081071853638, Val Acc: 54.53%\n",
      "Epoch: 1095,     Training Loss: 0.7385180592536926, Training Acc: 57.91%\n",
      "              Val Loss: 0.868420422077179, Val Acc: 54.54%\n",
      "Epoch: 1096,     Training Loss: 0.7298315167427063, Training Acc: 57.92%\n",
      "              Val Loss: 0.8899640440940857, Val Acc: 54.54%\n",
      "Epoch: 1097,     Training Loss: 0.7336190938949585, Training Acc: 57.93%\n",
      "              Val Loss: 0.8705119490623474, Val Acc: 54.55%\n",
      "Epoch: 1098,     Training Loss: 0.7256391048431396, Training Acc: 57.94%\n",
      "              Val Loss: 0.8873355984687805, Val Acc: 54.56%\n",
      "Epoch: 1099,     Training Loss: 0.7456216216087341, Training Acc: 57.95%\n",
      "              Val Loss: 0.9013450741767883, Val Acc: 54.57%\n",
      "Epoch: 1100,     Training Loss: 0.7415324449539185, Training Acc: 57.96%\n",
      "              Val Loss: 0.8737898468971252, Val Acc: 54.58%\n",
      "Epoch: 1101,     Training Loss: 0.7346269488334656, Training Acc: 57.97%\n",
      "              Val Loss: 0.871203601360321, Val Acc: 54.59%\n",
      "Epoch: 1102,     Training Loss: 0.722277045249939, Training Acc: 57.98%\n",
      "              Val Loss: 0.8912160992622375, Val Acc: 54.59%\n",
      "Epoch: 1103,     Training Loss: 0.7310433387756348, Training Acc: 57.99%\n",
      "              Val Loss: 0.8978661894798279, Val Acc: 54.60%\n",
      "Epoch: 1104,     Training Loss: 0.756064236164093, Training Acc: 58.00%\n",
      "              Val Loss: 0.9095342755317688, Val Acc: 54.61%\n",
      "Epoch: 1105,     Training Loss: 0.7520626783370972, Training Acc: 58.01%\n",
      "              Val Loss: 0.9112456440925598, Val Acc: 54.62%\n",
      "Epoch: 1106,     Training Loss: 0.7544337511062622, Training Acc: 58.02%\n",
      "              Val Loss: 0.8937325477600098, Val Acc: 54.62%\n",
      "Epoch: 1107,     Training Loss: 0.7353725433349609, Training Acc: 58.03%\n",
      "              Val Loss: 0.9614107012748718, Val Acc: 54.63%\n",
      "Epoch: 1108,     Training Loss: 0.7878821492195129, Training Acc: 58.04%\n",
      "              Val Loss: 0.9380866885185242, Val Acc: 54.64%\n",
      "Epoch: 1109,     Training Loss: 0.7873988151550293, Training Acc: 58.05%\n",
      "              Val Loss: 0.956635594367981, Val Acc: 54.64%\n",
      "Epoch: 1110,     Training Loss: 0.783226728439331, Training Acc: 58.05%\n",
      "              Val Loss: 0.9083026051521301, Val Acc: 54.65%\n",
      "Epoch: 1111,     Training Loss: 0.770061731338501, Training Acc: 58.06%\n",
      "              Val Loss: 0.8734817504882812, Val Acc: 54.65%\n",
      "Epoch: 1112,     Training Loss: 0.7318447232246399, Training Acc: 58.07%\n",
      "              Val Loss: 1.0086380243301392, Val Acc: 54.65%\n",
      "Epoch: 1113,     Training Loss: 0.8267832398414612, Training Acc: 58.07%\n",
      "              Val Loss: 1.0099551677703857, Val Acc: 54.66%\n",
      "Epoch: 1114,     Training Loss: 0.8929372429847717, Training Acc: 58.07%\n",
      "              Val Loss: 0.9782720804214478, Val Acc: 54.66%\n",
      "Epoch: 1115,     Training Loss: 0.821442186832428, Training Acc: 58.08%\n",
      "              Val Loss: 1.0632702112197876, Val Acc: 54.66%\n",
      "Epoch: 1116,     Training Loss: 0.8793110847473145, Training Acc: 58.08%\n",
      "              Val Loss: 1.0883427858352661, Val Acc: 54.66%\n",
      "Epoch: 1117,     Training Loss: 0.9464141726493835, Training Acc: 58.08%\n",
      "              Val Loss: 0.9295867681503296, Val Acc: 54.67%\n",
      "Epoch: 1118,     Training Loss: 0.7796390652656555, Training Acc: 58.08%\n",
      "              Val Loss: 0.9293762445449829, Val Acc: 54.67%\n",
      "Epoch: 1119,     Training Loss: 0.7697118520736694, Training Acc: 58.09%\n",
      "              Val Loss: 0.9670297503471375, Val Acc: 54.68%\n",
      "Epoch: 1120,     Training Loss: 0.8204697966575623, Training Acc: 58.10%\n",
      "              Val Loss: 0.9023171067237854, Val Acc: 54.68%\n",
      "Epoch: 1121,     Training Loss: 0.7405521869659424, Training Acc: 58.10%\n",
      "              Val Loss: 0.9591023921966553, Val Acc: 54.68%\n",
      "Epoch: 1122,     Training Loss: 0.7866302728652954, Training Acc: 58.11%\n",
      "              Val Loss: 0.9790873527526855, Val Acc: 54.69%\n",
      "Epoch: 1123,     Training Loss: 0.8302309513092041, Training Acc: 58.12%\n",
      "              Val Loss: 0.964256763458252, Val Acc: 54.69%\n",
      "Epoch: 1124,     Training Loss: 0.7996614575386047, Training Acc: 58.12%\n",
      "              Val Loss: 0.8916396498680115, Val Acc: 54.70%\n",
      "Epoch: 1125,     Training Loss: 0.7398827075958252, Training Acc: 58.13%\n",
      "              Val Loss: 0.9334618449211121, Val Acc: 54.70%\n",
      "Epoch: 1126,     Training Loss: 0.7997357249259949, Training Acc: 58.14%\n",
      "              Val Loss: 0.886695921421051, Val Acc: 54.71%\n",
      "Epoch: 1127,     Training Loss: 0.7332468628883362, Training Acc: 58.15%\n",
      "              Val Loss: 0.8974129557609558, Val Acc: 54.72%\n",
      "Epoch: 1128,     Training Loss: 0.7449243664741516, Training Acc: 58.15%\n",
      "              Val Loss: 0.8744105696678162, Val Acc: 54.73%\n",
      "Epoch: 1129,     Training Loss: 0.750257670879364, Training Acc: 58.16%\n",
      "              Val Loss: 0.9015793800354004, Val Acc: 54.73%\n",
      "Epoch: 1130,     Training Loss: 0.7493489980697632, Training Acc: 58.17%\n",
      "              Val Loss: 0.8783612251281738, Val Acc: 54.74%\n",
      "Epoch: 1131,     Training Loss: 0.7212063074111938, Training Acc: 58.18%\n",
      "              Val Loss: 0.896608293056488, Val Acc: 54.75%\n",
      "Epoch: 1132,     Training Loss: 0.743976354598999, Training Acc: 58.19%\n",
      "              Val Loss: 0.9585227370262146, Val Acc: 54.76%\n",
      "Epoch: 1133,     Training Loss: 0.7688193321228027, Training Acc: 58.20%\n",
      "              Val Loss: 0.973817765712738, Val Acc: 54.76%\n",
      "Epoch: 1134,     Training Loss: 0.8033183217048645, Training Acc: 58.20%\n",
      "              Val Loss: 0.9234663248062134, Val Acc: 54.77%\n",
      "Epoch: 1135,     Training Loss: 0.7559275031089783, Training Acc: 58.21%\n",
      "              Val Loss: 0.9179379940032959, Val Acc: 54.77%\n",
      "Epoch: 1136,     Training Loss: 0.7648698687553406, Training Acc: 58.22%\n",
      "              Val Loss: 0.9204061627388, Val Acc: 54.78%\n",
      "Epoch: 1137,     Training Loss: 0.7722181081771851, Training Acc: 58.23%\n",
      "              Val Loss: 0.9357103109359741, Val Acc: 54.78%\n",
      "Epoch: 1138,     Training Loss: 0.761168360710144, Training Acc: 58.23%\n",
      "              Val Loss: 0.8977184891700745, Val Acc: 54.79%\n",
      "Epoch: 1139,     Training Loss: 0.7597127556800842, Training Acc: 58.24%\n",
      "              Val Loss: 0.8568395972251892, Val Acc: 54.80%\n",
      "Epoch: 1140,     Training Loss: 0.7126938700675964, Training Acc: 58.25%\n",
      "              Val Loss: 0.9647781848907471, Val Acc: 54.80%\n",
      "Epoch: 1141,     Training Loss: 0.7807255387306213, Training Acc: 58.26%\n",
      "              Val Loss: 0.9005773067474365, Val Acc: 54.81%\n",
      "Epoch: 1142,     Training Loss: 0.7563040852546692, Training Acc: 58.26%\n",
      "              Val Loss: 0.9394882917404175, Val Acc: 54.81%\n",
      "Epoch: 1143,     Training Loss: 0.7662645578384399, Training Acc: 58.27%\n",
      "              Val Loss: 0.914714515209198, Val Acc: 54.82%\n",
      "Epoch: 1144,     Training Loss: 0.7459070086479187, Training Acc: 58.28%\n",
      "              Val Loss: 0.896576464176178, Val Acc: 54.83%\n",
      "Epoch: 1145,     Training Loss: 0.7330998778343201, Training Acc: 58.29%\n",
      "              Val Loss: 0.9497904777526855, Val Acc: 54.84%\n",
      "Epoch: 1146,     Training Loss: 0.7739360332489014, Training Acc: 58.30%\n",
      "              Val Loss: 0.8954020738601685, Val Acc: 54.84%\n",
      "Epoch: 1147,     Training Loss: 0.7488932609558105, Training Acc: 58.31%\n",
      "              Val Loss: 0.9191693067550659, Val Acc: 54.85%\n",
      "Epoch: 1148,     Training Loss: 0.7457403540611267, Training Acc: 58.31%\n",
      "              Val Loss: 0.8671121001243591, Val Acc: 54.86%\n",
      "Epoch: 1149,     Training Loss: 0.7165411114692688, Training Acc: 58.32%\n",
      "              Val Loss: 0.8635536432266235, Val Acc: 54.87%\n",
      "Epoch: 1150,     Training Loss: 0.713685929775238, Training Acc: 58.33%\n",
      "              Val Loss: 0.9336323738098145, Val Acc: 54.87%\n",
      "Epoch: 1151,     Training Loss: 0.7476204633712769, Training Acc: 58.34%\n",
      "              Val Loss: 0.8822377920150757, Val Acc: 54.88%\n",
      "Epoch: 1152,     Training Loss: 0.7360736727714539, Training Acc: 58.35%\n",
      "              Val Loss: 0.8912596106529236, Val Acc: 54.89%\n",
      "Epoch: 1153,     Training Loss: 0.7321064472198486, Training Acc: 58.36%\n",
      "              Val Loss: 0.8900656700134277, Val Acc: 54.90%\n",
      "Epoch: 1154,     Training Loss: 0.7237837314605713, Training Acc: 58.37%\n",
      "              Val Loss: 0.869996964931488, Val Acc: 54.91%\n",
      "Epoch: 1155,     Training Loss: 0.7075383067131042, Training Acc: 58.38%\n",
      "              Val Loss: 0.9372081756591797, Val Acc: 54.91%\n",
      "Epoch: 1156,     Training Loss: 0.7574917078018188, Training Acc: 58.39%\n",
      "              Val Loss: 0.9140344262123108, Val Acc: 54.92%\n",
      "Epoch: 1157,     Training Loss: 0.7609753608703613, Training Acc: 58.40%\n",
      "              Val Loss: 0.9271767139434814, Val Acc: 54.92%\n",
      "Epoch: 1158,     Training Loss: 0.7473419904708862, Training Acc: 58.40%\n",
      "              Val Loss: 0.8774167895317078, Val Acc: 54.93%\n",
      "Epoch: 1159,     Training Loss: 0.7304575443267822, Training Acc: 58.41%\n",
      "              Val Loss: 0.8560341000556946, Val Acc: 54.94%\n",
      "Epoch: 1160,     Training Loss: 0.7039919495582581, Training Acc: 58.42%\n",
      "              Val Loss: 0.9309130311012268, Val Acc: 54.94%\n",
      "Epoch: 1161,     Training Loss: 0.7514639496803284, Training Acc: 58.43%\n",
      "              Val Loss: 0.9273746013641357, Val Acc: 54.95%\n",
      "Epoch: 1162,     Training Loss: 0.7837111949920654, Training Acc: 58.43%\n",
      "              Val Loss: 0.9566549062728882, Val Acc: 54.95%\n",
      "Epoch: 1163,     Training Loss: 0.7699024677276611, Training Acc: 58.44%\n",
      "              Val Loss: 0.9365673065185547, Val Acc: 54.96%\n",
      "Epoch: 1164,     Training Loss: 0.7607429027557373, Training Acc: 58.45%\n",
      "              Val Loss: 0.9309328198432922, Val Acc: 54.97%\n",
      "Epoch: 1165,     Training Loss: 0.7610659003257751, Training Acc: 58.46%\n",
      "              Val Loss: 0.9540241360664368, Val Acc: 54.97%\n",
      "Epoch: 1166,     Training Loss: 0.774914562702179, Training Acc: 58.46%\n",
      "              Val Loss: 0.9312022924423218, Val Acc: 54.98%\n",
      "Epoch: 1167,     Training Loss: 0.7737892270088196, Training Acc: 58.47%\n",
      "              Val Loss: 0.9294097423553467, Val Acc: 54.99%\n",
      "Epoch: 1168,     Training Loss: 0.7455172538757324, Training Acc: 58.48%\n",
      "              Val Loss: 0.8999059200286865, Val Acc: 54.99%\n",
      "Epoch: 1169,     Training Loss: 0.754886269569397, Training Acc: 58.48%\n",
      "              Val Loss: 0.8836560845375061, Val Acc: 55.00%\n",
      "Epoch: 1170,     Training Loss: 0.7253984808921814, Training Acc: 58.49%\n",
      "              Val Loss: 0.924578845500946, Val Acc: 55.01%\n",
      "Epoch: 1171,     Training Loss: 0.7502931952476501, Training Acc: 58.50%\n",
      "              Val Loss: 0.8968984484672546, Val Acc: 55.01%\n",
      "Epoch: 1172,     Training Loss: 0.7356176972389221, Training Acc: 58.51%\n",
      "              Val Loss: 0.971579909324646, Val Acc: 55.02%\n",
      "Epoch: 1173,     Training Loss: 0.7881938815116882, Training Acc: 58.52%\n",
      "              Val Loss: 0.9449607133865356, Val Acc: 55.03%\n",
      "Epoch: 1174,     Training Loss: 0.7857102155685425, Training Acc: 58.52%\n",
      "              Val Loss: 0.9407444596290588, Val Acc: 55.03%\n",
      "Epoch: 1175,     Training Loss: 0.7544847130775452, Training Acc: 58.53%\n",
      "              Val Loss: 0.8898223042488098, Val Acc: 55.03%\n",
      "Epoch: 1176,     Training Loss: 0.732062816619873, Training Acc: 58.54%\n",
      "              Val Loss: 0.8675456047058105, Val Acc: 55.04%\n",
      "Epoch: 1177,     Training Loss: 0.7072070837020874, Training Acc: 58.55%\n",
      "              Val Loss: 0.9652758240699768, Val Acc: 55.05%\n",
      "Epoch: 1178,     Training Loss: 0.765632152557373, Training Acc: 58.55%\n",
      "              Val Loss: 0.9143057465553284, Val Acc: 55.05%\n",
      "Epoch: 1179,     Training Loss: 0.7622786164283752, Training Acc: 58.56%\n",
      "              Val Loss: 0.996113657951355, Val Acc: 55.06%\n",
      "Epoch: 1180,     Training Loss: 0.804175615310669, Training Acc: 58.57%\n",
      "              Val Loss: 0.9298879504203796, Val Acc: 55.06%\n",
      "Epoch: 1181,     Training Loss: 0.7701659202575684, Training Acc: 58.57%\n",
      "              Val Loss: 0.9313340783119202, Val Acc: 55.07%\n",
      "Epoch: 1182,     Training Loss: 0.7515139579772949, Training Acc: 58.58%\n",
      "              Val Loss: 0.8884260654449463, Val Acc: 55.08%\n",
      "Epoch: 1183,     Training Loss: 0.7190184593200684, Training Acc: 58.59%\n",
      "              Val Loss: 0.9022680521011353, Val Acc: 55.08%\n",
      "Epoch: 1184,     Training Loss: 0.7476239800453186, Training Acc: 58.60%\n",
      "              Val Loss: 0.9136493802070618, Val Acc: 55.09%\n",
      "Epoch: 1185,     Training Loss: 0.7252439856529236, Training Acc: 58.60%\n",
      "              Val Loss: 0.8723809719085693, Val Acc: 55.10%\n",
      "Epoch: 1186,     Training Loss: 0.7104484438896179, Training Acc: 58.62%\n",
      "              Val Loss: 0.8673604726791382, Val Acc: 55.10%\n",
      "Epoch: 1187,     Training Loss: 0.7054250240325928, Training Acc: 58.62%\n",
      "              Val Loss: 0.86505126953125, Val Acc: 55.11%\n",
      "Epoch: 1188,     Training Loss: 0.6979327201843262, Training Acc: 58.64%\n",
      "              Val Loss: 0.8737063407897949, Val Acc: 55.12%\n",
      "Epoch: 1189,     Training Loss: 0.7023950219154358, Training Acc: 58.65%\n",
      "              Val Loss: 0.8632847666740417, Val Acc: 55.13%\n",
      "Epoch: 1190,     Training Loss: 0.6964725255966187, Training Acc: 58.66%\n",
      "              Val Loss: 0.8896300792694092, Val Acc: 55.14%\n",
      "Epoch: 1191,     Training Loss: 0.7195203304290771, Training Acc: 58.67%\n",
      "              Val Loss: 0.899040699005127, Val Acc: 55.15%\n",
      "Epoch: 1192,     Training Loss: 0.7173181176185608, Training Acc: 58.67%\n",
      "              Val Loss: 0.914334774017334, Val Acc: 55.15%\n",
      "Epoch: 1193,     Training Loss: 0.7570058703422546, Training Acc: 58.68%\n",
      "              Val Loss: 0.9331169128417969, Val Acc: 55.16%\n",
      "Epoch: 1194,     Training Loss: 0.7457528114318848, Training Acc: 58.69%\n",
      "              Val Loss: 0.9024574756622314, Val Acc: 55.17%\n",
      "Epoch: 1195,     Training Loss: 0.7369711399078369, Training Acc: 58.70%\n",
      "              Val Loss: 0.8868260979652405, Val Acc: 55.17%\n",
      "Epoch: 1196,     Training Loss: 0.7162911891937256, Training Acc: 58.71%\n",
      "              Val Loss: 0.879909873008728, Val Acc: 55.18%\n",
      "Epoch: 1197,     Training Loss: 0.7098104953765869, Training Acc: 58.72%\n",
      "              Val Loss: 0.9334394335746765, Val Acc: 55.19%\n",
      "Epoch: 1198,     Training Loss: 0.7651405334472656, Training Acc: 58.72%\n",
      "              Val Loss: 0.9263602495193481, Val Acc: 55.19%\n",
      "Epoch: 1199,     Training Loss: 0.7447689175605774, Training Acc: 58.73%\n",
      "              Val Loss: 0.9199498891830444, Val Acc: 55.19%\n",
      "Epoch: 1200,     Training Loss: 0.764973521232605, Training Acc: 58.73%\n",
      "              Val Loss: 0.8776824474334717, Val Acc: 55.20%\n",
      "Epoch: 1201,     Training Loss: 0.7028573751449585, Training Acc: 58.74%\n",
      "              Val Loss: 0.9453550577163696, Val Acc: 55.21%\n",
      "Epoch: 1202,     Training Loss: 0.7534377574920654, Training Acc: 58.75%\n",
      "              Val Loss: 0.8824689388275146, Val Acc: 55.22%\n",
      "Epoch: 1203,     Training Loss: 0.7154406905174255, Training Acc: 58.76%\n",
      "              Val Loss: 0.9812450408935547, Val Acc: 55.22%\n",
      "Epoch: 1204,     Training Loss: 0.7880285382270813, Training Acc: 58.77%\n",
      "              Val Loss: 0.9551258683204651, Val Acc: 55.22%\n",
      "Epoch: 1205,     Training Loss: 0.7929183840751648, Training Acc: 58.77%\n",
      "              Val Loss: 0.9887228608131409, Val Acc: 55.23%\n",
      "Epoch: 1206,     Training Loss: 0.7870181798934937, Training Acc: 58.78%\n",
      "              Val Loss: 0.9136644601821899, Val Acc: 55.23%\n",
      "Epoch: 1207,     Training Loss: 0.7678369283676147, Training Acc: 58.78%\n",
      "              Val Loss: 0.8907720446586609, Val Acc: 55.24%\n",
      "Epoch: 1208,     Training Loss: 0.7247744798660278, Training Acc: 58.79%\n",
      "              Val Loss: 0.9953968524932861, Val Acc: 55.24%\n",
      "Epoch: 1209,     Training Loss: 0.791400671005249, Training Acc: 58.79%\n",
      "              Val Loss: 0.9659509062767029, Val Acc: 55.25%\n",
      "Epoch: 1210,     Training Loss: 0.7970566749572754, Training Acc: 58.80%\n",
      "              Val Loss: 0.978811502456665, Val Acc: 55.25%\n",
      "Epoch: 1211,     Training Loss: 0.8024219274520874, Training Acc: 58.80%\n",
      "              Val Loss: 0.8821668028831482, Val Acc: 55.26%\n",
      "Epoch: 1212,     Training Loss: 0.7207605242729187, Training Acc: 58.81%\n",
      "              Val Loss: 0.8996737599372864, Val Acc: 55.26%\n",
      "Epoch: 1213,     Training Loss: 0.7129391431808472, Training Acc: 58.82%\n",
      "              Val Loss: 0.8729163408279419, Val Acc: 55.27%\n",
      "Epoch: 1214,     Training Loss: 0.6956741213798523, Training Acc: 58.83%\n",
      "              Val Loss: 0.9002015590667725, Val Acc: 55.28%\n",
      "Epoch: 1215,     Training Loss: 0.7423697710037231, Training Acc: 58.84%\n",
      "              Val Loss: 0.8941558599472046, Val Acc: 55.28%\n",
      "Epoch: 1216,     Training Loss: 0.7145522236824036, Training Acc: 58.85%\n",
      "              Val Loss: 0.868358850479126, Val Acc: 55.29%\n",
      "Epoch: 1217,     Training Loss: 0.6952535510063171, Training Acc: 58.86%\n",
      "              Val Loss: 0.8516098260879517, Val Acc: 55.30%\n",
      "Epoch: 1218,     Training Loss: 0.6807084679603577, Training Acc: 58.87%\n",
      "              Val Loss: 0.8489410877227783, Val Acc: 55.31%\n",
      "Epoch: 1219,     Training Loss: 0.6796852350234985, Training Acc: 58.88%\n",
      "              Val Loss: 0.8532862663269043, Val Acc: 55.32%\n",
      "Epoch: 1220,     Training Loss: 0.6871601939201355, Training Acc: 58.89%\n",
      "              Val Loss: 0.8632509708404541, Val Acc: 55.33%\n",
      "Epoch: 1221,     Training Loss: 0.6847090125083923, Training Acc: 58.90%\n",
      "              Val Loss: 0.8734912872314453, Val Acc: 55.34%\n",
      "Epoch: 1222,     Training Loss: 0.7093585133552551, Training Acc: 58.91%\n",
      "              Val Loss: 0.8984503746032715, Val Acc: 55.34%\n",
      "Epoch: 1223,     Training Loss: 0.7162614464759827, Training Acc: 58.92%\n",
      "              Val Loss: 0.9117403626441956, Val Acc: 55.35%\n",
      "Epoch: 1224,     Training Loss: 0.7513782978057861, Training Acc: 58.93%\n",
      "              Val Loss: 0.9092597365379333, Val Acc: 55.36%\n",
      "Epoch: 1225,     Training Loss: 0.717048704624176, Training Acc: 58.93%\n",
      "              Val Loss: 0.8562442660331726, Val Acc: 55.37%\n",
      "Epoch: 1226,     Training Loss: 0.692919909954071, Training Acc: 58.94%\n",
      "              Val Loss: 0.8602379560470581, Val Acc: 55.37%\n",
      "Epoch: 1227,     Training Loss: 0.6830250024795532, Training Acc: 58.95%\n",
      "              Val Loss: 0.8580951690673828, Val Acc: 55.38%\n",
      "Epoch: 1228,     Training Loss: 0.6804302334785461, Training Acc: 58.96%\n",
      "              Val Loss: 0.8875234723091125, Val Acc: 55.39%\n",
      "Epoch: 1229,     Training Loss: 0.7142024040222168, Training Acc: 58.97%\n",
      "              Val Loss: 0.9246343970298767, Val Acc: 55.39%\n",
      "Epoch: 1230,     Training Loss: 0.7287564277648926, Training Acc: 58.98%\n",
      "              Val Loss: 0.962192177772522, Val Acc: 55.40%\n",
      "Epoch: 1231,     Training Loss: 0.787382960319519, Training Acc: 58.99%\n",
      "              Val Loss: 0.9704244136810303, Val Acc: 55.40%\n",
      "Epoch: 1232,     Training Loss: 0.7664481997489929, Training Acc: 58.99%\n",
      "              Val Loss: 0.8850035667419434, Val Acc: 55.41%\n",
      "Epoch: 1233,     Training Loss: 0.729610800743103, Training Acc: 59.00%\n",
      "              Val Loss: 0.8582088351249695, Val Acc: 55.41%\n",
      "Epoch: 1234,     Training Loss: 0.6887827515602112, Training Acc: 59.01%\n",
      "              Val Loss: 0.9898983240127563, Val Acc: 55.42%\n",
      "Epoch: 1235,     Training Loss: 0.7863816022872925, Training Acc: 59.01%\n",
      "              Val Loss: 1.1728508472442627, Val Acc: 55.41%\n",
      "Epoch: 1236,     Training Loss: 1.0336118936538696, Training Acc: 59.01%\n",
      "              Val Loss: 1.001418948173523, Val Acc: 55.41%\n",
      "Epoch: 1237,     Training Loss: 0.8348106145858765, Training Acc: 59.01%\n",
      "              Val Loss: 1.044075608253479, Val Acc: 55.41%\n",
      "Epoch: 1238,     Training Loss: 0.8396466970443726, Training Acc: 59.01%\n",
      "              Val Loss: 1.162003517150879, Val Acc: 55.41%\n",
      "Epoch: 1239,     Training Loss: 1.0090693235397339, Training Acc: 59.01%\n",
      "              Val Loss: 0.9125075340270996, Val Acc: 55.42%\n",
      "Epoch: 1240,     Training Loss: 0.7344556450843811, Training Acc: 59.02%\n",
      "              Val Loss: 0.9485237002372742, Val Acc: 55.42%\n",
      "Epoch: 1241,     Training Loss: 0.7917343378067017, Training Acc: 59.02%\n",
      "              Val Loss: 1.1142866611480713, Val Acc: 55.42%\n",
      "Epoch: 1242,     Training Loss: 0.9572502970695496, Training Acc: 59.02%\n",
      "              Val Loss: 1.0100476741790771, Val Acc: 55.42%\n",
      "Epoch: 1243,     Training Loss: 0.8132081031799316, Training Acc: 59.02%\n",
      "              Val Loss: 0.9633920192718506, Val Acc: 55.42%\n",
      "Epoch: 1244,     Training Loss: 0.7853632569313049, Training Acc: 59.03%\n",
      "              Val Loss: 1.0969443321228027, Val Acc: 55.42%\n",
      "Epoch: 1245,     Training Loss: 0.9511760473251343, Training Acc: 59.03%\n",
      "              Val Loss: 0.8701383471488953, Val Acc: 55.43%\n",
      "Epoch: 1246,     Training Loss: 0.7126671075820923, Training Acc: 59.04%\n",
      "              Val Loss: 1.153710961341858, Val Acc: 55.43%\n",
      "Epoch: 1247,     Training Loss: 0.9370282888412476, Training Acc: 59.03%\n",
      "              Val Loss: 1.3399754762649536, Val Acc: 55.42%\n",
      "Epoch: 1248,     Training Loss: 1.219214677810669, Training Acc: 59.03%\n",
      "              Val Loss: 0.9657687544822693, Val Acc: 55.43%\n",
      "Epoch: 1249,     Training Loss: 0.8427119255065918, Training Acc: 59.03%\n",
      "              Val Loss: 1.4547598361968994, Val Acc: 55.41%\n",
      "Epoch: 1250,     Training Loss: 1.2346583604812622, Training Acc: 59.02%\n",
      "              Val Loss: 1.4114893674850464, Val Acc: 55.41%\n",
      "Epoch: 1251,     Training Loss: 1.282829999923706, Training Acc: 59.01%\n",
      "              Val Loss: 1.244116187095642, Val Acc: 55.40%\n",
      "Epoch: 1252,     Training Loss: 1.1153838634490967, Training Acc: 59.01%\n",
      "              Val Loss: 1.4945062398910522, Val Acc: 55.39%\n",
      "Epoch: 1253,     Training Loss: 1.2393563985824585, Training Acc: 59.00%\n",
      "              Val Loss: 0.9597800970077515, Val Acc: 55.40%\n",
      "Epoch: 1254,     Training Loss: 0.7748554944992065, Training Acc: 59.01%\n",
      "              Val Loss: 1.19110906124115, Val Acc: 55.40%\n",
      "Epoch: 1255,     Training Loss: 1.0358221530914307, Training Acc: 59.01%\n",
      "              Val Loss: 0.9679034948348999, Val Acc: 55.40%\n",
      "Epoch: 1256,     Training Loss: 0.7932915687561035, Training Acc: 59.01%\n",
      "              Val Loss: 1.2734876871109009, Val Acc: 55.40%\n",
      "Epoch: 1257,     Training Loss: 1.0328458547592163, Training Acc: 59.01%\n",
      "              Val Loss: 0.926054835319519, Val Acc: 55.40%\n",
      "Epoch: 1258,     Training Loss: 0.7711052894592285, Training Acc: 59.02%\n",
      "              Val Loss: 1.0804691314697266, Val Acc: 55.40%\n",
      "Epoch: 1259,     Training Loss: 0.9297967553138733, Training Acc: 59.02%\n",
      "              Val Loss: 0.9488394856452942, Val Acc: 55.41%\n",
      "Epoch: 1260,     Training Loss: 0.7753139734268188, Training Acc: 59.02%\n",
      "              Val Loss: 1.100772500038147, Val Acc: 55.41%\n",
      "Epoch: 1261,     Training Loss: 0.8934764266014099, Training Acc: 59.02%\n",
      "              Val Loss: 0.9646250009536743, Val Acc: 55.41%\n",
      "Epoch: 1262,     Training Loss: 0.8396271467208862, Training Acc: 59.03%\n",
      "              Val Loss: 0.9423965215682983, Val Acc: 55.42%\n",
      "Epoch: 1263,     Training Loss: 0.8137063384056091, Training Acc: 59.03%\n",
      "              Val Loss: 1.0375292301177979, Val Acc: 55.42%\n",
      "Epoch: 1264,     Training Loss: 0.8477330803871155, Training Acc: 59.03%\n",
      "              Val Loss: 0.8814414739608765, Val Acc: 55.42%\n",
      "Epoch: 1265,     Training Loss: 0.7184528112411499, Training Acc: 59.04%\n",
      "              Val Loss: 0.9601375460624695, Val Acc: 55.43%\n",
      "Epoch: 1266,     Training Loss: 0.8171113729476929, Training Acc: 59.05%\n",
      "              Val Loss: 0.8888309001922607, Val Acc: 55.44%\n",
      "Epoch: 1267,     Training Loss: 0.7179794907569885, Training Acc: 59.05%\n",
      "              Val Loss: 0.963565468788147, Val Acc: 55.44%\n",
      "Epoch: 1268,     Training Loss: 0.7729924917221069, Training Acc: 59.06%\n",
      "              Val Loss: 0.9178796410560608, Val Acc: 55.45%\n",
      "Epoch: 1269,     Training Loss: 0.770353376865387, Training Acc: 59.07%\n",
      "              Val Loss: 0.8775839805603027, Val Acc: 55.45%\n",
      "Epoch: 1270,     Training Loss: 0.7173892855644226, Training Acc: 59.07%\n",
      "              Val Loss: 0.9738385677337646, Val Acc: 55.45%\n",
      "Epoch: 1271,     Training Loss: 0.7761424779891968, Training Acc: 59.08%\n",
      "              Val Loss: 0.8925434947013855, Val Acc: 55.46%\n",
      "Epoch: 1272,     Training Loss: 0.7427183389663696, Training Acc: 59.09%\n",
      "              Val Loss: 0.8632632493972778, Val Acc: 55.47%\n",
      "Epoch: 1273,     Training Loss: 0.7163657546043396, Training Acc: 59.09%\n",
      "              Val Loss: 0.9427904486656189, Val Acc: 55.47%\n",
      "Epoch: 1274,     Training Loss: 0.7583298683166504, Training Acc: 59.10%\n",
      "              Val Loss: 0.9194793701171875, Val Acc: 55.48%\n",
      "Epoch: 1275,     Training Loss: 0.7683269381523132, Training Acc: 59.11%\n",
      "              Val Loss: 0.8483532667160034, Val Acc: 55.49%\n",
      "Epoch: 1276,     Training Loss: 0.6899296045303345, Training Acc: 59.12%\n",
      "              Val Loss: 1.0323870182037354, Val Acc: 55.49%\n",
      "Epoch: 1277,     Training Loss: 0.8099822402000427, Training Acc: 59.12%\n",
      "              Val Loss: 0.9117210507392883, Val Acc: 55.50%\n",
      "Epoch: 1278,     Training Loss: 0.7559406757354736, Training Acc: 59.13%\n",
      "              Val Loss: 0.8813599348068237, Val Acc: 55.51%\n",
      "Epoch: 1279,     Training Loss: 0.7027614712715149, Training Acc: 59.14%\n",
      "              Val Loss: 0.990488588809967, Val Acc: 55.51%\n",
      "Epoch: 1280,     Training Loss: 0.7792852520942688, Training Acc: 59.14%\n",
      "              Val Loss: 0.9280319809913635, Val Acc: 55.51%\n",
      "Epoch: 1281,     Training Loss: 0.7815670967102051, Training Acc: 59.15%\n",
      "              Val Loss: 0.8674668073654175, Val Acc: 55.52%\n",
      "Epoch: 1282,     Training Loss: 0.7036373615264893, Training Acc: 59.16%\n",
      "              Val Loss: 1.0452228784561157, Val Acc: 55.52%\n",
      "Epoch: 1283,     Training Loss: 0.8354238867759705, Training Acc: 59.16%\n",
      "              Val Loss: 0.9618273973464966, Val Acc: 55.52%\n",
      "Epoch: 1284,     Training Loss: 0.8137273192405701, Training Acc: 59.16%\n",
      "              Val Loss: 0.8766745924949646, Val Acc: 55.53%\n",
      "Epoch: 1285,     Training Loss: 0.725598931312561, Training Acc: 59.17%\n",
      "              Val Loss: 1.068804383277893, Val Acc: 55.53%\n",
      "Epoch: 1286,     Training Loss: 0.8647741675376892, Training Acc: 59.17%\n",
      "              Val Loss: 0.9339299201965332, Val Acc: 55.54%\n",
      "Epoch: 1287,     Training Loss: 0.7722102403640747, Training Acc: 59.18%\n",
      "              Val Loss: 0.9100459814071655, Val Acc: 55.54%\n",
      "Epoch: 1288,     Training Loss: 0.7486943602561951, Training Acc: 59.18%\n",
      "              Val Loss: 1.0268776416778564, Val Acc: 55.54%\n",
      "Epoch: 1289,     Training Loss: 0.8294432163238525, Training Acc: 59.19%\n",
      "              Val Loss: 0.8597930073738098, Val Acc: 55.55%\n",
      "Epoch: 1290,     Training Loss: 0.6889858245849609, Training Acc: 59.20%\n",
      "              Val Loss: 0.9237483739852905, Val Acc: 55.56%\n",
      "Epoch: 1291,     Training Loss: 0.7534053921699524, Training Acc: 59.20%\n",
      "              Val Loss: 0.9086921215057373, Val Acc: 55.56%\n",
      "Epoch: 1292,     Training Loss: 0.7172192335128784, Training Acc: 59.21%\n",
      "              Val Loss: 0.8691409230232239, Val Acc: 55.57%\n",
      "Epoch: 1293,     Training Loss: 0.6874398589134216, Training Acc: 59.22%\n",
      "              Val Loss: 0.9007571339607239, Val Acc: 55.58%\n",
      "Epoch: 1294,     Training Loss: 0.7252724170684814, Training Acc: 59.23%\n",
      "              Val Loss: 0.8723902106285095, Val Acc: 55.58%\n",
      "Epoch: 1295,     Training Loss: 0.6806005239486694, Training Acc: 59.24%\n",
      "              Val Loss: 0.8859187960624695, Val Acc: 55.59%\n",
      "Epoch: 1296,     Training Loss: 0.6943181753158569, Training Acc: 59.25%\n",
      "              Val Loss: 0.8844460248947144, Val Acc: 55.60%\n",
      "Epoch: 1297,     Training Loss: 0.7146537899971008, Training Acc: 59.25%\n",
      "              Val Loss: 0.8515539765357971, Val Acc: 55.61%\n",
      "Epoch: 1298,     Training Loss: 0.6714134216308594, Training Acc: 59.26%\n",
      "              Val Loss: 0.9013800621032715, Val Acc: 55.61%\n",
      "Epoch: 1299,     Training Loss: 0.7051516175270081, Training Acc: 59.27%\n",
      "              Val Loss: 0.9013793468475342, Val Acc: 55.62%\n",
      "Epoch: 1300,     Training Loss: 0.7335588335990906, Training Acc: 59.28%\n",
      "              Val Loss: 0.8555777072906494, Val Acc: 55.63%\n",
      "Epoch: 1301,     Training Loss: 0.6731191873550415, Training Acc: 59.29%\n",
      "              Val Loss: 0.9225267171859741, Val Acc: 55.63%\n",
      "Epoch: 1302,     Training Loss: 0.7175993919372559, Training Acc: 59.30%\n",
      "              Val Loss: 0.935899555683136, Val Acc: 55.64%\n",
      "Epoch: 1303,     Training Loss: 0.7632080912590027, Training Acc: 59.30%\n",
      "              Val Loss: 0.8463041186332703, Val Acc: 55.64%\n",
      "Epoch: 1304,     Training Loss: 0.6660598516464233, Training Acc: 59.31%\n",
      "              Val Loss: 0.935157835483551, Val Acc: 55.65%\n",
      "Epoch: 1305,     Training Loss: 0.7357093691825867, Training Acc: 59.32%\n",
      "              Val Loss: 0.9621246457099915, Val Acc: 55.65%\n",
      "Epoch: 1306,     Training Loss: 0.793130099773407, Training Acc: 59.32%\n",
      "              Val Loss: 0.8532076478004456, Val Acc: 55.66%\n",
      "Epoch: 1307,     Training Loss: 0.6710246205329895, Training Acc: 59.33%\n",
      "              Val Loss: 1.0063666105270386, Val Acc: 55.66%\n",
      "Epoch: 1308,     Training Loss: 0.8033103346824646, Training Acc: 59.33%\n",
      "              Val Loss: 1.018845558166504, Val Acc: 55.66%\n",
      "Epoch: 1309,     Training Loss: 0.8527414202690125, Training Acc: 59.34%\n",
      "              Val Loss: 0.8860388398170471, Val Acc: 55.67%\n",
      "Epoch: 1310,     Training Loss: 0.7050637602806091, Training Acc: 59.35%\n",
      "              Val Loss: 1.1390049457550049, Val Acc: 55.67%\n",
      "Epoch: 1311,     Training Loss: 0.9183490872383118, Training Acc: 59.34%\n",
      "              Val Loss: 1.0472936630249023, Val Acc: 55.67%\n",
      "Epoch: 1312,     Training Loss: 0.9013112783432007, Training Acc: 59.34%\n",
      "              Val Loss: 0.9492100477218628, Val Acc: 55.67%\n",
      "Epoch: 1313,     Training Loss: 0.7977390289306641, Training Acc: 59.35%\n",
      "              Val Loss: 1.1887909173965454, Val Acc: 55.67%\n",
      "Epoch: 1314,     Training Loss: 0.9719288349151611, Training Acc: 59.35%\n",
      "              Val Loss: 0.8985742330551147, Val Acc: 55.67%\n",
      "Epoch: 1315,     Training Loss: 0.7306188344955444, Training Acc: 59.35%\n",
      "              Val Loss: 0.9704036712646484, Val Acc: 55.68%\n",
      "Epoch: 1316,     Training Loss: 0.8184276819229126, Training Acc: 59.36%\n",
      "              Val Loss: 0.9320634603500366, Val Acc: 55.68%\n",
      "Epoch: 1317,     Training Loss: 0.7425167560577393, Training Acc: 59.36%\n",
      "              Val Loss: 0.9301140308380127, Val Acc: 55.69%\n",
      "Epoch: 1318,     Training Loss: 0.7297624945640564, Training Acc: 59.37%\n",
      "              Val Loss: 0.9400047063827515, Val Acc: 55.69%\n",
      "Epoch: 1319,     Training Loss: 0.7673645615577698, Training Acc: 59.38%\n",
      "              Val Loss: 0.8742499351501465, Val Acc: 55.70%\n",
      "Epoch: 1320,     Training Loss: 0.6935626864433289, Training Acc: 59.38%\n",
      "              Val Loss: 1.0090861320495605, Val Acc: 55.70%\n",
      "Epoch: 1321,     Training Loss: 0.7944448590278625, Training Acc: 59.39%\n",
      "              Val Loss: 0.9259207248687744, Val Acc: 55.71%\n",
      "Epoch: 1322,     Training Loss: 0.7413988709449768, Training Acc: 59.39%\n",
      "              Val Loss: 0.9043219089508057, Val Acc: 55.71%\n",
      "Epoch: 1323,     Training Loss: 0.7233139872550964, Training Acc: 59.40%\n",
      "              Val Loss: 0.9914743900299072, Val Acc: 55.72%\n",
      "Epoch: 1324,     Training Loss: 0.7836470603942871, Training Acc: 59.40%\n",
      "              Val Loss: 0.8642475605010986, Val Acc: 55.72%\n",
      "Epoch: 1325,     Training Loss: 0.6825127601623535, Training Acc: 59.41%\n",
      "              Val Loss: 0.8943052887916565, Val Acc: 55.73%\n",
      "Epoch: 1326,     Training Loss: 0.7158657908439636, Training Acc: 59.42%\n",
      "              Val Loss: 0.9105840921401978, Val Acc: 55.74%\n",
      "Epoch: 1327,     Training Loss: 0.7111411094665527, Training Acc: 59.43%\n",
      "              Val Loss: 0.8491200804710388, Val Acc: 55.75%\n",
      "Epoch: 1328,     Training Loss: 0.6650041937828064, Training Acc: 59.44%\n",
      "              Val Loss: 0.8846752643585205, Val Acc: 55.76%\n",
      "Epoch: 1329,     Training Loss: 0.7036258578300476, Training Acc: 59.45%\n",
      "              Val Loss: 0.8738550543785095, Val Acc: 55.76%\n",
      "Epoch: 1330,     Training Loss: 0.6744063496589661, Training Acc: 59.46%\n",
      "              Val Loss: 0.8680943846702576, Val Acc: 55.77%\n",
      "Epoch: 1331,     Training Loss: 0.6695920825004578, Training Acc: 59.47%\n",
      "              Val Loss: 0.881702721118927, Val Acc: 55.78%\n",
      "Epoch: 1332,     Training Loss: 0.6969842314720154, Training Acc: 59.48%\n",
      "              Val Loss: 0.8523174524307251, Val Acc: 55.79%\n",
      "Epoch: 1333,     Training Loss: 0.661709725856781, Training Acc: 59.49%\n",
      "              Val Loss: 0.8711446523666382, Val Acc: 55.79%\n",
      "Epoch: 1334,     Training Loss: 0.6758322715759277, Training Acc: 59.49%\n",
      "              Val Loss: 0.8678949475288391, Val Acc: 55.80%\n",
      "Epoch: 1335,     Training Loss: 0.6900179982185364, Training Acc: 59.50%\n",
      "              Val Loss: 0.8421634435653687, Val Acc: 55.81%\n",
      "Epoch: 1336,     Training Loss: 0.6550419330596924, Training Acc: 59.51%\n",
      "              Val Loss: 0.8776348829269409, Val Acc: 55.82%\n",
      "Epoch: 1337,     Training Loss: 0.6782267093658447, Training Acc: 59.52%\n",
      "              Val Loss: 0.8759218454360962, Val Acc: 55.83%\n",
      "Epoch: 1338,     Training Loss: 0.6899272799491882, Training Acc: 59.53%\n",
      "              Val Loss: 0.8500633239746094, Val Acc: 55.84%\n",
      "Epoch: 1339,     Training Loss: 0.6544075608253479, Training Acc: 59.54%\n",
      "              Val Loss: 0.8917278051376343, Val Acc: 55.84%\n",
      "Epoch: 1340,     Training Loss: 0.6824876666069031, Training Acc: 59.55%\n",
      "              Val Loss: 0.8924522995948792, Val Acc: 55.85%\n",
      "Epoch: 1341,     Training Loss: 0.7003689408302307, Training Acc: 59.56%\n",
      "              Val Loss: 0.8507815599441528, Val Acc: 55.86%\n",
      "Epoch: 1342,     Training Loss: 0.6536829471588135, Training Acc: 59.57%\n",
      "              Val Loss: 0.8882924914360046, Val Acc: 55.86%\n",
      "Epoch: 1343,     Training Loss: 0.68682461977005, Training Acc: 59.58%\n",
      "              Val Loss: 0.8959412574768066, Val Acc: 55.87%\n",
      "Epoch: 1344,     Training Loss: 0.7085058689117432, Training Acc: 59.59%\n",
      "              Val Loss: 0.8503100872039795, Val Acc: 55.88%\n",
      "Epoch: 1345,     Training Loss: 0.6528759002685547, Training Acc: 59.60%\n",
      "              Val Loss: 0.8916934132575989, Val Acc: 55.89%\n",
      "Epoch: 1346,     Training Loss: 0.6914684176445007, Training Acc: 59.60%\n",
      "              Val Loss: 0.9004763960838318, Val Acc: 55.89%\n",
      "Epoch: 1347,     Training Loss: 0.7156819105148315, Training Acc: 59.61%\n",
      "              Val Loss: 0.8536213636398315, Val Acc: 55.90%\n",
      "Epoch: 1348,     Training Loss: 0.6537677049636841, Training Acc: 59.62%\n",
      "              Val Loss: 0.902601957321167, Val Acc: 55.91%\n",
      "Epoch: 1349,     Training Loss: 0.6960981488227844, Training Acc: 59.63%\n",
      "              Val Loss: 0.9155043959617615, Val Acc: 55.92%\n",
      "Epoch: 1350,     Training Loss: 0.7307309508323669, Training Acc: 59.64%\n",
      "              Val Loss: 0.8489741683006287, Val Acc: 55.93%\n",
      "Epoch: 1351,     Training Loss: 0.6498314738273621, Training Acc: 59.65%\n",
      "              Val Loss: 0.9243513345718384, Val Acc: 55.93%\n",
      "Epoch: 1352,     Training Loss: 0.7118949890136719, Training Acc: 59.65%\n",
      "              Val Loss: 0.945283055305481, Val Acc: 55.93%\n",
      "Epoch: 1353,     Training Loss: 0.7633503079414368, Training Acc: 59.66%\n",
      "              Val Loss: 0.8455712199211121, Val Acc: 55.94%\n",
      "Epoch: 1354,     Training Loss: 0.6484813690185547, Training Acc: 59.67%\n",
      "              Val Loss: 0.9897243976593018, Val Acc: 55.94%\n",
      "Epoch: 1355,     Training Loss: 0.764738142490387, Training Acc: 59.67%\n",
      "              Val Loss: 1.0140002965927124, Val Acc: 55.94%\n",
      "Epoch: 1356,     Training Loss: 0.8350273966789246, Training Acc: 59.68%\n",
      "              Val Loss: 0.8529078960418701, Val Acc: 55.95%\n",
      "Epoch: 1357,     Training Loss: 0.6646111011505127, Training Acc: 59.69%\n",
      "              Val Loss: 1.1286336183547974, Val Acc: 55.95%\n",
      "Epoch: 1358,     Training Loss: 0.9010685086250305, Training Acc: 59.68%\n",
      "              Val Loss: 1.0829157829284668, Val Acc: 55.95%\n",
      "Epoch: 1359,     Training Loss: 0.9141162037849426, Training Acc: 59.68%\n",
      "              Val Loss: 0.9360959529876709, Val Acc: 55.96%\n",
      "Epoch: 1360,     Training Loss: 0.7621350884437561, Training Acc: 59.69%\n",
      "              Val Loss: 1.2584657669067383, Val Acc: 55.95%\n",
      "Epoch: 1361,     Training Loss: 1.0242407321929932, Training Acc: 59.68%\n",
      "              Val Loss: 0.9406184554100037, Val Acc: 55.95%\n",
      "Epoch: 1362,     Training Loss: 0.7655454277992249, Training Acc: 59.69%\n",
      "              Val Loss: 1.0247743129730225, Val Acc: 55.96%\n",
      "Epoch: 1363,     Training Loss: 0.8525810837745667, Training Acc: 59.69%\n",
      "              Val Loss: 0.9538574814796448, Val Acc: 55.96%\n",
      "Epoch: 1364,     Training Loss: 0.7524376511573792, Training Acc: 59.70%\n",
      "              Val Loss: 0.925353467464447, Val Acc: 55.96%\n",
      "Epoch: 1365,     Training Loss: 0.7258093357086182, Training Acc: 59.70%\n",
      "              Val Loss: 0.9726791977882385, Val Acc: 55.97%\n",
      "Epoch: 1366,     Training Loss: 0.7967309355735779, Training Acc: 59.71%\n",
      "              Val Loss: 0.8889987468719482, Val Acc: 55.98%\n",
      "Epoch: 1367,     Training Loss: 0.7009226083755493, Training Acc: 59.71%\n",
      "              Val Loss: 1.0597374439239502, Val Acc: 55.97%\n",
      "Epoch: 1368,     Training Loss: 0.8378735184669495, Training Acc: 59.71%\n",
      "              Val Loss: 0.8941496014595032, Val Acc: 55.98%\n",
      "Epoch: 1369,     Training Loss: 0.7096119523048401, Training Acc: 59.72%\n",
      "              Val Loss: 0.929820716381073, Val Acc: 55.99%\n",
      "Epoch: 1370,     Training Loss: 0.7477713227272034, Training Acc: 59.73%\n",
      "              Val Loss: 0.9401476383209229, Val Acc: 55.99%\n",
      "Epoch: 1371,     Training Loss: 0.7262346148490906, Training Acc: 59.73%\n",
      "              Val Loss: 0.866004228591919, Val Acc: 56.00%\n",
      "Epoch: 1372,     Training Loss: 0.6660423278808594, Training Acc: 59.74%\n",
      "              Val Loss: 0.9054562449455261, Val Acc: 56.00%\n",
      "Epoch: 1373,     Training Loss: 0.7181138396263123, Training Acc: 59.75%\n",
      "              Val Loss: 0.8732481598854065, Val Acc: 56.01%\n",
      "Epoch: 1374,     Training Loss: 0.6624775528907776, Training Acc: 59.76%\n",
      "              Val Loss: 0.9291494488716125, Val Acc: 56.02%\n",
      "Epoch: 1375,     Training Loss: 0.708199679851532, Training Acc: 59.77%\n",
      "              Val Loss: 0.9083226919174194, Val Acc: 56.02%\n",
      "Epoch: 1376,     Training Loss: 0.713619589805603, Training Acc: 59.77%\n",
      "              Val Loss: 0.8708367943763733, Val Acc: 56.03%\n",
      "Epoch: 1377,     Training Loss: 0.6658681631088257, Training Acc: 59.78%\n",
      "              Val Loss: 0.9537102580070496, Val Acc: 56.03%\n",
      "Epoch: 1378,     Training Loss: 0.7293819189071655, Training Acc: 59.79%\n",
      "              Val Loss: 0.895642101764679, Val Acc: 56.04%\n",
      "Epoch: 1379,     Training Loss: 0.7017483711242676, Training Acc: 59.80%\n",
      "              Val Loss: 0.853283166885376, Val Acc: 56.05%\n",
      "Epoch: 1380,     Training Loss: 0.6592255234718323, Training Acc: 59.81%\n",
      "              Val Loss: 0.9448977708816528, Val Acc: 56.05%\n",
      "Epoch: 1381,     Training Loss: 0.727185070514679, Training Acc: 59.81%\n",
      "              Val Loss: 0.8795346617698669, Val Acc: 56.06%\n",
      "Epoch: 1382,     Training Loss: 0.6860811114311218, Training Acc: 59.82%\n",
      "              Val Loss: 0.8546715378761292, Val Acc: 56.07%\n",
      "Epoch: 1383,     Training Loss: 0.6563868522644043, Training Acc: 59.83%\n",
      "              Val Loss: 0.9404697418212891, Val Acc: 56.07%\n",
      "Epoch: 1384,     Training Loss: 0.7208030223846436, Training Acc: 59.84%\n",
      "              Val Loss: 0.8781932592391968, Val Acc: 56.08%\n",
      "Epoch: 1385,     Training Loss: 0.6772735714912415, Training Acc: 59.85%\n",
      "              Val Loss: 0.8606829643249512, Val Acc: 56.09%\n",
      "Epoch: 1386,     Training Loss: 0.6557798981666565, Training Acc: 59.86%\n",
      "              Val Loss: 0.9347086548805237, Val Acc: 56.10%\n",
      "Epoch: 1387,     Training Loss: 0.7123420238494873, Training Acc: 59.86%\n",
      "              Val Loss: 0.8740429878234863, Val Acc: 56.10%\n",
      "Epoch: 1388,     Training Loss: 0.6730273962020874, Training Acc: 59.87%\n",
      "              Val Loss: 0.8605515956878662, Val Acc: 56.11%\n",
      "Epoch: 1389,     Training Loss: 0.6554300785064697, Training Acc: 59.88%\n",
      "              Val Loss: 0.9270522594451904, Val Acc: 56.12%\n",
      "Epoch: 1390,     Training Loss: 0.7048375010490417, Training Acc: 59.89%\n",
      "              Val Loss: 0.8717814683914185, Val Acc: 56.12%\n",
      "Epoch: 1391,     Training Loss: 0.6700829267501831, Training Acc: 59.90%\n",
      "              Val Loss: 0.8588234186172485, Val Acc: 56.13%\n",
      "Epoch: 1392,     Training Loss: 0.6545963287353516, Training Acc: 59.91%\n",
      "              Val Loss: 0.9239541888237, Val Acc: 56.14%\n",
      "Epoch: 1393,     Training Loss: 0.701191782951355, Training Acc: 59.91%\n",
      "              Val Loss: 0.8765571713447571, Val Acc: 56.14%\n",
      "Epoch: 1394,     Training Loss: 0.6726006269454956, Training Acc: 59.92%\n",
      "              Val Loss: 0.8543023467063904, Val Acc: 56.15%\n",
      "Epoch: 1395,     Training Loss: 0.6486936807632446, Training Acc: 59.93%\n",
      "              Val Loss: 0.9212315082550049, Val Acc: 56.16%\n",
      "Epoch: 1396,     Training Loss: 0.6970937848091125, Training Acc: 59.94%\n",
      "              Val Loss: 0.8811218738555908, Val Acc: 56.16%\n",
      "Epoch: 1397,     Training Loss: 0.6750762462615967, Training Acc: 59.95%\n",
      "              Val Loss: 0.8507742881774902, Val Acc: 56.17%\n",
      "Epoch: 1398,     Training Loss: 0.6434952020645142, Training Acc: 59.96%\n",
      "              Val Loss: 0.9195227026939392, Val Acc: 56.18%\n",
      "Epoch: 1399,     Training Loss: 0.6967306733131409, Training Acc: 59.97%\n",
      "              Val Loss: 0.8817288875579834, Val Acc: 56.19%\n",
      "Epoch: 1400,     Training Loss: 0.678236722946167, Training Acc: 59.97%\n",
      "              Val Loss: 0.8447409868240356, Val Acc: 56.20%\n",
      "Epoch: 1401,     Training Loss: 0.6382198929786682, Training Acc: 59.99%\n",
      "              Val Loss: 0.918062150478363, Val Acc: 56.20%\n",
      "Epoch: 1402,     Training Loss: 0.6961129903793335, Training Acc: 59.99%\n",
      "              Val Loss: 0.8852527737617493, Val Acc: 56.21%\n",
      "Epoch: 1403,     Training Loss: 0.6839013695716858, Training Acc: 60.00%\n",
      "              Val Loss: 0.8437783122062683, Val Acc: 56.22%\n",
      "Epoch: 1404,     Training Loss: 0.6357441544532776, Training Acc: 60.01%\n",
      "              Val Loss: 0.9271104335784912, Val Acc: 56.22%\n",
      "Epoch: 1405,     Training Loss: 0.6995522379875183, Training Acc: 60.02%\n",
      "              Val Loss: 0.8976081013679504, Val Acc: 56.23%\n",
      "Epoch: 1406,     Training Loss: 0.6955887079238892, Training Acc: 60.02%\n",
      "              Val Loss: 0.84348464012146, Val Acc: 56.24%\n",
      "Epoch: 1407,     Training Loss: 0.6342242956161499, Training Acc: 60.03%\n",
      "              Val Loss: 0.9396539926528931, Val Acc: 56.24%\n",
      "Epoch: 1408,     Training Loss: 0.709200382232666, Training Acc: 60.04%\n",
      "              Val Loss: 0.9163411855697632, Val Acc: 56.25%\n",
      "Epoch: 1409,     Training Loss: 0.714257001876831, Training Acc: 60.05%\n",
      "              Val Loss: 0.8470330238342285, Val Acc: 56.25%\n",
      "Epoch: 1410,     Training Loss: 0.6370513439178467, Training Acc: 60.06%\n",
      "              Val Loss: 0.9613489508628845, Val Acc: 56.25%\n",
      "Epoch: 1411,     Training Loss: 0.7286562323570251, Training Acc: 60.06%\n",
      "              Val Loss: 0.9437662363052368, Val Acc: 56.26%\n",
      "Epoch: 1412,     Training Loss: 0.7426502108573914, Training Acc: 60.07%\n",
      "              Val Loss: 0.8692172169685364, Val Acc: 56.27%\n",
      "Epoch: 1413,     Training Loss: 0.6507298946380615, Training Acc: 60.08%\n",
      "              Val Loss: 1.0102540254592896, Val Acc: 56.27%\n",
      "Epoch: 1414,     Training Loss: 0.7717168927192688, Training Acc: 60.08%\n",
      "              Val Loss: 0.9919866919517517, Val Acc: 56.27%\n",
      "Epoch: 1415,     Training Loss: 0.7891347408294678, Training Acc: 60.08%\n",
      "              Val Loss: 0.8832602500915527, Val Acc: 56.28%\n",
      "Epoch: 1416,     Training Loss: 0.6641262173652649, Training Acc: 60.09%\n",
      "              Val Loss: 1.1028996706008911, Val Acc: 56.28%\n",
      "Epoch: 1417,     Training Loss: 0.8488026261329651, Training Acc: 60.09%\n",
      "              Val Loss: 0.9947965145111084, Val Acc: 56.28%\n",
      "Epoch: 1418,     Training Loss: 0.7944667935371399, Training Acc: 60.10%\n",
      "              Val Loss: 0.9029677510261536, Val Acc: 56.29%\n",
      "Epoch: 1419,     Training Loss: 0.6962045431137085, Training Acc: 60.10%\n",
      "              Val Loss: 1.1294173002243042, Val Acc: 56.28%\n",
      "Epoch: 1420,     Training Loss: 0.8796667456626892, Training Acc: 60.10%\n",
      "              Val Loss: 0.927467942237854, Val Acc: 56.29%\n",
      "Epoch: 1421,     Training Loss: 0.732161283493042, Training Acc: 60.11%\n",
      "              Val Loss: 0.9377706050872803, Val Acc: 56.30%\n",
      "Epoch: 1422,     Training Loss: 0.7382084131240845, Training Acc: 60.11%\n",
      "              Val Loss: 1.0209990739822388, Val Acc: 56.30%\n",
      "Epoch: 1423,     Training Loss: 0.7833333015441895, Training Acc: 60.12%\n",
      "              Val Loss: 0.8570339679718018, Val Acc: 56.30%\n",
      "Epoch: 1424,     Training Loss: 0.6454212069511414, Training Acc: 60.13%\n",
      "              Val Loss: 0.9306671619415283, Val Acc: 56.31%\n",
      "Epoch: 1425,     Training Loss: 0.7233490943908691, Training Acc: 60.13%\n",
      "              Val Loss: 0.8779436349868774, Val Acc: 56.32%\n",
      "Epoch: 1426,     Training Loss: 0.654237687587738, Training Acc: 60.14%\n",
      "              Val Loss: 0.903221070766449, Val Acc: 56.32%\n",
      "Epoch: 1427,     Training Loss: 0.672788679599762, Training Acc: 60.15%\n",
      "              Val Loss: 0.9057363867759705, Val Acc: 56.33%\n",
      "Epoch: 1428,     Training Loss: 0.6936743855476379, Training Acc: 60.15%\n",
      "              Val Loss: 0.8630167245864868, Val Acc: 56.34%\n",
      "Epoch: 1429,     Training Loss: 0.6434220671653748, Training Acc: 60.16%\n",
      "              Val Loss: 0.9464345574378967, Val Acc: 56.34%\n",
      "Epoch: 1430,     Training Loss: 0.7035158276557922, Training Acc: 60.17%\n",
      "              Val Loss: 0.9008879065513611, Val Acc: 56.35%\n",
      "Epoch: 1431,     Training Loss: 0.6850128173828125, Training Acc: 60.18%\n",
      "              Val Loss: 0.8715555667877197, Val Acc: 56.35%\n",
      "Epoch: 1432,     Training Loss: 0.6517701148986816, Training Acc: 60.19%\n",
      "              Val Loss: 0.9437332153320312, Val Acc: 56.36%\n",
      "Epoch: 1433,     Training Loss: 0.7065325379371643, Training Acc: 60.19%\n",
      "              Val Loss: 0.904453456401825, Val Acc: 56.36%\n",
      "Epoch: 1434,     Training Loss: 0.6839402914047241, Training Acc: 60.20%\n",
      "              Val Loss: 0.8664584159851074, Val Acc: 56.37%\n",
      "Epoch: 1435,     Training Loss: 0.6427755951881409, Training Acc: 60.21%\n",
      "              Val Loss: 0.9535694122314453, Val Acc: 56.38%\n",
      "Epoch: 1436,     Training Loss: 0.7132824659347534, Training Acc: 60.22%\n",
      "              Val Loss: 0.8981344103813171, Val Acc: 56.39%\n",
      "Epoch: 1437,     Training Loss: 0.6744709610939026, Training Acc: 60.23%\n",
      "              Val Loss: 0.871529757976532, Val Acc: 56.39%\n",
      "Epoch: 1438,     Training Loss: 0.6449087262153625, Training Acc: 60.24%\n",
      "              Val Loss: 0.9368093013763428, Val Acc: 56.40%\n",
      "Epoch: 1439,     Training Loss: 0.7029175758361816, Training Acc: 60.24%\n",
      "              Val Loss: 0.8760714530944824, Val Acc: 56.41%\n",
      "Epoch: 1440,     Training Loss: 0.6584894061088562, Training Acc: 60.25%\n",
      "              Val Loss: 0.8646074533462524, Val Acc: 56.42%\n",
      "Epoch: 1441,     Training Loss: 0.6404477953910828, Training Acc: 60.26%\n",
      "              Val Loss: 0.9106701612472534, Val Acc: 56.42%\n",
      "Epoch: 1442,     Training Loss: 0.6785948276519775, Training Acc: 60.27%\n",
      "              Val Loss: 0.8700439929962158, Val Acc: 56.43%\n",
      "Epoch: 1443,     Training Loss: 0.6544559001922607, Training Acc: 60.28%\n",
      "              Val Loss: 0.8636695146560669, Val Acc: 56.44%\n",
      "Epoch: 1444,     Training Loss: 0.6351561546325684, Training Acc: 60.29%\n",
      "              Val Loss: 0.9148914217948914, Val Acc: 56.44%\n",
      "Epoch: 1445,     Training Loss: 0.6729996204376221, Training Acc: 60.29%\n",
      "              Val Loss: 0.8777536749839783, Val Acc: 56.45%\n",
      "Epoch: 1446,     Training Loss: 0.6596162915229797, Training Acc: 60.30%\n",
      "              Val Loss: 0.8621662259101868, Val Acc: 56.46%\n",
      "Epoch: 1447,     Training Loss: 0.6314071416854858, Training Acc: 60.31%\n",
      "              Val Loss: 0.9170864820480347, Val Acc: 56.46%\n",
      "Epoch: 1448,     Training Loss: 0.669212818145752, Training Acc: 60.32%\n",
      "              Val Loss: 0.8903836011886597, Val Acc: 56.47%\n",
      "Epoch: 1449,     Training Loss: 0.6645621657371521, Training Acc: 60.33%\n",
      "              Val Loss: 0.8566341400146484, Val Acc: 56.47%\n",
      "Epoch: 1450,     Training Loss: 0.6278465390205383, Training Acc: 60.34%\n",
      "              Val Loss: 0.9073818325996399, Val Acc: 56.48%\n",
      "Epoch: 1451,     Training Loss: 0.6630111932754517, Training Acc: 60.34%\n",
      "              Val Loss: 0.898588240146637, Val Acc: 56.49%\n",
      "Epoch: 1452,     Training Loss: 0.6706741452217102, Training Acc: 60.35%\n",
      "              Val Loss: 0.853273332118988, Val Acc: 56.49%\n",
      "Epoch: 1453,     Training Loss: 0.6242889761924744, Training Acc: 60.36%\n",
      "              Val Loss: 0.8942974805831909, Val Acc: 56.50%\n",
      "Epoch: 1454,     Training Loss: 0.6523871421813965, Training Acc: 60.37%\n",
      "              Val Loss: 0.898995041847229, Val Acc: 56.51%\n",
      "Epoch: 1455,     Training Loss: 0.671370267868042, Training Acc: 60.38%\n",
      "              Val Loss: 0.8521280884742737, Val Acc: 56.51%\n",
      "Epoch: 1456,     Training Loss: 0.6203047037124634, Training Acc: 60.39%\n",
      "              Val Loss: 0.8826202154159546, Val Acc: 56.52%\n",
      "Epoch: 1457,     Training Loss: 0.640787661075592, Training Acc: 60.40%\n",
      "              Val Loss: 0.8921811580657959, Val Acc: 56.53%\n",
      "Epoch: 1458,     Training Loss: 0.6650026440620422, Training Acc: 60.41%\n",
      "              Val Loss: 0.8557443022727966, Val Acc: 56.54%\n",
      "Epoch: 1459,     Training Loss: 0.6223732829093933, Training Acc: 60.42%\n",
      "              Val Loss: 0.8651962876319885, Val Acc: 56.54%\n",
      "Epoch: 1460,     Training Loss: 0.6271577477455139, Training Acc: 60.43%\n",
      "              Val Loss: 0.87744140625, Val Acc: 56.55%\n",
      "Epoch: 1461,     Training Loss: 0.6487499475479126, Training Acc: 60.44%\n",
      "              Val Loss: 0.8638485074043274, Val Acc: 56.56%\n",
      "Epoch: 1462,     Training Loss: 0.6255416870117188, Training Acc: 60.45%\n",
      "              Val Loss: 0.8543062806129456, Val Acc: 56.57%\n",
      "Epoch: 1463,     Training Loss: 0.6160584092140198, Training Acc: 60.46%\n",
      "              Val Loss: 0.8640581369400024, Val Acc: 56.57%\n",
      "Epoch: 1464,     Training Loss: 0.6314936876296997, Training Acc: 60.47%\n",
      "              Val Loss: 0.8706281781196594, Val Acc: 56.58%\n",
      "Epoch: 1465,     Training Loss: 0.6278343796730042, Training Acc: 60.48%\n",
      "              Val Loss: 0.8539057374000549, Val Acc: 56.59%\n",
      "Epoch: 1466,     Training Loss: 0.6139018535614014, Training Acc: 60.49%\n",
      "              Val Loss: 0.8545510768890381, Val Acc: 56.60%\n",
      "Epoch: 1467,     Training Loss: 0.6168017387390137, Training Acc: 60.50%\n",
      "              Val Loss: 0.8684651851654053, Val Acc: 56.61%\n",
      "Epoch: 1468,     Training Loss: 0.6257018446922302, Training Acc: 60.51%\n",
      "              Val Loss: 0.8644935488700867, Val Acc: 56.62%\n",
      "Epoch: 1469,     Training Loss: 0.6240565180778503, Training Acc: 60.52%\n",
      "              Val Loss: 0.8599352240562439, Val Acc: 56.62%\n",
      "Epoch: 1470,     Training Loss: 0.6152363419532776, Training Acc: 60.53%\n",
      "              Val Loss: 0.859514057636261, Val Acc: 56.63%\n",
      "Epoch: 1471,     Training Loss: 0.6173959970474243, Training Acc: 60.54%\n",
      "              Val Loss: 0.8752729296684265, Val Acc: 56.64%\n",
      "Epoch: 1472,     Training Loss: 0.6297825574874878, Training Acc: 60.55%\n",
      "              Val Loss: 0.8742969632148743, Val Acc: 56.65%\n",
      "Epoch: 1473,     Training Loss: 0.6233710050582886, Training Acc: 60.56%\n",
      "              Val Loss: 0.8541092872619629, Val Acc: 56.66%\n",
      "Epoch: 1474,     Training Loss: 0.6167404055595398, Training Acc: 60.57%\n",
      "              Val Loss: 0.8627377152442932, Val Acc: 56.66%\n",
      "Epoch: 1475,     Training Loss: 0.6158074736595154, Training Acc: 60.58%\n",
      "              Val Loss: 0.8786319494247437, Val Acc: 56.67%\n",
      "Epoch: 1476,     Training Loss: 0.6241304278373718, Training Acc: 60.59%\n",
      "              Val Loss: 0.8646951913833618, Val Acc: 56.68%\n",
      "Epoch: 1477,     Training Loss: 0.6290149092674255, Training Acc: 60.60%\n",
      "              Val Loss: 0.8584488034248352, Val Acc: 56.69%\n",
      "Epoch: 1478,     Training Loss: 0.6102802157402039, Training Acc: 60.61%\n",
      "              Val Loss: 0.8691531419754028, Val Acc: 56.70%\n",
      "Epoch: 1479,     Training Loss: 0.613588273525238, Training Acc: 60.62%\n",
      "              Val Loss: 0.8611207604408264, Val Acc: 56.70%\n",
      "Epoch: 1480,     Training Loss: 0.621084988117218, Training Acc: 60.63%\n",
      "              Val Loss: 0.8687777519226074, Val Acc: 56.71%\n",
      "Epoch: 1481,     Training Loss: 0.6197367906570435, Training Acc: 60.64%\n",
      "              Val Loss: 0.8749427199363708, Val Acc: 56.72%\n",
      "Epoch: 1482,     Training Loss: 0.6224133968353271, Training Acc: 60.65%\n",
      "              Val Loss: 0.8542317152023315, Val Acc: 56.73%\n",
      "Epoch: 1483,     Training Loss: 0.6059576272964478, Training Acc: 60.66%\n",
      "              Val Loss: 0.8630280494689941, Val Acc: 56.74%\n",
      "Epoch: 1484,     Training Loss: 0.6156968474388123, Training Acc: 60.67%\n",
      "              Val Loss: 0.88580322265625, Val Acc: 56.74%\n",
      "Epoch: 1485,     Training Loss: 0.6309373378753662, Training Acc: 60.68%\n",
      "              Val Loss: 0.8788564205169678, Val Acc: 56.75%\n",
      "Epoch: 1486,     Training Loss: 0.6203429698944092, Training Acc: 60.69%\n",
      "              Val Loss: 0.8703428506851196, Val Acc: 56.76%\n",
      "Epoch: 1487,     Training Loss: 0.6276623010635376, Training Acc: 60.69%\n",
      "              Val Loss: 0.8693939447402954, Val Acc: 56.77%\n",
      "Epoch: 1488,     Training Loss: 0.609464168548584, Training Acc: 60.70%\n",
      "              Val Loss: 0.8882675170898438, Val Acc: 56.77%\n",
      "Epoch: 1489,     Training Loss: 0.6242964267730713, Training Acc: 60.71%\n",
      "              Val Loss: 0.8873441815376282, Val Acc: 56.78%\n",
      "Epoch: 1490,     Training Loss: 0.6516758799552917, Training Acc: 60.72%\n",
      "              Val Loss: 0.8679691553115845, Val Acc: 56.79%\n",
      "Epoch: 1491,     Training Loss: 0.6124361157417297, Training Acc: 60.73%\n",
      "              Val Loss: 0.8921239972114563, Val Acc: 56.80%\n",
      "Epoch: 1492,     Training Loss: 0.6262136101722717, Training Acc: 60.74%\n",
      "              Val Loss: 0.8565959930419922, Val Acc: 56.81%\n",
      "Epoch: 1493,     Training Loss: 0.608013391494751, Training Acc: 60.75%\n",
      "              Val Loss: 0.8844642639160156, Val Acc: 56.81%\n",
      "Epoch: 1494,     Training Loss: 0.6317289471626282, Training Acc: 60.76%\n",
      "              Val Loss: 0.9318975210189819, Val Acc: 56.82%\n",
      "Epoch: 1495,     Training Loss: 0.6691794395446777, Training Acc: 60.77%\n",
      "              Val Loss: 0.8961339592933655, Val Acc: 56.83%\n",
      "Epoch: 1496,     Training Loss: 0.6296007037162781, Training Acc: 60.78%\n",
      "              Val Loss: 0.9056196808815002, Val Acc: 56.83%\n",
      "Epoch: 1497,     Training Loss: 0.667584240436554, Training Acc: 60.78%\n",
      "              Val Loss: 0.8897994160652161, Val Acc: 56.84%\n",
      "Epoch: 1498,     Training Loss: 0.6298305988311768, Training Acc: 60.79%\n",
      "              Val Loss: 0.9922215938568115, Val Acc: 56.84%\n",
      "Epoch: 1499,     Training Loss: 0.7111544609069824, Training Acc: 60.80%\n",
      "              Val Loss: 1.011976957321167, Val Acc: 56.84%\n",
      "Epoch: 1500,     Training Loss: 0.7906818985939026, Training Acc: 60.80%\n",
      "              Val Loss: 0.9404968023300171, Val Acc: 56.85%\n",
      "Epoch: 1501,     Training Loss: 0.6899784803390503, Training Acc: 60.80%\n",
      "              Val Loss: 1.0473580360412598, Val Acc: 56.85%\n",
      "Epoch: 1502,     Training Loss: 0.7581366896629333, Training Acc: 60.81%\n",
      "              Val Loss: 1.080937147140503, Val Acc: 56.85%\n",
      "Epoch: 1503,     Training Loss: 0.8247562646865845, Training Acc: 60.81%\n",
      "              Val Loss: 1.0696614980697632, Val Acc: 56.85%\n",
      "Epoch: 1504,     Training Loss: 0.8024441599845886, Training Acc: 60.81%\n",
      "              Val Loss: 0.9620115756988525, Val Acc: 56.86%\n",
      "Epoch: 1505,     Training Loss: 0.6942980885505676, Training Acc: 60.82%\n",
      "              Val Loss: 0.9860790371894836, Val Acc: 56.86%\n",
      "Epoch: 1506,     Training Loss: 0.7115638256072998, Training Acc: 60.83%\n",
      "              Val Loss: 0.9664495587348938, Val Acc: 56.87%\n",
      "Epoch: 1507,     Training Loss: 0.6970465779304504, Training Acc: 60.83%\n",
      "              Val Loss: 0.9714030623435974, Val Acc: 56.87%\n",
      "Epoch: 1508,     Training Loss: 0.7275922894477844, Training Acc: 60.84%\n",
      "              Val Loss: 0.8658907413482666, Val Acc: 56.88%\n",
      "Epoch: 1509,     Training Loss: 0.6150176525115967, Training Acc: 60.84%\n",
      "              Val Loss: 0.9560560584068298, Val Acc: 56.88%\n",
      "Epoch: 1510,     Training Loss: 0.6867552995681763, Training Acc: 60.85%\n",
      "              Val Loss: 0.9790071249008179, Val Acc: 56.89%\n",
      "Epoch: 1511,     Training Loss: 0.7471644878387451, Training Acc: 60.85%\n",
      "              Val Loss: 0.935983419418335, Val Acc: 56.89%\n",
      "Epoch: 1512,     Training Loss: 0.6743689179420471, Training Acc: 60.86%\n",
      "              Val Loss: 0.9148757457733154, Val Acc: 56.90%\n",
      "Epoch: 1513,     Training Loss: 0.655562162399292, Training Acc: 60.87%\n",
      "              Val Loss: 1.0422391891479492, Val Acc: 56.90%\n",
      "Epoch: 1514,     Training Loss: 0.7870393395423889, Training Acc: 60.87%\n",
      "              Val Loss: 0.9611430168151855, Val Acc: 56.90%\n",
      "Epoch: 1515,     Training Loss: 0.6784115433692932, Training Acc: 60.88%\n",
      "              Val Loss: 0.9442216753959656, Val Acc: 56.91%\n",
      "Epoch: 1516,     Training Loss: 0.6610047817230225, Training Acc: 60.89%\n",
      "              Val Loss: 0.8908887505531311, Val Acc: 56.92%\n",
      "Epoch: 1517,     Training Loss: 0.6534045934677124, Training Acc: 60.90%\n",
      "              Val Loss: 0.9429154396057129, Val Acc: 56.92%\n",
      "Epoch: 1518,     Training Loss: 0.673450767993927, Training Acc: 60.90%\n",
      "              Val Loss: 0.9112118482589722, Val Acc: 56.93%\n",
      "Epoch: 1519,     Training Loss: 0.6510486006736755, Training Acc: 60.91%\n",
      "              Val Loss: 0.8825030326843262, Val Acc: 56.94%\n",
      "Epoch: 1520,     Training Loss: 0.6141785979270935, Training Acc: 60.92%\n",
      "              Val Loss: 0.858691394329071, Val Acc: 56.95%\n",
      "Epoch: 1521,     Training Loss: 0.6126238107681274, Training Acc: 60.93%\n",
      "              Val Loss: 0.8652673363685608, Val Acc: 56.95%\n",
      "Epoch: 1522,     Training Loss: 0.6160820126533508, Training Acc: 60.94%\n",
      "              Val Loss: 0.921537458896637, Val Acc: 56.96%\n",
      "Epoch: 1523,     Training Loss: 0.635324239730835, Training Acc: 60.95%\n",
      "              Val Loss: 0.8760927319526672, Val Acc: 56.97%\n",
      "Epoch: 1524,     Training Loss: 0.6124246716499329, Training Acc: 60.96%\n",
      "              Val Loss: 0.8762767314910889, Val Acc: 56.98%\n",
      "Epoch: 1525,     Training Loss: 0.6073354482650757, Training Acc: 60.97%\n",
      "              Val Loss: 0.8732478618621826, Val Acc: 56.99%\n",
      "Epoch: 1526,     Training Loss: 0.5990763306617737, Training Acc: 60.98%\n",
      "              Val Loss: 0.8582125306129456, Val Acc: 56.99%\n",
      "Epoch: 1527,     Training Loss: 0.596925675868988, Training Acc: 60.99%\n",
      "              Val Loss: 0.8715196847915649, Val Acc: 57.00%\n",
      "Epoch: 1528,     Training Loss: 0.6124700307846069, Training Acc: 61.00%\n",
      "              Val Loss: 0.8714462518692017, Val Acc: 57.01%\n",
      "Epoch: 1529,     Training Loss: 0.6200964450836182, Training Acc: 61.00%\n",
      "              Val Loss: 0.880439281463623, Val Acc: 57.02%\n",
      "Epoch: 1530,     Training Loss: 0.6191805005073547, Training Acc: 61.01%\n",
      "              Val Loss: 0.8621863722801208, Val Acc: 57.03%\n",
      "Epoch: 1531,     Training Loss: 0.6200016140937805, Training Acc: 61.02%\n",
      "              Val Loss: 0.8547534942626953, Val Acc: 57.03%\n",
      "Epoch: 1532,     Training Loss: 0.597698450088501, Training Acc: 61.03%\n",
      "              Val Loss: 0.8518481254577637, Val Acc: 57.04%\n",
      "Epoch: 1533,     Training Loss: 0.5964361429214478, Training Acc: 61.04%\n",
      "              Val Loss: 0.8353555798530579, Val Acc: 57.05%\n",
      "Epoch: 1534,     Training Loss: 0.592275857925415, Training Acc: 61.05%\n",
      "              Val Loss: 0.8471444845199585, Val Acc: 57.06%\n",
      "Epoch: 1535,     Training Loss: 0.5950347781181335, Training Acc: 61.06%\n",
      "              Val Loss: 0.8693017363548279, Val Acc: 57.07%\n",
      "Epoch: 1536,     Training Loss: 0.610711395740509, Training Acc: 61.07%\n",
      "              Val Loss: 0.8661330938339233, Val Acc: 57.07%\n",
      "Epoch: 1537,     Training Loss: 0.6060186624526978, Training Acc: 61.08%\n",
      "              Val Loss: 0.8692269325256348, Val Acc: 57.08%\n",
      "Epoch: 1538,     Training Loss: 0.6235620975494385, Training Acc: 61.09%\n",
      "              Val Loss: 0.8816073536872864, Val Acc: 57.09%\n",
      "Epoch: 1539,     Training Loss: 0.6153188943862915, Training Acc: 61.10%\n",
      "              Val Loss: 0.8835067749023438, Val Acc: 57.10%\n",
      "Epoch: 1540,     Training Loss: 0.6274212002754211, Training Acc: 61.11%\n",
      "              Val Loss: 0.8785251379013062, Val Acc: 57.10%\n",
      "Epoch: 1541,     Training Loss: 0.6196382641792297, Training Acc: 61.11%\n",
      "              Val Loss: 0.8734332919120789, Val Acc: 57.11%\n",
      "Epoch: 1542,     Training Loss: 0.6240997314453125, Training Acc: 61.12%\n",
      "              Val Loss: 0.88420569896698, Val Acc: 57.11%\n",
      "Epoch: 1543,     Training Loss: 0.6179313063621521, Training Acc: 61.13%\n",
      "              Val Loss: 0.8731446266174316, Val Acc: 57.12%\n",
      "Epoch: 1544,     Training Loss: 0.6178672313690186, Training Acc: 61.14%\n",
      "              Val Loss: 0.8758865594863892, Val Acc: 57.13%\n",
      "Epoch: 1545,     Training Loss: 0.6091623902320862, Training Acc: 61.15%\n",
      "              Val Loss: 0.8756348490715027, Val Acc: 57.14%\n",
      "Epoch: 1546,     Training Loss: 0.6125437021255493, Training Acc: 61.16%\n",
      "              Val Loss: 0.8657872080802917, Val Acc: 57.14%\n",
      "Epoch: 1547,     Training Loss: 0.5970613956451416, Training Acc: 61.17%\n",
      "              Val Loss: 0.8530808091163635, Val Acc: 57.15%\n",
      "Epoch: 1548,     Training Loss: 0.5966489911079407, Training Acc: 61.18%\n",
      "              Val Loss: 0.850517749786377, Val Acc: 57.16%\n",
      "Epoch: 1549,     Training Loss: 0.586142361164093, Training Acc: 61.19%\n",
      "              Val Loss: 0.8450201153755188, Val Acc: 57.17%\n",
      "Epoch: 1550,     Training Loss: 0.5854723453521729, Training Acc: 61.20%\n",
      "              Val Loss: 0.8429296016693115, Val Acc: 57.18%\n",
      "Epoch: 1551,     Training Loss: 0.5830286741256714, Training Acc: 61.21%\n",
      "              Val Loss: 0.846068263053894, Val Acc: 57.19%\n",
      "Epoch: 1552,     Training Loss: 0.5805537104606628, Training Acc: 61.22%\n",
      "              Val Loss: 0.8512104749679565, Val Acc: 57.20%\n",
      "Epoch: 1553,     Training Loss: 0.5807352066040039, Training Acc: 61.23%\n",
      "              Val Loss: 0.8452047109603882, Val Acc: 57.21%\n",
      "Epoch: 1554,     Training Loss: 0.5823790431022644, Training Acc: 61.24%\n",
      "              Val Loss: 0.8525496125221252, Val Acc: 57.21%\n",
      "Epoch: 1555,     Training Loss: 0.583824098110199, Training Acc: 61.25%\n",
      "              Val Loss: 0.8638114929199219, Val Acc: 57.22%\n",
      "Epoch: 1556,     Training Loss: 0.5971458554267883, Training Acc: 61.26%\n",
      "              Val Loss: 0.8868705630302429, Val Acc: 57.23%\n",
      "Epoch: 1557,     Training Loss: 0.6166749596595764, Training Acc: 61.27%\n",
      "              Val Loss: 0.9403040409088135, Val Acc: 57.23%\n",
      "Epoch: 1558,     Training Loss: 0.6843349933624268, Training Acc: 61.27%\n",
      "              Val Loss: 0.9974563717842102, Val Acc: 57.23%\n",
      "Epoch: 1559,     Training Loss: 0.714637041091919, Training Acc: 61.28%\n",
      "              Val Loss: 1.0940773487091064, Val Acc: 57.23%\n",
      "Epoch: 1560,     Training Loss: 0.8466521501541138, Training Acc: 61.28%\n",
      "              Val Loss: 0.897488534450531, Val Acc: 57.24%\n",
      "Epoch: 1561,     Training Loss: 0.6376507878303528, Training Acc: 61.28%\n",
      "              Val Loss: 0.8595545291900635, Val Acc: 57.25%\n",
      "Epoch: 1562,     Training Loss: 0.5960260033607483, Training Acc: 61.29%\n",
      "              Val Loss: 0.9316117167472839, Val Acc: 57.25%\n",
      "Epoch: 1563,     Training Loss: 0.6739603281021118, Training Acc: 61.30%\n",
      "              Val Loss: 0.9613338708877563, Val Acc: 57.25%\n",
      "Epoch: 1564,     Training Loss: 0.6863152384757996, Training Acc: 61.30%\n",
      "              Val Loss: 0.9520028829574585, Val Acc: 57.26%\n",
      "Epoch: 1565,     Training Loss: 0.6943539381027222, Training Acc: 61.31%\n",
      "              Val Loss: 0.8715968132019043, Val Acc: 57.27%\n",
      "Epoch: 1566,     Training Loss: 0.6015416383743286, Training Acc: 61.32%\n",
      "              Val Loss: 0.9204389452934265, Val Acc: 57.27%\n",
      "Epoch: 1567,     Training Loss: 0.6494928002357483, Training Acc: 61.32%\n",
      "              Val Loss: 1.0123591423034668, Val Acc: 57.27%\n",
      "Epoch: 1568,     Training Loss: 0.7560727000236511, Training Acc: 61.33%\n",
      "              Val Loss: 0.9523522853851318, Val Acc: 57.28%\n",
      "Epoch: 1569,     Training Loss: 0.6761176586151123, Training Acc: 61.33%\n",
      "              Val Loss: 0.8677974939346313, Val Acc: 57.28%\n",
      "Epoch: 1570,     Training Loss: 0.6315205097198486, Training Acc: 61.34%\n",
      "              Val Loss: 0.871014416217804, Val Acc: 57.29%\n",
      "Epoch: 1571,     Training Loss: 0.6096019148826599, Training Acc: 61.35%\n",
      "              Val Loss: 1.0045896768569946, Val Acc: 57.29%\n",
      "Epoch: 1572,     Training Loss: 0.7012678384780884, Training Acc: 61.35%\n",
      "              Val Loss: 1.013248324394226, Val Acc: 57.30%\n",
      "Epoch: 1573,     Training Loss: 0.7666762471199036, Training Acc: 61.36%\n",
      "              Val Loss: 0.918017566204071, Val Acc: 57.30%\n",
      "Epoch: 1574,     Training Loss: 0.6579322814941406, Training Acc: 61.36%\n",
      "              Val Loss: 0.9638128876686096, Val Acc: 57.31%\n",
      "Epoch: 1575,     Training Loss: 0.6688104867935181, Training Acc: 61.37%\n",
      "              Val Loss: 1.036209225654602, Val Acc: 57.31%\n",
      "Epoch: 1576,     Training Loss: 0.7574253678321838, Training Acc: 61.37%\n",
      "              Val Loss: 1.0701031684875488, Val Acc: 57.31%\n",
      "Epoch: 1577,     Training Loss: 0.7615067958831787, Training Acc: 61.38%\n",
      "              Val Loss: 0.9550859928131104, Val Acc: 57.32%\n",
      "Epoch: 1578,     Training Loss: 0.6954302787780762, Training Acc: 61.38%\n",
      "              Val Loss: 0.9375121593475342, Val Acc: 57.32%\n",
      "Epoch: 1579,     Training Loss: 0.6664226055145264, Training Acc: 61.39%\n",
      "              Val Loss: 0.9422637820243835, Val Acc: 57.32%\n",
      "Epoch: 1580,     Training Loss: 0.6675859093666077, Training Acc: 61.39%\n",
      "              Val Loss: 1.0114216804504395, Val Acc: 57.33%\n",
      "Epoch: 1581,     Training Loss: 0.7617033123970032, Training Acc: 61.40%\n",
      "              Val Loss: 0.8694910407066345, Val Acc: 57.33%\n",
      "Epoch: 1582,     Training Loss: 0.6092156767845154, Training Acc: 61.41%\n",
      "              Val Loss: 0.9183057546615601, Val Acc: 57.34%\n",
      "Epoch: 1583,     Training Loss: 0.6481184959411621, Training Acc: 61.41%\n",
      "              Val Loss: 0.9947332739830017, Val Acc: 57.34%\n",
      "Epoch: 1584,     Training Loss: 0.7491278052330017, Training Acc: 61.42%\n",
      "              Val Loss: 0.8857240080833435, Val Acc: 57.35%\n",
      "Epoch: 1585,     Training Loss: 0.6157770156860352, Training Acc: 61.43%\n",
      "              Val Loss: 0.9552510976791382, Val Acc: 57.35%\n",
      "Epoch: 1586,     Training Loss: 0.6554726958274841, Training Acc: 61.43%\n",
      "              Val Loss: 1.0070472955703735, Val Acc: 57.36%\n",
      "Epoch: 1587,     Training Loss: 0.7478980422019958, Training Acc: 61.44%\n",
      "              Val Loss: 0.9625488519668579, Val Acc: 57.36%\n",
      "Epoch: 1588,     Training Loss: 0.6769837141036987, Training Acc: 61.44%\n",
      "              Val Loss: 0.870125949382782, Val Acc: 57.37%\n",
      "Epoch: 1589,     Training Loss: 0.5913657546043396, Training Acc: 61.45%\n",
      "              Val Loss: 0.940417468547821, Val Acc: 57.37%\n",
      "Epoch: 1590,     Training Loss: 0.6670648455619812, Training Acc: 61.46%\n",
      "              Val Loss: 0.9720401763916016, Val Acc: 57.38%\n",
      "Epoch: 1591,     Training Loss: 0.677463710308075, Training Acc: 61.46%\n",
      "              Val Loss: 0.9701012372970581, Val Acc: 57.38%\n",
      "Epoch: 1592,     Training Loss: 0.7022420763969421, Training Acc: 61.47%\n",
      "              Val Loss: 0.8807387351989746, Val Acc: 57.39%\n",
      "Epoch: 1593,     Training Loss: 0.6050211191177368, Training Acc: 61.48%\n",
      "              Val Loss: 0.9114731550216675, Val Acc: 57.39%\n",
      "Epoch: 1594,     Training Loss: 0.622544527053833, Training Acc: 61.48%\n",
      "              Val Loss: 0.9815444946289062, Val Acc: 57.40%\n",
      "Epoch: 1595,     Training Loss: 0.7123575806617737, Training Acc: 61.49%\n",
      "              Val Loss: 0.9207651615142822, Val Acc: 57.40%\n",
      "Epoch: 1596,     Training Loss: 0.648313581943512, Training Acc: 61.49%\n",
      "              Val Loss: 0.8622426390647888, Val Acc: 57.41%\n",
      "Epoch: 1597,     Training Loss: 0.6154652237892151, Training Acc: 61.50%\n",
      "              Val Loss: 0.837206244468689, Val Acc: 57.42%\n",
      "Epoch: 1598,     Training Loss: 0.5801969170570374, Training Acc: 61.51%\n",
      "              Val Loss: 0.912574827671051, Val Acc: 57.42%\n",
      "Epoch: 1599,     Training Loss: 0.6289161443710327, Training Acc: 61.52%\n",
      "              Val Loss: 0.9304916262626648, Val Acc: 57.43%\n",
      "Epoch: 1600,     Training Loss: 0.6626937985420227, Training Acc: 61.52%\n",
      "              Val Loss: 0.901944100856781, Val Acc: 57.43%\n",
      "Epoch: 1601,     Training Loss: 0.6291985511779785, Training Acc: 61.53%\n",
      "              Val Loss: 0.8442074060440063, Val Acc: 57.44%\n",
      "Epoch: 1602,     Training Loss: 0.5894071459770203, Training Acc: 61.54%\n",
      "              Val Loss: 0.8425552845001221, Val Acc: 57.45%\n",
      "Epoch: 1603,     Training Loss: 0.5774827599525452, Training Acc: 61.55%\n",
      "              Val Loss: 0.8867790102958679, Val Acc: 57.46%\n",
      "Epoch: 1604,     Training Loss: 0.6061962246894836, Training Acc: 61.56%\n",
      "              Val Loss: 0.8836909532546997, Val Acc: 57.46%\n",
      "Epoch: 1605,     Training Loss: 0.6369913816452026, Training Acc: 61.57%\n",
      "              Val Loss: 0.9006578922271729, Val Acc: 57.47%\n",
      "Epoch: 1606,     Training Loss: 0.642758846282959, Training Acc: 61.57%\n",
      "              Val Loss: 0.8965710401535034, Val Acc: 57.48%\n",
      "Epoch: 1607,     Training Loss: 0.6292824745178223, Training Acc: 61.58%\n",
      "              Val Loss: 0.875632107257843, Val Acc: 57.48%\n",
      "Epoch: 1608,     Training Loss: 0.5884585380554199, Training Acc: 61.59%\n",
      "              Val Loss: 0.8719536066055298, Val Acc: 57.49%\n",
      "Epoch: 1609,     Training Loss: 0.6026939153671265, Training Acc: 61.60%\n",
      "              Val Loss: 0.8642160892486572, Val Acc: 57.50%\n",
      "Epoch: 1610,     Training Loss: 0.6022074222564697, Training Acc: 61.61%\n",
      "              Val Loss: 0.957876980304718, Val Acc: 57.50%\n",
      "Epoch: 1611,     Training Loss: 0.6709550619125366, Training Acc: 61.61%\n",
      "              Val Loss: 0.9838649034500122, Val Acc: 57.50%\n",
      "Epoch: 1612,     Training Loss: 0.7390463948249817, Training Acc: 61.61%\n",
      "              Val Loss: 0.9578428864479065, Val Acc: 57.51%\n",
      "Epoch: 1613,     Training Loss: 0.6727352142333984, Training Acc: 61.62%\n",
      "              Val Loss: 0.9522345066070557, Val Acc: 57.51%\n",
      "Epoch: 1614,     Training Loss: 0.6734572052955627, Training Acc: 61.63%\n",
      "              Val Loss: 0.9064421057701111, Val Acc: 57.52%\n",
      "Epoch: 1615,     Training Loss: 0.6314228177070618, Training Acc: 61.63%\n",
      "              Val Loss: 1.029588222503662, Val Acc: 57.52%\n",
      "Epoch: 1616,     Training Loss: 0.7319057583808899, Training Acc: 61.64%\n",
      "              Val Loss: 1.0117977857589722, Val Acc: 57.52%\n",
      "Epoch: 1617,     Training Loss: 0.7454286217689514, Training Acc: 61.64%\n",
      "              Val Loss: 0.9954127669334412, Val Acc: 57.53%\n",
      "Epoch: 1618,     Training Loss: 0.6947969794273376, Training Acc: 61.64%\n",
      "              Val Loss: 0.8559948205947876, Val Acc: 57.53%\n",
      "Epoch: 1619,     Training Loss: 0.6136055588722229, Training Acc: 61.65%\n",
      "              Val Loss: 0.8725075721740723, Val Acc: 57.54%\n",
      "Epoch: 1620,     Training Loss: 0.6172088384628296, Training Acc: 61.66%\n",
      "              Val Loss: 0.9344276189804077, Val Acc: 57.54%\n",
      "Epoch: 1621,     Training Loss: 0.629482090473175, Training Acc: 61.67%\n",
      "              Val Loss: 0.9512547254562378, Val Acc: 57.55%\n",
      "Epoch: 1622,     Training Loss: 0.6587712168693542, Training Acc: 61.67%\n",
      "              Val Loss: 0.9426465034484863, Val Acc: 57.55%\n",
      "Epoch: 1623,     Training Loss: 0.6526841521263123, Training Acc: 61.68%\n",
      "              Val Loss: 0.9234046936035156, Val Acc: 57.56%\n",
      "Epoch: 1624,     Training Loss: 0.6523498296737671, Training Acc: 61.68%\n",
      "              Val Loss: 0.8914979696273804, Val Acc: 57.56%\n",
      "Epoch: 1625,     Training Loss: 0.6067213416099548, Training Acc: 61.69%\n",
      "              Val Loss: 0.8682667016983032, Val Acc: 57.57%\n",
      "Epoch: 1626,     Training Loss: 0.5854779481887817, Training Acc: 61.70%\n",
      "              Val Loss: 0.885292649269104, Val Acc: 57.58%\n",
      "Epoch: 1627,     Training Loss: 0.6098546385765076, Training Acc: 61.71%\n",
      "              Val Loss: 0.9173557758331299, Val Acc: 57.58%\n",
      "Epoch: 1628,     Training Loss: 0.6280260682106018, Training Acc: 61.72%\n",
      "              Val Loss: 0.9453474283218384, Val Acc: 57.59%\n",
      "Epoch: 1629,     Training Loss: 0.6758759021759033, Training Acc: 61.72%\n",
      "              Val Loss: 0.933420717716217, Val Acc: 57.59%\n",
      "Epoch: 1630,     Training Loss: 0.6316959857940674, Training Acc: 61.73%\n",
      "              Val Loss: 0.912686288356781, Val Acc: 57.60%\n",
      "Epoch: 1631,     Training Loss: 0.630821943283081, Training Acc: 61.73%\n",
      "              Val Loss: 0.8666739463806152, Val Acc: 57.61%\n",
      "Epoch: 1632,     Training Loss: 0.5850683450698853, Training Acc: 61.74%\n",
      "              Val Loss: 0.862253725528717, Val Acc: 57.61%\n",
      "Epoch: 1633,     Training Loss: 0.5795269012451172, Training Acc: 61.75%\n",
      "              Val Loss: 0.8920985460281372, Val Acc: 57.62%\n",
      "Epoch: 1634,     Training Loss: 0.6015614867210388, Training Acc: 61.76%\n",
      "              Val Loss: 0.8944650292396545, Val Acc: 57.63%\n",
      "Epoch: 1635,     Training Loss: 0.6013444662094116, Training Acc: 61.77%\n",
      "              Val Loss: 0.9316952228546143, Val Acc: 57.63%\n",
      "Epoch: 1636,     Training Loss: 0.657853364944458, Training Acc: 61.78%\n",
      "              Val Loss: 0.9302240014076233, Val Acc: 57.63%\n",
      "Epoch: 1637,     Training Loss: 0.641567587852478, Training Acc: 61.78%\n",
      "              Val Loss: 0.9324701428413391, Val Acc: 57.64%\n",
      "Epoch: 1638,     Training Loss: 0.6696059703826904, Training Acc: 61.79%\n",
      "              Val Loss: 0.877623975276947, Val Acc: 57.64%\n",
      "Epoch: 1639,     Training Loss: 0.5963928699493408, Training Acc: 61.79%\n",
      "              Val Loss: 0.8695489764213562, Val Acc: 57.65%\n",
      "Epoch: 1640,     Training Loss: 0.5813818573951721, Training Acc: 61.80%\n",
      "              Val Loss: 0.8913528323173523, Val Acc: 57.66%\n",
      "Epoch: 1641,     Training Loss: 0.6013739705085754, Training Acc: 61.81%\n",
      "              Val Loss: 0.9244157671928406, Val Acc: 57.66%\n",
      "Epoch: 1642,     Training Loss: 0.6312561631202698, Training Acc: 61.82%\n",
      "              Val Loss: 0.9819892048835754, Val Acc: 57.67%\n",
      "Epoch: 1643,     Training Loss: 0.7073726654052734, Training Acc: 61.82%\n",
      "              Val Loss: 0.9670869708061218, Val Acc: 57.67%\n",
      "Epoch: 1644,     Training Loss: 0.6587821245193481, Training Acc: 61.83%\n",
      "              Val Loss: 0.9223388433456421, Val Acc: 57.67%\n",
      "Epoch: 1645,     Training Loss: 0.6634798645973206, Training Acc: 61.83%\n",
      "              Val Loss: 0.8487735986709595, Val Acc: 57.68%\n",
      "Epoch: 1646,     Training Loss: 0.5722717046737671, Training Acc: 61.84%\n",
      "              Val Loss: 0.9177390933036804, Val Acc: 57.69%\n",
      "Epoch: 1647,     Training Loss: 0.6198440790176392, Training Acc: 61.85%\n",
      "              Val Loss: 0.9333345890045166, Val Acc: 57.69%\n",
      "Epoch: 1648,     Training Loss: 0.6644313335418701, Training Acc: 61.86%\n",
      "              Val Loss: 0.9949324131011963, Val Acc: 57.69%\n",
      "Epoch: 1649,     Training Loss: 0.6942675709724426, Training Acc: 61.86%\n",
      "              Val Loss: 0.9567400217056274, Val Acc: 57.70%\n",
      "Epoch: 1650,     Training Loss: 0.6766999959945679, Training Acc: 61.87%\n",
      "              Val Loss: 0.9251401424407959, Val Acc: 57.70%\n",
      "Epoch: 1651,     Training Loss: 0.622640073299408, Training Acc: 61.87%\n",
      "              Val Loss: 0.8843877911567688, Val Acc: 57.71%\n",
      "Epoch: 1652,     Training Loss: 0.6037142276763916, Training Acc: 61.88%\n",
      "              Val Loss: 0.8942018747329712, Val Acc: 57.72%\n",
      "Epoch: 1653,     Training Loss: 0.6175729632377625, Training Acc: 61.89%\n",
      "              Val Loss: 0.9973326325416565, Val Acc: 57.72%\n",
      "Epoch: 1654,     Training Loss: 0.6722054481506348, Training Acc: 61.89%\n",
      "              Val Loss: 0.9611936807632446, Val Acc: 57.72%\n",
      "Epoch: 1655,     Training Loss: 0.6988992094993591, Training Acc: 61.90%\n",
      "              Val Loss: 0.9325959086418152, Val Acc: 57.73%\n",
      "Epoch: 1656,     Training Loss: 0.6491619944572449, Training Acc: 61.90%\n",
      "              Val Loss: 0.8594180941581726, Val Acc: 57.73%\n",
      "Epoch: 1657,     Training Loss: 0.5839219093322754, Training Acc: 61.91%\n",
      "              Val Loss: 0.8678455948829651, Val Acc: 57.74%\n",
      "Epoch: 1658,     Training Loss: 0.585134744644165, Training Acc: 61.92%\n",
      "              Val Loss: 0.9107891917228699, Val Acc: 57.75%\n",
      "Epoch: 1659,     Training Loss: 0.616994321346283, Training Acc: 61.93%\n",
      "              Val Loss: 0.9142230153083801, Val Acc: 57.75%\n",
      "Epoch: 1660,     Training Loss: 0.6395196318626404, Training Acc: 61.93%\n",
      "              Val Loss: 0.9272624254226685, Val Acc: 57.76%\n",
      "Epoch: 1661,     Training Loss: 0.6135196089744568, Training Acc: 61.94%\n",
      "              Val Loss: 0.8636812567710876, Val Acc: 57.77%\n",
      "Epoch: 1662,     Training Loss: 0.5810174345970154, Training Acc: 61.95%\n",
      "              Val Loss: 0.8532049655914307, Val Acc: 57.77%\n",
      "Epoch: 1663,     Training Loss: 0.5707335472106934, Training Acc: 61.96%\n",
      "              Val Loss: 0.8545324802398682, Val Acc: 57.78%\n",
      "Epoch: 1664,     Training Loss: 0.5644301772117615, Training Acc: 61.97%\n",
      "              Val Loss: 0.8494489192962646, Val Acc: 57.79%\n",
      "Epoch: 1665,     Training Loss: 0.5726481080055237, Training Acc: 61.98%\n",
      "              Val Loss: 0.8741546869277954, Val Acc: 57.79%\n",
      "Epoch: 1666,     Training Loss: 0.5933990478515625, Training Acc: 61.98%\n",
      "              Val Loss: 0.8987143635749817, Val Acc: 57.80%\n",
      "Epoch: 1667,     Training Loss: 0.6201111078262329, Training Acc: 61.99%\n",
      "              Val Loss: 0.9334643483161926, Val Acc: 57.80%\n",
      "Epoch: 1668,     Training Loss: 0.6280815005302429, Training Acc: 62.00%\n",
      "              Val Loss: 0.9293811917304993, Val Acc: 57.81%\n",
      "Epoch: 1669,     Training Loss: 0.6596564650535583, Training Acc: 62.00%\n",
      "              Val Loss: 0.8953558206558228, Val Acc: 57.81%\n",
      "Epoch: 1670,     Training Loss: 0.6016985774040222, Training Acc: 62.01%\n",
      "              Val Loss: 0.873635470867157, Val Acc: 57.82%\n",
      "Epoch: 1671,     Training Loss: 0.5751726627349854, Training Acc: 62.02%\n",
      "              Val Loss: 0.8698631525039673, Val Acc: 57.83%\n",
      "Epoch: 1672,     Training Loss: 0.5774732232093811, Training Acc: 62.03%\n",
      "              Val Loss: 0.9170424938201904, Val Acc: 57.84%\n",
      "Epoch: 1673,     Training Loss: 0.6205658316612244, Training Acc: 62.04%\n",
      "              Val Loss: 1.0042239427566528, Val Acc: 57.84%\n",
      "Epoch: 1674,     Training Loss: 0.7200227379798889, Training Acc: 62.04%\n",
      "              Val Loss: 0.9871755242347717, Val Acc: 57.84%\n",
      "Epoch: 1675,     Training Loss: 0.6799755692481995, Training Acc: 62.04%\n",
      "              Val Loss: 0.9286420941352844, Val Acc: 57.84%\n",
      "Epoch: 1676,     Training Loss: 0.6685896515846252, Training Acc: 62.05%\n",
      "              Val Loss: 0.9012516140937805, Val Acc: 57.85%\n",
      "Epoch: 1677,     Training Loss: 0.6113487482070923, Training Acc: 62.06%\n",
      "              Val Loss: 0.9459741115570068, Val Acc: 57.85%\n",
      "Epoch: 1678,     Training Loss: 0.6296619176864624, Training Acc: 62.06%\n",
      "              Val Loss: 0.9837406277656555, Val Acc: 57.86%\n",
      "Epoch: 1679,     Training Loss: 0.6977724432945251, Training Acc: 62.07%\n",
      "              Val Loss: 1.046871542930603, Val Acc: 57.86%\n",
      "Epoch: 1680,     Training Loss: 0.7398431301116943, Training Acc: 62.07%\n",
      "              Val Loss: 1.0897959470748901, Val Acc: 57.86%\n",
      "Epoch: 1681,     Training Loss: 0.8042417764663696, Training Acc: 62.07%\n",
      "              Val Loss: 0.9168782830238342, Val Acc: 57.87%\n",
      "Epoch: 1682,     Training Loss: 0.6194785833358765, Training Acc: 62.08%\n",
      "              Val Loss: 0.9848268032073975, Val Acc: 57.87%\n",
      "Epoch: 1683,     Training Loss: 0.6793275475502014, Training Acc: 62.08%\n",
      "              Val Loss: 1.0847541093826294, Val Acc: 57.87%\n",
      "Epoch: 1684,     Training Loss: 0.8265464901924133, Training Acc: 62.08%\n",
      "              Val Loss: 0.873481035232544, Val Acc: 57.88%\n",
      "Epoch: 1685,     Training Loss: 0.5866022109985352, Training Acc: 62.09%\n",
      "              Val Loss: 1.094927191734314, Val Acc: 57.88%\n",
      "Epoch: 1686,     Training Loss: 0.7875719666481018, Training Acc: 62.09%\n",
      "              Val Loss: 1.3924654722213745, Val Acc: 57.87%\n",
      "Epoch: 1687,     Training Loss: 1.1605653762817383, Training Acc: 62.09%\n",
      "              Val Loss: 0.9782311320304871, Val Acc: 57.88%\n",
      "Epoch: 1688,     Training Loss: 0.7312709093093872, Training Acc: 62.09%\n",
      "              Val Loss: 1.8342610597610474, Val Acc: 57.86%\n",
      "Epoch: 1689,     Training Loss: 1.4617196321487427, Training Acc: 62.08%\n",
      "              Val Loss: 1.6565731763839722, Val Acc: 57.86%\n",
      "Epoch: 1690,     Training Loss: 1.455642819404602, Training Acc: 62.07%\n",
      "              Val Loss: 1.8376531600952148, Val Acc: 57.85%\n",
      "Epoch: 1691,     Training Loss: 1.6821686029434204, Training Acc: 62.07%\n",
      "              Val Loss: 1.0284264087677002, Val Acc: 57.85%\n",
      "Epoch: 1692,     Training Loss: 0.8533782958984375, Training Acc: 62.07%\n",
      "              Val Loss: 2.0378193855285645, Val Acc: 57.84%\n",
      "Epoch: 1693,     Training Loss: 1.7595950365066528, Training Acc: 62.06%\n",
      "              Val Loss: 1.021484613418579, Val Acc: 57.84%\n",
      "Epoch: 1694,     Training Loss: 0.795066773891449, Training Acc: 62.06%\n",
      "              Val Loss: 1.456575870513916, Val Acc: 57.84%\n",
      "Epoch: 1695,     Training Loss: 1.300365924835205, Training Acc: 62.05%\n",
      "              Val Loss: 1.2956522703170776, Val Acc: 57.84%\n",
      "Epoch: 1696,     Training Loss: 1.1771293878555298, Training Acc: 62.05%\n",
      "              Val Loss: 0.9926837086677551, Val Acc: 57.84%\n",
      "Epoch: 1697,     Training Loss: 0.8375171422958374, Training Acc: 62.05%\n",
      "              Val Loss: 1.4564868211746216, Val Acc: 57.83%\n",
      "Epoch: 1698,     Training Loss: 1.2671953439712524, Training Acc: 62.05%\n",
      "              Val Loss: 1.0571930408477783, Val Acc: 57.83%\n",
      "Epoch: 1699,     Training Loss: 0.9223385453224182, Training Acc: 62.04%\n",
      "              Val Loss: 1.154842495918274, Val Acc: 57.83%\n",
      "Epoch: 1700,     Training Loss: 1.0473978519439697, Training Acc: 62.04%\n",
      "              Val Loss: 1.2658332586288452, Val Acc: 57.83%\n",
      "Epoch: 1701,     Training Loss: 1.1312555074691772, Training Acc: 62.04%\n",
      "              Val Loss: 1.0525184869766235, Val Acc: 57.83%\n",
      "Epoch: 1702,     Training Loss: 0.887139081954956, Training Acc: 62.04%\n",
      "              Val Loss: 1.1426677703857422, Val Acc: 57.83%\n",
      "Epoch: 1703,     Training Loss: 0.924818217754364, Training Acc: 62.04%\n",
      "              Val Loss: 1.1861999034881592, Val Acc: 57.82%\n",
      "Epoch: 1704,     Training Loss: 0.9534996747970581, Training Acc: 62.03%\n",
      "              Val Loss: 0.9994915127754211, Val Acc: 57.82%\n",
      "Epoch: 1705,     Training Loss: 0.802004337310791, Training Acc: 62.04%\n",
      "              Val Loss: 1.082506537437439, Val Acc: 57.82%\n",
      "Epoch: 1706,     Training Loss: 0.9138308167457581, Training Acc: 62.04%\n",
      "              Val Loss: 1.0618488788604736, Val Acc: 57.82%\n",
      "Epoch: 1707,     Training Loss: 0.8911678194999695, Training Acc: 62.04%\n",
      "              Val Loss: 0.9427239298820496, Val Acc: 57.82%\n",
      "Epoch: 1708,     Training Loss: 0.771731972694397, Training Acc: 62.04%\n",
      "              Val Loss: 1.077825903892517, Val Acc: 57.82%\n",
      "Epoch: 1709,     Training Loss: 0.8655537366867065, Training Acc: 62.04%\n",
      "              Val Loss: 0.9903743863105774, Val Acc: 57.82%\n",
      "Epoch: 1710,     Training Loss: 0.792820155620575, Training Acc: 62.04%\n",
      "              Val Loss: 0.9338463544845581, Val Acc: 57.83%\n",
      "Epoch: 1711,     Training Loss: 0.7673813700675964, Training Acc: 62.04%\n",
      "              Val Loss: 0.9791176319122314, Val Acc: 57.83%\n",
      "Epoch: 1712,     Training Loss: 0.8147081136703491, Training Acc: 62.05%\n",
      "              Val Loss: 0.9245292544364929, Val Acc: 57.83%\n",
      "Epoch: 1713,     Training Loss: 0.7444842457771301, Training Acc: 62.05%\n",
      "              Val Loss: 0.9791386127471924, Val Acc: 57.83%\n",
      "Epoch: 1714,     Training Loss: 0.7749897241592407, Training Acc: 62.05%\n",
      "              Val Loss: 0.9514824151992798, Val Acc: 57.83%\n",
      "Epoch: 1715,     Training Loss: 0.7527515888214111, Training Acc: 62.05%\n",
      "              Val Loss: 0.9080507755279541, Val Acc: 57.84%\n",
      "Epoch: 1716,     Training Loss: 0.7256603837013245, Training Acc: 62.06%\n",
      "              Val Loss: 0.929086446762085, Val Acc: 57.84%\n",
      "Epoch: 1717,     Training Loss: 0.7502555847167969, Training Acc: 62.06%\n",
      "              Val Loss: 0.8848076462745667, Val Acc: 57.85%\n",
      "Epoch: 1718,     Training Loss: 0.6997009515762329, Training Acc: 62.07%\n",
      "              Val Loss: 0.9251192212104797, Val Acc: 57.85%\n",
      "Epoch: 1719,     Training Loss: 0.7293123602867126, Training Acc: 62.07%\n",
      "              Val Loss: 0.8882918357849121, Val Acc: 57.86%\n",
      "Epoch: 1720,     Training Loss: 0.6932811141014099, Training Acc: 62.08%\n",
      "              Val Loss: 0.8971492648124695, Val Acc: 57.86%\n",
      "Epoch: 1721,     Training Loss: 0.7000863552093506, Training Acc: 62.08%\n",
      "              Val Loss: 0.9016593098640442, Val Acc: 57.87%\n",
      "Epoch: 1722,     Training Loss: 0.6994457840919495, Training Acc: 62.09%\n",
      "              Val Loss: 0.8671007752418518, Val Acc: 57.87%\n",
      "Epoch: 1723,     Training Loss: 0.6649510264396667, Training Acc: 62.09%\n",
      "              Val Loss: 0.9006230235099792, Val Acc: 57.88%\n",
      "Epoch: 1724,     Training Loss: 0.6966531276702881, Training Acc: 62.10%\n",
      "              Val Loss: 0.8602606058120728, Val Acc: 57.88%\n",
      "Epoch: 1725,     Training Loss: 0.6577093601226807, Training Acc: 62.10%\n",
      "              Val Loss: 0.8888193368911743, Val Acc: 57.89%\n",
      "Epoch: 1726,     Training Loss: 0.68231201171875, Training Acc: 62.11%\n",
      "              Val Loss: 0.8592565059661865, Val Acc: 57.89%\n",
      "Epoch: 1727,     Training Loss: 0.6508894562721252, Training Acc: 62.12%\n",
      "              Val Loss: 0.8844996094703674, Val Acc: 57.90%\n",
      "Epoch: 1728,     Training Loss: 0.6678598523139954, Training Acc: 62.12%\n",
      "              Val Loss: 0.8684628009796143, Val Acc: 57.90%\n",
      "Epoch: 1729,     Training Loss: 0.6464276909828186, Training Acc: 62.13%\n",
      "              Val Loss: 0.8766618967056274, Val Acc: 57.91%\n",
      "Epoch: 1730,     Training Loss: 0.6530824899673462, Training Acc: 62.14%\n",
      "              Val Loss: 0.8690051436424255, Val Acc: 57.92%\n",
      "Epoch: 1731,     Training Loss: 0.6454169750213623, Training Acc: 62.14%\n",
      "              Val Loss: 0.877193808555603, Val Acc: 57.92%\n",
      "Epoch: 1732,     Training Loss: 0.6451388001441956, Training Acc: 62.15%\n",
      "              Val Loss: 0.8880738019943237, Val Acc: 57.93%\n",
      "Epoch: 1733,     Training Loss: 0.6420024037361145, Training Acc: 62.15%\n",
      "              Val Loss: 0.8850436210632324, Val Acc: 57.94%\n",
      "Epoch: 1734,     Training Loss: 0.6397966146469116, Training Acc: 62.16%\n",
      "              Val Loss: 0.8794047832489014, Val Acc: 57.94%\n",
      "Epoch: 1735,     Training Loss: 0.6345624923706055, Training Acc: 62.17%\n",
      "              Val Loss: 0.8883154392242432, Val Acc: 57.95%\n",
      "Epoch: 1736,     Training Loss: 0.6347750425338745, Training Acc: 62.18%\n",
      "              Val Loss: 0.8885513544082642, Val Acc: 57.95%\n",
      "Epoch: 1737,     Training Loss: 0.6293793320655823, Training Acc: 62.18%\n",
      "              Val Loss: 0.8908141851425171, Val Acc: 57.96%\n",
      "Epoch: 1738,     Training Loss: 0.6300795078277588, Training Acc: 62.19%\n",
      "              Val Loss: 0.8875167965888977, Val Acc: 57.97%\n",
      "Epoch: 1739,     Training Loss: 0.6250320076942444, Training Acc: 62.20%\n",
      "              Val Loss: 0.8883313536643982, Val Acc: 57.97%\n",
      "Epoch: 1740,     Training Loss: 0.6250797510147095, Training Acc: 62.20%\n",
      "              Val Loss: 0.8799057006835938, Val Acc: 57.98%\n",
      "Epoch: 1741,     Training Loss: 0.6210142374038696, Training Acc: 62.21%\n",
      "              Val Loss: 0.8803724646568298, Val Acc: 57.99%\n",
      "Epoch: 1742,     Training Loss: 0.6213667392730713, Training Acc: 62.22%\n",
      "              Val Loss: 0.8856953978538513, Val Acc: 58.00%\n",
      "Epoch: 1743,     Training Loss: 0.6169708371162415, Training Acc: 62.23%\n",
      "              Val Loss: 0.8929592370986938, Val Acc: 58.00%\n",
      "Epoch: 1744,     Training Loss: 0.6181871891021729, Training Acc: 62.23%\n",
      "              Val Loss: 0.8826231360435486, Val Acc: 58.01%\n",
      "Epoch: 1745,     Training Loss: 0.6134706139564514, Training Acc: 62.24%\n",
      "              Val Loss: 0.8838305473327637, Val Acc: 58.02%\n",
      "Epoch: 1746,     Training Loss: 0.6144418716430664, Training Acc: 62.25%\n",
      "              Val Loss: 0.8867219686508179, Val Acc: 58.02%\n",
      "Epoch: 1747,     Training Loss: 0.6107593774795532, Training Acc: 62.26%\n",
      "              Val Loss: 0.8870607614517212, Val Acc: 58.03%\n",
      "Epoch: 1748,     Training Loss: 0.6104240417480469, Training Acc: 62.26%\n",
      "              Val Loss: 0.8798574209213257, Val Acc: 58.04%\n",
      "Epoch: 1749,     Training Loss: 0.6079515218734741, Training Acc: 62.27%\n",
      "              Val Loss: 0.8777990937232971, Val Acc: 58.04%\n",
      "Epoch: 1750,     Training Loss: 0.6067670583724976, Training Acc: 62.28%\n",
      "              Val Loss: 0.8759152293205261, Val Acc: 58.05%\n",
      "Epoch: 1751,     Training Loss: 0.6048137545585632, Training Acc: 62.29%\n",
      "              Val Loss: 0.8726428151130676, Val Acc: 58.06%\n",
      "Epoch: 1752,     Training Loss: 0.6041262149810791, Training Acc: 62.29%\n",
      "              Val Loss: 0.8699806928634644, Val Acc: 58.07%\n",
      "Epoch: 1753,     Training Loss: 0.601342499256134, Training Acc: 62.30%\n",
      "              Val Loss: 0.8727755546569824, Val Acc: 58.07%\n",
      "Epoch: 1754,     Training Loss: 0.601317286491394, Training Acc: 62.31%\n",
      "              Val Loss: 0.8678244948387146, Val Acc: 58.08%\n",
      "Epoch: 1755,     Training Loss: 0.5985262393951416, Training Acc: 62.32%\n",
      "              Val Loss: 0.8686183094978333, Val Acc: 58.09%\n",
      "Epoch: 1756,     Training Loss: 0.5982175469398499, Training Acc: 62.33%\n",
      "              Val Loss: 0.8704220056533813, Val Acc: 58.10%\n",
      "Epoch: 1757,     Training Loss: 0.5960586071014404, Training Acc: 62.33%\n",
      "              Val Loss: 0.8710517287254333, Val Acc: 58.10%\n",
      "Epoch: 1758,     Training Loss: 0.5948216319084167, Training Acc: 62.34%\n",
      "              Val Loss: 0.8685640096664429, Val Acc: 58.11%\n",
      "Epoch: 1759,     Training Loss: 0.5938237309455872, Training Acc: 62.35%\n",
      "              Val Loss: 0.8665002584457397, Val Acc: 58.12%\n",
      "Epoch: 1760,     Training Loss: 0.5913854241371155, Training Acc: 62.36%\n",
      "              Val Loss: 0.8681082129478455, Val Acc: 58.13%\n",
      "Epoch: 1761,     Training Loss: 0.5904760956764221, Training Acc: 62.37%\n",
      "              Val Loss: 0.8661164045333862, Val Acc: 58.13%\n",
      "Epoch: 1762,     Training Loss: 0.5882783532142639, Training Acc: 62.37%\n",
      "              Val Loss: 0.8660277724266052, Val Acc: 58.14%\n",
      "Epoch: 1763,     Training Loss: 0.5875146985054016, Training Acc: 62.38%\n",
      "              Val Loss: 0.8646081686019897, Val Acc: 58.15%\n",
      "Epoch: 1764,     Training Loss: 0.585554838180542, Training Acc: 62.39%\n",
      "              Val Loss: 0.8643915057182312, Val Acc: 58.16%\n",
      "Epoch: 1765,     Training Loss: 0.5851076245307922, Training Acc: 62.40%\n",
      "              Val Loss: 0.8639920949935913, Val Acc: 58.17%\n",
      "Epoch: 1766,     Training Loss: 0.5835775136947632, Training Acc: 62.41%\n",
      "              Val Loss: 0.8638136386871338, Val Acc: 58.17%\n",
      "Epoch: 1767,     Training Loss: 0.5823847055435181, Training Acc: 62.42%\n",
      "              Val Loss: 0.864203929901123, Val Acc: 58.18%\n",
      "Epoch: 1768,     Training Loss: 0.581372082233429, Training Acc: 62.42%\n",
      "              Val Loss: 0.8635793924331665, Val Acc: 58.19%\n",
      "Epoch: 1769,     Training Loss: 0.5796246528625488, Training Acc: 62.43%\n",
      "              Val Loss: 0.862560510635376, Val Acc: 58.20%\n",
      "Epoch: 1770,     Training Loss: 0.578639030456543, Training Acc: 62.44%\n",
      "              Val Loss: 0.8625959753990173, Val Acc: 58.21%\n",
      "Epoch: 1771,     Training Loss: 0.5770474672317505, Training Acc: 62.45%\n",
      "              Val Loss: 0.8634780049324036, Val Acc: 58.21%\n",
      "Epoch: 1772,     Training Loss: 0.5756174325942993, Training Acc: 62.46%\n",
      "              Val Loss: 0.8617063760757446, Val Acc: 58.22%\n",
      "Epoch: 1773,     Training Loss: 0.5740761756896973, Training Acc: 62.47%\n",
      "              Val Loss: 0.8589622974395752, Val Acc: 58.23%\n",
      "Epoch: 1774,     Training Loss: 0.5725393295288086, Training Acc: 62.47%\n",
      "              Val Loss: 0.8587119579315186, Val Acc: 58.24%\n",
      "Epoch: 1775,     Training Loss: 0.5709637403488159, Training Acc: 62.48%\n",
      "              Val Loss: 0.8566198945045471, Val Acc: 58.25%\n",
      "Epoch: 1776,     Training Loss: 0.569331705570221, Training Acc: 62.49%\n",
      "              Val Loss: 0.8525914549827576, Val Acc: 58.25%\n",
      "Epoch: 1777,     Training Loss: 0.5678816437721252, Training Acc: 62.50%\n",
      "              Val Loss: 0.8507063388824463, Val Acc: 58.26%\n",
      "Epoch: 1778,     Training Loss: 0.5660361647605896, Training Acc: 62.51%\n",
      "              Val Loss: 0.8500259518623352, Val Acc: 58.27%\n",
      "Epoch: 1779,     Training Loss: 0.5647124648094177, Training Acc: 62.52%\n",
      "              Val Loss: 0.8470205068588257, Val Acc: 58.28%\n",
      "Epoch: 1780,     Training Loss: 0.5633171796798706, Training Acc: 62.53%\n",
      "              Val Loss: 0.8459323644638062, Val Acc: 58.29%\n",
      "Epoch: 1781,     Training Loss: 0.5618799328804016, Training Acc: 62.53%\n",
      "              Val Loss: 0.8465080261230469, Val Acc: 58.29%\n",
      "Epoch: 1782,     Training Loss: 0.560753583908081, Training Acc: 62.54%\n",
      "              Val Loss: 0.8449559211730957, Val Acc: 58.30%\n",
      "Epoch: 1783,     Training Loss: 0.5595811605453491, Training Acc: 62.55%\n",
      "              Val Loss: 0.8420724272727966, Val Acc: 58.31%\n",
      "Epoch: 1784,     Training Loss: 0.5584834814071655, Training Acc: 62.56%\n",
      "              Val Loss: 0.8405654430389404, Val Acc: 58.32%\n",
      "Epoch: 1785,     Training Loss: 0.5573553442955017, Training Acc: 62.57%\n",
      "              Val Loss: 0.840867280960083, Val Acc: 58.33%\n",
      "Epoch: 1786,     Training Loss: 0.5562434792518616, Training Acc: 62.58%\n",
      "              Val Loss: 0.8385272026062012, Val Acc: 58.33%\n",
      "Epoch: 1787,     Training Loss: 0.5550082921981812, Training Acc: 62.59%\n",
      "              Val Loss: 0.8369881510734558, Val Acc: 58.34%\n",
      "Epoch: 1788,     Training Loss: 0.5538991689682007, Training Acc: 62.59%\n",
      "              Val Loss: 0.8384025692939758, Val Acc: 58.35%\n",
      "Epoch: 1789,     Training Loss: 0.5526955127716064, Training Acc: 62.60%\n",
      "              Val Loss: 0.835414707660675, Val Acc: 58.36%\n",
      "Epoch: 1790,     Training Loss: 0.5513087511062622, Training Acc: 62.61%\n",
      "              Val Loss: 0.8344600796699524, Val Acc: 58.36%\n",
      "Epoch: 1791,     Training Loss: 0.5501457452774048, Training Acc: 62.62%\n",
      "              Val Loss: 0.8343173265457153, Val Acc: 58.37%\n",
      "Epoch: 1792,     Training Loss: 0.5489618182182312, Training Acc: 62.63%\n",
      "              Val Loss: 0.831519365310669, Val Acc: 58.38%\n",
      "Epoch: 1793,     Training Loss: 0.5478498935699463, Training Acc: 62.64%\n",
      "              Val Loss: 0.8296871781349182, Val Acc: 58.39%\n",
      "Epoch: 1794,     Training Loss: 0.5468828678131104, Training Acc: 62.65%\n",
      "              Val Loss: 0.8288358449935913, Val Acc: 58.39%\n",
      "Epoch: 1795,     Training Loss: 0.5458441972732544, Training Acc: 62.65%\n",
      "              Val Loss: 0.829784095287323, Val Acc: 58.40%\n",
      "Epoch: 1796,     Training Loss: 0.5449529886245728, Training Acc: 62.66%\n",
      "              Val Loss: 0.8277140855789185, Val Acc: 58.41%\n",
      "Epoch: 1797,     Training Loss: 0.5440644025802612, Training Acc: 62.67%\n",
      "              Val Loss: 0.8275271654129028, Val Acc: 58.42%\n",
      "Epoch: 1798,     Training Loss: 0.5431471467018127, Training Acc: 62.68%\n",
      "              Val Loss: 0.8265975117683411, Val Acc: 58.43%\n",
      "Epoch: 1799,     Training Loss: 0.5423006415367126, Training Acc: 62.69%\n",
      "              Val Loss: 0.8250437378883362, Val Acc: 58.43%\n",
      "Epoch: 1800,     Training Loss: 0.5415295362472534, Training Acc: 62.70%\n",
      "              Val Loss: 0.8251588940620422, Val Acc: 58.44%\n",
      "Epoch: 1801,     Training Loss: 0.5408046841621399, Training Acc: 62.71%\n",
      "              Val Loss: 0.8254421353340149, Val Acc: 58.45%\n",
      "Epoch: 1802,     Training Loss: 0.5401028990745544, Training Acc: 62.72%\n",
      "              Val Loss: 0.8273128271102905, Val Acc: 58.46%\n",
      "Epoch: 1803,     Training Loss: 0.5393336415290833, Training Acc: 62.73%\n",
      "              Val Loss: 0.8269131183624268, Val Acc: 58.47%\n",
      "Epoch: 1804,     Training Loss: 0.5386233329772949, Training Acc: 62.74%\n",
      "              Val Loss: 0.8287659287452698, Val Acc: 58.47%\n",
      "Epoch: 1805,     Training Loss: 0.5380291938781738, Training Acc: 62.74%\n",
      "              Val Loss: 0.827547550201416, Val Acc: 58.48%\n",
      "Epoch: 1806,     Training Loss: 0.5377635955810547, Training Acc: 62.75%\n",
      "              Val Loss: 0.8298805356025696, Val Acc: 58.49%\n",
      "Epoch: 1807,     Training Loss: 0.5380045175552368, Training Acc: 62.76%\n",
      "              Val Loss: 0.8292193412780762, Val Acc: 58.50%\n",
      "Epoch: 1808,     Training Loss: 0.5395117402076721, Training Acc: 62.77%\n",
      "              Val Loss: 0.8396636843681335, Val Acc: 58.50%\n",
      "Epoch: 1809,     Training Loss: 0.5440459251403809, Training Acc: 62.78%\n",
      "              Val Loss: 0.8458960652351379, Val Acc: 58.51%\n",
      "Epoch: 1810,     Training Loss: 0.559785783290863, Training Acc: 62.79%\n",
      "              Val Loss: 0.8822945952415466, Val Acc: 58.52%\n",
      "Epoch: 1811,     Training Loss: 0.5809637308120728, Training Acc: 62.80%\n",
      "              Val Loss: 0.9246811866760254, Val Acc: 58.52%\n",
      "Epoch: 1812,     Training Loss: 0.6441917419433594, Training Acc: 62.80%\n",
      "              Val Loss: 0.9321999549865723, Val Acc: 58.52%\n",
      "Epoch: 1813,     Training Loss: 0.6274653077125549, Training Acc: 62.80%\n",
      "              Val Loss: 0.9028565287590027, Val Acc: 58.53%\n",
      "Epoch: 1814,     Training Loss: 0.6301231384277344, Training Acc: 62.81%\n",
      "              Val Loss: 0.8433801531791687, Val Acc: 58.53%\n",
      "Epoch: 1815,     Training Loss: 0.5528232455253601, Training Acc: 62.82%\n",
      "              Val Loss: 0.8437421917915344, Val Acc: 58.54%\n",
      "Epoch: 1816,     Training Loss: 0.5495226383209229, Training Acc: 62.83%\n",
      "              Val Loss: 0.8798204064369202, Val Acc: 58.55%\n",
      "Epoch: 1817,     Training Loss: 0.6001291275024414, Training Acc: 62.83%\n",
      "              Val Loss: 0.8865765333175659, Val Acc: 58.55%\n",
      "Epoch: 1818,     Training Loss: 0.5894891619682312, Training Acc: 62.84%\n",
      "              Val Loss: 0.8425870537757874, Val Acc: 58.56%\n",
      "Epoch: 1819,     Training Loss: 0.5617744326591492, Training Acc: 62.85%\n",
      "              Val Loss: 0.8280627727508545, Val Acc: 58.57%\n",
      "Epoch: 1820,     Training Loss: 0.5367470383644104, Training Acc: 62.86%\n",
      "              Val Loss: 0.8585712313652039, Val Acc: 58.57%\n",
      "Epoch: 1821,     Training Loss: 0.5598127841949463, Training Acc: 62.86%\n",
      "              Val Loss: 0.8842790126800537, Val Acc: 58.58%\n",
      "Epoch: 1822,     Training Loss: 0.6026878952980042, Training Acc: 62.87%\n",
      "              Val Loss: 0.8908958435058594, Val Acc: 58.58%\n",
      "Epoch: 1823,     Training Loss: 0.5890240669250488, Training Acc: 62.88%\n",
      "              Val Loss: 0.8440865278244019, Val Acc: 58.59%\n",
      "Epoch: 1824,     Training Loss: 0.5663939714431763, Training Acc: 62.89%\n",
      "              Val Loss: 0.8279381394386292, Val Acc: 58.60%\n",
      "Epoch: 1825,     Training Loss: 0.5358695387840271, Training Acc: 62.89%\n",
      "              Val Loss: 0.8512510657310486, Val Acc: 58.60%\n",
      "Epoch: 1826,     Training Loss: 0.5490444302558899, Training Acc: 62.90%\n",
      "              Val Loss: 0.8621169924736023, Val Acc: 58.61%\n",
      "Epoch: 1827,     Training Loss: 0.582655131816864, Training Acc: 62.91%\n",
      "              Val Loss: 0.8809282183647156, Val Acc: 58.61%\n",
      "Epoch: 1828,     Training Loss: 0.584399402141571, Training Acc: 62.92%\n",
      "              Val Loss: 0.8953315615653992, Val Acc: 58.62%\n",
      "Epoch: 1829,     Training Loss: 0.6019340753555298, Training Acc: 62.92%\n",
      "              Val Loss: 0.8653588891029358, Val Acc: 58.62%\n",
      "Epoch: 1830,     Training Loss: 0.5581234693527222, Training Acc: 62.93%\n",
      "              Val Loss: 0.8404561877250671, Val Acc: 58.63%\n",
      "Epoch: 1831,     Training Loss: 0.5549668073654175, Training Acc: 62.94%\n",
      "              Val Loss: 0.8259322643280029, Val Acc: 58.64%\n",
      "Epoch: 1832,     Training Loss: 0.5307596325874329, Training Acc: 62.95%\n",
      "              Val Loss: 0.8712657690048218, Val Acc: 58.64%\n",
      "Epoch: 1833,     Training Loss: 0.5616346001625061, Training Acc: 62.95%\n",
      "              Val Loss: 0.8843338489532471, Val Acc: 58.65%\n",
      "Epoch: 1834,     Training Loss: 0.606138288974762, Training Acc: 62.96%\n",
      "              Val Loss: 0.9080106616020203, Val Acc: 58.65%\n",
      "Epoch: 1835,     Training Loss: 0.6050900220870972, Training Acc: 62.97%\n",
      "              Val Loss: 0.9264926910400391, Val Acc: 58.66%\n",
      "Epoch: 1836,     Training Loss: 0.6340146064758301, Training Acc: 62.97%\n",
      "              Val Loss: 0.870491087436676, Val Acc: 58.66%\n",
      "Epoch: 1837,     Training Loss: 0.5659497976303101, Training Acc: 62.98%\n",
      "              Val Loss: 0.8620269298553467, Val Acc: 58.67%\n",
      "Epoch: 1838,     Training Loss: 0.57456374168396, Training Acc: 62.99%\n",
      "              Val Loss: 0.8533667922019958, Val Acc: 58.68%\n",
      "Epoch: 1839,     Training Loss: 0.5606468319892883, Training Acc: 62.99%\n",
      "              Val Loss: 0.9574128985404968, Val Acc: 58.68%\n",
      "Epoch: 1840,     Training Loss: 0.6332770586013794, Training Acc: 63.00%\n",
      "              Val Loss: 0.9523069858551025, Val Acc: 58.68%\n",
      "Epoch: 1841,     Training Loss: 0.6877220273017883, Training Acc: 63.00%\n",
      "              Val Loss: 0.9035916328430176, Val Acc: 58.69%\n",
      "Epoch: 1842,     Training Loss: 0.6111271381378174, Training Acc: 63.01%\n",
      "              Val Loss: 0.8904963731765747, Val Acc: 58.69%\n",
      "Epoch: 1843,     Training Loss: 0.5815573930740356, Training Acc: 63.01%\n",
      "              Val Loss: 0.8835901618003845, Val Acc: 58.70%\n",
      "Epoch: 1844,     Training Loss: 0.5880152583122253, Training Acc: 63.02%\n",
      "              Val Loss: 0.9164620041847229, Val Acc: 58.70%\n",
      "Epoch: 1845,     Training Loss: 0.6300665140151978, Training Acc: 63.03%\n",
      "              Val Loss: 0.907142698764801, Val Acc: 58.71%\n",
      "Epoch: 1846,     Training Loss: 0.6322739124298096, Training Acc: 63.03%\n",
      "              Val Loss: 0.9261839389801025, Val Acc: 58.71%\n",
      "Epoch: 1847,     Training Loss: 0.596930980682373, Training Acc: 63.04%\n",
      "              Val Loss: 0.8319584131240845, Val Acc: 58.72%\n",
      "Epoch: 1848,     Training Loss: 0.5326493978500366, Training Acc: 63.05%\n",
      "              Val Loss: 0.8490644097328186, Val Acc: 58.73%\n",
      "Epoch: 1849,     Training Loss: 0.5555323958396912, Training Acc: 63.05%\n",
      "              Val Loss: 0.859360933303833, Val Acc: 58.73%\n",
      "Epoch: 1850,     Training Loss: 0.5526947379112244, Training Acc: 63.06%\n",
      "              Val Loss: 0.8980688452720642, Val Acc: 58.74%\n",
      "Epoch: 1851,     Training Loss: 0.5928667187690735, Training Acc: 63.07%\n",
      "              Val Loss: 0.861481249332428, Val Acc: 58.74%\n",
      "Epoch: 1852,     Training Loss: 0.5598457455635071, Training Acc: 63.08%\n",
      "              Val Loss: 0.856245219707489, Val Acc: 58.75%\n",
      "Epoch: 1853,     Training Loss: 0.5633612275123596, Training Acc: 63.08%\n",
      "              Val Loss: 0.8397113084793091, Val Acc: 58.76%\n",
      "Epoch: 1854,     Training Loss: 0.537231981754303, Training Acc: 63.09%\n",
      "              Val Loss: 0.844696044921875, Val Acc: 58.76%\n",
      "Epoch: 1855,     Training Loss: 0.5386055111885071, Training Acc: 63.10%\n",
      "              Val Loss: 0.8445969223976135, Val Acc: 58.77%\n",
      "Epoch: 1856,     Training Loss: 0.5403298735618591, Training Acc: 63.11%\n",
      "              Val Loss: 0.8437530398368835, Val Acc: 58.78%\n",
      "Epoch: 1857,     Training Loss: 0.5353572964668274, Training Acc: 63.12%\n",
      "              Val Loss: 0.850226640701294, Val Acc: 58.78%\n",
      "Epoch: 1858,     Training Loss: 0.5369566082954407, Training Acc: 63.13%\n",
      "              Val Loss: 0.8387776017189026, Val Acc: 58.79%\n",
      "Epoch: 1859,     Training Loss: 0.531817615032196, Training Acc: 63.13%\n",
      "              Val Loss: 0.8577774167060852, Val Acc: 58.80%\n",
      "Epoch: 1860,     Training Loss: 0.565207302570343, Training Acc: 63.14%\n",
      "              Val Loss: 0.9067730903625488, Val Acc: 58.80%\n",
      "Epoch: 1861,     Training Loss: 0.5948637127876282, Training Acc: 63.15%\n",
      "              Val Loss: 1.055281400680542, Val Acc: 58.80%\n",
      "Epoch: 1862,     Training Loss: 0.763936460018158, Training Acc: 63.15%\n",
      "              Val Loss: 1.2756253480911255, Val Acc: 58.80%\n",
      "Epoch: 1863,     Training Loss: 0.9477365016937256, Training Acc: 63.15%\n",
      "              Val Loss: 1.4463098049163818, Val Acc: 58.79%\n",
      "Epoch: 1864,     Training Loss: 1.2563787698745728, Training Acc: 63.14%\n",
      "              Val Loss: 1.137535572052002, Val Acc: 58.79%\n",
      "Epoch: 1865,     Training Loss: 0.8911077976226807, Training Acc: 63.14%\n",
      "              Val Loss: 1.7311124801635742, Val Acc: 58.78%\n",
      "Epoch: 1866,     Training Loss: 1.425331711769104, Training Acc: 63.13%\n",
      "              Val Loss: 1.3463810682296753, Val Acc: 58.78%\n",
      "Epoch: 1867,     Training Loss: 1.0963873863220215, Training Acc: 63.13%\n",
      "              Val Loss: 1.4396291971206665, Val Acc: 58.77%\n",
      "Epoch: 1868,     Training Loss: 1.251382827758789, Training Acc: 63.12%\n",
      "              Val Loss: 1.0458416938781738, Val Acc: 58.78%\n",
      "Epoch: 1869,     Training Loss: 0.8206804394721985, Training Acc: 63.12%\n",
      "              Val Loss: 1.6366751194000244, Val Acc: 58.77%\n",
      "Epoch: 1870,     Training Loss: 1.3769803047180176, Training Acc: 63.11%\n",
      "              Val Loss: 1.032902717590332, Val Acc: 58.77%\n",
      "Epoch: 1871,     Training Loss: 0.8161593079566956, Training Acc: 63.12%\n",
      "              Val Loss: 1.2747693061828613, Val Acc: 58.77%\n",
      "Epoch: 1872,     Training Loss: 1.0985469818115234, Training Acc: 63.11%\n",
      "              Val Loss: 1.101344347000122, Val Acc: 58.77%\n",
      "Epoch: 1873,     Training Loss: 0.9188535809516907, Training Acc: 63.12%\n",
      "              Val Loss: 1.0871847867965698, Val Acc: 58.77%\n",
      "Epoch: 1874,     Training Loss: 0.8974024057388306, Training Acc: 63.12%\n",
      "              Val Loss: 1.0748074054718018, Val Acc: 58.76%\n",
      "Epoch: 1875,     Training Loss: 0.8829413056373596, Training Acc: 63.11%\n",
      "              Val Loss: 1.0543889999389648, Val Acc: 58.76%\n",
      "Epoch: 1876,     Training Loss: 0.851187527179718, Training Acc: 63.11%\n",
      "              Val Loss: 1.0243501663208008, Val Acc: 58.77%\n",
      "Epoch: 1877,     Training Loss: 0.8308367133140564, Training Acc: 63.11%\n",
      "              Val Loss: 1.0746839046478271, Val Acc: 58.77%\n",
      "Epoch: 1878,     Training Loss: 0.8524051904678345, Training Acc: 63.11%\n",
      "              Val Loss: 1.049647331237793, Val Acc: 58.77%\n",
      "Epoch: 1879,     Training Loss: 0.8143484592437744, Training Acc: 63.12%\n",
      "              Val Loss: 0.9756304025650024, Val Acc: 58.77%\n",
      "Epoch: 1880,     Training Loss: 0.7800793647766113, Training Acc: 63.12%\n",
      "              Val Loss: 0.97840416431427, Val Acc: 58.77%\n",
      "Epoch: 1881,     Training Loss: 0.7729611992835999, Training Acc: 63.12%\n",
      "              Val Loss: 1.001533031463623, Val Acc: 58.78%\n",
      "Epoch: 1882,     Training Loss: 0.7491672039031982, Training Acc: 63.12%\n",
      "              Val Loss: 1.0002150535583496, Val Acc: 58.78%\n",
      "Epoch: 1883,     Training Loss: 0.7713375687599182, Training Acc: 63.12%\n",
      "              Val Loss: 0.8855186700820923, Val Acc: 58.78%\n",
      "Epoch: 1884,     Training Loss: 0.7096326351165771, Training Acc: 63.13%\n",
      "              Val Loss: 0.9361715912818909, Val Acc: 58.78%\n",
      "Epoch: 1885,     Training Loss: 0.743831992149353, Training Acc: 63.13%\n",
      "              Val Loss: 0.9426579475402832, Val Acc: 58.79%\n",
      "Epoch: 1886,     Training Loss: 0.7118074893951416, Training Acc: 63.13%\n",
      "              Val Loss: 0.9001132249832153, Val Acc: 58.79%\n",
      "Epoch: 1887,     Training Loss: 0.6753262877464294, Training Acc: 63.14%\n",
      "              Val Loss: 0.9341166019439697, Val Acc: 58.80%\n",
      "Epoch: 1888,     Training Loss: 0.7142045497894287, Training Acc: 63.14%\n",
      "              Val Loss: 0.8721916079521179, Val Acc: 58.80%\n",
      "Epoch: 1889,     Training Loss: 0.6591855883598328, Training Acc: 63.15%\n",
      "              Val Loss: 0.9371085166931152, Val Acc: 58.80%\n",
      "Epoch: 1890,     Training Loss: 0.6961302161216736, Training Acc: 63.15%\n",
      "              Val Loss: 0.8539783954620361, Val Acc: 58.81%\n",
      "Epoch: 1891,     Training Loss: 0.6309806704521179, Training Acc: 63.15%\n",
      "              Val Loss: 0.9111632704734802, Val Acc: 58.82%\n",
      "Epoch: 1892,     Training Loss: 0.6734798550605774, Training Acc: 63.16%\n",
      "              Val Loss: 0.8909738659858704, Val Acc: 58.82%\n",
      "Epoch: 1893,     Training Loss: 0.6278795003890991, Training Acc: 63.17%\n",
      "              Val Loss: 0.9393812417984009, Val Acc: 58.82%\n",
      "Epoch: 1894,     Training Loss: 0.652660071849823, Training Acc: 63.17%\n",
      "              Val Loss: 0.9093748331069946, Val Acc: 58.83%\n",
      "Epoch: 1895,     Training Loss: 0.6395360827445984, Training Acc: 63.18%\n",
      "              Val Loss: 0.8819316625595093, Val Acc: 58.83%\n",
      "Epoch: 1896,     Training Loss: 0.6309500932693481, Training Acc: 63.18%\n",
      "              Val Loss: 0.901091456413269, Val Acc: 58.84%\n",
      "Epoch: 1897,     Training Loss: 0.6380606889724731, Training Acc: 63.19%\n",
      "              Val Loss: 0.8736383318901062, Val Acc: 58.84%\n",
      "Epoch: 1898,     Training Loss: 0.6108149886131287, Training Acc: 63.19%\n",
      "              Val Loss: 0.883380651473999, Val Acc: 58.85%\n",
      "Epoch: 1899,     Training Loss: 0.6299397945404053, Training Acc: 63.20%\n",
      "              Val Loss: 0.8581714630126953, Val Acc: 58.85%\n",
      "Epoch: 1900,     Training Loss: 0.6081591248512268, Training Acc: 63.20%\n",
      "              Val Loss: 0.8802986145019531, Val Acc: 58.86%\n",
      "Epoch: 1901,     Training Loss: 0.6218803524971008, Training Acc: 63.21%\n",
      "              Val Loss: 0.8474448323249817, Val Acc: 58.87%\n",
      "Epoch: 1902,     Training Loss: 0.6008481383323669, Training Acc: 63.22%\n",
      "              Val Loss: 0.8554145693778992, Val Acc: 58.87%\n",
      "Epoch: 1903,     Training Loss: 0.6120361685752869, Training Acc: 63.22%\n",
      "              Val Loss: 0.8476030230522156, Val Acc: 58.88%\n",
      "Epoch: 1904,     Training Loss: 0.6005592346191406, Training Acc: 63.23%\n",
      "              Val Loss: 0.850614070892334, Val Acc: 58.88%\n",
      "Epoch: 1905,     Training Loss: 0.6028162240982056, Training Acc: 63.24%\n",
      "              Val Loss: 0.8421220183372498, Val Acc: 58.89%\n",
      "Epoch: 1906,     Training Loss: 0.5971126556396484, Training Acc: 63.24%\n",
      "              Val Loss: 0.8500008583068848, Val Acc: 58.90%\n",
      "Epoch: 1907,     Training Loss: 0.5974249839782715, Training Acc: 63.25%\n",
      "              Val Loss: 0.8542584180831909, Val Acc: 58.90%\n",
      "Epoch: 1908,     Training Loss: 0.5935027599334717, Training Acc: 63.26%\n",
      "              Val Loss: 0.8499019742012024, Val Acc: 58.91%\n",
      "Epoch: 1909,     Training Loss: 0.5928545594215393, Training Acc: 63.26%\n",
      "              Val Loss: 0.8472609519958496, Val Acc: 58.92%\n",
      "Epoch: 1910,     Training Loss: 0.5898465514183044, Training Acc: 63.27%\n",
      "              Val Loss: 0.8546367883682251, Val Acc: 58.92%\n",
      "Epoch: 1911,     Training Loss: 0.5877624750137329, Training Acc: 63.28%\n",
      "              Val Loss: 0.8568795919418335, Val Acc: 58.93%\n",
      "Epoch: 1912,     Training Loss: 0.5868972539901733, Training Acc: 63.28%\n",
      "              Val Loss: 0.8500392436981201, Val Acc: 58.94%\n",
      "Epoch: 1913,     Training Loss: 0.5845587253570557, Training Acc: 63.29%\n",
      "              Val Loss: 0.8472045660018921, Val Acc: 58.94%\n",
      "Epoch: 1914,     Training Loss: 0.582832932472229, Training Acc: 63.30%\n",
      "              Val Loss: 0.8482153415679932, Val Acc: 58.95%\n",
      "Epoch: 1915,     Training Loss: 0.5797567963600159, Training Acc: 63.30%\n",
      "              Val Loss: 0.8469588756561279, Val Acc: 58.96%\n",
      "Epoch: 1916,     Training Loss: 0.5788820385932922, Training Acc: 63.31%\n",
      "              Val Loss: 0.8395601511001587, Val Acc: 58.96%\n",
      "Epoch: 1917,     Training Loss: 0.5757540464401245, Training Acc: 63.32%\n",
      "              Val Loss: 0.8408938646316528, Val Acc: 58.97%\n",
      "Epoch: 1918,     Training Loss: 0.573671817779541, Training Acc: 63.33%\n",
      "              Val Loss: 0.8446226716041565, Val Acc: 58.98%\n",
      "Epoch: 1919,     Training Loss: 0.5697090029716492, Training Acc: 63.33%\n",
      "              Val Loss: 0.8485074043273926, Val Acc: 58.98%\n",
      "Epoch: 1920,     Training Loss: 0.5680949687957764, Training Acc: 63.34%\n",
      "              Val Loss: 0.8486445546150208, Val Acc: 58.99%\n",
      "Epoch: 1921,     Training Loss: 0.5650578141212463, Training Acc: 63.35%\n",
      "              Val Loss: 0.8510318994522095, Val Acc: 59.00%\n",
      "Epoch: 1922,     Training Loss: 0.5633527040481567, Training Acc: 63.36%\n",
      "              Val Loss: 0.8522965908050537, Val Acc: 59.00%\n",
      "Epoch: 1923,     Training Loss: 0.560021162033081, Training Acc: 63.36%\n",
      "              Val Loss: 0.8535832762718201, Val Acc: 59.01%\n",
      "Epoch: 1924,     Training Loss: 0.5584773421287537, Training Acc: 63.37%\n",
      "              Val Loss: 0.850199282169342, Val Acc: 59.02%\n",
      "Epoch: 1925,     Training Loss: 0.5562658905982971, Training Acc: 63.38%\n",
      "              Val Loss: 0.8499188423156738, Val Acc: 59.02%\n",
      "Epoch: 1926,     Training Loss: 0.554517388343811, Training Acc: 63.39%\n",
      "              Val Loss: 0.8526514172554016, Val Acc: 59.03%\n",
      "Epoch: 1927,     Training Loss: 0.5512745380401611, Training Acc: 63.39%\n",
      "              Val Loss: 0.853690505027771, Val Acc: 59.04%\n",
      "Epoch: 1928,     Training Loss: 0.5501784682273865, Training Acc: 63.40%\n",
      "              Val Loss: 0.8503332734107971, Val Acc: 59.04%\n",
      "Epoch: 1929,     Training Loss: 0.5481266975402832, Training Acc: 63.41%\n",
      "              Val Loss: 0.8510617017745972, Val Acc: 59.05%\n",
      "Epoch: 1930,     Training Loss: 0.5464227795600891, Training Acc: 63.42%\n",
      "              Val Loss: 0.8489935398101807, Val Acc: 59.06%\n",
      "Epoch: 1931,     Training Loss: 0.544074296951294, Training Acc: 63.42%\n",
      "              Val Loss: 0.844113290309906, Val Acc: 59.06%\n",
      "Epoch: 1932,     Training Loss: 0.54249107837677, Training Acc: 63.43%\n",
      "              Val Loss: 0.8410296440124512, Val Acc: 59.07%\n",
      "Epoch: 1933,     Training Loss: 0.5404372215270996, Training Acc: 63.44%\n",
      "              Val Loss: 0.8411029577255249, Val Acc: 59.08%\n",
      "Epoch: 1934,     Training Loss: 0.5386728644371033, Training Acc: 63.45%\n",
      "              Val Loss: 0.8415911197662354, Val Acc: 59.09%\n",
      "Epoch: 1935,     Training Loss: 0.5363910794258118, Training Acc: 63.46%\n",
      "              Val Loss: 0.838745653629303, Val Acc: 59.09%\n",
      "Epoch: 1936,     Training Loss: 0.5349693298339844, Training Acc: 63.46%\n",
      "              Val Loss: 0.8343698978424072, Val Acc: 59.10%\n",
      "Epoch: 1937,     Training Loss: 0.5328119397163391, Training Acc: 63.47%\n",
      "              Val Loss: 0.8323806524276733, Val Acc: 59.11%\n",
      "Epoch: 1938,     Training Loss: 0.5318600535392761, Training Acc: 63.48%\n",
      "              Val Loss: 0.8251932263374329, Val Acc: 59.11%\n",
      "Epoch: 1939,     Training Loss: 0.5298268795013428, Training Acc: 63.49%\n",
      "              Val Loss: 0.8215185403823853, Val Acc: 59.12%\n",
      "Epoch: 1940,     Training Loss: 0.5288940668106079, Training Acc: 63.49%\n",
      "              Val Loss: 0.8182506561279297, Val Acc: 59.13%\n",
      "Epoch: 1941,     Training Loss: 0.5268600583076477, Training Acc: 63.50%\n",
      "              Val Loss: 0.8167354464530945, Val Acc: 59.14%\n",
      "Epoch: 1942,     Training Loss: 0.5260553956031799, Training Acc: 63.51%\n",
      "              Val Loss: 0.8135064840316772, Val Acc: 59.14%\n",
      "Epoch: 1943,     Training Loss: 0.524569034576416, Training Acc: 63.52%\n",
      "              Val Loss: 0.8099653124809265, Val Acc: 59.15%\n",
      "Epoch: 1944,     Training Loss: 0.5237458348274231, Training Acc: 63.53%\n",
      "              Val Loss: 0.8076919317245483, Val Acc: 59.16%\n",
      "Epoch: 1945,     Training Loss: 0.522384762763977, Training Acc: 63.53%\n",
      "              Val Loss: 0.805188000202179, Val Acc: 59.17%\n",
      "Epoch: 1946,     Training Loss: 0.5216408967971802, Training Acc: 63.54%\n",
      "              Val Loss: 0.8033183217048645, Val Acc: 59.17%\n",
      "Epoch: 1947,     Training Loss: 0.5206351280212402, Training Acc: 63.55%\n",
      "              Val Loss: 0.8039958477020264, Val Acc: 59.18%\n",
      "Epoch: 1948,     Training Loss: 0.5198584198951721, Training Acc: 63.56%\n",
      "              Val Loss: 0.8050075769424438, Val Acc: 59.19%\n",
      "Epoch: 1949,     Training Loss: 0.5188231468200684, Training Acc: 63.57%\n",
      "              Val Loss: 0.8044052124023438, Val Acc: 59.19%\n",
      "Epoch: 1950,     Training Loss: 0.5181546807289124, Training Acc: 63.58%\n",
      "              Val Loss: 0.8049834966659546, Val Acc: 59.20%\n",
      "Epoch: 1951,     Training Loss: 0.5173032879829407, Training Acc: 63.58%\n",
      "              Val Loss: 0.8024250864982605, Val Acc: 59.21%\n",
      "Epoch: 1952,     Training Loss: 0.5169717669487, Training Acc: 63.59%\n",
      "              Val Loss: 0.804594099521637, Val Acc: 59.22%\n",
      "Epoch: 1953,     Training Loss: 0.5167674422264099, Training Acc: 63.60%\n",
      "              Val Loss: 0.8011760115623474, Val Acc: 59.22%\n",
      "Epoch: 1954,     Training Loss: 0.5177352428436279, Training Acc: 63.61%\n",
      "              Val Loss: 0.8108922839164734, Val Acc: 59.23%\n",
      "Epoch: 1955,     Training Loss: 0.519790768623352, Training Acc: 63.62%\n",
      "              Val Loss: 0.8092283010482788, Val Acc: 59.24%\n",
      "Epoch: 1956,     Training Loss: 0.5275083780288696, Training Acc: 63.62%\n",
      "              Val Loss: 0.8376442193984985, Val Acc: 59.24%\n",
      "Epoch: 1957,     Training Loss: 0.5392342209815979, Training Acc: 63.63%\n",
      "              Val Loss: 0.860248863697052, Val Acc: 59.25%\n",
      "Epoch: 1958,     Training Loss: 0.5788031220436096, Training Acc: 63.64%\n",
      "              Val Loss: 0.906088650226593, Val Acc: 59.25%\n",
      "Epoch: 1959,     Training Loss: 0.5943654775619507, Training Acc: 63.64%\n",
      "              Val Loss: 0.9331138134002686, Val Acc: 59.25%\n",
      "Epoch: 1960,     Training Loss: 0.6597635746002197, Training Acc: 63.65%\n",
      "              Val Loss: 0.8728781938552856, Val Acc: 59.26%\n",
      "Epoch: 1961,     Training Loss: 0.5729997158050537, Training Acc: 63.65%\n",
      "              Val Loss: 0.8169934749603271, Val Acc: 59.26%\n",
      "Epoch: 1962,     Training Loss: 0.5307675004005432, Training Acc: 63.66%\n",
      "              Val Loss: 0.8074215054512024, Val Acc: 59.27%\n",
      "Epoch: 1963,     Training Loss: 0.517289936542511, Training Acc: 63.67%\n",
      "              Val Loss: 0.8497302532196045, Val Acc: 59.28%\n",
      "Epoch: 1964,     Training Loss: 0.5481271147727966, Training Acc: 63.67%\n",
      "              Val Loss: 0.874796450138092, Val Acc: 59.28%\n",
      "Epoch: 1965,     Training Loss: 0.589209794998169, Training Acc: 63.68%\n",
      "              Val Loss: 0.8863200545310974, Val Acc: 59.28%\n",
      "Epoch: 1966,     Training Loss: 0.5692573189735413, Training Acc: 63.69%\n",
      "              Val Loss: 0.8356074690818787, Val Acc: 59.29%\n",
      "Epoch: 1967,     Training Loss: 0.550397515296936, Training Acc: 63.69%\n",
      "              Val Loss: 0.8194787502288818, Val Acc: 59.30%\n",
      "Epoch: 1968,     Training Loss: 0.5196327567100525, Training Acc: 63.70%\n",
      "              Val Loss: 0.8350830078125, Val Acc: 59.30%\n",
      "Epoch: 1969,     Training Loss: 0.5248956680297852, Training Acc: 63.71%\n",
      "              Val Loss: 0.8315712809562683, Val Acc: 59.31%\n",
      "Epoch: 1970,     Training Loss: 0.5439377427101135, Training Acc: 63.72%\n",
      "              Val Loss: 0.866304337978363, Val Acc: 59.31%\n",
      "Epoch: 1971,     Training Loss: 0.5598527789115906, Training Acc: 63.72%\n",
      "              Val Loss: 0.8662563562393188, Val Acc: 59.32%\n",
      "Epoch: 1972,     Training Loss: 0.5670932531356812, Training Acc: 63.73%\n",
      "              Val Loss: 0.8638225793838501, Val Acc: 59.32%\n",
      "Epoch: 1973,     Training Loss: 0.5438534021377563, Training Acc: 63.73%\n",
      "              Val Loss: 0.8184370398521423, Val Acc: 59.33%\n",
      "Epoch: 1974,     Training Loss: 0.5294750332832336, Training Acc: 63.74%\n",
      "              Val Loss: 0.8091973662376404, Val Acc: 59.34%\n",
      "Epoch: 1975,     Training Loss: 0.5110418796539307, Training Acc: 63.75%\n",
      "              Val Loss: 0.8431682586669922, Val Acc: 59.34%\n",
      "Epoch: 1976,     Training Loss: 0.5247352123260498, Training Acc: 63.76%\n",
      "              Val Loss: 0.8328059315681458, Val Acc: 59.35%\n",
      "Epoch: 1977,     Training Loss: 0.5345649123191833, Training Acc: 63.77%\n",
      "              Val Loss: 0.8770678043365479, Val Acc: 59.35%\n",
      "Epoch: 1978,     Training Loss: 0.5656777620315552, Training Acc: 63.77%\n",
      "              Val Loss: 0.9049984216690063, Val Acc: 59.36%\n",
      "Epoch: 1979,     Training Loss: 0.6047313213348389, Training Acc: 63.78%\n",
      "              Val Loss: 0.9238593578338623, Val Acc: 59.36%\n",
      "Epoch: 1980,     Training Loss: 0.5883661508560181, Training Acc: 63.78%\n",
      "              Val Loss: 0.8870692253112793, Val Acc: 59.37%\n",
      "Epoch: 1981,     Training Loss: 0.5919137597084045, Training Acc: 63.79%\n",
      "              Val Loss: 0.8440325856208801, Val Acc: 59.37%\n",
      "Epoch: 1982,     Training Loss: 0.5321189165115356, Training Acc: 63.79%\n",
      "              Val Loss: 0.8687284588813782, Val Acc: 59.38%\n",
      "Epoch: 1983,     Training Loss: 0.5388721823692322, Training Acc: 63.80%\n",
      "              Val Loss: 0.8584861755371094, Val Acc: 59.38%\n",
      "Epoch: 1984,     Training Loss: 0.5500872135162354, Training Acc: 63.81%\n",
      "              Val Loss: 0.9139258861541748, Val Acc: 59.39%\n",
      "Epoch: 1985,     Training Loss: 0.5981667041778564, Training Acc: 63.81%\n",
      "              Val Loss: 0.9336392879486084, Val Acc: 59.39%\n",
      "Epoch: 1986,     Training Loss: 0.6382977962493896, Training Acc: 63.82%\n",
      "              Val Loss: 0.9248995184898376, Val Acc: 59.39%\n",
      "Epoch: 1987,     Training Loss: 0.5923892855644226, Training Acc: 63.82%\n",
      "              Val Loss: 0.8375311493873596, Val Acc: 59.40%\n",
      "Epoch: 1988,     Training Loss: 0.549315869808197, Training Acc: 63.83%\n",
      "              Val Loss: 0.8180029988288879, Val Acc: 59.41%\n",
      "Epoch: 1989,     Training Loss: 0.5211727023124695, Training Acc: 63.84%\n",
      "              Val Loss: 0.8639212250709534, Val Acc: 59.41%\n",
      "Epoch: 1990,     Training Loss: 0.540879487991333, Training Acc: 63.84%\n",
      "              Val Loss: 0.8804773092269897, Val Acc: 59.42%\n",
      "Epoch: 1991,     Training Loss: 0.5789623260498047, Training Acc: 63.85%\n",
      "              Val Loss: 0.8984484076499939, Val Acc: 59.42%\n",
      "Epoch: 1992,     Training Loss: 0.5815140008926392, Training Acc: 63.85%\n",
      "              Val Loss: 0.8721209764480591, Val Acc: 59.42%\n",
      "Epoch: 1993,     Training Loss: 0.5735018253326416, Training Acc: 63.86%\n",
      "              Val Loss: 0.8575307726860046, Val Acc: 59.43%\n",
      "Epoch: 1994,     Training Loss: 0.5326572060585022, Training Acc: 63.87%\n",
      "              Val Loss: 0.8103509545326233, Val Acc: 59.44%\n",
      "Epoch: 1995,     Training Loss: 0.505818784236908, Training Acc: 63.87%\n",
      "              Val Loss: 0.8129033446311951, Val Acc: 59.44%\n",
      "Epoch: 1996,     Training Loss: 0.5153996348381042, Training Acc: 63.88%\n",
      "              Val Loss: 0.8490455746650696, Val Acc: 59.45%\n",
      "Epoch: 1997,     Training Loss: 0.529434323310852, Training Acc: 63.89%\n",
      "              Val Loss: 0.8593266010284424, Val Acc: 59.45%\n",
      "Epoch: 1998,     Training Loss: 0.5565546154975891, Training Acc: 63.90%\n",
      "              Val Loss: 0.8611373901367188, Val Acc: 59.46%\n",
      "Epoch: 1999,     Training Loss: 0.5443034768104553, Training Acc: 63.90%\n",
      "              Val Loss: 0.8415470719337463, Val Acc: 59.46%\n",
      "Epoch: 2000,     Training Loss: 0.5408669710159302, Training Acc: 63.91%\n",
      "              Val Loss: 0.8336164951324463, Val Acc: 59.47%\n",
      "Epoch: 2001,     Training Loss: 0.5155495405197144, Training Acc: 63.92%\n",
      "              Val Loss: 0.8094291687011719, Val Acc: 59.48%\n",
      "Epoch: 2002,     Training Loss: 0.5013693571090698, Training Acc: 63.93%\n",
      "              Val Loss: 0.8090268969535828, Val Acc: 59.48%\n",
      "Epoch: 2003,     Training Loss: 0.501372218132019, Training Acc: 63.93%\n",
      "              Val Loss: 0.8269923329353333, Val Acc: 59.49%\n",
      "Epoch: 2004,     Training Loss: 0.5091819167137146, Training Acc: 63.94%\n",
      "              Val Loss: 0.8333218097686768, Val Acc: 59.50%\n",
      "Epoch: 2005,     Training Loss: 0.5245020389556885, Training Acc: 63.95%\n",
      "              Val Loss: 0.8602398633956909, Val Acc: 59.50%\n",
      "Epoch: 2006,     Training Loss: 0.5373621582984924, Training Acc: 63.96%\n",
      "              Val Loss: 0.8750820755958557, Val Acc: 59.51%\n",
      "Epoch: 2007,     Training Loss: 0.5733199119567871, Training Acc: 63.96%\n",
      "              Val Loss: 0.8826970458030701, Val Acc: 59.51%\n",
      "Epoch: 2008,     Training Loss: 0.5589188933372498, Training Acc: 63.97%\n",
      "              Val Loss: 0.8666666150093079, Val Acc: 59.51%\n",
      "Epoch: 2009,     Training Loss: 0.5661711692810059, Training Acc: 63.97%\n",
      "              Val Loss: 0.8464140295982361, Val Acc: 59.52%\n",
      "Epoch: 2010,     Training Loss: 0.5288889408111572, Training Acc: 63.98%\n",
      "              Val Loss: 0.8181547522544861, Val Acc: 59.53%\n",
      "Epoch: 2011,     Training Loss: 0.5116459131240845, Training Acc: 63.99%\n",
      "              Val Loss: 0.814279317855835, Val Acc: 59.53%\n",
      "Epoch: 2012,     Training Loss: 0.49836719036102295, Training Acc: 64.00%\n",
      "              Val Loss: 0.8160632252693176, Val Acc: 59.54%\n",
      "Epoch: 2013,     Training Loss: 0.49821358919143677, Training Acc: 64.00%\n",
      "              Val Loss: 0.8192263841629028, Val Acc: 59.55%\n",
      "Epoch: 2014,     Training Loss: 0.5084349513053894, Training Acc: 64.01%\n",
      "              Val Loss: 0.8429003357887268, Val Acc: 59.55%\n",
      "Epoch: 2015,     Training Loss: 0.5211095213890076, Training Acc: 64.02%\n",
      "              Val Loss: 0.8518431186676025, Val Acc: 59.56%\n",
      "Epoch: 2016,     Training Loss: 0.5489470362663269, Training Acc: 64.03%\n",
      "              Val Loss: 0.8816208839416504, Val Acc: 59.56%\n",
      "Epoch: 2017,     Training Loss: 0.5571191310882568, Training Acc: 64.03%\n",
      "              Val Loss: 0.9000111222267151, Val Acc: 59.56%\n",
      "Epoch: 2018,     Training Loss: 0.6004299521446228, Training Acc: 64.04%\n",
      "              Val Loss: 0.8812695145606995, Val Acc: 59.57%\n",
      "Epoch: 2019,     Training Loss: 0.5589213371276855, Training Acc: 64.04%\n",
      "              Val Loss: 0.8567076325416565, Val Acc: 59.57%\n",
      "Epoch: 2020,     Training Loss: 0.5473672747612, Training Acc: 64.05%\n",
      "              Val Loss: 0.8307061195373535, Val Acc: 59.58%\n",
      "Epoch: 2021,     Training Loss: 0.5076321959495544, Training Acc: 64.06%\n",
      "              Val Loss: 0.8127749562263489, Val Acc: 59.59%\n",
      "Epoch: 2022,     Training Loss: 0.49582019448280334, Training Acc: 64.06%\n",
      "              Val Loss: 0.8185752630233765, Val Acc: 59.59%\n",
      "Epoch: 2023,     Training Loss: 0.504187822341919, Training Acc: 64.07%\n",
      "              Val Loss: 0.8520971536636353, Val Acc: 59.60%\n",
      "Epoch: 2024,     Training Loss: 0.5257418155670166, Training Acc: 64.08%\n",
      "              Val Loss: 0.8774463534355164, Val Acc: 59.60%\n",
      "Epoch: 2025,     Training Loss: 0.5730062127113342, Training Acc: 64.08%\n",
      "              Val Loss: 0.894925594329834, Val Acc: 59.60%\n",
      "Epoch: 2026,     Training Loss: 0.5701978206634521, Training Acc: 64.09%\n",
      "              Val Loss: 0.902760922908783, Val Acc: 59.61%\n",
      "Epoch: 2027,     Training Loss: 0.5957696437835693, Training Acc: 64.09%\n",
      "              Val Loss: 0.8586410284042358, Val Acc: 59.61%\n",
      "Epoch: 2028,     Training Loss: 0.5317879319190979, Training Acc: 64.10%\n",
      "              Val Loss: 0.8197397589683533, Val Acc: 59.62%\n",
      "Epoch: 2029,     Training Loss: 0.5024586915969849, Training Acc: 64.11%\n",
      "              Val Loss: 0.8226348161697388, Val Acc: 59.63%\n",
      "Epoch: 2030,     Training Loss: 0.4969400465488434, Training Acc: 64.12%\n",
      "              Val Loss: 0.8581321835517883, Val Acc: 59.63%\n",
      "Epoch: 2031,     Training Loss: 0.5209189653396606, Training Acc: 64.12%\n",
      "              Val Loss: 0.8897651433944702, Val Acc: 59.64%\n",
      "Epoch: 2032,     Training Loss: 0.5755809545516968, Training Acc: 64.13%\n",
      "              Val Loss: 0.9045137166976929, Val Acc: 59.64%\n",
      "Epoch: 2033,     Training Loss: 0.5725525617599487, Training Acc: 64.13%\n",
      "              Val Loss: 0.8998468518257141, Val Acc: 59.64%\n",
      "Epoch: 2034,     Training Loss: 0.5949074029922485, Training Acc: 64.14%\n",
      "              Val Loss: 0.8503395915031433, Val Acc: 59.65%\n",
      "Epoch: 2035,     Training Loss: 0.5275179147720337, Training Acc: 64.15%\n",
      "              Val Loss: 0.8109970092773438, Val Acc: 59.65%\n",
      "Epoch: 2036,     Training Loss: 0.5004426836967468, Training Acc: 64.15%\n",
      "              Val Loss: 0.8177413940429688, Val Acc: 59.66%\n",
      "Epoch: 2037,     Training Loss: 0.49864596128463745, Training Acc: 64.16%\n",
      "              Val Loss: 0.8651455044746399, Val Acc: 59.67%\n",
      "Epoch: 2038,     Training Loss: 0.5250224471092224, Training Acc: 64.17%\n",
      "              Val Loss: 0.8998034596443176, Val Acc: 59.67%\n",
      "Epoch: 2039,     Training Loss: 0.5773248076438904, Training Acc: 64.17%\n",
      "              Val Loss: 0.9094207882881165, Val Acc: 59.67%\n",
      "Epoch: 2040,     Training Loss: 0.5723318457603455, Training Acc: 64.18%\n",
      "              Val Loss: 0.9038333296775818, Val Acc: 59.68%\n",
      "Epoch: 2041,     Training Loss: 0.5903878808021545, Training Acc: 64.19%\n",
      "              Val Loss: 0.8496343493461609, Val Acc: 59.68%\n",
      "Epoch: 2042,     Training Loss: 0.5232606530189514, Training Acc: 64.19%\n",
      "              Val Loss: 0.8118101358413696, Val Acc: 59.69%\n",
      "Epoch: 2043,     Training Loss: 0.5016917586326599, Training Acc: 64.20%\n",
      "              Val Loss: 0.823805570602417, Val Acc: 59.70%\n",
      "Epoch: 2044,     Training Loss: 0.5046477317810059, Training Acc: 64.21%\n",
      "              Val Loss: 0.8824025988578796, Val Acc: 59.70%\n",
      "Epoch: 2045,     Training Loss: 0.5391331315040588, Training Acc: 64.21%\n",
      "              Val Loss: 0.9261982440948486, Val Acc: 59.70%\n",
      "Epoch: 2046,     Training Loss: 0.6075016856193542, Training Acc: 64.22%\n",
      "              Val Loss: 0.9176251888275146, Val Acc: 59.71%\n",
      "Epoch: 2047,     Training Loss: 0.5828081369400024, Training Acc: 64.22%\n",
      "              Val Loss: 0.8995326161384583, Val Acc: 59.71%\n",
      "Epoch: 2048,     Training Loss: 0.5789988040924072, Training Acc: 64.23%\n",
      "              Val Loss: 0.8459905982017517, Val Acc: 59.72%\n",
      "Epoch: 2049,     Training Loss: 0.5129714012145996, Training Acc: 64.24%\n",
      "              Val Loss: 0.835122287273407, Val Acc: 59.72%\n",
      "Epoch: 2050,     Training Loss: 0.5190504193305969, Training Acc: 64.24%\n",
      "              Val Loss: 0.8618102073669434, Val Acc: 59.73%\n",
      "Epoch: 2051,     Training Loss: 0.542028546333313, Training Acc: 64.25%\n",
      "              Val Loss: 0.9426048398017883, Val Acc: 59.73%\n",
      "Epoch: 2052,     Training Loss: 0.5868920683860779, Training Acc: 64.25%\n",
      "              Val Loss: 0.9754178524017334, Val Acc: 59.73%\n",
      "Epoch: 2053,     Training Loss: 0.6623492240905762, Training Acc: 64.26%\n",
      "              Val Loss: 0.9019879102706909, Val Acc: 59.74%\n",
      "Epoch: 2054,     Training Loss: 0.5715892314910889, Training Acc: 64.26%\n",
      "              Val Loss: 0.866829514503479, Val Acc: 59.74%\n",
      "Epoch: 2055,     Training Loss: 0.5291014313697815, Training Acc: 64.27%\n",
      "              Val Loss: 0.8583425879478455, Val Acc: 59.75%\n",
      "Epoch: 2056,     Training Loss: 0.5262376666069031, Training Acc: 64.28%\n",
      "              Val Loss: 0.9045937061309814, Val Acc: 59.75%\n",
      "Epoch: 2057,     Training Loss: 0.576885998249054, Training Acc: 64.28%\n",
      "              Val Loss: 0.9307640194892883, Val Acc: 59.75%\n",
      "Epoch: 2058,     Training Loss: 0.6158175468444824, Training Acc: 64.29%\n",
      "              Val Loss: 0.9217057824134827, Val Acc: 59.76%\n",
      "Epoch: 2059,     Training Loss: 0.5718897581100464, Training Acc: 64.29%\n",
      "              Val Loss: 0.8447543978691101, Val Acc: 59.76%\n",
      "Epoch: 2060,     Training Loss: 0.5314913988113403, Training Acc: 64.30%\n",
      "              Val Loss: 0.8247119784355164, Val Acc: 59.77%\n",
      "Epoch: 2061,     Training Loss: 0.5078810453414917, Training Acc: 64.30%\n",
      "              Val Loss: 0.8575713634490967, Val Acc: 59.77%\n",
      "Epoch: 2062,     Training Loss: 0.5189697742462158, Training Acc: 64.31%\n",
      "              Val Loss: 0.8745760321617126, Val Acc: 59.78%\n",
      "Epoch: 2063,     Training Loss: 0.5510844588279724, Training Acc: 64.32%\n",
      "              Val Loss: 0.8887009620666504, Val Acc: 59.78%\n",
      "Epoch: 2064,     Training Loss: 0.5531574487686157, Training Acc: 64.32%\n",
      "              Val Loss: 0.8665706515312195, Val Acc: 59.79%\n",
      "Epoch: 2065,     Training Loss: 0.5371219515800476, Training Acc: 64.33%\n",
      "              Val Loss: 0.8542700409889221, Val Acc: 59.79%\n",
      "Epoch: 2066,     Training Loss: 0.5112547278404236, Training Acc: 64.34%\n",
      "              Val Loss: 0.8162476420402527, Val Acc: 59.80%\n",
      "Epoch: 2067,     Training Loss: 0.49386337399482727, Training Acc: 64.34%\n",
      "              Val Loss: 0.8183703422546387, Val Acc: 59.81%\n",
      "Epoch: 2068,     Training Loss: 0.49783915281295776, Training Acc: 64.35%\n",
      "              Val Loss: 0.8526086211204529, Val Acc: 59.81%\n",
      "Epoch: 2069,     Training Loss: 0.5125653743743896, Training Acc: 64.36%\n",
      "              Val Loss: 0.8526355624198914, Val Acc: 59.82%\n",
      "Epoch: 2070,     Training Loss: 0.5306450128555298, Training Acc: 64.37%\n",
      "              Val Loss: 0.8632660508155823, Val Acc: 59.82%\n",
      "Epoch: 2071,     Training Loss: 0.5318995714187622, Training Acc: 64.37%\n",
      "              Val Loss: 0.8677527904510498, Val Acc: 59.83%\n",
      "Epoch: 2072,     Training Loss: 0.5422500371932983, Training Acc: 64.38%\n",
      "              Val Loss: 0.8626768589019775, Val Acc: 59.83%\n",
      "Epoch: 2073,     Training Loss: 0.5228458642959595, Training Acc: 64.38%\n",
      "              Val Loss: 0.8350307941436768, Val Acc: 59.84%\n",
      "Epoch: 2074,     Training Loss: 0.5156118273735046, Training Acc: 64.39%\n",
      "              Val Loss: 0.8243657946586609, Val Acc: 59.84%\n",
      "Epoch: 2075,     Training Loss: 0.49458542466163635, Training Acc: 64.40%\n",
      "              Val Loss: 0.8340612053871155, Val Acc: 59.85%\n",
      "Epoch: 2076,     Training Loss: 0.49582594633102417, Training Acc: 64.41%\n",
      "              Val Loss: 0.8198787569999695, Val Acc: 59.86%\n",
      "Epoch: 2077,     Training Loss: 0.4892248511314392, Training Acc: 64.41%\n",
      "              Val Loss: 0.8370887041091919, Val Acc: 59.86%\n",
      "Epoch: 2078,     Training Loss: 0.5061673521995544, Training Acc: 64.42%\n",
      "              Val Loss: 0.8597157001495361, Val Acc: 59.87%\n",
      "Epoch: 2079,     Training Loss: 0.5277565717697144, Training Acc: 64.43%\n",
      "              Val Loss: 0.9078176617622375, Val Acc: 59.87%\n",
      "Epoch: 2080,     Training Loss: 0.5577875375747681, Training Acc: 64.43%\n",
      "              Val Loss: 0.9450691342353821, Val Acc: 59.87%\n",
      "Epoch: 2081,     Training Loss: 0.6345040202140808, Training Acc: 64.44%\n",
      "              Val Loss: 0.9210404753684998, Val Acc: 59.88%\n",
      "Epoch: 2082,     Training Loss: 0.5833371877670288, Training Acc: 64.44%\n",
      "              Val Loss: 0.9206753373146057, Val Acc: 59.88%\n",
      "Epoch: 2083,     Training Loss: 0.5856236815452576, Training Acc: 64.45%\n",
      "              Val Loss: 0.8602181077003479, Val Acc: 59.88%\n",
      "Epoch: 2084,     Training Loss: 0.516359269618988, Training Acc: 64.45%\n",
      "              Val Loss: 0.8613210916519165, Val Acc: 59.89%\n",
      "Epoch: 2085,     Training Loss: 0.5373097062110901, Training Acc: 64.46%\n",
      "              Val Loss: 0.8982902765274048, Val Acc: 59.89%\n",
      "Epoch: 2086,     Training Loss: 0.5660719871520996, Training Acc: 64.47%\n",
      "              Val Loss: 1.0133482217788696, Val Acc: 59.90%\n",
      "Epoch: 2087,     Training Loss: 0.6431638598442078, Training Acc: 64.47%\n",
      "              Val Loss: 1.057744026184082, Val Acc: 59.90%\n",
      "Epoch: 2088,     Training Loss: 0.7588342428207397, Training Acc: 64.47%\n",
      "              Val Loss: 0.9186422228813171, Val Acc: 59.90%\n",
      "Epoch: 2089,     Training Loss: 0.5879637598991394, Training Acc: 64.47%\n",
      "              Val Loss: 0.8884987831115723, Val Acc: 59.90%\n",
      "Epoch: 2090,     Training Loss: 0.5430418252944946, Training Acc: 64.48%\n",
      "              Val Loss: 0.9742287993431091, Val Acc: 59.91%\n",
      "Epoch: 2091,     Training Loss: 0.6389496922492981, Training Acc: 64.48%\n",
      "              Val Loss: 0.9305711388587952, Val Acc: 59.91%\n",
      "Epoch: 2092,     Training Loss: 0.6005321145057678, Training Acc: 64.49%\n",
      "              Val Loss: 0.8617732524871826, Val Acc: 59.91%\n",
      "Epoch: 2093,     Training Loss: 0.5375949740409851, Training Acc: 64.49%\n",
      "              Val Loss: 0.8621072173118591, Val Acc: 59.92%\n",
      "Epoch: 2094,     Training Loss: 0.50791335105896, Training Acc: 64.50%\n",
      "              Val Loss: 0.9157594442367554, Val Acc: 59.92%\n",
      "Epoch: 2095,     Training Loss: 0.5497193932533264, Training Acc: 64.51%\n",
      "              Val Loss: 0.935615599155426, Val Acc: 59.93%\n",
      "Epoch: 2096,     Training Loss: 0.6163799166679382, Training Acc: 64.51%\n",
      "              Val Loss: 0.8416974544525146, Val Acc: 59.93%\n",
      "Epoch: 2097,     Training Loss: 0.5215820074081421, Training Acc: 64.52%\n",
      "              Val Loss: 0.8644683957099915, Val Acc: 59.94%\n",
      "Epoch: 2098,     Training Loss: 0.5200170278549194, Training Acc: 64.52%\n",
      "              Val Loss: 0.925382137298584, Val Acc: 59.94%\n",
      "Epoch: 2099,     Training Loss: 0.5847501754760742, Training Acc: 64.53%\n",
      "              Val Loss: 0.9319284558296204, Val Acc: 59.94%\n",
      "Epoch: 2100,     Training Loss: 0.5917866826057434, Training Acc: 64.53%\n",
      "              Val Loss: 0.9182658195495605, Val Acc: 59.95%\n",
      "Epoch: 2101,     Training Loss: 0.5822805166244507, Training Acc: 64.54%\n",
      "              Val Loss: 0.8823401927947998, Val Acc: 59.95%\n",
      "Epoch: 2102,     Training Loss: 0.5229638814926147, Training Acc: 64.54%\n",
      "              Val Loss: 0.8858743906021118, Val Acc: 59.96%\n",
      "Epoch: 2103,     Training Loss: 0.5225638151168823, Training Acc: 64.55%\n",
      "              Val Loss: 0.9348403811454773, Val Acc: 59.96%\n",
      "Epoch: 2104,     Training Loss: 0.589257001876831, Training Acc: 64.56%\n",
      "              Val Loss: 0.906272292137146, Val Acc: 59.96%\n",
      "Epoch: 2105,     Training Loss: 0.5625689029693604, Training Acc: 64.56%\n",
      "              Val Loss: 0.8519600629806519, Val Acc: 59.97%\n",
      "Epoch: 2106,     Training Loss: 0.5442149043083191, Training Acc: 64.57%\n",
      "              Val Loss: 0.8120605945587158, Val Acc: 59.98%\n",
      "Epoch: 2107,     Training Loss: 0.4943159520626068, Training Acc: 64.57%\n",
      "              Val Loss: 0.8552785515785217, Val Acc: 59.98%\n",
      "Epoch: 2108,     Training Loss: 0.5122029185295105, Training Acc: 64.58%\n",
      "              Val Loss: 0.8973830342292786, Val Acc: 59.99%\n",
      "Epoch: 2109,     Training Loss: 0.5534608960151672, Training Acc: 64.59%\n",
      "              Val Loss: 0.8887593150138855, Val Acc: 59.99%\n",
      "Epoch: 2110,     Training Loss: 0.538779079914093, Training Acc: 64.59%\n",
      "              Val Loss: 0.8530914187431335, Val Acc: 60.00%\n",
      "Epoch: 2111,     Training Loss: 0.5143774747848511, Training Acc: 64.60%\n",
      "              Val Loss: 0.8472078442573547, Val Acc: 60.00%\n",
      "Epoch: 2112,     Training Loss: 0.4910144805908203, Training Acc: 64.61%\n",
      "              Val Loss: 0.8593682646751404, Val Acc: 60.01%\n",
      "Epoch: 2113,     Training Loss: 0.49685126543045044, Training Acc: 64.61%\n",
      "              Val Loss: 0.8403578996658325, Val Acc: 60.01%\n",
      "Epoch: 2114,     Training Loss: 0.5064533352851868, Training Acc: 64.62%\n",
      "              Val Loss: 0.8633600473403931, Val Acc: 60.02%\n",
      "Epoch: 2115,     Training Loss: 0.5238403081893921, Training Acc: 64.63%\n",
      "              Val Loss: 0.8750199675559998, Val Acc: 60.03%\n",
      "Epoch: 2116,     Training Loss: 0.5300416350364685, Training Acc: 64.63%\n",
      "              Val Loss: 0.8794984221458435, Val Acc: 60.03%\n",
      "Epoch: 2117,     Training Loss: 0.5186010599136353, Training Acc: 64.64%\n",
      "              Val Loss: 0.8503197431564331, Val Acc: 60.04%\n",
      "Epoch: 2118,     Training Loss: 0.5200332403182983, Training Acc: 64.65%\n",
      "              Val Loss: 0.8323349952697754, Val Acc: 60.04%\n",
      "Epoch: 2119,     Training Loss: 0.4991809129714966, Training Acc: 64.65%\n",
      "              Val Loss: 0.851206362247467, Val Acc: 60.05%\n",
      "Epoch: 2120,     Training Loss: 0.5004852414131165, Training Acc: 64.66%\n",
      "              Val Loss: 0.8386661410331726, Val Acc: 60.05%\n",
      "Epoch: 2121,     Training Loss: 0.4811537563800812, Training Acc: 64.67%\n",
      "              Val Loss: 0.8503493666648865, Val Acc: 60.06%\n",
      "Epoch: 2122,     Training Loss: 0.4981374740600586, Training Acc: 64.68%\n",
      "              Val Loss: 0.8459761738777161, Val Acc: 60.07%\n",
      "Epoch: 2123,     Training Loss: 0.49856993556022644, Training Acc: 64.68%\n",
      "              Val Loss: 0.8942756056785583, Val Acc: 60.07%\n",
      "Epoch: 2124,     Training Loss: 0.5322675704956055, Training Acc: 64.69%\n",
      "              Val Loss: 0.9148162603378296, Val Acc: 60.07%\n",
      "Epoch: 2125,     Training Loss: 0.5823485255241394, Training Acc: 64.69%\n",
      "              Val Loss: 0.9359455108642578, Val Acc: 60.08%\n",
      "Epoch: 2126,     Training Loss: 0.5834198594093323, Training Acc: 64.70%\n",
      "              Val Loss: 0.9771385192871094, Val Acc: 60.08%\n",
      "Epoch: 2127,     Training Loss: 0.6268592476844788, Training Acc: 64.70%\n",
      "              Val Loss: 0.9079049825668335, Val Acc: 60.08%\n",
      "Epoch: 2128,     Training Loss: 0.5461727976799011, Training Acc: 64.71%\n",
      "              Val Loss: 0.8613351583480835, Val Acc: 60.09%\n",
      "Epoch: 2129,     Training Loss: 0.5267606973648071, Training Acc: 64.71%\n",
      "              Val Loss: 0.8488611578941345, Val Acc: 60.09%\n",
      "Epoch: 2130,     Training Loss: 0.5032544732093811, Training Acc: 64.72%\n",
      "              Val Loss: 0.965803325176239, Val Acc: 60.10%\n",
      "Epoch: 2131,     Training Loss: 0.5878455638885498, Training Acc: 64.72%\n",
      "              Val Loss: 1.0241910219192505, Val Acc: 60.10%\n",
      "Epoch: 2132,     Training Loss: 0.6991432309150696, Training Acc: 64.73%\n",
      "              Val Loss: 0.9569500684738159, Val Acc: 60.10%\n",
      "Epoch: 2133,     Training Loss: 0.62431800365448, Training Acc: 64.73%\n",
      "              Val Loss: 0.8781226873397827, Val Acc: 60.11%\n",
      "Epoch: 2134,     Training Loss: 0.5371522307395935, Training Acc: 64.74%\n",
      "              Val Loss: 0.8859651684761047, Val Acc: 60.11%\n",
      "Epoch: 2135,     Training Loss: 0.5243796706199646, Training Acc: 64.74%\n",
      "              Val Loss: 0.9077339172363281, Val Acc: 60.11%\n",
      "Epoch: 2136,     Training Loss: 0.5569599270820618, Training Acc: 64.75%\n",
      "              Val Loss: 0.9630656242370605, Val Acc: 60.12%\n",
      "Epoch: 2137,     Training Loss: 0.6239708065986633, Training Acc: 64.75%\n",
      "              Val Loss: 0.8866173028945923, Val Acc: 60.12%\n",
      "Epoch: 2138,     Training Loss: 0.528710663318634, Training Acc: 64.76%\n",
      "              Val Loss: 0.8365747928619385, Val Acc: 60.13%\n",
      "Epoch: 2139,     Training Loss: 0.486885666847229, Training Acc: 64.76%\n",
      "              Val Loss: 0.8608955144882202, Val Acc: 60.13%\n",
      "Epoch: 2140,     Training Loss: 0.5192265510559082, Training Acc: 64.77%\n",
      "              Val Loss: 0.8731880784034729, Val Acc: 60.14%\n",
      "Epoch: 2141,     Training Loss: 0.5251327753067017, Training Acc: 64.78%\n",
      "              Val Loss: 0.885738730430603, Val Acc: 60.14%\n",
      "Epoch: 2142,     Training Loss: 0.5441538095474243, Training Acc: 64.78%\n",
      "              Val Loss: 0.8542050719261169, Val Acc: 60.15%\n",
      "Epoch: 2143,     Training Loss: 0.49780142307281494, Training Acc: 64.79%\n",
      "              Val Loss: 0.8423053026199341, Val Acc: 60.15%\n",
      "Epoch: 2144,     Training Loss: 0.4899275600910187, Training Acc: 64.80%\n",
      "              Val Loss: 0.8523913025856018, Val Acc: 60.16%\n",
      "Epoch: 2145,     Training Loss: 0.4925942122936249, Training Acc: 64.80%\n",
      "              Val Loss: 0.8825214505195618, Val Acc: 60.16%\n",
      "Epoch: 2146,     Training Loss: 0.5195200443267822, Training Acc: 64.81%\n",
      "              Val Loss: 0.8990551829338074, Val Acc: 60.17%\n",
      "Epoch: 2147,     Training Loss: 0.5571626424789429, Training Acc: 64.82%\n",
      "              Val Loss: 0.8950441479682922, Val Acc: 60.17%\n",
      "Epoch: 2148,     Training Loss: 0.5338636636734009, Training Acc: 64.82%\n",
      "              Val Loss: 0.8906763195991516, Val Acc: 60.18%\n",
      "Epoch: 2149,     Training Loss: 0.5259702801704407, Training Acc: 64.83%\n",
      "              Val Loss: 0.8532832860946655, Val Acc: 60.18%\n",
      "Epoch: 2150,     Training Loss: 0.494983971118927, Training Acc: 64.83%\n",
      "              Val Loss: 0.8237636685371399, Val Acc: 60.19%\n",
      "Epoch: 2151,     Training Loss: 0.48711541295051575, Training Acc: 64.84%\n",
      "              Val Loss: 0.8321601748466492, Val Acc: 60.19%\n",
      "Epoch: 2152,     Training Loss: 0.48960649967193604, Training Acc: 64.85%\n",
      "              Val Loss: 0.8829368352890015, Val Acc: 60.20%\n",
      "Epoch: 2153,     Training Loss: 0.5151969194412231, Training Acc: 64.86%\n",
      "              Val Loss: 0.9145063161849976, Val Acc: 60.20%\n",
      "Epoch: 2154,     Training Loss: 0.5655739903450012, Training Acc: 64.86%\n",
      "              Val Loss: 0.9375990033149719, Val Acc: 60.20%\n",
      "Epoch: 2155,     Training Loss: 0.5763108134269714, Training Acc: 64.86%\n",
      "              Val Loss: 0.9729336500167847, Val Acc: 60.21%\n",
      "Epoch: 2156,     Training Loss: 0.6206939816474915, Training Acc: 64.87%\n",
      "              Val Loss: 0.8854653239250183, Val Acc: 60.21%\n",
      "Epoch: 2157,     Training Loss: 0.5210462808609009, Training Acc: 64.87%\n",
      "              Val Loss: 0.8444816470146179, Val Acc: 60.22%\n",
      "Epoch: 2158,     Training Loss: 0.49084919691085815, Training Acc: 64.88%\n",
      "              Val Loss: 0.8744140863418579, Val Acc: 60.22%\n",
      "Epoch: 2159,     Training Loss: 0.517342209815979, Training Acc: 64.89%\n",
      "              Val Loss: 0.9336395859718323, Val Acc: 60.23%\n",
      "Epoch: 2160,     Training Loss: 0.5575843453407288, Training Acc: 64.89%\n",
      "              Val Loss: 0.949505090713501, Val Acc: 60.23%\n",
      "Epoch: 2161,     Training Loss: 0.602613091468811, Training Acc: 64.90%\n",
      "              Val Loss: 0.8753632307052612, Val Acc: 60.23%\n",
      "Epoch: 2162,     Training Loss: 0.5279558300971985, Training Acc: 64.90%\n",
      "              Val Loss: 0.8348391056060791, Val Acc: 60.24%\n",
      "Epoch: 2163,     Training Loss: 0.4883899390697479, Training Acc: 64.91%\n",
      "              Val Loss: 0.8299790024757385, Val Acc: 60.24%\n",
      "Epoch: 2164,     Training Loss: 0.4877029359340668, Training Acc: 64.92%\n",
      "              Val Loss: 0.8625301122665405, Val Acc: 60.25%\n",
      "Epoch: 2165,     Training Loss: 0.5192153453826904, Training Acc: 64.92%\n",
      "              Val Loss: 0.8978050947189331, Val Acc: 60.25%\n",
      "Epoch: 2166,     Training Loss: 0.5509070754051208, Training Acc: 64.93%\n",
      "              Val Loss: 0.900026798248291, Val Acc: 60.26%\n",
      "Epoch: 2167,     Training Loss: 0.5269469618797302, Training Acc: 64.93%\n",
      "              Val Loss: 0.8705793619155884, Val Acc: 60.26%\n",
      "Epoch: 2168,     Training Loss: 0.5117464661598206, Training Acc: 64.94%\n",
      "              Val Loss: 0.8438244462013245, Val Acc: 60.27%\n",
      "Epoch: 2169,     Training Loss: 0.48416054248809814, Training Acc: 64.95%\n",
      "              Val Loss: 0.8475397229194641, Val Acc: 60.27%\n",
      "Epoch: 2170,     Training Loss: 0.47991687059402466, Training Acc: 64.95%\n",
      "              Val Loss: 0.8487066030502319, Val Acc: 60.28%\n",
      "Epoch: 2171,     Training Loss: 0.49075013399124146, Training Acc: 64.96%\n",
      "              Val Loss: 0.8636969923973083, Val Acc: 60.28%\n",
      "Epoch: 2172,     Training Loss: 0.5101593732833862, Training Acc: 64.97%\n",
      "              Val Loss: 0.8797574043273926, Val Acc: 60.29%\n",
      "Epoch: 2173,     Training Loss: 0.526541531085968, Training Acc: 64.97%\n",
      "              Val Loss: 0.8776752948760986, Val Acc: 60.29%\n",
      "Epoch: 2174,     Training Loss: 0.5156464576721191, Training Acc: 64.98%\n",
      "              Val Loss: 0.8557241559028625, Val Acc: 60.30%\n",
      "Epoch: 2175,     Training Loss: 0.5144445300102234, Training Acc: 64.99%\n",
      "              Val Loss: 0.8372345566749573, Val Acc: 60.30%\n",
      "Epoch: 2176,     Training Loss: 0.48915383219718933, Training Acc: 64.99%\n",
      "              Val Loss: 0.8383723497390747, Val Acc: 60.31%\n",
      "Epoch: 2177,     Training Loss: 0.4810435175895691, Training Acc: 65.00%\n",
      "              Val Loss: 0.8265106678009033, Val Acc: 60.31%\n",
      "Epoch: 2178,     Training Loss: 0.47181475162506104, Training Acc: 65.01%\n",
      "              Val Loss: 0.8416963815689087, Val Acc: 60.32%\n",
      "Epoch: 2179,     Training Loss: 0.4883229732513428, Training Acc: 65.01%\n",
      "              Val Loss: 0.8648796677589417, Val Acc: 60.33%\n",
      "Epoch: 2180,     Training Loss: 0.5023229718208313, Training Acc: 65.02%\n",
      "              Val Loss: 0.9115895628929138, Val Acc: 60.33%\n",
      "Epoch: 2181,     Training Loss: 0.5319746136665344, Training Acc: 65.03%\n",
      "              Val Loss: 0.9480465650558472, Val Acc: 60.33%\n",
      "Epoch: 2182,     Training Loss: 0.5955831408500671, Training Acc: 65.03%\n",
      "              Val Loss: 0.931892454624176, Val Acc: 60.33%\n",
      "Epoch: 2183,     Training Loss: 0.5681993961334229, Training Acc: 65.03%\n",
      "              Val Loss: 0.9363422989845276, Val Acc: 60.34%\n",
      "Epoch: 2184,     Training Loss: 0.5753540992736816, Training Acc: 65.04%\n",
      "              Val Loss: 0.8689483404159546, Val Acc: 60.34%\n",
      "Epoch: 2185,     Training Loss: 0.5039486885070801, Training Acc: 65.05%\n",
      "              Val Loss: 0.8489376306533813, Val Acc: 60.35%\n",
      "Epoch: 2186,     Training Loss: 0.5053960680961609, Training Acc: 65.05%\n",
      "              Val Loss: 0.8860724568367004, Val Acc: 60.35%\n",
      "Epoch: 2187,     Training Loss: 0.5266706943511963, Training Acc: 65.06%\n",
      "              Val Loss: 0.9778398275375366, Val Acc: 60.35%\n",
      "Epoch: 2188,     Training Loss: 0.593504011631012, Training Acc: 65.06%\n",
      "              Val Loss: 1.0373754501342773, Val Acc: 60.36%\n",
      "Epoch: 2189,     Training Loss: 0.7004532814025879, Training Acc: 65.06%\n",
      "              Val Loss: 0.9338446855545044, Val Acc: 60.36%\n",
      "Epoch: 2190,     Training Loss: 0.5756017565727234, Training Acc: 65.07%\n",
      "              Val Loss: 0.873638391494751, Val Acc: 60.36%\n",
      "Epoch: 2191,     Training Loss: 0.5078084468841553, Training Acc: 65.07%\n",
      "              Val Loss: 0.9045543074607849, Val Acc: 60.37%\n",
      "Epoch: 2192,     Training Loss: 0.5336811542510986, Training Acc: 65.08%\n",
      "              Val Loss: 0.9418215751647949, Val Acc: 60.37%\n",
      "Epoch: 2193,     Training Loss: 0.5716170072555542, Training Acc: 65.08%\n",
      "              Val Loss: 0.9533953070640564, Val Acc: 60.37%\n",
      "Epoch: 2194,     Training Loss: 0.5876584053039551, Training Acc: 65.09%\n",
      "              Val Loss: 0.8783197999000549, Val Acc: 60.38%\n",
      "Epoch: 2195,     Training Loss: 0.5035369396209717, Training Acc: 65.09%\n",
      "              Val Loss: 0.8472268581390381, Val Acc: 60.38%\n",
      "Epoch: 2196,     Training Loss: 0.4889683425426483, Training Acc: 65.10%\n",
      "              Val Loss: 0.8791188597679138, Val Acc: 60.39%\n",
      "Epoch: 2197,     Training Loss: 0.5381922125816345, Training Acc: 65.11%\n",
      "              Val Loss: 0.8770056962966919, Val Acc: 60.39%\n",
      "Epoch: 2198,     Training Loss: 0.5202341675758362, Training Acc: 65.11%\n",
      "              Val Loss: 0.8614656925201416, Val Acc: 60.40%\n",
      "Epoch: 2199,     Training Loss: 0.5083537697792053, Training Acc: 65.12%\n",
      "              Val Loss: 0.8346573710441589, Val Acc: 60.40%\n",
      "Epoch: 2200,     Training Loss: 0.4780309200286865, Training Acc: 65.13%\n",
      "              Val Loss: 0.8467115163803101, Val Acc: 60.41%\n",
      "Epoch: 2201,     Training Loss: 0.48816460371017456, Training Acc: 65.13%\n",
      "              Val Loss: 0.8886377811431885, Val Acc: 60.41%\n",
      "Epoch: 2202,     Training Loss: 0.5167990326881409, Training Acc: 65.14%\n",
      "              Val Loss: 0.901370108127594, Val Acc: 60.42%\n",
      "Epoch: 2203,     Training Loss: 0.5243877172470093, Training Acc: 65.14%\n",
      "              Val Loss: 0.898590624332428, Val Acc: 60.42%\n",
      "Epoch: 2204,     Training Loss: 0.5376577377319336, Training Acc: 65.15%\n",
      "              Val Loss: 0.8692401051521301, Val Acc: 60.42%\n",
      "Epoch: 2205,     Training Loss: 0.5028541088104248, Training Acc: 65.16%\n",
      "              Val Loss: 0.8658259510993958, Val Acc: 60.43%\n",
      "Epoch: 2206,     Training Loss: 0.4943631887435913, Training Acc: 65.16%\n",
      "              Val Loss: 0.8407706618309021, Val Acc: 60.44%\n",
      "Epoch: 2207,     Training Loss: 0.47676247358322144, Training Acc: 65.17%\n",
      "              Val Loss: 0.8357581496238708, Val Acc: 60.44%\n",
      "Epoch: 2208,     Training Loss: 0.48287278413772583, Training Acc: 65.18%\n",
      "              Val Loss: 0.8442447185516357, Val Acc: 60.45%\n",
      "Epoch: 2209,     Training Loss: 0.4840894043445587, Training Acc: 65.18%\n",
      "              Val Loss: 0.8890085816383362, Val Acc: 60.45%\n",
      "Epoch: 2210,     Training Loss: 0.5095710158348083, Training Acc: 65.19%\n",
      "              Val Loss: 0.910908043384552, Val Acc: 60.45%\n",
      "Epoch: 2211,     Training Loss: 0.5539711117744446, Training Acc: 65.20%\n",
      "              Val Loss: 0.9337458610534668, Val Acc: 60.46%\n",
      "Epoch: 2212,     Training Loss: 0.5641071796417236, Training Acc: 65.20%\n",
      "              Val Loss: 0.9922583103179932, Val Acc: 60.46%\n",
      "Epoch: 2213,     Training Loss: 0.6236134171485901, Training Acc: 65.20%\n",
      "              Val Loss: 0.9101883172988892, Val Acc: 60.46%\n",
      "Epoch: 2214,     Training Loss: 0.5345451235771179, Training Acc: 65.21%\n",
      "              Val Loss: 0.8537535071372986, Val Acc: 60.47%\n",
      "Epoch: 2215,     Training Loss: 0.4985911250114441, Training Acc: 65.21%\n",
      "              Val Loss: 0.8440346717834473, Val Acc: 60.47%\n",
      "Epoch: 2216,     Training Loss: 0.48046016693115234, Training Acc: 65.22%\n",
      "              Val Loss: 0.9316589832305908, Val Acc: 60.48%\n",
      "Epoch: 2217,     Training Loss: 0.5420218110084534, Training Acc: 65.23%\n",
      "              Val Loss: 0.9819576144218445, Val Acc: 60.48%\n",
      "Epoch: 2218,     Training Loss: 0.6187440156936646, Training Acc: 65.23%\n",
      "              Val Loss: 0.93137526512146, Val Acc: 60.48%\n",
      "Epoch: 2219,     Training Loss: 0.5707874894142151, Training Acc: 65.23%\n",
      "              Val Loss: 0.890482485294342, Val Acc: 60.49%\n",
      "Epoch: 2220,     Training Loss: 0.5249964594841003, Training Acc: 65.24%\n",
      "              Val Loss: 0.8574957251548767, Val Acc: 60.49%\n",
      "Epoch: 2221,     Training Loss: 0.4900743365287781, Training Acc: 65.25%\n",
      "              Val Loss: 0.8689148426055908, Val Acc: 60.50%\n",
      "Epoch: 2222,     Training Loss: 0.5131243467330933, Training Acc: 65.25%\n",
      "              Val Loss: 0.9073252081871033, Val Acc: 60.50%\n",
      "Epoch: 2223,     Training Loss: 0.5516303181648254, Training Acc: 65.26%\n",
      "              Val Loss: 0.921828031539917, Val Acc: 60.50%\n",
      "Epoch: 2224,     Training Loss: 0.5353235006332397, Training Acc: 65.26%\n",
      "              Val Loss: 0.877849817276001, Val Acc: 60.51%\n",
      "Epoch: 2225,     Training Loss: 0.5098637938499451, Training Acc: 65.27%\n",
      "              Val Loss: 0.8481643795967102, Val Acc: 60.51%\n",
      "Epoch: 2226,     Training Loss: 0.48607608675956726, Training Acc: 65.28%\n",
      "              Val Loss: 0.8505033254623413, Val Acc: 60.52%\n",
      "Epoch: 2227,     Training Loss: 0.4746040105819702, Training Acc: 65.28%\n",
      "              Val Loss: 0.8720983862876892, Val Acc: 60.52%\n",
      "Epoch: 2228,     Training Loss: 0.4954449534416199, Training Acc: 65.29%\n",
      "              Val Loss: 0.873928427696228, Val Acc: 60.53%\n",
      "Epoch: 2229,     Training Loss: 0.5021882057189941, Training Acc: 65.29%\n",
      "              Val Loss: 0.8784141540527344, Val Acc: 60.53%\n",
      "Epoch: 2230,     Training Loss: 0.5042462348937988, Training Acc: 65.30%\n",
      "              Val Loss: 0.8692782521247864, Val Acc: 60.54%\n",
      "Epoch: 2231,     Training Loss: 0.487154096364975, Training Acc: 65.31%\n",
      "              Val Loss: 0.8398432731628418, Val Acc: 60.54%\n",
      "Epoch: 2232,     Training Loss: 0.47113117575645447, Training Acc: 65.32%\n",
      "              Val Loss: 0.8313552141189575, Val Acc: 60.55%\n",
      "Epoch: 2233,     Training Loss: 0.46715623140335083, Training Acc: 65.32%\n",
      "              Val Loss: 0.8347200155258179, Val Acc: 60.56%\n",
      "Epoch: 2234,     Training Loss: 0.4649464786052704, Training Acc: 65.33%\n",
      "              Val Loss: 0.844744861125946, Val Acc: 60.56%\n",
      "Epoch: 2235,     Training Loss: 0.476705402135849, Training Acc: 65.34%\n",
      "              Val Loss: 0.8620254993438721, Val Acc: 60.57%\n",
      "Epoch: 2236,     Training Loss: 0.4908777177333832, Training Acc: 65.34%\n",
      "              Val Loss: 0.9034668207168579, Val Acc: 60.57%\n",
      "Epoch: 2237,     Training Loss: 0.5331114530563354, Training Acc: 65.35%\n",
      "              Val Loss: 0.928993284702301, Val Acc: 60.57%\n",
      "Epoch: 2238,     Training Loss: 0.5468685030937195, Training Acc: 65.35%\n",
      "              Val Loss: 0.9844975471496582, Val Acc: 60.58%\n",
      "Epoch: 2239,     Training Loss: 0.6145396828651428, Training Acc: 65.36%\n",
      "              Val Loss: 0.9116165637969971, Val Acc: 60.58%\n",
      "Epoch: 2240,     Training Loss: 0.5395026206970215, Training Acc: 65.36%\n",
      "              Val Loss: 0.8709692358970642, Val Acc: 60.58%\n",
      "Epoch: 2241,     Training Loss: 0.5012790560722351, Training Acc: 65.37%\n",
      "              Val Loss: 0.8443396091461182, Val Acc: 60.59%\n",
      "Epoch: 2242,     Training Loss: 0.4730888307094574, Training Acc: 65.37%\n",
      "              Val Loss: 0.8534780144691467, Val Acc: 60.59%\n",
      "Epoch: 2243,     Training Loss: 0.48456138372421265, Training Acc: 65.38%\n",
      "              Val Loss: 0.9135251641273499, Val Acc: 60.60%\n",
      "Epoch: 2244,     Training Loss: 0.5389317870140076, Training Acc: 65.39%\n",
      "              Val Loss: 0.9212602376937866, Val Acc: 60.60%\n",
      "Epoch: 2245,     Training Loss: 0.540972113609314, Training Acc: 65.39%\n",
      "              Val Loss: 0.9176302552223206, Val Acc: 60.60%\n",
      "Epoch: 2246,     Training Loss: 0.561092734336853, Training Acc: 65.40%\n",
      "              Val Loss: 0.8713345527648926, Val Acc: 60.61%\n",
      "Epoch: 2247,     Training Loss: 0.5050352215766907, Training Acc: 65.40%\n",
      "              Val Loss: 0.8493121266365051, Val Acc: 60.61%\n",
      "Epoch: 2248,     Training Loss: 0.4778980612754822, Training Acc: 65.41%\n",
      "              Val Loss: 0.8553780913352966, Val Acc: 60.62%\n",
      "Epoch: 2249,     Training Loss: 0.4839501678943634, Training Acc: 65.41%\n",
      "              Val Loss: 0.8874042630195618, Val Acc: 60.62%\n",
      "Epoch: 2250,     Training Loss: 0.5132590532302856, Training Acc: 65.42%\n",
      "              Val Loss: 0.9548614025115967, Val Acc: 60.63%\n",
      "Epoch: 2251,     Training Loss: 0.5628778338432312, Training Acc: 65.43%\n",
      "              Val Loss: 0.9310247302055359, Val Acc: 60.63%\n",
      "Epoch: 2252,     Training Loss: 0.539257287979126, Training Acc: 65.43%\n",
      "              Val Loss: 0.8967020511627197, Val Acc: 60.63%\n",
      "Epoch: 2253,     Training Loss: 0.5377516746520996, Training Acc: 65.44%\n",
      "              Val Loss: 0.8576215505599976, Val Acc: 60.64%\n",
      "Epoch: 2254,     Training Loss: 0.49253299832344055, Training Acc: 65.44%\n",
      "              Val Loss: 0.866281270980835, Val Acc: 60.64%\n",
      "Epoch: 2255,     Training Loss: 0.4883267879486084, Training Acc: 65.45%\n",
      "              Val Loss: 0.8445398807525635, Val Acc: 60.65%\n",
      "Epoch: 2256,     Training Loss: 0.47861358523368835, Training Acc: 65.45%\n",
      "              Val Loss: 0.8710441589355469, Val Acc: 60.65%\n",
      "Epoch: 2257,     Training Loss: 0.5110466480255127, Training Acc: 65.46%\n",
      "              Val Loss: 0.9108298420906067, Val Acc: 60.66%\n",
      "Epoch: 2258,     Training Loss: 0.5360113382339478, Training Acc: 65.47%\n",
      "              Val Loss: 0.9470571875572205, Val Acc: 60.66%\n",
      "Epoch: 2259,     Training Loss: 0.5542783141136169, Training Acc: 65.47%\n",
      "              Val Loss: 0.9402354955673218, Val Acc: 60.66%\n",
      "Epoch: 2260,     Training Loss: 0.5829166769981384, Training Acc: 65.47%\n",
      "              Val Loss: 0.8982129693031311, Val Acc: 60.67%\n",
      "Epoch: 2261,     Training Loss: 0.525818943977356, Training Acc: 65.48%\n",
      "              Val Loss: 0.8787751793861389, Val Acc: 60.67%\n",
      "Epoch: 2262,     Training Loss: 0.497977077960968, Training Acc: 65.49%\n",
      "              Val Loss: 0.8543159365653992, Val Acc: 60.68%\n",
      "Epoch: 2263,     Training Loss: 0.47501522302627563, Training Acc: 65.49%\n",
      "              Val Loss: 0.8742725253105164, Val Acc: 60.68%\n",
      "Epoch: 2264,     Training Loss: 0.5081827640533447, Training Acc: 65.50%\n",
      "              Val Loss: 0.9282180666923523, Val Acc: 60.68%\n",
      "Epoch: 2265,     Training Loss: 0.5456786155700684, Training Acc: 65.50%\n",
      "              Val Loss: 0.9666956067085266, Val Acc: 60.69%\n",
      "Epoch: 2266,     Training Loss: 0.5623959898948669, Training Acc: 65.51%\n",
      "              Val Loss: 0.9467628598213196, Val Acc: 60.69%\n",
      "Epoch: 2267,     Training Loss: 0.5800033211708069, Training Acc: 65.51%\n",
      "              Val Loss: 0.8786097764968872, Val Acc: 60.69%\n",
      "Epoch: 2268,     Training Loss: 0.5133843421936035, Training Acc: 65.52%\n",
      "              Val Loss: 0.8486796021461487, Val Acc: 60.70%\n",
      "Epoch: 2269,     Training Loss: 0.4762249290943146, Training Acc: 65.52%\n",
      "              Val Loss: 0.8622339367866516, Val Acc: 60.70%\n",
      "Epoch: 2270,     Training Loss: 0.4896550476551056, Training Acc: 65.53%\n",
      "              Val Loss: 0.8915429711341858, Val Acc: 60.71%\n",
      "Epoch: 2271,     Training Loss: 0.5239167213439941, Training Acc: 65.54%\n",
      "              Val Loss: 0.9548596143722534, Val Acc: 60.71%\n",
      "Epoch: 2272,     Training Loss: 0.5763428211212158, Training Acc: 65.54%\n",
      "              Val Loss: 0.9423487782478333, Val Acc: 60.71%\n",
      "Epoch: 2273,     Training Loss: 0.5442136526107788, Training Acc: 65.54%\n",
      "              Val Loss: 0.8827457427978516, Val Acc: 60.72%\n",
      "Epoch: 2274,     Training Loss: 0.5123935341835022, Training Acc: 65.55%\n",
      "              Val Loss: 0.8381914496421814, Val Acc: 60.72%\n",
      "Epoch: 2275,     Training Loss: 0.4733014702796936, Training Acc: 65.56%\n",
      "              Val Loss: 0.8609684705734253, Val Acc: 60.73%\n",
      "Epoch: 2276,     Training Loss: 0.4808545410633087, Training Acc: 65.56%\n",
      "              Val Loss: 0.9042205214500427, Val Acc: 60.73%\n",
      "Epoch: 2277,     Training Loss: 0.5245121717453003, Training Acc: 65.57%\n",
      "              Val Loss: 0.9061805605888367, Val Acc: 60.73%\n",
      "Epoch: 2278,     Training Loss: 0.5274803042411804, Training Acc: 65.57%\n",
      "              Val Loss: 0.927908718585968, Val Acc: 60.74%\n",
      "Epoch: 2279,     Training Loss: 0.547995388507843, Training Acc: 65.58%\n",
      "              Val Loss: 0.8897957801818848, Val Acc: 60.74%\n",
      "Epoch: 2280,     Training Loss: 0.5001029372215271, Training Acc: 65.58%\n",
      "              Val Loss: 0.8371821045875549, Val Acc: 60.75%\n",
      "Epoch: 2281,     Training Loss: 0.46701428294181824, Training Acc: 65.59%\n",
      "              Val Loss: 0.8393584489822388, Val Acc: 60.75%\n",
      "Epoch: 2282,     Training Loss: 0.4666025638580322, Training Acc: 65.60%\n",
      "              Val Loss: 0.88056480884552, Val Acc: 60.76%\n",
      "Epoch: 2283,     Training Loss: 0.493678480386734, Training Acc: 65.60%\n",
      "              Val Loss: 0.917274534702301, Val Acc: 60.76%\n",
      "Epoch: 2284,     Training Loss: 0.534449577331543, Training Acc: 65.61%\n",
      "              Val Loss: 0.897182285785675, Val Acc: 60.77%\n",
      "Epoch: 2285,     Training Loss: 0.5153414607048035, Training Acc: 65.61%\n",
      "              Val Loss: 0.8929808735847473, Val Acc: 60.77%\n",
      "Epoch: 2286,     Training Loss: 0.5132073163986206, Training Acc: 65.62%\n",
      "              Val Loss: 0.8639509081840515, Val Acc: 60.77%\n",
      "Epoch: 2287,     Training Loss: 0.48008909821510315, Training Acc: 65.63%\n",
      "              Val Loss: 0.8325574398040771, Val Acc: 60.78%\n",
      "Epoch: 2288,     Training Loss: 0.46010735630989075, Training Acc: 65.63%\n",
      "              Val Loss: 0.8575997352600098, Val Acc: 60.79%\n",
      "Epoch: 2289,     Training Loss: 0.4753749370574951, Training Acc: 65.64%\n",
      "              Val Loss: 0.8966342806816101, Val Acc: 60.79%\n",
      "Epoch: 2290,     Training Loss: 0.500657320022583, Training Acc: 65.65%\n",
      "              Val Loss: 0.9547659158706665, Val Acc: 60.79%\n",
      "Epoch: 2291,     Training Loss: 0.5664615035057068, Training Acc: 65.65%\n",
      "              Val Loss: 0.923552393913269, Val Acc: 60.80%\n",
      "Epoch: 2292,     Training Loss: 0.5433041453361511, Training Acc: 65.65%\n",
      "              Val Loss: 0.9245712161064148, Val Acc: 60.80%\n",
      "Epoch: 2293,     Training Loss: 0.5505884885787964, Training Acc: 65.66%\n",
      "              Val Loss: 0.867550790309906, Val Acc: 60.80%\n",
      "Epoch: 2294,     Training Loss: 0.4872061014175415, Training Acc: 65.66%\n",
      "              Val Loss: 0.838223934173584, Val Acc: 60.81%\n",
      "Epoch: 2295,     Training Loss: 0.4708176851272583, Training Acc: 65.67%\n",
      "              Val Loss: 0.8566049933433533, Val Acc: 60.81%\n",
      "Epoch: 2296,     Training Loss: 0.4801291525363922, Training Acc: 65.68%\n",
      "              Val Loss: 0.8668120503425598, Val Acc: 60.82%\n",
      "Epoch: 2297,     Training Loss: 0.468453973531723, Training Acc: 65.68%\n",
      "              Val Loss: 0.8704792857170105, Val Acc: 60.82%\n",
      "Epoch: 2298,     Training Loss: 0.47713229060173035, Training Acc: 65.69%\n",
      "              Val Loss: 0.8419089317321777, Val Acc: 60.83%\n",
      "Epoch: 2299,     Training Loss: 0.4677433669567108, Training Acc: 65.70%\n",
      "              Val Loss: 0.8489446043968201, Val Acc: 60.83%\n",
      "Epoch: 2300,     Training Loss: 0.4709550142288208, Training Acc: 65.70%\n",
      "              Val Loss: 0.8530616760253906, Val Acc: 60.84%\n",
      "Epoch: 2301,     Training Loss: 0.46851271390914917, Training Acc: 65.71%\n",
      "              Val Loss: 0.8597701191902161, Val Acc: 60.84%\n",
      "Epoch: 2302,     Training Loss: 0.4722433090209961, Training Acc: 65.72%\n",
      "              Val Loss: 0.8520392775535583, Val Acc: 60.85%\n",
      "Epoch: 2303,     Training Loss: 0.47489577531814575, Training Acc: 65.72%\n",
      "              Val Loss: 0.8681063055992126, Val Acc: 60.85%\n",
      "Epoch: 2304,     Training Loss: 0.473946750164032, Training Acc: 65.73%\n",
      "              Val Loss: 0.8830440044403076, Val Acc: 60.86%\n",
      "Epoch: 2305,     Training Loss: 0.47976115345954895, Training Acc: 65.74%\n",
      "              Val Loss: 0.8846791982650757, Val Acc: 60.86%\n",
      "Epoch: 2306,     Training Loss: 0.49040862917900085, Training Acc: 65.74%\n",
      "              Val Loss: 0.9039620757102966, Val Acc: 60.87%\n",
      "Epoch: 2307,     Training Loss: 0.5302289724349976, Training Acc: 65.75%\n",
      "              Val Loss: 0.9304774403572083, Val Acc: 60.87%\n",
      "Epoch: 2308,     Training Loss: 0.5414556264877319, Training Acc: 65.75%\n",
      "              Val Loss: 1.0336730480194092, Val Acc: 60.87%\n",
      "Epoch: 2309,     Training Loss: 0.6483922004699707, Training Acc: 65.76%\n",
      "              Val Loss: 0.9287893772125244, Val Acc: 60.87%\n",
      "Epoch: 2310,     Training Loss: 0.5524044632911682, Training Acc: 65.76%\n",
      "              Val Loss: 0.8753232359886169, Val Acc: 60.88%\n",
      "Epoch: 2311,     Training Loss: 0.5075206160545349, Training Acc: 65.76%\n",
      "              Val Loss: 0.840872585773468, Val Acc: 60.88%\n",
      "Epoch: 2312,     Training Loss: 0.4609113931655884, Training Acc: 65.77%\n",
      "              Val Loss: 0.9077851176261902, Val Acc: 60.89%\n",
      "Epoch: 2313,     Training Loss: 0.5079566836357117, Training Acc: 65.78%\n",
      "              Val Loss: 0.9826657772064209, Val Acc: 60.89%\n",
      "Epoch: 2314,     Training Loss: 0.5971581339836121, Training Acc: 65.78%\n",
      "              Val Loss: 0.9114693403244019, Val Acc: 60.89%\n",
      "Epoch: 2315,     Training Loss: 0.5349510312080383, Training Acc: 65.79%\n",
      "              Val Loss: 0.8726435303688049, Val Acc: 60.90%\n",
      "Epoch: 2316,     Training Loss: 0.49040085077285767, Training Acc: 65.79%\n",
      "              Val Loss: 0.8488812446594238, Val Acc: 60.90%\n",
      "Epoch: 2317,     Training Loss: 0.4724520444869995, Training Acc: 65.80%\n",
      "              Val Loss: 0.8715424537658691, Val Acc: 60.91%\n",
      "Epoch: 2318,     Training Loss: 0.5016868710517883, Training Acc: 65.80%\n",
      "              Val Loss: 0.9430583119392395, Val Acc: 60.91%\n",
      "Epoch: 2319,     Training Loss: 0.5684256553649902, Training Acc: 65.81%\n",
      "              Val Loss: 0.9193673133850098, Val Acc: 60.91%\n",
      "Epoch: 2320,     Training Loss: 0.5251426696777344, Training Acc: 65.81%\n",
      "              Val Loss: 0.8919402360916138, Val Acc: 60.92%\n",
      "Epoch: 2321,     Training Loss: 0.5048719644546509, Training Acc: 65.82%\n",
      "              Val Loss: 0.8569401502609253, Val Acc: 60.92%\n",
      "Epoch: 2322,     Training Loss: 0.4702061712741852, Training Acc: 65.82%\n",
      "              Val Loss: 0.8674169778823853, Val Acc: 60.93%\n",
      "Epoch: 2323,     Training Loss: 0.4730735719203949, Training Acc: 65.83%\n",
      "              Val Loss: 0.9164960980415344, Val Acc: 60.93%\n",
      "Epoch: 2324,     Training Loss: 0.5166051387786865, Training Acc: 65.84%\n",
      "              Val Loss: 0.9044027924537659, Val Acc: 60.93%\n",
      "Epoch: 2325,     Training Loss: 0.5097757577896118, Training Acc: 65.84%\n",
      "              Val Loss: 0.9281026721000671, Val Acc: 60.94%\n",
      "Epoch: 2326,     Training Loss: 0.5339008569717407, Training Acc: 65.85%\n",
      "              Val Loss: 0.8833001852035522, Val Acc: 60.94%\n",
      "Epoch: 2327,     Training Loss: 0.49069538712501526, Training Acc: 65.85%\n",
      "              Val Loss: 0.8561089038848877, Val Acc: 60.95%\n",
      "Epoch: 2328,     Training Loss: 0.47845345735549927, Training Acc: 65.86%\n",
      "              Val Loss: 0.8388659954071045, Val Acc: 60.95%\n",
      "Epoch: 2329,     Training Loss: 0.45641154050827026, Training Acc: 65.87%\n",
      "              Val Loss: 0.8666372895240784, Val Acc: 60.96%\n",
      "Epoch: 2330,     Training Loss: 0.47161442041397095, Training Acc: 65.87%\n",
      "              Val Loss: 0.8990770578384399, Val Acc: 60.96%\n",
      "Epoch: 2331,     Training Loss: 0.5094072818756104, Training Acc: 65.88%\n",
      "              Val Loss: 0.9176203012466431, Val Acc: 60.96%\n",
      "Epoch: 2332,     Training Loss: 0.5301631093025208, Training Acc: 65.88%\n",
      "              Val Loss: 1.0146427154541016, Val Acc: 60.97%\n",
      "Epoch: 2333,     Training Loss: 0.619219183921814, Training Acc: 65.89%\n",
      "              Val Loss: 0.9470484852790833, Val Acc: 60.97%\n",
      "Epoch: 2334,     Training Loss: 0.5469967126846313, Training Acc: 65.89%\n",
      "              Val Loss: 0.9029530882835388, Val Acc: 60.97%\n",
      "Epoch: 2335,     Training Loss: 0.5187634229660034, Training Acc: 65.90%\n",
      "              Val Loss: 0.8550323247909546, Val Acc: 60.98%\n",
      "Epoch: 2336,     Training Loss: 0.4623548984527588, Training Acc: 65.90%\n",
      "              Val Loss: 0.936126708984375, Val Acc: 60.98%\n",
      "Epoch: 2337,     Training Loss: 0.519232451915741, Training Acc: 65.91%\n",
      "              Val Loss: 1.0260335206985474, Val Acc: 60.98%\n",
      "Epoch: 2338,     Training Loss: 0.6272730827331543, Training Acc: 65.91%\n",
      "              Val Loss: 0.9483516812324524, Val Acc: 60.98%\n",
      "Epoch: 2339,     Training Loss: 0.5676935911178589, Training Acc: 65.91%\n",
      "              Val Loss: 0.9462073445320129, Val Acc: 60.99%\n",
      "Epoch: 2340,     Training Loss: 0.5504546165466309, Training Acc: 65.92%\n",
      "              Val Loss: 0.8839068412780762, Val Acc: 60.99%\n",
      "Epoch: 2341,     Training Loss: 0.4926249384880066, Training Acc: 65.92%\n",
      "              Val Loss: 0.8902053833007812, Val Acc: 61.00%\n",
      "Epoch: 2342,     Training Loss: 0.5123891830444336, Training Acc: 65.93%\n",
      "              Val Loss: 0.9306418895721436, Val Acc: 61.00%\n",
      "Epoch: 2343,     Training Loss: 0.5439178943634033, Training Acc: 65.93%\n",
      "              Val Loss: 0.9626739621162415, Val Acc: 61.00%\n",
      "Epoch: 2344,     Training Loss: 0.5395270586013794, Training Acc: 65.94%\n",
      "              Val Loss: 0.9420343041419983, Val Acc: 61.01%\n",
      "Epoch: 2345,     Training Loss: 0.5461380481719971, Training Acc: 65.94%\n",
      "              Val Loss: 0.8754078149795532, Val Acc: 61.01%\n",
      "Epoch: 2346,     Training Loss: 0.4978317320346832, Training Acc: 65.95%\n",
      "              Val Loss: 0.8831213116645813, Val Acc: 61.01%\n",
      "Epoch: 2347,     Training Loss: 0.4873352348804474, Training Acc: 65.95%\n",
      "              Val Loss: 0.879798412322998, Val Acc: 61.02%\n",
      "Epoch: 2348,     Training Loss: 0.4834117889404297, Training Acc: 65.96%\n",
      "              Val Loss: 0.9132944345474243, Val Acc: 61.02%\n",
      "Epoch: 2349,     Training Loss: 0.5202919244766235, Training Acc: 65.96%\n",
      "              Val Loss: 0.924709677696228, Val Acc: 61.03%\n",
      "Epoch: 2350,     Training Loss: 0.5360772013664246, Training Acc: 65.97%\n",
      "              Val Loss: 0.9447647333145142, Val Acc: 61.03%\n",
      "Epoch: 2351,     Training Loss: 0.5359362959861755, Training Acc: 65.97%\n",
      "              Val Loss: 0.9162779450416565, Val Acc: 61.03%\n",
      "Epoch: 2352,     Training Loss: 0.5340276956558228, Training Acc: 65.98%\n",
      "              Val Loss: 0.8713381290435791, Val Acc: 61.04%\n",
      "Epoch: 2353,     Training Loss: 0.5000231266021729, Training Acc: 65.98%\n",
      "              Val Loss: 0.8573505282402039, Val Acc: 61.04%\n",
      "Epoch: 2354,     Training Loss: 0.47522738575935364, Training Acc: 65.99%\n",
      "              Val Loss: 0.863142728805542, Val Acc: 61.05%\n",
      "Epoch: 2355,     Training Loss: 0.4778553247451782, Training Acc: 66.00%\n",
      "              Val Loss: 0.901681661605835, Val Acc: 61.05%\n",
      "Epoch: 2356,     Training Loss: 0.504604697227478, Training Acc: 66.00%\n",
      "              Val Loss: 0.9562784433364868, Val Acc: 61.06%\n",
      "Epoch: 2357,     Training Loss: 0.5567248463630676, Training Acc: 66.01%\n",
      "              Val Loss: 0.9434980750083923, Val Acc: 61.06%\n",
      "Epoch: 2358,     Training Loss: 0.5429489016532898, Training Acc: 66.01%\n",
      "              Val Loss: 0.8954778909683228, Val Acc: 61.06%\n",
      "Epoch: 2359,     Training Loss: 0.5314640998840332, Training Acc: 66.02%\n",
      "              Val Loss: 0.8707481622695923, Val Acc: 61.07%\n",
      "Epoch: 2360,     Training Loss: 0.4836966395378113, Training Acc: 66.02%\n",
      "              Val Loss: 0.883148193359375, Val Acc: 61.07%\n",
      "Epoch: 2361,     Training Loss: 0.4734700322151184, Training Acc: 66.03%\n",
      "              Val Loss: 0.9054136872291565, Val Acc: 61.07%\n",
      "Epoch: 2362,     Training Loss: 0.5048540830612183, Training Acc: 66.03%\n",
      "              Val Loss: 0.9146515727043152, Val Acc: 61.08%\n",
      "Epoch: 2363,     Training Loss: 0.5214104056358337, Training Acc: 66.04%\n",
      "              Val Loss: 0.9466278553009033, Val Acc: 61.08%\n",
      "Epoch: 2364,     Training Loss: 0.5416259169578552, Training Acc: 66.04%\n",
      "              Val Loss: 0.8943608999252319, Val Acc: 61.08%\n",
      "Epoch: 2365,     Training Loss: 0.5035096406936646, Training Acc: 66.05%\n",
      "              Val Loss: 0.8323478698730469, Val Acc: 61.09%\n",
      "Epoch: 2366,     Training Loss: 0.47770047187805176, Training Acc: 66.05%\n",
      "              Val Loss: 0.8321791887283325, Val Acc: 61.09%\n",
      "Epoch: 2367,     Training Loss: 0.4562099575996399, Training Acc: 66.06%\n",
      "              Val Loss: 0.891559362411499, Val Acc: 61.10%\n",
      "Epoch: 2368,     Training Loss: 0.47920870780944824, Training Acc: 66.07%\n",
      "              Val Loss: 0.9106881618499756, Val Acc: 61.10%\n",
      "Epoch: 2369,     Training Loss: 0.5060165524482727, Training Acc: 66.07%\n",
      "              Val Loss: 0.9109257459640503, Val Acc: 61.11%\n",
      "Epoch: 2370,     Training Loss: 0.5207614302635193, Training Acc: 66.08%\n",
      "              Val Loss: 0.9418104290962219, Val Acc: 61.11%\n",
      "Epoch: 2371,     Training Loss: 0.5404388308525085, Training Acc: 66.08%\n",
      "              Val Loss: 0.8870754837989807, Val Acc: 61.11%\n",
      "Epoch: 2372,     Training Loss: 0.49093684554100037, Training Acc: 66.09%\n",
      "              Val Loss: 0.8437908291816711, Val Acc: 61.12%\n",
      "Epoch: 2373,     Training Loss: 0.46707019209861755, Training Acc: 66.09%\n",
      "              Val Loss: 0.8411600589752197, Val Acc: 61.12%\n",
      "Epoch: 2374,     Training Loss: 0.45784053206443787, Training Acc: 66.10%\n",
      "              Val Loss: 0.9093009233474731, Val Acc: 61.13%\n",
      "Epoch: 2375,     Training Loss: 0.5009264945983887, Training Acc: 66.11%\n",
      "              Val Loss: 0.9381660223007202, Val Acc: 61.13%\n",
      "Epoch: 2376,     Training Loss: 0.5473072528839111, Training Acc: 66.11%\n",
      "              Val Loss: 0.9383790493011475, Val Acc: 61.13%\n",
      "Epoch: 2377,     Training Loss: 0.5539743304252625, Training Acc: 66.11%\n",
      "              Val Loss: 0.9821054935455322, Val Acc: 61.14%\n",
      "Epoch: 2378,     Training Loss: 0.5890400409698486, Training Acc: 66.12%\n",
      "              Val Loss: 0.8900233507156372, Val Acc: 61.14%\n",
      "Epoch: 2379,     Training Loss: 0.4968721866607666, Training Acc: 66.12%\n",
      "              Val Loss: 0.8684608936309814, Val Acc: 61.14%\n",
      "Epoch: 2380,     Training Loss: 0.48608943819999695, Training Acc: 66.13%\n",
      "              Val Loss: 0.928131639957428, Val Acc: 61.15%\n",
      "Epoch: 2381,     Training Loss: 0.5279580950737, Training Acc: 66.13%\n",
      "              Val Loss: 0.9808799624443054, Val Acc: 61.15%\n",
      "Epoch: 2382,     Training Loss: 0.5607520341873169, Training Acc: 66.14%\n",
      "              Val Loss: 0.9849763512611389, Val Acc: 61.15%\n",
      "Epoch: 2383,     Training Loss: 0.6068712472915649, Training Acc: 66.14%\n",
      "              Val Loss: 0.8696887493133545, Val Acc: 61.16%\n",
      "Epoch: 2384,     Training Loss: 0.5011813044548035, Training Acc: 66.14%\n",
      "              Val Loss: 0.8992598056793213, Val Acc: 61.16%\n",
      "Epoch: 2385,     Training Loss: 0.4973500072956085, Training Acc: 66.15%\n",
      "              Val Loss: 0.956929087638855, Val Acc: 61.16%\n",
      "Epoch: 2386,     Training Loss: 0.5542935132980347, Training Acc: 66.15%\n",
      "              Val Loss: 0.9304258227348328, Val Acc: 61.17%\n",
      "Epoch: 2387,     Training Loss: 0.5360541939735413, Training Acc: 66.16%\n",
      "              Val Loss: 0.8883354663848877, Val Acc: 61.17%\n",
      "Epoch: 2388,     Training Loss: 0.4864612817764282, Training Acc: 66.16%\n",
      "              Val Loss: 0.8747255206108093, Val Acc: 61.18%\n",
      "Epoch: 2389,     Training Loss: 0.4631117582321167, Training Acc: 66.17%\n",
      "              Val Loss: 0.8619820475578308, Val Acc: 61.18%\n",
      "Epoch: 2390,     Training Loss: 0.471036821603775, Training Acc: 66.18%\n",
      "              Val Loss: 0.8836991786956787, Val Acc: 61.18%\n",
      "Epoch: 2391,     Training Loss: 0.5088115930557251, Training Acc: 66.18%\n",
      "              Val Loss: 0.8690616488456726, Val Acc: 61.19%\n",
      "Epoch: 2392,     Training Loss: 0.4846760034561157, Training Acc: 66.19%\n",
      "              Val Loss: 0.8649146556854248, Val Acc: 61.19%\n",
      "Epoch: 2393,     Training Loss: 0.4632999300956726, Training Acc: 66.19%\n",
      "              Val Loss: 0.8648539781570435, Val Acc: 61.20%\n",
      "Epoch: 2394,     Training Loss: 0.45464184880256653, Training Acc: 66.20%\n",
      "              Val Loss: 0.856354296207428, Val Acc: 61.20%\n",
      "Epoch: 2395,     Training Loss: 0.4525787830352783, Training Acc: 66.21%\n",
      "              Val Loss: 0.8688644170761108, Val Acc: 61.21%\n",
      "Epoch: 2396,     Training Loss: 0.47205793857574463, Training Acc: 66.21%\n",
      "              Val Loss: 0.8712390661239624, Val Acc: 61.21%\n",
      "Epoch: 2397,     Training Loss: 0.4715195894241333, Training Acc: 66.22%\n",
      "              Val Loss: 0.873308002948761, Val Acc: 61.22%\n",
      "Epoch: 2398,     Training Loss: 0.4767691493034363, Training Acc: 66.23%\n",
      "              Val Loss: 0.8627033233642578, Val Acc: 61.22%\n",
      "Epoch: 2399,     Training Loss: 0.46322810649871826, Training Acc: 66.23%\n",
      "              Val Loss: 0.8669777512550354, Val Acc: 61.23%\n",
      "Epoch: 2400,     Training Loss: 0.4668464958667755, Training Acc: 66.24%\n",
      "              Val Loss: 0.8560991883277893, Val Acc: 61.23%\n",
      "Epoch: 2401,     Training Loss: 0.45312434434890747, Training Acc: 66.24%\n",
      "              Val Loss: 0.854266345500946, Val Acc: 61.24%\n",
      "Epoch: 2402,     Training Loss: 0.4525347650051117, Training Acc: 66.25%\n",
      "              Val Loss: 0.8513436913490295, Val Acc: 61.24%\n",
      "Epoch: 2403,     Training Loss: 0.447138249874115, Training Acc: 66.26%\n",
      "              Val Loss: 0.8435571789741516, Val Acc: 61.25%\n",
      "Epoch: 2404,     Training Loss: 0.44737792015075684, Training Acc: 66.26%\n",
      "              Val Loss: 0.8384285569190979, Val Acc: 61.25%\n",
      "Epoch: 2405,     Training Loss: 0.4449095129966736, Training Acc: 66.27%\n",
      "              Val Loss: 0.8463205695152283, Val Acc: 61.26%\n",
      "Epoch: 2406,     Training Loss: 0.4440213143825531, Training Acc: 66.28%\n",
      "              Val Loss: 0.855109691619873, Val Acc: 61.26%\n",
      "Epoch: 2407,     Training Loss: 0.4439423084259033, Training Acc: 66.28%\n",
      "              Val Loss: 0.8452760577201843, Val Acc: 61.27%\n",
      "Epoch: 2408,     Training Loss: 0.4421350061893463, Training Acc: 66.29%\n",
      "              Val Loss: 0.8411610126495361, Val Acc: 61.27%\n",
      "Epoch: 2409,     Training Loss: 0.4441455006599426, Training Acc: 66.30%\n",
      "              Val Loss: 0.8462535738945007, Val Acc: 61.28%\n",
      "Epoch: 2410,     Training Loss: 0.44658851623535156, Training Acc: 66.30%\n",
      "              Val Loss: 0.8600162267684937, Val Acc: 61.28%\n",
      "Epoch: 2411,     Training Loss: 0.4573477804660797, Training Acc: 66.31%\n",
      "              Val Loss: 0.8891968727111816, Val Acc: 61.29%\n",
      "Epoch: 2412,     Training Loss: 0.493986576795578, Training Acc: 66.31%\n",
      "              Val Loss: 0.9381711483001709, Val Acc: 61.29%\n",
      "Epoch: 2413,     Training Loss: 0.5406564474105835, Training Acc: 66.32%\n",
      "              Val Loss: 1.1392641067504883, Val Acc: 61.29%\n",
      "Epoch: 2414,     Training Loss: 0.7494789361953735, Training Acc: 66.32%\n",
      "              Val Loss: 0.9643924236297607, Val Acc: 61.29%\n",
      "Epoch: 2415,     Training Loss: 0.5765025019645691, Training Acc: 66.32%\n",
      "              Val Loss: 0.8677563667297363, Val Acc: 61.29%\n",
      "Epoch: 2416,     Training Loss: 0.48531100153923035, Training Acc: 66.33%\n",
      "              Val Loss: 0.8749455213546753, Val Acc: 61.30%\n",
      "Epoch: 2417,     Training Loss: 0.47831499576568604, Training Acc: 66.33%\n",
      "              Val Loss: 0.9576987624168396, Val Acc: 61.30%\n",
      "Epoch: 2418,     Training Loss: 0.5524484515190125, Training Acc: 66.34%\n",
      "              Val Loss: 1.011995553970337, Val Acc: 61.30%\n",
      "Epoch: 2419,     Training Loss: 0.6245197057723999, Training Acc: 66.34%\n",
      "              Val Loss: 0.8543972969055176, Val Acc: 61.31%\n",
      "Epoch: 2420,     Training Loss: 0.47692394256591797, Training Acc: 66.35%\n",
      "              Val Loss: 0.9404487609863281, Val Acc: 61.31%\n",
      "Epoch: 2421,     Training Loss: 0.5378636121749878, Training Acc: 66.35%\n",
      "              Val Loss: 1.0947940349578857, Val Acc: 61.31%\n",
      "Epoch: 2422,     Training Loss: 0.7112017869949341, Training Acc: 66.35%\n",
      "              Val Loss: 0.8709209561347961, Val Acc: 61.31%\n",
      "Epoch: 2423,     Training Loss: 0.504723310470581, Training Acc: 66.36%\n",
      "              Val Loss: 0.9406248331069946, Val Acc: 61.32%\n",
      "Epoch: 2424,     Training Loss: 0.5360543727874756, Training Acc: 66.36%\n",
      "              Val Loss: 1.178257703781128, Val Acc: 61.32%\n",
      "Epoch: 2425,     Training Loss: 0.7538765072822571, Training Acc: 66.36%\n",
      "              Val Loss: 0.8806993365287781, Val Acc: 61.32%\n",
      "Epoch: 2426,     Training Loss: 0.5376085042953491, Training Acc: 66.36%\n",
      "              Val Loss: 0.8611099123954773, Val Acc: 61.32%\n",
      "Epoch: 2427,     Training Loss: 0.5136833190917969, Training Acc: 66.37%\n",
      "              Val Loss: 1.063806414604187, Val Acc: 61.33%\n",
      "Epoch: 2428,     Training Loss: 0.6651305556297302, Training Acc: 66.37%\n",
      "              Val Loss: 0.9287841320037842, Val Acc: 61.33%\n",
      "Epoch: 2429,     Training Loss: 0.530625581741333, Training Acc: 66.38%\n",
      "              Val Loss: 0.8792079091072083, Val Acc: 61.33%\n",
      "Epoch: 2430,     Training Loss: 0.5010064840316772, Training Acc: 66.38%\n",
      "              Val Loss: 0.9896266460418701, Val Acc: 61.34%\n",
      "Epoch: 2431,     Training Loss: 0.5974676012992859, Training Acc: 66.38%\n",
      "              Val Loss: 0.903664231300354, Val Acc: 61.34%\n",
      "Epoch: 2432,     Training Loss: 0.49098291993141174, Training Acc: 66.39%\n",
      "              Val Loss: 0.9040609002113342, Val Acc: 61.34%\n",
      "Epoch: 2433,     Training Loss: 0.5044061541557312, Training Acc: 66.40%\n",
      "              Val Loss: 0.8996521234512329, Val Acc: 61.35%\n",
      "Epoch: 2434,     Training Loss: 0.5179827213287354, Training Acc: 66.40%\n",
      "              Val Loss: 0.9219374060630798, Val Acc: 61.35%\n",
      "Epoch: 2435,     Training Loss: 0.5150136947631836, Training Acc: 66.41%\n",
      "              Val Loss: 0.8741357922554016, Val Acc: 61.35%\n",
      "Epoch: 2436,     Training Loss: 0.4755617380142212, Training Acc: 66.41%\n",
      "              Val Loss: 0.8643606305122375, Val Acc: 61.36%\n",
      "Epoch: 2437,     Training Loss: 0.4648943245410919, Training Acc: 66.42%\n",
      "              Val Loss: 0.8661239147186279, Val Acc: 61.36%\n",
      "Epoch: 2438,     Training Loss: 0.46605148911476135, Training Acc: 66.42%\n",
      "              Val Loss: 0.8677929639816284, Val Acc: 61.37%\n",
      "Epoch: 2439,     Training Loss: 0.47510069608688354, Training Acc: 66.43%\n",
      "              Val Loss: 0.8781479001045227, Val Acc: 61.37%\n",
      "Epoch: 2440,     Training Loss: 0.4717603325843811, Training Acc: 66.43%\n",
      "              Val Loss: 0.8890078067779541, Val Acc: 61.38%\n",
      "Epoch: 2441,     Training Loss: 0.47239363193511963, Training Acc: 66.44%\n",
      "              Val Loss: 0.8833523392677307, Val Acc: 61.38%\n",
      "Epoch: 2442,     Training Loss: 0.46755629777908325, Training Acc: 66.45%\n",
      "              Val Loss: 0.857035219669342, Val Acc: 61.39%\n",
      "Epoch: 2443,     Training Loss: 0.4591417610645294, Training Acc: 66.45%\n",
      "              Val Loss: 0.849066972732544, Val Acc: 61.39%\n",
      "Epoch: 2444,     Training Loss: 0.4587900936603546, Training Acc: 66.46%\n",
      "              Val Loss: 0.8393158912658691, Val Acc: 61.40%\n",
      "Epoch: 2445,     Training Loss: 0.45205461978912354, Training Acc: 66.46%\n",
      "              Val Loss: 0.8480510711669922, Val Acc: 61.40%\n",
      "Epoch: 2446,     Training Loss: 0.4526401162147522, Training Acc: 66.47%\n",
      "              Val Loss: 0.8415412902832031, Val Acc: 61.41%\n",
      "Epoch: 2447,     Training Loss: 0.4461458623409271, Training Acc: 66.48%\n",
      "              Val Loss: 0.8530901074409485, Val Acc: 61.41%\n",
      "Epoch: 2448,     Training Loss: 0.44818729162216187, Training Acc: 66.48%\n",
      "              Val Loss: 0.8603708744049072, Val Acc: 61.42%\n",
      "Epoch: 2449,     Training Loss: 0.4457181692123413, Training Acc: 66.49%\n",
      "              Val Loss: 0.8772985935211182, Val Acc: 61.42%\n",
      "Epoch: 2450,     Training Loss: 0.4525620639324188, Training Acc: 66.50%\n",
      "              Val Loss: 0.8801572322845459, Val Acc: 61.42%\n",
      "Epoch: 2451,     Training Loss: 0.46472790837287903, Training Acc: 66.50%\n",
      "              Val Loss: 0.9102028012275696, Val Acc: 61.43%\n",
      "Epoch: 2452,     Training Loss: 0.4951222240924835, Training Acc: 66.51%\n",
      "              Val Loss: 1.0288822650909424, Val Acc: 61.43%\n",
      "Epoch: 2453,     Training Loss: 0.6206278800964355, Training Acc: 66.51%\n",
      "              Val Loss: 0.9737891554832458, Val Acc: 61.43%\n",
      "Epoch: 2454,     Training Loss: 0.5626079440116882, Training Acc: 66.51%\n",
      "              Val Loss: 0.9436672329902649, Val Acc: 61.43%\n",
      "Epoch: 2455,     Training Loss: 0.554059624671936, Training Acc: 66.52%\n",
      "              Val Loss: 0.8411308526992798, Val Acc: 61.44%\n",
      "Epoch: 2456,     Training Loss: 0.4538951516151428, Training Acc: 66.52%\n",
      "              Val Loss: 0.9372956156730652, Val Acc: 61.44%\n",
      "Epoch: 2457,     Training Loss: 0.5316057801246643, Training Acc: 66.53%\n",
      "              Val Loss: 1.0698221921920776, Val Acc: 61.44%\n",
      "Epoch: 2458,     Training Loss: 0.6887305378913879, Training Acc: 66.53%\n",
      "              Val Loss: 0.8599972724914551, Val Acc: 61.45%\n",
      "Epoch: 2459,     Training Loss: 0.48491790890693665, Training Acc: 66.53%\n",
      "              Val Loss: 0.8988285064697266, Val Acc: 61.45%\n",
      "Epoch: 2460,     Training Loss: 0.5107541680335999, Training Acc: 66.54%\n",
      "              Val Loss: 1.0506155490875244, Val Acc: 61.45%\n",
      "Epoch: 2461,     Training Loss: 0.6753883361816406, Training Acc: 66.54%\n",
      "              Val Loss: 0.8542401194572449, Val Acc: 61.46%\n",
      "Epoch: 2462,     Training Loss: 0.47705432772636414, Training Acc: 66.55%\n",
      "              Val Loss: 0.9751164317131042, Val Acc: 61.46%\n",
      "Epoch: 2463,     Training Loss: 0.5685306787490845, Training Acc: 66.55%\n",
      "              Val Loss: 1.2076194286346436, Val Acc: 61.46%\n",
      "Epoch: 2464,     Training Loss: 0.8151610493659973, Training Acc: 66.55%\n",
      "              Val Loss: 0.842664897441864, Val Acc: 61.46%\n",
      "Epoch: 2465,     Training Loss: 0.46742168068885803, Training Acc: 66.55%\n",
      "              Val Loss: 1.267707109451294, Val Acc: 61.46%\n",
      "Epoch: 2466,     Training Loss: 0.8488760590553284, Training Acc: 66.55%\n",
      "              Val Loss: 1.8225921392440796, Val Acc: 61.45%\n",
      "Epoch: 2467,     Training Loss: 1.4890507459640503, Training Acc: 66.54%\n",
      "              Val Loss: 1.2627995014190674, Val Acc: 61.45%\n",
      "Epoch: 2468,     Training Loss: 0.9904447793960571, Training Acc: 66.54%\n",
      "              Val Loss: 1.521598219871521, Val Acc: 61.44%\n",
      "Epoch: 2469,     Training Loss: 1.1998733282089233, Training Acc: 66.53%\n",
      "              Val Loss: 1.000176191329956, Val Acc: 61.45%\n",
      "Epoch: 2470,     Training Loss: 0.6250795125961304, Training Acc: 66.54%\n",
      "              Val Loss: 1.396824598312378, Val Acc: 61.45%\n",
      "Epoch: 2471,     Training Loss: 1.0391467809677124, Training Acc: 66.54%\n",
      "              Val Loss: 0.9614262580871582, Val Acc: 61.45%\n",
      "Epoch: 2472,     Training Loss: 0.7587627172470093, Training Acc: 66.54%\n",
      "              Val Loss: 1.1277939081192017, Val Acc: 61.45%\n",
      "Epoch: 2473,     Training Loss: 0.9083718061447144, Training Acc: 66.54%\n",
      "              Val Loss: 1.0354620218276978, Val Acc: 61.45%\n",
      "Epoch: 2474,     Training Loss: 0.8419125080108643, Training Acc: 66.53%\n",
      "              Val Loss: 0.9024507999420166, Val Acc: 61.45%\n",
      "Epoch: 2475,     Training Loss: 0.7135576605796814, Training Acc: 66.54%\n",
      "              Val Loss: 1.077082633972168, Val Acc: 61.45%\n",
      "Epoch: 2476,     Training Loss: 0.8725398778915405, Training Acc: 66.54%\n",
      "              Val Loss: 0.8921909928321838, Val Acc: 61.45%\n",
      "Epoch: 2477,     Training Loss: 0.7074746489524841, Training Acc: 66.54%\n",
      "              Val Loss: 0.9814728498458862, Val Acc: 61.45%\n",
      "Epoch: 2478,     Training Loss: 0.7672274112701416, Training Acc: 66.54%\n",
      "              Val Loss: 0.9768913984298706, Val Acc: 61.45%\n",
      "Epoch: 2479,     Training Loss: 0.7462852001190186, Training Acc: 66.54%\n",
      "              Val Loss: 0.8474897146224976, Val Acc: 61.46%\n",
      "Epoch: 2480,     Training Loss: 0.6714166402816772, Training Acc: 66.54%\n",
      "              Val Loss: 0.9072763919830322, Val Acc: 61.46%\n",
      "Epoch: 2481,     Training Loss: 0.7499495148658752, Training Acc: 66.54%\n",
      "              Val Loss: 0.7985517978668213, Val Acc: 61.46%\n",
      "Epoch: 2482,     Training Loss: 0.6162192821502686, Training Acc: 66.55%\n",
      "              Val Loss: 0.9537434577941895, Val Acc: 61.46%\n",
      "Epoch: 2483,     Training Loss: 0.7338419556617737, Training Acc: 66.55%\n",
      "              Val Loss: 0.8280738592147827, Val Acc: 61.47%\n",
      "Epoch: 2484,     Training Loss: 0.6314985156059265, Training Acc: 66.55%\n",
      "              Val Loss: 0.8622115254402161, Val Acc: 61.47%\n",
      "Epoch: 2485,     Training Loss: 0.6627913117408752, Training Acc: 66.55%\n",
      "              Val Loss: 0.8323674201965332, Val Acc: 61.47%\n",
      "Epoch: 2486,     Training Loss: 0.6212261319160461, Training Acc: 66.55%\n",
      "              Val Loss: 0.8689186573028564, Val Acc: 61.48%\n",
      "Epoch: 2487,     Training Loss: 0.6335839629173279, Training Acc: 66.56%\n",
      "              Val Loss: 0.8796351552009583, Val Acc: 61.48%\n",
      "Epoch: 2488,     Training Loss: 0.6506919264793396, Training Acc: 66.56%\n",
      "              Val Loss: 0.8033320903778076, Val Acc: 61.48%\n",
      "Epoch: 2489,     Training Loss: 0.5978423953056335, Training Acc: 66.56%\n",
      "              Val Loss: 0.8220332264900208, Val Acc: 61.48%\n",
      "Epoch: 2490,     Training Loss: 0.6278024315834045, Training Acc: 66.57%\n",
      "              Val Loss: 0.7744165062904358, Val Acc: 61.49%\n",
      "Epoch: 2491,     Training Loss: 0.5911151170730591, Training Acc: 66.57%\n",
      "              Val Loss: 0.7958693504333496, Val Acc: 61.49%\n",
      "Epoch: 2492,     Training Loss: 0.6119061708450317, Training Acc: 66.57%\n",
      "              Val Loss: 0.7695810198783875, Val Acc: 61.50%\n",
      "Epoch: 2493,     Training Loss: 0.5649542808532715, Training Acc: 66.58%\n",
      "              Val Loss: 0.8125572800636292, Val Acc: 61.50%\n",
      "Epoch: 2494,     Training Loss: 0.5837171077728271, Training Acc: 66.58%\n",
      "              Val Loss: 0.8079676628112793, Val Acc: 61.50%\n",
      "Epoch: 2495,     Training Loss: 0.5661922693252563, Training Acc: 66.58%\n",
      "              Val Loss: 0.8167209625244141, Val Acc: 61.51%\n",
      "Epoch: 2496,     Training Loss: 0.5684362649917603, Training Acc: 66.59%\n",
      "              Val Loss: 0.7742587924003601, Val Acc: 61.51%\n",
      "Epoch: 2497,     Training Loss: 0.5436118841171265, Training Acc: 66.59%\n",
      "              Val Loss: 0.7890162467956543, Val Acc: 61.52%\n",
      "Epoch: 2498,     Training Loss: 0.55442214012146, Training Acc: 66.60%\n",
      "              Val Loss: 0.7784127593040466, Val Acc: 61.52%\n",
      "Epoch: 2499,     Training Loss: 0.5388489365577698, Training Acc: 66.60%\n",
      "              Val Loss: 0.7765751481056213, Val Acc: 61.52%\n",
      "Epoch: 2500,     Training Loss: 0.5340325832366943, Training Acc: 66.61%\n",
      "              Val Loss: 0.7725184559822083, Val Acc: 61.53%\n",
      "Epoch: 2501,     Training Loss: 0.5331734418869019, Training Acc: 66.61%\n",
      "              Val Loss: 0.7672703266143799, Val Acc: 61.53%\n",
      "Epoch: 2502,     Training Loss: 0.5182207226753235, Training Acc: 66.62%\n",
      "              Val Loss: 0.7902680039405823, Val Acc: 61.54%\n",
      "Epoch: 2503,     Training Loss: 0.5263513326644897, Training Acc: 66.62%\n",
      "              Val Loss: 0.7455111145973206, Val Acc: 61.54%\n",
      "Epoch: 2504,     Training Loss: 0.506055474281311, Training Acc: 66.62%\n",
      "              Val Loss: 0.7454227209091187, Val Acc: 61.55%\n",
      "Epoch: 2505,     Training Loss: 0.512019157409668, Training Acc: 66.63%\n",
      "              Val Loss: 0.7444825172424316, Val Acc: 61.55%\n",
      "Epoch: 2506,     Training Loss: 0.4990449547767639, Training Acc: 66.64%\n",
      "              Val Loss: 0.7525373101234436, Val Acc: 61.56%\n",
      "Epoch: 2507,     Training Loss: 0.5026841163635254, Training Acc: 66.64%\n",
      "              Val Loss: 0.7412015795707703, Val Acc: 61.56%\n",
      "Epoch: 2508,     Training Loss: 0.48934081196784973, Training Acc: 66.65%\n",
      "              Val Loss: 0.7496885657310486, Val Acc: 61.57%\n",
      "Epoch: 2509,     Training Loss: 0.49435365200042725, Training Acc: 66.65%\n",
      "              Val Loss: 0.7355043292045593, Val Acc: 61.57%\n",
      "Epoch: 2510,     Training Loss: 0.48617953062057495, Training Acc: 66.66%\n",
      "              Val Loss: 0.7472403049468994, Val Acc: 61.58%\n",
      "Epoch: 2511,     Training Loss: 0.4881957173347473, Training Acc: 66.66%\n",
      "              Val Loss: 0.7319715619087219, Val Acc: 61.58%\n",
      "Epoch: 2512,     Training Loss: 0.478382408618927, Training Acc: 66.67%\n",
      "              Val Loss: 0.7359834909439087, Val Acc: 61.59%\n",
      "Epoch: 2513,     Training Loss: 0.4802949130535126, Training Acc: 66.67%\n",
      "              Val Loss: 0.7432370781898499, Val Acc: 61.59%\n",
      "Epoch: 2514,     Training Loss: 0.4755103588104248, Training Acc: 66.68%\n",
      "              Val Loss: 0.7546741366386414, Val Acc: 61.60%\n",
      "Epoch: 2515,     Training Loss: 0.4760402739048004, Training Acc: 66.68%\n",
      "              Val Loss: 0.7586454749107361, Val Acc: 61.60%\n",
      "Epoch: 2516,     Training Loss: 0.47133544087409973, Training Acc: 66.69%\n",
      "              Val Loss: 0.7569397687911987, Val Acc: 61.61%\n",
      "Epoch: 2517,     Training Loss: 0.4707176685333252, Training Acc: 66.69%\n",
      "              Val Loss: 0.7582272291183472, Val Acc: 61.61%\n",
      "Epoch: 2518,     Training Loss: 0.46810460090637207, Training Acc: 66.70%\n",
      "              Val Loss: 0.7703843116760254, Val Acc: 61.62%\n",
      "Epoch: 2519,     Training Loss: 0.4676041007041931, Training Acc: 66.70%\n",
      "              Val Loss: 0.7698847055435181, Val Acc: 61.62%\n",
      "Epoch: 2520,     Training Loss: 0.4676530063152313, Training Acc: 66.71%\n",
      "              Val Loss: 0.7734094858169556, Val Acc: 61.63%\n",
      "Epoch: 2521,     Training Loss: 0.4661882519721985, Training Acc: 66.72%\n",
      "              Val Loss: 0.7700103521347046, Val Acc: 61.63%\n",
      "Epoch: 2522,     Training Loss: 0.4649096727371216, Training Acc: 66.72%\n",
      "              Val Loss: 0.7785751223564148, Val Acc: 61.63%\n",
      "Epoch: 2523,     Training Loss: 0.46375197172164917, Training Acc: 66.73%\n",
      "              Val Loss: 0.773083508014679, Val Acc: 61.64%\n",
      "Epoch: 2524,     Training Loss: 0.4637013375759125, Training Acc: 66.73%\n",
      "              Val Loss: 0.774939775466919, Val Acc: 61.65%\n",
      "Epoch: 2525,     Training Loss: 0.4628165066242218, Training Acc: 66.74%\n",
      "              Val Loss: 0.7694966197013855, Val Acc: 61.65%\n",
      "Epoch: 2526,     Training Loss: 0.4635167419910431, Training Acc: 66.74%\n",
      "              Val Loss: 0.7784369587898254, Val Acc: 61.66%\n",
      "Epoch: 2527,     Training Loss: 0.4616568088531494, Training Acc: 66.75%\n",
      "              Val Loss: 0.7758447527885437, Val Acc: 61.66%\n",
      "Epoch: 2528,     Training Loss: 0.46314290165901184, Training Acc: 66.76%\n",
      "              Val Loss: 0.7806464433670044, Val Acc: 61.67%\n",
      "Epoch: 2529,     Training Loss: 0.46247565746307373, Training Acc: 66.76%\n",
      "              Val Loss: 0.7764647603034973, Val Acc: 61.67%\n",
      "Epoch: 2530,     Training Loss: 0.4657285213470459, Training Acc: 66.77%\n",
      "              Val Loss: 0.7881962656974792, Val Acc: 61.67%\n",
      "Epoch: 2531,     Training Loss: 0.4679865539073944, Training Acc: 66.77%\n",
      "              Val Loss: 0.7869099974632263, Val Acc: 61.68%\n",
      "Epoch: 2532,     Training Loss: 0.4796029329299927, Training Acc: 66.78%\n",
      "              Val Loss: 0.796191930770874, Val Acc: 61.68%\n",
      "Epoch: 2533,     Training Loss: 0.4794503450393677, Training Acc: 66.78%\n",
      "              Val Loss: 0.8052845597267151, Val Acc: 61.69%\n",
      "Epoch: 2534,     Training Loss: 0.5016459822654724, Training Acc: 66.79%\n",
      "              Val Loss: 0.8021631836891174, Val Acc: 61.69%\n",
      "Epoch: 2535,     Training Loss: 0.48648858070373535, Training Acc: 66.79%\n",
      "              Val Loss: 0.7945340871810913, Val Acc: 61.70%\n",
      "Epoch: 2536,     Training Loss: 0.48874005675315857, Training Acc: 66.80%\n",
      "              Val Loss: 0.7799417972564697, Val Acc: 61.70%\n",
      "Epoch: 2537,     Training Loss: 0.46419084072113037, Training Acc: 66.80%\n",
      "              Val Loss: 0.7633244395256042, Val Acc: 61.70%\n",
      "Epoch: 2538,     Training Loss: 0.4527813792228699, Training Acc: 66.81%\n",
      "              Val Loss: 0.763080894947052, Val Acc: 61.71%\n",
      "Epoch: 2539,     Training Loss: 0.4498094320297241, Training Acc: 66.82%\n",
      "              Val Loss: 0.7723425030708313, Val Acc: 61.71%\n",
      "Epoch: 2540,     Training Loss: 0.4538244903087616, Training Acc: 66.82%\n",
      "              Val Loss: 0.7815992832183838, Val Acc: 61.72%\n",
      "Epoch: 2541,     Training Loss: 0.46641460061073303, Training Acc: 66.83%\n",
      "              Val Loss: 0.8108243346214294, Val Acc: 61.72%\n",
      "Epoch: 2542,     Training Loss: 0.4847170114517212, Training Acc: 66.83%\n",
      "              Val Loss: 0.8604400753974915, Val Acc: 61.73%\n",
      "Epoch: 2543,     Training Loss: 0.5485577583312988, Training Acc: 66.84%\n",
      "              Val Loss: 0.8409827947616577, Val Acc: 61.73%\n",
      "Epoch: 2544,     Training Loss: 0.5160892009735107, Training Acc: 66.84%\n",
      "              Val Loss: 0.8316105008125305, Val Acc: 61.73%\n",
      "Epoch: 2545,     Training Loss: 0.5188132524490356, Training Acc: 66.84%\n",
      "              Val Loss: 0.7859588861465454, Val Acc: 61.74%\n",
      "Epoch: 2546,     Training Loss: 0.46277156472206116, Training Acc: 66.85%\n",
      "              Val Loss: 0.7793921828269958, Val Acc: 61.74%\n",
      "Epoch: 2547,     Training Loss: 0.45229610800743103, Training Acc: 66.86%\n",
      "              Val Loss: 0.8074089288711548, Val Acc: 61.75%\n",
      "Epoch: 2548,     Training Loss: 0.48209792375564575, Training Acc: 66.86%\n",
      "              Val Loss: 0.8339794874191284, Val Acc: 61.75%\n",
      "Epoch: 2549,     Training Loss: 0.49738609790802, Training Acc: 66.87%\n",
      "              Val Loss: 0.853624701499939, Val Acc: 61.75%\n",
      "Epoch: 2550,     Training Loss: 0.5321202278137207, Training Acc: 66.87%\n",
      "              Val Loss: 0.80158531665802, Val Acc: 61.76%\n",
      "Epoch: 2551,     Training Loss: 0.47444477677345276, Training Acc: 66.87%\n",
      "              Val Loss: 0.7662418484687805, Val Acc: 61.76%\n",
      "Epoch: 2552,     Training Loss: 0.4502345323562622, Training Acc: 66.88%\n",
      "              Val Loss: 0.7755151987075806, Val Acc: 61.77%\n",
      "Epoch: 2553,     Training Loss: 0.4562651813030243, Training Acc: 66.89%\n",
      "              Val Loss: 0.8107075691223145, Val Acc: 61.77%\n",
      "Epoch: 2554,     Training Loss: 0.4736920893192291, Training Acc: 66.89%\n",
      "              Val Loss: 0.835442304611206, Val Acc: 61.78%\n",
      "Epoch: 2555,     Training Loss: 0.5060348510742188, Training Acc: 66.90%\n",
      "              Val Loss: 0.8124125599861145, Val Acc: 61.78%\n",
      "Epoch: 2556,     Training Loss: 0.47638797760009766, Training Acc: 66.90%\n",
      "              Val Loss: 0.7931025624275208, Val Acc: 61.78%\n",
      "Epoch: 2557,     Training Loss: 0.46391499042510986, Training Acc: 66.91%\n",
      "              Val Loss: 0.7824392914772034, Val Acc: 61.79%\n",
      "Epoch: 2558,     Training Loss: 0.4473733901977539, Training Acc: 66.91%\n",
      "              Val Loss: 0.7834905982017517, Val Acc: 61.79%\n",
      "Epoch: 2559,     Training Loss: 0.44606781005859375, Training Acc: 66.92%\n",
      "              Val Loss: 0.78571617603302, Val Acc: 61.80%\n",
      "Epoch: 2560,     Training Loss: 0.45307695865631104, Training Acc: 66.92%\n",
      "              Val Loss: 0.7996249198913574, Val Acc: 61.80%\n",
      "Epoch: 2561,     Training Loss: 0.46413493156433105, Training Acc: 66.93%\n",
      "              Val Loss: 0.8144462704658508, Val Acc: 61.81%\n",
      "Epoch: 2562,     Training Loss: 0.48641520738601685, Training Acc: 66.93%\n",
      "              Val Loss: 0.802089512348175, Val Acc: 61.81%\n",
      "Epoch: 2563,     Training Loss: 0.47213324904441833, Training Acc: 66.94%\n",
      "              Val Loss: 0.8038618564605713, Val Acc: 61.82%\n",
      "Epoch: 2564,     Training Loss: 0.4770340323448181, Training Acc: 66.95%\n",
      "              Val Loss: 0.7889012694358826, Val Acc: 61.82%\n",
      "Epoch: 2565,     Training Loss: 0.45811736583709717, Training Acc: 66.95%\n",
      "              Val Loss: 0.784839391708374, Val Acc: 61.82%\n",
      "Epoch: 2566,     Training Loss: 0.4537414610385895, Training Acc: 66.96%\n",
      "              Val Loss: 0.7769646644592285, Val Acc: 61.83%\n",
      "Epoch: 2567,     Training Loss: 0.4442870318889618, Training Acc: 66.96%\n",
      "              Val Loss: 0.7745815515518188, Val Acc: 61.83%\n",
      "Epoch: 2568,     Training Loss: 0.4418331980705261, Training Acc: 66.97%\n",
      "              Val Loss: 0.7786849737167358, Val Acc: 61.84%\n",
      "Epoch: 2569,     Training Loss: 0.4435579776763916, Training Acc: 66.97%\n",
      "              Val Loss: 0.7839218974113464, Val Acc: 61.84%\n",
      "Epoch: 2570,     Training Loss: 0.44760552048683167, Training Acc: 66.98%\n",
      "              Val Loss: 0.7977168560028076, Val Acc: 61.85%\n",
      "Epoch: 2571,     Training Loss: 0.46516719460487366, Training Acc: 66.99%\n",
      "              Val Loss: 0.8280291557312012, Val Acc: 61.85%\n",
      "Epoch: 2572,     Training Loss: 0.48523110151290894, Training Acc: 66.99%\n",
      "              Val Loss: 0.9180715084075928, Val Acc: 61.85%\n",
      "Epoch: 2573,     Training Loss: 0.5798418521881104, Training Acc: 66.99%\n",
      "              Val Loss: 0.8634905815124512, Val Acc: 61.86%\n",
      "Epoch: 2574,     Training Loss: 0.5262871980667114, Training Acc: 67.00%\n",
      "              Val Loss: 0.8472592830657959, Val Acc: 61.86%\n",
      "Epoch: 2575,     Training Loss: 0.5163928866386414, Training Acc: 67.00%\n",
      "              Val Loss: 0.7836230993270874, Val Acc: 61.86%\n",
      "Epoch: 2576,     Training Loss: 0.45369377732276917, Training Acc: 67.01%\n",
      "              Val Loss: 0.8015533685684204, Val Acc: 61.87%\n",
      "Epoch: 2577,     Training Loss: 0.46427416801452637, Training Acc: 67.01%\n",
      "              Val Loss: 0.8595804572105408, Val Acc: 61.87%\n",
      "Epoch: 2578,     Training Loss: 0.5215749144554138, Training Acc: 67.02%\n",
      "              Val Loss: 0.8353683352470398, Val Acc: 61.87%\n",
      "Epoch: 2579,     Training Loss: 0.493642657995224, Training Acc: 67.02%\n",
      "              Val Loss: 0.8025425672531128, Val Acc: 61.88%\n",
      "Epoch: 2580,     Training Loss: 0.4764099419116974, Training Acc: 67.03%\n",
      "              Val Loss: 0.7713988423347473, Val Acc: 61.88%\n",
      "Epoch: 2581,     Training Loss: 0.4441653788089752, Training Acc: 67.03%\n",
      "              Val Loss: 0.7917775511741638, Val Acc: 61.89%\n",
      "Epoch: 2582,     Training Loss: 0.45708367228507996, Training Acc: 67.04%\n",
      "              Val Loss: 0.838474452495575, Val Acc: 61.89%\n",
      "Epoch: 2583,     Training Loss: 0.5068251490592957, Training Acc: 67.04%\n",
      "              Val Loss: 0.8292697072029114, Val Acc: 61.90%\n",
      "Epoch: 2584,     Training Loss: 0.48752447962760925, Training Acc: 67.05%\n",
      "              Val Loss: 0.8190602660179138, Val Acc: 61.90%\n",
      "Epoch: 2585,     Training Loss: 0.4859819710254669, Training Acc: 67.05%\n",
      "              Val Loss: 0.7819680571556091, Val Acc: 61.90%\n",
      "Epoch: 2586,     Training Loss: 0.44610118865966797, Training Acc: 67.06%\n",
      "              Val Loss: 0.786553144454956, Val Acc: 61.91%\n",
      "Epoch: 2587,     Training Loss: 0.4486984610557556, Training Acc: 67.06%\n",
      "              Val Loss: 0.8220854997634888, Val Acc: 61.91%\n",
      "Epoch: 2588,     Training Loss: 0.48238319158554077, Training Acc: 67.07%\n",
      "              Val Loss: 0.8207366466522217, Val Acc: 61.92%\n",
      "Epoch: 2589,     Training Loss: 0.47468987107276917, Training Acc: 67.07%\n",
      "              Val Loss: 0.8010602593421936, Val Acc: 61.92%\n",
      "Epoch: 2590,     Training Loss: 0.4714618921279907, Training Acc: 67.08%\n",
      "              Val Loss: 0.7738569378852844, Val Acc: 61.93%\n",
      "Epoch: 2591,     Training Loss: 0.4442788064479828, Training Acc: 67.08%\n",
      "              Val Loss: 0.7779865264892578, Val Acc: 61.93%\n",
      "Epoch: 2592,     Training Loss: 0.4430862069129944, Training Acc: 67.09%\n",
      "              Val Loss: 0.7923892736434937, Val Acc: 61.94%\n",
      "Epoch: 2593,     Training Loss: 0.4583536386489868, Training Acc: 67.09%\n",
      "              Val Loss: 0.8085395693778992, Val Acc: 61.94%\n",
      "Epoch: 2594,     Training Loss: 0.4698558449745178, Training Acc: 67.10%\n",
      "              Val Loss: 0.8528208136558533, Val Acc: 61.94%\n",
      "Epoch: 2595,     Training Loss: 0.5129585266113281, Training Acc: 67.10%\n",
      "              Val Loss: 0.8222413063049316, Val Acc: 61.95%\n",
      "Epoch: 2596,     Training Loss: 0.4791644215583801, Training Acc: 67.11%\n",
      "              Val Loss: 0.80008864402771, Val Acc: 61.95%\n",
      "Epoch: 2597,     Training Loss: 0.4658665359020233, Training Acc: 67.11%\n",
      "              Val Loss: 0.7800503373146057, Val Acc: 61.96%\n",
      "Epoch: 2598,     Training Loss: 0.44015368819236755, Training Acc: 67.12%\n",
      "              Val Loss: 0.7994080185890198, Val Acc: 61.96%\n",
      "Epoch: 2599,     Training Loss: 0.4486696124076843, Training Acc: 67.13%\n",
      "              Val Loss: 0.815629780292511, Val Acc: 61.96%\n",
      "Epoch: 2600,     Training Loss: 0.475432813167572, Training Acc: 67.13%\n",
      "              Val Loss: 0.8231332302093506, Val Acc: 61.97%\n",
      "Epoch: 2601,     Training Loss: 0.48149874806404114, Training Acc: 67.14%\n",
      "              Val Loss: 0.8681585192680359, Val Acc: 61.97%\n",
      "Epoch: 2602,     Training Loss: 0.5239838361740112, Training Acc: 67.14%\n",
      "              Val Loss: 0.8099529147148132, Val Acc: 61.98%\n",
      "Epoch: 2603,     Training Loss: 0.46878933906555176, Training Acc: 67.14%\n",
      "              Val Loss: 0.782626748085022, Val Acc: 61.98%\n",
      "Epoch: 2604,     Training Loss: 0.45526400208473206, Training Acc: 67.15%\n",
      "              Val Loss: 0.7874502539634705, Val Acc: 61.99%\n",
      "Epoch: 2605,     Training Loss: 0.4468744993209839, Training Acc: 67.16%\n",
      "              Val Loss: 0.8373562097549438, Val Acc: 61.99%\n",
      "Epoch: 2606,     Training Loss: 0.47944405674934387, Training Acc: 67.16%\n",
      "              Val Loss: 0.8545626997947693, Val Acc: 61.99%\n",
      "Epoch: 2607,     Training Loss: 0.5222947597503662, Training Acc: 67.16%\n",
      "              Val Loss: 0.8196019530296326, Val Acc: 62.00%\n",
      "Epoch: 2608,     Training Loss: 0.48421528935432434, Training Acc: 67.17%\n",
      "              Val Loss: 0.8325061798095703, Val Acc: 62.00%\n",
      "Epoch: 2609,     Training Loss: 0.4838138520717621, Training Acc: 67.17%\n",
      "              Val Loss: 0.7917504906654358, Val Acc: 62.00%\n",
      "Epoch: 2610,     Training Loss: 0.4422915279865265, Training Acc: 67.18%\n",
      "              Val Loss: 0.836397647857666, Val Acc: 62.01%\n",
      "Epoch: 2611,     Training Loss: 0.48629623651504517, Training Acc: 67.18%\n",
      "              Val Loss: 0.903685986995697, Val Acc: 62.01%\n",
      "Epoch: 2612,     Training Loss: 0.5502052903175354, Training Acc: 67.19%\n",
      "              Val Loss: 0.921874463558197, Val Acc: 62.01%\n",
      "Epoch: 2613,     Training Loss: 0.5551419258117676, Training Acc: 67.19%\n",
      "              Val Loss: 0.9309372901916504, Val Acc: 62.01%\n",
      "Epoch: 2614,     Training Loss: 0.6104390025138855, Training Acc: 67.19%\n",
      "              Val Loss: 0.8108004927635193, Val Acc: 62.02%\n",
      "Epoch: 2615,     Training Loss: 0.4931977093219757, Training Acc: 67.20%\n",
      "              Val Loss: 0.9229008555412292, Val Acc: 62.02%\n",
      "Epoch: 2616,     Training Loss: 0.5597726702690125, Training Acc: 67.20%\n",
      "              Val Loss: 1.0215164422988892, Val Acc: 62.02%\n",
      "Epoch: 2617,     Training Loss: 0.6681422591209412, Training Acc: 67.20%\n",
      "              Val Loss: 0.912021815776825, Val Acc: 62.02%\n",
      "Epoch: 2618,     Training Loss: 0.563372790813446, Training Acc: 67.21%\n",
      "              Val Loss: 0.7914524674415588, Val Acc: 62.03%\n",
      "Epoch: 2619,     Training Loss: 0.45440128445625305, Training Acc: 67.21%\n",
      "              Val Loss: 0.839545726776123, Val Acc: 62.03%\n",
      "Epoch: 2620,     Training Loss: 0.4980703592300415, Training Acc: 67.22%\n",
      "              Val Loss: 0.8185737133026123, Val Acc: 62.04%\n",
      "Epoch: 2621,     Training Loss: 0.48450976610183716, Training Acc: 67.22%\n",
      "              Val Loss: 0.817629337310791, Val Acc: 62.04%\n",
      "Epoch: 2622,     Training Loss: 0.4901464581489563, Training Acc: 67.22%\n",
      "              Val Loss: 0.8027776479721069, Val Acc: 62.04%\n",
      "Epoch: 2623,     Training Loss: 0.45059746503829956, Training Acc: 67.23%\n",
      "              Val Loss: 0.8160679340362549, Val Acc: 62.05%\n",
      "Epoch: 2624,     Training Loss: 0.4574671685695648, Training Acc: 67.24%\n",
      "              Val Loss: 0.8105477094650269, Val Acc: 62.05%\n",
      "Epoch: 2625,     Training Loss: 0.4805181920528412, Training Acc: 67.24%\n",
      "              Val Loss: 0.8323735594749451, Val Acc: 62.05%\n",
      "Epoch: 2626,     Training Loss: 0.4947361350059509, Training Acc: 67.24%\n",
      "              Val Loss: 0.8588870167732239, Val Acc: 62.06%\n",
      "Epoch: 2627,     Training Loss: 0.516585111618042, Training Acc: 67.25%\n",
      "              Val Loss: 0.8341941237449646, Val Acc: 62.06%\n",
      "Epoch: 2628,     Training Loss: 0.4782199561595917, Training Acc: 67.25%\n",
      "              Val Loss: 0.7934507727622986, Val Acc: 62.07%\n",
      "Epoch: 2629,     Training Loss: 0.4544239342212677, Training Acc: 67.26%\n",
      "              Val Loss: 0.8071951270103455, Val Acc: 62.07%\n",
      "Epoch: 2630,     Training Loss: 0.46736085414886475, Training Acc: 67.26%\n",
      "              Val Loss: 0.8471730947494507, Val Acc: 62.07%\n",
      "Epoch: 2631,     Training Loss: 0.4896375238895416, Training Acc: 67.27%\n",
      "              Val Loss: 0.8710100054740906, Val Acc: 62.08%\n",
      "Epoch: 2632,     Training Loss: 0.5390857458114624, Training Acc: 67.27%\n",
      "              Val Loss: 0.8240394592285156, Val Acc: 62.08%\n",
      "Epoch: 2633,     Training Loss: 0.49344879388809204, Training Acc: 67.28%\n",
      "              Val Loss: 0.7871390581130981, Val Acc: 62.08%\n",
      "Epoch: 2634,     Training Loss: 0.45544737577438354, Training Acc: 67.28%\n",
      "              Val Loss: 0.7988540530204773, Val Acc: 62.09%\n",
      "Epoch: 2635,     Training Loss: 0.4432433843612671, Training Acc: 67.29%\n",
      "              Val Loss: 0.8272905945777893, Val Acc: 62.09%\n",
      "Epoch: 2636,     Training Loss: 0.45955994725227356, Training Acc: 67.29%\n",
      "              Val Loss: 0.8224560022354126, Val Acc: 62.10%\n",
      "Epoch: 2637,     Training Loss: 0.48054972290992737, Training Acc: 67.30%\n",
      "              Val Loss: 0.8193923234939575, Val Acc: 62.10%\n",
      "Epoch: 2638,     Training Loss: 0.47167834639549255, Training Acc: 67.30%\n",
      "              Val Loss: 0.8065932989120483, Val Acc: 62.10%\n",
      "Epoch: 2639,     Training Loss: 0.4577683210372925, Training Acc: 67.31%\n",
      "              Val Loss: 0.8043453097343445, Val Acc: 62.11%\n",
      "Epoch: 2640,     Training Loss: 0.447134405374527, Training Acc: 67.31%\n",
      "              Val Loss: 0.8005163073539734, Val Acc: 62.11%\n",
      "Epoch: 2641,     Training Loss: 0.4432426691055298, Training Acc: 67.32%\n",
      "              Val Loss: 0.8143856525421143, Val Acc: 62.12%\n",
      "Epoch: 2642,     Training Loss: 0.45745179057121277, Training Acc: 67.32%\n",
      "              Val Loss: 0.8578999042510986, Val Acc: 62.12%\n",
      "Epoch: 2643,     Training Loss: 0.4913412034511566, Training Acc: 67.33%\n",
      "              Val Loss: 0.9086725115776062, Val Acc: 62.12%\n",
      "Epoch: 2644,     Training Loss: 0.5715095400810242, Training Acc: 67.33%\n",
      "              Val Loss: 0.8443394303321838, Val Acc: 62.13%\n",
      "Epoch: 2645,     Training Loss: 0.5037471652030945, Training Acc: 67.34%\n",
      "              Val Loss: 0.8151182532310486, Val Acc: 62.13%\n",
      "Epoch: 2646,     Training Loss: 0.46877095103263855, Training Acc: 67.34%\n",
      "              Val Loss: 0.8008735179901123, Val Acc: 62.13%\n",
      "Epoch: 2647,     Training Loss: 0.4446648061275482, Training Acc: 67.35%\n",
      "              Val Loss: 0.8289096355438232, Val Acc: 62.14%\n",
      "Epoch: 2648,     Training Loss: 0.4652728736400604, Training Acc: 67.35%\n",
      "              Val Loss: 0.8784991502761841, Val Acc: 62.14%\n",
      "Epoch: 2649,     Training Loss: 0.5240659117698669, Training Acc: 67.35%\n",
      "              Val Loss: 0.8568212389945984, Val Acc: 62.14%\n",
      "Epoch: 2650,     Training Loss: 0.4952220022678375, Training Acc: 67.36%\n",
      "              Val Loss: 0.8162077069282532, Val Acc: 62.15%\n",
      "Epoch: 2651,     Training Loss: 0.4830625057220459, Training Acc: 67.36%\n",
      "              Val Loss: 0.778494119644165, Val Acc: 62.15%\n",
      "Epoch: 2652,     Training Loss: 0.4411546587944031, Training Acc: 67.37%\n",
      "              Val Loss: 0.8199741244316101, Val Acc: 62.16%\n",
      "Epoch: 2653,     Training Loss: 0.4596625864505768, Training Acc: 67.37%\n",
      "              Val Loss: 0.9107499718666077, Val Acc: 62.16%\n",
      "Epoch: 2654,     Training Loss: 0.5460699200630188, Training Acc: 67.38%\n",
      "              Val Loss: 0.8777173757553101, Val Acc: 62.16%\n",
      "Epoch: 2655,     Training Loss: 0.5033198595046997, Training Acc: 67.38%\n",
      "              Val Loss: 0.8670600056648254, Val Acc: 62.17%\n",
      "Epoch: 2656,     Training Loss: 0.510001540184021, Training Acc: 67.39%\n",
      "              Val Loss: 0.7927910685539246, Val Acc: 62.17%\n",
      "Epoch: 2657,     Training Loss: 0.447950541973114, Training Acc: 67.39%\n",
      "              Val Loss: 0.8179723620414734, Val Acc: 62.17%\n",
      "Epoch: 2658,     Training Loss: 0.457540899515152, Training Acc: 67.40%\n",
      "              Val Loss: 0.8843865394592285, Val Acc: 62.18%\n",
      "Epoch: 2659,     Training Loss: 0.5280875563621521, Training Acc: 67.40%\n",
      "              Val Loss: 0.8446822166442871, Val Acc: 62.18%\n",
      "Epoch: 2660,     Training Loss: 0.47750580310821533, Training Acc: 67.40%\n",
      "              Val Loss: 0.7972835302352905, Val Acc: 62.18%\n",
      "Epoch: 2661,     Training Loss: 0.4471474587917328, Training Acc: 67.41%\n",
      "              Val Loss: 0.7966744899749756, Val Acc: 62.19%\n",
      "Epoch: 2662,     Training Loss: 0.44782784581184387, Training Acc: 67.42%\n",
      "              Val Loss: 0.8140895962715149, Val Acc: 62.19%\n",
      "Epoch: 2663,     Training Loss: 0.46598830819129944, Training Acc: 67.42%\n",
      "              Val Loss: 0.8455073833465576, Val Acc: 62.20%\n",
      "Epoch: 2664,     Training Loss: 0.4959498345851898, Training Acc: 67.42%\n",
      "              Val Loss: 0.8139150142669678, Val Acc: 62.20%\n",
      "Epoch: 2665,     Training Loss: 0.45121312141418457, Training Acc: 67.43%\n",
      "              Val Loss: 0.7898499369621277, Val Acc: 62.20%\n",
      "Epoch: 2666,     Training Loss: 0.4328330159187317, Training Acc: 67.44%\n",
      "              Val Loss: 0.7942103743553162, Val Acc: 62.21%\n",
      "Epoch: 2667,     Training Loss: 0.43721339106559753, Training Acc: 67.44%\n",
      "              Val Loss: 0.8120436072349548, Val Acc: 62.21%\n",
      "Epoch: 2668,     Training Loss: 0.4445607662200928, Training Acc: 67.45%\n",
      "              Val Loss: 0.8245072960853577, Val Acc: 62.22%\n",
      "Epoch: 2669,     Training Loss: 0.466007262468338, Training Acc: 67.45%\n",
      "              Val Loss: 0.8291816115379333, Val Acc: 62.22%\n",
      "Epoch: 2670,     Training Loss: 0.46429482102394104, Training Acc: 67.46%\n",
      "              Val Loss: 0.8339723348617554, Val Acc: 62.23%\n",
      "Epoch: 2671,     Training Loss: 0.48163437843322754, Training Acc: 67.46%\n",
      "              Val Loss: 0.8113240599632263, Val Acc: 62.23%\n",
      "Epoch: 2672,     Training Loss: 0.4519933760166168, Training Acc: 67.47%\n",
      "              Val Loss: 0.7896725535392761, Val Acc: 62.23%\n",
      "Epoch: 2673,     Training Loss: 0.43513843417167664, Training Acc: 67.47%\n",
      "              Val Loss: 0.7887852191925049, Val Acc: 62.24%\n",
      "Epoch: 2674,     Training Loss: 0.4313099980354309, Training Acc: 67.48%\n",
      "              Val Loss: 0.8024948835372925, Val Acc: 62.24%\n",
      "Epoch: 2675,     Training Loss: 0.4394479990005493, Training Acc: 67.48%\n",
      "              Val Loss: 0.8233667016029358, Val Acc: 62.25%\n",
      "Epoch: 2676,     Training Loss: 0.46697962284088135, Training Acc: 67.49%\n",
      "              Val Loss: 0.8452587127685547, Val Acc: 62.25%\n",
      "Epoch: 2677,     Training Loss: 0.48016712069511414, Training Acc: 67.49%\n",
      "              Val Loss: 0.8800237774848938, Val Acc: 62.25%\n",
      "Epoch: 2678,     Training Loss: 0.5333161354064941, Training Acc: 67.50%\n",
      "              Val Loss: 0.8310326933860779, Val Acc: 62.25%\n",
      "Epoch: 2679,     Training Loss: 0.47189465165138245, Training Acc: 67.50%\n",
      "              Val Loss: 0.8019010424613953, Val Acc: 62.26%\n",
      "Epoch: 2680,     Training Loss: 0.44054508209228516, Training Acc: 67.51%\n",
      "              Val Loss: 0.7988362312316895, Val Acc: 62.26%\n",
      "Epoch: 2681,     Training Loss: 0.43169134855270386, Training Acc: 67.51%\n",
      "              Val Loss: 0.8322286009788513, Val Acc: 62.27%\n",
      "Epoch: 2682,     Training Loss: 0.46060219407081604, Training Acc: 67.52%\n",
      "              Val Loss: 0.8888364434242249, Val Acc: 62.27%\n",
      "Epoch: 2683,     Training Loss: 0.5250844359397888, Training Acc: 67.52%\n",
      "              Val Loss: 0.8693697452545166, Val Acc: 62.27%\n",
      "Epoch: 2684,     Training Loss: 0.5041738748550415, Training Acc: 67.52%\n",
      "              Val Loss: 0.8337778449058533, Val Acc: 62.28%\n",
      "Epoch: 2685,     Training Loss: 0.49467000365257263, Training Acc: 67.53%\n",
      "              Val Loss: 0.7849367260932922, Val Acc: 62.28%\n",
      "Epoch: 2686,     Training Loss: 0.4373363256454468, Training Acc: 67.53%\n",
      "              Val Loss: 0.8428429365158081, Val Acc: 62.28%\n",
      "Epoch: 2687,     Training Loss: 0.4719911813735962, Training Acc: 67.54%\n",
      "              Val Loss: 0.8875348567962646, Val Acc: 62.29%\n",
      "Epoch: 2688,     Training Loss: 0.5290530920028687, Training Acc: 67.54%\n",
      "              Val Loss: 0.8427023887634277, Val Acc: 62.29%\n",
      "Epoch: 2689,     Training Loss: 0.48365646600723267, Training Acc: 67.55%\n",
      "              Val Loss: 0.8237157464027405, Val Acc: 62.29%\n",
      "Epoch: 2690,     Training Loss: 0.4606519937515259, Training Acc: 67.55%\n",
      "              Val Loss: 0.7991475462913513, Val Acc: 62.30%\n",
      "Epoch: 2691,     Training Loss: 0.44078072905540466, Training Acc: 67.56%\n",
      "              Val Loss: 0.8345568180084229, Val Acc: 62.30%\n",
      "Epoch: 2692,     Training Loss: 0.4755017161369324, Training Acc: 67.56%\n",
      "              Val Loss: 0.8896708488464355, Val Acc: 62.31%\n",
      "Epoch: 2693,     Training Loss: 0.5255594849586487, Training Acc: 67.56%\n",
      "              Val Loss: 0.896880030632019, Val Acc: 62.31%\n",
      "Epoch: 2694,     Training Loss: 0.5075485706329346, Training Acc: 67.57%\n",
      "              Val Loss: 0.8280677795410156, Val Acc: 62.31%\n",
      "Epoch: 2695,     Training Loss: 0.47116076946258545, Training Acc: 67.57%\n",
      "              Val Loss: 0.8093052506446838, Val Acc: 62.32%\n",
      "Epoch: 2696,     Training Loss: 0.44791263341903687, Training Acc: 67.58%\n",
      "              Val Loss: 0.86162930727005, Val Acc: 62.32%\n",
      "Epoch: 2697,     Training Loss: 0.48524391651153564, Training Acc: 67.58%\n",
      "              Val Loss: 0.9284675717353821, Val Acc: 62.32%\n",
      "Epoch: 2698,     Training Loss: 0.5713396668434143, Training Acc: 67.58%\n",
      "              Val Loss: 0.8494454026222229, Val Acc: 62.32%\n",
      "Epoch: 2699,     Training Loss: 0.4920670986175537, Training Acc: 67.59%\n",
      "              Val Loss: 0.8280225992202759, Val Acc: 62.33%\n",
      "Epoch: 2700,     Training Loss: 0.464446485042572, Training Acc: 67.59%\n",
      "              Val Loss: 0.813645601272583, Val Acc: 62.33%\n",
      "Epoch: 2701,     Training Loss: 0.4505375325679779, Training Acc: 67.60%\n",
      "              Val Loss: 0.8289237022399902, Val Acc: 62.34%\n",
      "Epoch: 2702,     Training Loss: 0.46931636333465576, Training Acc: 67.60%\n",
      "              Val Loss: 0.8608855605125427, Val Acc: 62.34%\n",
      "Epoch: 2703,     Training Loss: 0.5000832676887512, Training Acc: 67.61%\n",
      "              Val Loss: 0.8917171359062195, Val Acc: 62.34%\n",
      "Epoch: 2704,     Training Loss: 0.5027140378952026, Training Acc: 67.61%\n",
      "              Val Loss: 0.8539839386940002, Val Acc: 62.34%\n",
      "Epoch: 2705,     Training Loss: 0.5034622550010681, Training Acc: 67.62%\n",
      "              Val Loss: 0.8160111308097839, Val Acc: 62.35%\n",
      "Epoch: 2706,     Training Loss: 0.45550668239593506, Training Acc: 67.62%\n",
      "              Val Loss: 0.8329841494560242, Val Acc: 62.35%\n",
      "Epoch: 2707,     Training Loss: 0.4561273455619812, Training Acc: 67.63%\n",
      "              Val Loss: 0.848680317401886, Val Acc: 62.36%\n",
      "Epoch: 2708,     Training Loss: 0.4774957299232483, Training Acc: 67.63%\n",
      "              Val Loss: 0.8592869639396667, Val Acc: 62.36%\n",
      "Epoch: 2709,     Training Loss: 0.4888386130332947, Training Acc: 67.63%\n",
      "              Val Loss: 0.9072548747062683, Val Acc: 62.36%\n",
      "Epoch: 2710,     Training Loss: 0.5422315001487732, Training Acc: 67.64%\n",
      "              Val Loss: 0.884980320930481, Val Acc: 62.36%\n",
      "Epoch: 2711,     Training Loss: 0.5024318099021912, Training Acc: 67.64%\n",
      "              Val Loss: 0.8197033405303955, Val Acc: 62.37%\n",
      "Epoch: 2712,     Training Loss: 0.4713778793811798, Training Acc: 67.65%\n",
      "              Val Loss: 0.796822190284729, Val Acc: 62.37%\n",
      "Epoch: 2713,     Training Loss: 0.44124361872673035, Training Acc: 67.65%\n",
      "              Val Loss: 0.874274730682373, Val Acc: 62.37%\n",
      "Epoch: 2714,     Training Loss: 0.48659247159957886, Training Acc: 67.66%\n",
      "              Val Loss: 0.9033164381980896, Val Acc: 62.38%\n",
      "Epoch: 2715,     Training Loss: 0.535029411315918, Training Acc: 67.66%\n",
      "              Val Loss: 0.8351216316223145, Val Acc: 62.38%\n",
      "Epoch: 2716,     Training Loss: 0.47303321957588196, Training Acc: 67.66%\n",
      "              Val Loss: 0.8018736839294434, Val Acc: 62.38%\n",
      "Epoch: 2717,     Training Loss: 0.4372529685497284, Training Acc: 67.67%\n",
      "              Val Loss: 0.7986298203468323, Val Acc: 62.39%\n",
      "Epoch: 2718,     Training Loss: 0.43470871448516846, Training Acc: 67.67%\n",
      "              Val Loss: 0.8221784234046936, Val Acc: 62.39%\n",
      "Epoch: 2719,     Training Loss: 0.45408180356025696, Training Acc: 67.68%\n",
      "              Val Loss: 0.8404077291488647, Val Acc: 62.40%\n",
      "Epoch: 2720,     Training Loss: 0.4830903112888336, Training Acc: 67.68%\n",
      "              Val Loss: 0.8498572707176208, Val Acc: 62.40%\n",
      "Epoch: 2721,     Training Loss: 0.4694478511810303, Training Acc: 67.69%\n",
      "              Val Loss: 0.8234603404998779, Val Acc: 62.40%\n",
      "Epoch: 2722,     Training Loss: 0.45522648096084595, Training Acc: 67.69%\n",
      "              Val Loss: 0.7974774241447449, Val Acc: 62.41%\n",
      "Epoch: 2723,     Training Loss: 0.4330012798309326, Training Acc: 67.70%\n",
      "              Val Loss: 0.807689905166626, Val Acc: 62.41%\n",
      "Epoch: 2724,     Training Loss: 0.4308856129646301, Training Acc: 67.70%\n",
      "              Val Loss: 0.8277991414070129, Val Acc: 62.42%\n",
      "Epoch: 2725,     Training Loss: 0.45707592368125916, Training Acc: 67.71%\n",
      "              Val Loss: 0.8400381207466125, Val Acc: 62.42%\n",
      "Epoch: 2726,     Training Loss: 0.46676886081695557, Training Acc: 67.71%\n",
      "              Val Loss: 0.862220287322998, Val Acc: 62.42%\n",
      "Epoch: 2727,     Training Loss: 0.5014579892158508, Training Acc: 67.72%\n",
      "              Val Loss: 0.8304007053375244, Val Acc: 62.43%\n",
      "Epoch: 2728,     Training Loss: 0.46246689558029175, Training Acc: 67.72%\n",
      "              Val Loss: 0.7914019823074341, Val Acc: 62.43%\n",
      "Epoch: 2729,     Training Loss: 0.4299832582473755, Training Acc: 67.73%\n",
      "              Val Loss: 0.8026667833328247, Val Acc: 62.43%\n",
      "Epoch: 2730,     Training Loss: 0.4308070242404938, Training Acc: 67.73%\n",
      "              Val Loss: 0.8360599279403687, Val Acc: 62.44%\n",
      "Epoch: 2731,     Training Loss: 0.4522392153739929, Training Acc: 67.74%\n",
      "              Val Loss: 0.8949551582336426, Val Acc: 62.44%\n",
      "Epoch: 2732,     Training Loss: 0.5212550163269043, Training Acc: 67.74%\n",
      "              Val Loss: 0.8878434896469116, Val Acc: 62.44%\n",
      "Epoch: 2733,     Training Loss: 0.5209403038024902, Training Acc: 67.75%\n",
      "              Val Loss: 0.8835296034812927, Val Acc: 62.45%\n",
      "Epoch: 2734,     Training Loss: 0.5221916437149048, Training Acc: 67.75%\n",
      "              Val Loss: 0.8085734844207764, Val Acc: 62.45%\n",
      "Epoch: 2735,     Training Loss: 0.440740704536438, Training Acc: 67.75%\n",
      "              Val Loss: 0.8375405669212341, Val Acc: 62.45%\n",
      "Epoch: 2736,     Training Loss: 0.4573400616645813, Training Acc: 67.76%\n",
      "              Val Loss: 0.9186031818389893, Val Acc: 62.46%\n",
      "Epoch: 2737,     Training Loss: 0.5384882092475891, Training Acc: 67.76%\n",
      "              Val Loss: 0.8510730266571045, Val Acc: 62.46%\n",
      "Epoch: 2738,     Training Loss: 0.47799938917160034, Training Acc: 67.77%\n",
      "              Val Loss: 0.8019452691078186, Val Acc: 62.46%\n",
      "Epoch: 2739,     Training Loss: 0.43952515721321106, Training Acc: 67.77%\n",
      "              Val Loss: 0.8036452531814575, Val Acc: 62.47%\n",
      "Epoch: 2740,     Training Loss: 0.44612857699394226, Training Acc: 67.78%\n",
      "              Val Loss: 0.8235273957252502, Val Acc: 62.47%\n",
      "Epoch: 2741,     Training Loss: 0.4525972604751587, Training Acc: 67.78%\n",
      "              Val Loss: 0.8656487464904785, Val Acc: 62.47%\n",
      "Epoch: 2742,     Training Loss: 0.5000513195991516, Training Acc: 67.79%\n",
      "              Val Loss: 0.8723174333572388, Val Acc: 62.47%\n",
      "Epoch: 2743,     Training Loss: 0.4831498861312866, Training Acc: 67.79%\n",
      "              Val Loss: 0.8188097476959229, Val Acc: 62.48%\n",
      "Epoch: 2744,     Training Loss: 0.45658570528030396, Training Acc: 67.79%\n",
      "              Val Loss: 0.8057375550270081, Val Acc: 62.48%\n",
      "Epoch: 2745,     Training Loss: 0.43668484687805176, Training Acc: 67.80%\n",
      "              Val Loss: 0.8171016573905945, Val Acc: 62.49%\n",
      "Epoch: 2746,     Training Loss: 0.4418129324913025, Training Acc: 67.80%\n",
      "              Val Loss: 0.8506724834442139, Val Acc: 62.49%\n",
      "Epoch: 2747,     Training Loss: 0.48092326521873474, Training Acc: 67.81%\n",
      "              Val Loss: 0.8396164178848267, Val Acc: 62.49%\n",
      "Epoch: 2748,     Training Loss: 0.4639229476451874, Training Acc: 67.81%\n",
      "              Val Loss: 0.8643444180488586, Val Acc: 62.50%\n",
      "Epoch: 2749,     Training Loss: 0.492051899433136, Training Acc: 67.82%\n",
      "              Val Loss: 0.8460537791252136, Val Acc: 62.50%\n",
      "Epoch: 2750,     Training Loss: 0.4716401696205139, Training Acc: 67.82%\n",
      "              Val Loss: 0.8045461773872375, Val Acc: 62.50%\n",
      "Epoch: 2751,     Training Loss: 0.4480151832103729, Training Acc: 67.83%\n",
      "              Val Loss: 0.804829478263855, Val Acc: 62.51%\n",
      "Epoch: 2752,     Training Loss: 0.4366464912891388, Training Acc: 67.83%\n",
      "              Val Loss: 0.8437167406082153, Val Acc: 62.51%\n",
      "Epoch: 2753,     Training Loss: 0.4564370810985565, Training Acc: 67.84%\n",
      "              Val Loss: 0.8713883757591248, Val Acc: 62.51%\n",
      "Epoch: 2754,     Training Loss: 0.5021580457687378, Training Acc: 67.84%\n",
      "              Val Loss: 0.8572213649749756, Val Acc: 62.52%\n",
      "Epoch: 2755,     Training Loss: 0.4805021286010742, Training Acc: 67.85%\n",
      "              Val Loss: 0.886692225933075, Val Acc: 62.52%\n",
      "Epoch: 2756,     Training Loss: 0.5028113722801208, Training Acc: 67.85%\n",
      "              Val Loss: 0.8490038514137268, Val Acc: 62.52%\n",
      "Epoch: 2757,     Training Loss: 0.4691030979156494, Training Acc: 67.85%\n",
      "              Val Loss: 0.8233351707458496, Val Acc: 62.53%\n",
      "Epoch: 2758,     Training Loss: 0.45648765563964844, Training Acc: 67.86%\n",
      "              Val Loss: 0.8231378197669983, Val Acc: 62.53%\n",
      "Epoch: 2759,     Training Loss: 0.4489913582801819, Training Acc: 67.86%\n",
      "              Val Loss: 0.9078441858291626, Val Acc: 62.53%\n",
      "Epoch: 2760,     Training Loss: 0.5026319026947021, Training Acc: 67.87%\n",
      "              Val Loss: 0.9268477559089661, Val Acc: 62.53%\n",
      "Epoch: 2761,     Training Loss: 0.5603300333023071, Training Acc: 67.87%\n",
      "              Val Loss: 0.865285336971283, Val Acc: 62.54%\n",
      "Epoch: 2762,     Training Loss: 0.50221848487854, Training Acc: 67.87%\n",
      "              Val Loss: 0.8540565967559814, Val Acc: 62.54%\n",
      "Epoch: 2763,     Training Loss: 0.47319361567497253, Training Acc: 67.88%\n",
      "              Val Loss: 0.833244800567627, Val Acc: 62.54%\n",
      "Epoch: 2764,     Training Loss: 0.45207253098487854, Training Acc: 67.88%\n",
      "              Val Loss: 0.8903009295463562, Val Acc: 62.55%\n",
      "Epoch: 2765,     Training Loss: 0.5019294023513794, Training Acc: 67.89%\n",
      "              Val Loss: 0.9496400952339172, Val Acc: 62.55%\n",
      "Epoch: 2766,     Training Loss: 0.5758876800537109, Training Acc: 67.89%\n",
      "              Val Loss: 0.9506337642669678, Val Acc: 62.55%\n",
      "Epoch: 2767,     Training Loss: 0.5486345887184143, Training Acc: 67.89%\n",
      "              Val Loss: 0.8545864224433899, Val Acc: 62.55%\n",
      "Epoch: 2768,     Training Loss: 0.5003017783164978, Training Acc: 67.90%\n",
      "              Val Loss: 0.8157585263252258, Val Acc: 62.56%\n",
      "Epoch: 2769,     Training Loss: 0.45494747161865234, Training Acc: 67.90%\n",
      "              Val Loss: 0.9175270795822144, Val Acc: 62.56%\n",
      "Epoch: 2770,     Training Loss: 0.5147702097892761, Training Acc: 67.90%\n",
      "              Val Loss: 0.9937875866889954, Val Acc: 62.56%\n",
      "Epoch: 2771,     Training Loss: 0.6115419864654541, Training Acc: 67.91%\n",
      "              Val Loss: 0.8357557058334351, Val Acc: 62.57%\n",
      "Epoch: 2772,     Training Loss: 0.46695923805236816, Training Acc: 67.91%\n",
      "              Val Loss: 0.8163052201271057, Val Acc: 62.57%\n",
      "Epoch: 2773,     Training Loss: 0.4453447461128235, Training Acc: 67.91%\n",
      "              Val Loss: 0.8628164529800415, Val Acc: 62.57%\n",
      "Epoch: 2774,     Training Loss: 0.5006864666938782, Training Acc: 67.92%\n",
      "              Val Loss: 0.8620858192443848, Val Acc: 62.57%\n",
      "Epoch: 2775,     Training Loss: 0.4871034324169159, Training Acc: 67.92%\n",
      "              Val Loss: 0.8106651306152344, Val Acc: 62.58%\n",
      "Epoch: 2776,     Training Loss: 0.4423781931400299, Training Acc: 67.93%\n",
      "              Val Loss: 0.8265078663825989, Val Acc: 62.58%\n",
      "Epoch: 2777,     Training Loss: 0.44115641713142395, Training Acc: 67.93%\n",
      "              Val Loss: 0.8588847517967224, Val Acc: 62.58%\n",
      "Epoch: 2778,     Training Loss: 0.4645271301269531, Training Acc: 67.94%\n",
      "              Val Loss: 0.8533474802970886, Val Acc: 62.59%\n",
      "Epoch: 2779,     Training Loss: 0.4787324070930481, Training Acc: 67.94%\n",
      "              Val Loss: 0.8228699564933777, Val Acc: 62.59%\n",
      "Epoch: 2780,     Training Loss: 0.45060864090919495, Training Acc: 67.95%\n",
      "              Val Loss: 0.8007781505584717, Val Acc: 62.60%\n",
      "Epoch: 2781,     Training Loss: 0.42823609709739685, Training Acc: 67.95%\n",
      "              Val Loss: 0.8212993144989014, Val Acc: 62.60%\n",
      "Epoch: 2782,     Training Loss: 0.43883809447288513, Training Acc: 67.96%\n",
      "              Val Loss: 0.8346009254455566, Val Acc: 62.60%\n",
      "Epoch: 2783,     Training Loss: 0.44587552547454834, Training Acc: 67.96%\n",
      "              Val Loss: 0.8856659531593323, Val Acc: 62.61%\n",
      "Epoch: 2784,     Training Loss: 0.5024689435958862, Training Acc: 67.97%\n",
      "              Val Loss: 0.8847508430480957, Val Acc: 62.61%\n",
      "Epoch: 2785,     Training Loss: 0.4973270297050476, Training Acc: 67.97%\n",
      "              Val Loss: 0.9102510213851929, Val Acc: 62.61%\n",
      "Epoch: 2786,     Training Loss: 0.5401417016983032, Training Acc: 67.97%\n",
      "              Val Loss: 0.8192812204360962, Val Acc: 62.61%\n",
      "Epoch: 2787,     Training Loss: 0.44996941089630127, Training Acc: 67.98%\n",
      "              Val Loss: 0.8233705759048462, Val Acc: 62.62%\n",
      "Epoch: 2788,     Training Loss: 0.4413377046585083, Training Acc: 67.98%\n",
      "              Val Loss: 0.8757904767990112, Val Acc: 62.62%\n",
      "Epoch: 2789,     Training Loss: 0.49586188793182373, Training Acc: 67.99%\n",
      "              Val Loss: 0.8572903275489807, Val Acc: 62.62%\n",
      "Epoch: 2790,     Training Loss: 0.4865143895149231, Training Acc: 67.99%\n",
      "              Val Loss: 0.8639973402023315, Val Acc: 62.63%\n",
      "Epoch: 2791,     Training Loss: 0.4924176037311554, Training Acc: 67.99%\n",
      "              Val Loss: 0.8144476413726807, Val Acc: 62.63%\n",
      "Epoch: 2792,     Training Loss: 0.4419412612915039, Training Acc: 68.00%\n",
      "              Val Loss: 0.8034618496894836, Val Acc: 62.63%\n",
      "Epoch: 2793,     Training Loss: 0.4389152526855469, Training Acc: 68.00%\n",
      "              Val Loss: 0.8401511311531067, Val Acc: 62.64%\n",
      "Epoch: 2794,     Training Loss: 0.46543747186660767, Training Acc: 68.01%\n",
      "              Val Loss: 0.8816749453544617, Val Acc: 62.64%\n",
      "Epoch: 2795,     Training Loss: 0.4857741892337799, Training Acc: 68.01%\n",
      "              Val Loss: 0.8630020618438721, Val Acc: 62.64%\n",
      "Epoch: 2796,     Training Loss: 0.4937065541744232, Training Acc: 68.02%\n",
      "              Val Loss: 0.8129242062568665, Val Acc: 62.65%\n",
      "Epoch: 2797,     Training Loss: 0.4392755925655365, Training Acc: 68.02%\n",
      "              Val Loss: 0.8568606376647949, Val Acc: 62.65%\n",
      "Epoch: 2798,     Training Loss: 0.4559198021888733, Training Acc: 68.03%\n",
      "              Val Loss: 0.8929057121276855, Val Acc: 62.65%\n",
      "Epoch: 2799,     Training Loss: 0.5038046836853027, Training Acc: 68.03%\n",
      "              Val Loss: 0.8931558132171631, Val Acc: 62.66%\n",
      "Epoch: 2800,     Training Loss: 0.5023045539855957, Training Acc: 68.03%\n",
      "              Val Loss: 0.9249341487884521, Val Acc: 62.66%\n",
      "Epoch: 2801,     Training Loss: 0.5385482907295227, Training Acc: 68.04%\n",
      "              Val Loss: 0.849112331867218, Val Acc: 62.66%\n",
      "Epoch: 2802,     Training Loss: 0.46345770359039307, Training Acc: 68.04%\n",
      "              Val Loss: 0.823952317237854, Val Acc: 62.66%\n",
      "Epoch: 2803,     Training Loss: 0.4622335135936737, Training Acc: 68.04%\n",
      "              Val Loss: 0.881917417049408, Val Acc: 62.67%\n",
      "Epoch: 2804,     Training Loss: 0.499393105506897, Training Acc: 68.05%\n",
      "              Val Loss: 0.8766323328018188, Val Acc: 62.67%\n",
      "Epoch: 2805,     Training Loss: 0.476003497838974, Training Acc: 68.05%\n",
      "              Val Loss: 0.8330090045928955, Val Acc: 62.67%\n",
      "Epoch: 2806,     Training Loss: 0.4521659016609192, Training Acc: 68.06%\n",
      "              Val Loss: 0.8068599700927734, Val Acc: 62.68%\n",
      "Epoch: 2807,     Training Loss: 0.4326706826686859, Training Acc: 68.06%\n",
      "              Val Loss: 0.8385375738143921, Val Acc: 62.68%\n",
      "Epoch: 2808,     Training Loss: 0.4465503692626953, Training Acc: 68.07%\n",
      "              Val Loss: 0.8645318746566772, Val Acc: 62.69%\n",
      "Epoch: 2809,     Training Loss: 0.4790287911891937, Training Acc: 68.07%\n",
      "              Val Loss: 0.8386917114257812, Val Acc: 62.69%\n",
      "Epoch: 2810,     Training Loss: 0.44970250129699707, Training Acc: 68.08%\n",
      "              Val Loss: 0.8408244848251343, Val Acc: 62.69%\n",
      "Epoch: 2811,     Training Loss: 0.4509690999984741, Training Acc: 68.08%\n",
      "              Val Loss: 0.8171048760414124, Val Acc: 62.70%\n",
      "Epoch: 2812,     Training Loss: 0.4259142279624939, Training Acc: 68.09%\n",
      "              Val Loss: 0.8050279021263123, Val Acc: 62.70%\n",
      "Epoch: 2813,     Training Loss: 0.42935413122177124, Training Acc: 68.09%\n",
      "              Val Loss: 0.8211759328842163, Val Acc: 62.70%\n",
      "Epoch: 2814,     Training Loss: 0.43474820256233215, Training Acc: 68.10%\n",
      "              Val Loss: 0.8385581374168396, Val Acc: 62.71%\n",
      "Epoch: 2815,     Training Loss: 0.439309686422348, Training Acc: 68.10%\n",
      "              Val Loss: 0.8330737352371216, Val Acc: 62.71%\n",
      "Epoch: 2816,     Training Loss: 0.44334954023361206, Training Acc: 68.11%\n",
      "              Val Loss: 0.8142985701560974, Val Acc: 62.71%\n",
      "Epoch: 2817,     Training Loss: 0.4254871606826782, Training Acc: 68.11%\n",
      "              Val Loss: 0.8115710616111755, Val Acc: 62.72%\n",
      "Epoch: 2818,     Training Loss: 0.42394816875457764, Training Acc: 68.12%\n",
      "              Val Loss: 0.7947227358818054, Val Acc: 62.72%\n",
      "Epoch: 2819,     Training Loss: 0.41622990369796753, Training Acc: 68.12%\n",
      "              Val Loss: 0.7958641052246094, Val Acc: 62.73%\n",
      "Epoch: 2820,     Training Loss: 0.42020806670188904, Training Acc: 68.13%\n",
      "              Val Loss: 0.808736264705658, Val Acc: 62.73%\n",
      "Epoch: 2821,     Training Loss: 0.41993850469589233, Training Acc: 68.13%\n",
      "              Val Loss: 0.8382194638252258, Val Acc: 62.73%\n",
      "Epoch: 2822,     Training Loss: 0.4363182485103607, Training Acc: 68.14%\n",
      "              Val Loss: 0.8770676255226135, Val Acc: 62.74%\n",
      "Epoch: 2823,     Training Loss: 0.486319363117218, Training Acc: 68.14%\n",
      "              Val Loss: 0.9109004735946655, Val Acc: 62.74%\n",
      "Epoch: 2824,     Training Loss: 0.5220405459403992, Training Acc: 68.14%\n",
      "              Val Loss: 1.1071879863739014, Val Acc: 62.74%\n",
      "Epoch: 2825,     Training Loss: 0.7266477942466736, Training Acc: 68.14%\n",
      "              Val Loss: 0.8681071400642395, Val Acc: 62.74%\n",
      "Epoch: 2826,     Training Loss: 0.4903436005115509, Training Acc: 68.15%\n",
      "              Val Loss: 0.9231493473052979, Val Acc: 62.74%\n",
      "Epoch: 2827,     Training Loss: 0.5498993396759033, Training Acc: 68.15%\n",
      "              Val Loss: 1.0703034400939941, Val Acc: 62.74%\n",
      "Epoch: 2828,     Training Loss: 0.6904157400131226, Training Acc: 68.15%\n",
      "              Val Loss: 0.8784049153327942, Val Acc: 62.75%\n",
      "Epoch: 2829,     Training Loss: 0.510610818862915, Training Acc: 68.15%\n",
      "              Val Loss: 0.8775172233581543, Val Acc: 62.75%\n",
      "Epoch: 2830,     Training Loss: 0.5378056764602661, Training Acc: 68.16%\n",
      "              Val Loss: 0.9589691162109375, Val Acc: 62.75%\n",
      "Epoch: 2831,     Training Loss: 0.595345139503479, Training Acc: 68.16%\n",
      "              Val Loss: 0.8972522020339966, Val Acc: 62.75%\n",
      "Epoch: 2832,     Training Loss: 0.48432981967926025, Training Acc: 68.16%\n",
      "              Val Loss: 0.9224231243133545, Val Acc: 62.75%\n",
      "Epoch: 2833,     Training Loss: 0.5114994645118713, Training Acc: 68.17%\n",
      "              Val Loss: 0.9963525533676147, Val Acc: 62.76%\n",
      "Epoch: 2834,     Training Loss: 0.6238158345222473, Training Acc: 68.17%\n",
      "              Val Loss: 0.9580830931663513, Val Acc: 62.76%\n",
      "Epoch: 2835,     Training Loss: 0.5549709796905518, Training Acc: 68.17%\n",
      "              Val Loss: 1.2064955234527588, Val Acc: 62.76%\n",
      "Epoch: 2836,     Training Loss: 0.7948136925697327, Training Acc: 68.17%\n",
      "              Val Loss: 1.4159153699874878, Val Acc: 62.75%\n",
      "Epoch: 2837,     Training Loss: 1.0627105236053467, Training Acc: 68.17%\n",
      "              Val Loss: 1.056746006011963, Val Acc: 62.75%\n",
      "Epoch: 2838,     Training Loss: 0.7698385715484619, Training Acc: 68.17%\n",
      "              Val Loss: 1.3360586166381836, Val Acc: 62.75%\n",
      "Epoch: 2839,     Training Loss: 0.9923480749130249, Training Acc: 68.17%\n",
      "              Val Loss: 1.6063364744186401, Val Acc: 62.75%\n",
      "Epoch: 2840,     Training Loss: 1.2734549045562744, Training Acc: 68.16%\n",
      "              Val Loss: 1.3486180305480957, Val Acc: 62.74%\n",
      "Epoch: 2841,     Training Loss: 1.0199412107467651, Training Acc: 68.16%\n",
      "              Val Loss: 1.3981125354766846, Val Acc: 62.74%\n",
      "Epoch: 2842,     Training Loss: 1.0248031616210938, Training Acc: 68.16%\n",
      "              Val Loss: 1.002274513244629, Val Acc: 62.74%\n",
      "Epoch: 2843,     Training Loss: 0.7102148532867432, Training Acc: 68.16%\n",
      "              Val Loss: 1.126314640045166, Val Acc: 62.74%\n",
      "Epoch: 2844,     Training Loss: 0.882611870765686, Training Acc: 68.16%\n",
      "              Val Loss: 1.1077585220336914, Val Acc: 62.74%\n",
      "Epoch: 2845,     Training Loss: 0.8439719676971436, Training Acc: 68.16%\n",
      "              Val Loss: 1.077518105506897, Val Acc: 62.74%\n",
      "Epoch: 2846,     Training Loss: 0.7849705219268799, Training Acc: 68.16%\n",
      "              Val Loss: 0.9677835702896118, Val Acc: 62.74%\n",
      "Epoch: 2847,     Training Loss: 0.7111939191818237, Training Acc: 68.16%\n",
      "              Val Loss: 1.0025835037231445, Val Acc: 62.74%\n",
      "Epoch: 2848,     Training Loss: 0.7783947587013245, Training Acc: 68.16%\n",
      "              Val Loss: 0.9532108306884766, Val Acc: 62.74%\n",
      "Epoch: 2849,     Training Loss: 0.7151443362236023, Training Acc: 68.16%\n",
      "              Val Loss: 0.9160152673721313, Val Acc: 62.74%\n",
      "Epoch: 2850,     Training Loss: 0.6656022667884827, Training Acc: 68.16%\n",
      "              Val Loss: 0.8731807470321655, Val Acc: 62.75%\n",
      "Epoch: 2851,     Training Loss: 0.6256499290466309, Training Acc: 68.16%\n",
      "              Val Loss: 0.8877547383308411, Val Acc: 62.75%\n",
      "Epoch: 2852,     Training Loss: 0.6493189930915833, Training Acc: 68.16%\n",
      "              Val Loss: 0.8614711165428162, Val Acc: 62.75%\n",
      "Epoch: 2853,     Training Loss: 0.6037719249725342, Training Acc: 68.16%\n",
      "              Val Loss: 0.8995213508605957, Val Acc: 62.75%\n",
      "Epoch: 2854,     Training Loss: 0.6329027414321899, Training Acc: 68.17%\n",
      "              Val Loss: 0.8217261433601379, Val Acc: 62.75%\n",
      "Epoch: 2855,     Training Loss: 0.5666952133178711, Training Acc: 68.17%\n",
      "              Val Loss: 0.8525123596191406, Val Acc: 62.76%\n",
      "Epoch: 2856,     Training Loss: 0.6015313267707825, Training Acc: 68.17%\n",
      "              Val Loss: 0.788948655128479, Val Acc: 62.76%\n",
      "Epoch: 2857,     Training Loss: 0.5503545999526978, Training Acc: 68.17%\n",
      "              Val Loss: 0.8186333179473877, Val Acc: 62.76%\n",
      "Epoch: 2858,     Training Loss: 0.5790601372718811, Training Acc: 68.18%\n",
      "              Val Loss: 0.770916759967804, Val Acc: 62.77%\n",
      "Epoch: 2859,     Training Loss: 0.5504324436187744, Training Acc: 68.18%\n",
      "              Val Loss: 0.7794778943061829, Val Acc: 62.77%\n",
      "Epoch: 2860,     Training Loss: 0.5525810122489929, Training Acc: 68.18%\n",
      "              Val Loss: 0.7957952618598938, Val Acc: 62.77%\n",
      "Epoch: 2861,     Training Loss: 0.5423557758331299, Training Acc: 68.18%\n",
      "              Val Loss: 0.7711318135261536, Val Acc: 62.78%\n",
      "Epoch: 2862,     Training Loss: 0.521207332611084, Training Acc: 68.19%\n",
      "              Val Loss: 0.7937350273132324, Val Acc: 62.78%\n",
      "Epoch: 2863,     Training Loss: 0.5328080058097839, Training Acc: 68.19%\n",
      "              Val Loss: 0.7835191488265991, Val Acc: 62.78%\n",
      "Epoch: 2864,     Training Loss: 0.5128664970397949, Training Acc: 68.19%\n",
      "              Val Loss: 0.7852044701576233, Val Acc: 62.79%\n",
      "Epoch: 2865,     Training Loss: 0.5111294388771057, Training Acc: 68.20%\n",
      "              Val Loss: 0.7706153988838196, Val Acc: 62.79%\n",
      "Epoch: 2866,     Training Loss: 0.5078502893447876, Training Acc: 68.20%\n",
      "              Val Loss: 0.7605326175689697, Val Acc: 62.79%\n",
      "Epoch: 2867,     Training Loss: 0.49154892563819885, Training Acc: 68.21%\n",
      "              Val Loss: 0.7675179839134216, Val Acc: 62.80%\n",
      "Epoch: 2868,     Training Loss: 0.49897509813308716, Training Acc: 68.21%\n",
      "              Val Loss: 0.7523571252822876, Val Acc: 62.80%\n",
      "Epoch: 2869,     Training Loss: 0.5077893733978271, Training Acc: 68.21%\n",
      "              Val Loss: 0.7407757043838501, Val Acc: 62.81%\n",
      "Epoch: 2870,     Training Loss: 0.4840521216392517, Training Acc: 68.22%\n",
      "              Val Loss: 0.7492857575416565, Val Acc: 62.81%\n",
      "Epoch: 2871,     Training Loss: 0.4791768789291382, Training Acc: 68.22%\n",
      "              Val Loss: 0.7707493305206299, Val Acc: 62.81%\n",
      "Epoch: 2872,     Training Loss: 0.5018877983093262, Training Acc: 68.22%\n",
      "              Val Loss: 0.7769607305526733, Val Acc: 62.82%\n",
      "Epoch: 2873,     Training Loss: 0.48437175154685974, Training Acc: 68.23%\n",
      "              Val Loss: 0.7523544430732727, Val Acc: 62.82%\n",
      "Epoch: 2874,     Training Loss: 0.4671868085861206, Training Acc: 68.23%\n",
      "              Val Loss: 0.7573027014732361, Val Acc: 62.82%\n",
      "Epoch: 2875,     Training Loss: 0.47570645809173584, Training Acc: 68.24%\n",
      "              Val Loss: 0.7700525522232056, Val Acc: 62.83%\n",
      "Epoch: 2876,     Training Loss: 0.4736998379230499, Training Acc: 68.24%\n",
      "              Val Loss: 0.7622983455657959, Val Acc: 62.83%\n",
      "Epoch: 2877,     Training Loss: 0.4633178412914276, Training Acc: 68.25%\n",
      "              Val Loss: 0.7714447975158691, Val Acc: 62.84%\n",
      "Epoch: 2878,     Training Loss: 0.4603797197341919, Training Acc: 68.25%\n",
      "              Val Loss: 0.7759194374084473, Val Acc: 62.84%\n",
      "Epoch: 2879,     Training Loss: 0.4605492353439331, Training Acc: 68.26%\n",
      "              Val Loss: 0.776600182056427, Val Acc: 62.84%\n",
      "Epoch: 2880,     Training Loss: 0.4667028486728668, Training Acc: 68.26%\n",
      "              Val Loss: 0.7851928472518921, Val Acc: 62.85%\n",
      "Epoch: 2881,     Training Loss: 0.466610312461853, Training Acc: 68.26%\n",
      "              Val Loss: 0.7800726294517517, Val Acc: 62.85%\n",
      "Epoch: 2882,     Training Loss: 0.4593717157840729, Training Acc: 68.27%\n",
      "              Val Loss: 0.7837932109832764, Val Acc: 62.86%\n",
      "Epoch: 2883,     Training Loss: 0.451875239610672, Training Acc: 68.27%\n",
      "              Val Loss: 0.7844998836517334, Val Acc: 62.86%\n",
      "Epoch: 2884,     Training Loss: 0.44943875074386597, Training Acc: 68.28%\n",
      "              Val Loss: 0.7868085503578186, Val Acc: 62.86%\n",
      "Epoch: 2885,     Training Loss: 0.45645812153816223, Training Acc: 68.28%\n",
      "              Val Loss: 0.7909176349639893, Val Acc: 62.87%\n",
      "Epoch: 2886,     Training Loss: 0.4541172385215759, Training Acc: 68.29%\n",
      "              Val Loss: 0.7874628305435181, Val Acc: 62.87%\n",
      "Epoch: 2887,     Training Loss: 0.45248791575431824, Training Acc: 68.29%\n",
      "              Val Loss: 0.7868902087211609, Val Acc: 62.87%\n",
      "Epoch: 2888,     Training Loss: 0.4473514258861542, Training Acc: 68.30%\n",
      "              Val Loss: 0.7737473845481873, Val Acc: 62.88%\n",
      "Epoch: 2889,     Training Loss: 0.4416125416755676, Training Acc: 68.30%\n",
      "              Val Loss: 0.7727320194244385, Val Acc: 62.88%\n",
      "Epoch: 2890,     Training Loss: 0.4416672885417938, Training Acc: 68.31%\n",
      "              Val Loss: 0.7743527889251709, Val Acc: 62.89%\n",
      "Epoch: 2891,     Training Loss: 0.44026893377304077, Training Acc: 68.31%\n",
      "              Val Loss: 0.7789576649665833, Val Acc: 62.89%\n",
      "Epoch: 2892,     Training Loss: 0.44396546483039856, Training Acc: 68.31%\n",
      "              Val Loss: 0.7827633619308472, Val Acc: 62.89%\n",
      "Epoch: 2893,     Training Loss: 0.44198834896087646, Training Acc: 68.32%\n",
      "              Val Loss: 0.7777681946754456, Val Acc: 62.90%\n",
      "Epoch: 2894,     Training Loss: 0.4439748525619507, Training Acc: 68.32%\n",
      "              Val Loss: 0.7910552024841309, Val Acc: 62.90%\n",
      "Epoch: 2895,     Training Loss: 0.4507499635219574, Training Acc: 68.33%\n",
      "              Val Loss: 0.8126227855682373, Val Acc: 62.90%\n",
      "Epoch: 2896,     Training Loss: 0.47736454010009766, Training Acc: 68.33%\n",
      "              Val Loss: 0.8356334567070007, Val Acc: 62.91%\n",
      "Epoch: 2897,     Training Loss: 0.48230358958244324, Training Acc: 68.34%\n",
      "              Val Loss: 0.832297682762146, Val Acc: 62.91%\n",
      "Epoch: 2898,     Training Loss: 0.49680012464523315, Training Acc: 68.34%\n",
      "              Val Loss: 0.7997768521308899, Val Acc: 62.91%\n",
      "Epoch: 2899,     Training Loss: 0.4542083442211151, Training Acc: 68.34%\n",
      "              Val Loss: 0.7861988544464111, Val Acc: 62.92%\n",
      "Epoch: 2900,     Training Loss: 0.43720465898513794, Training Acc: 68.35%\n",
      "              Val Loss: 0.8054986596107483, Val Acc: 62.92%\n",
      "Epoch: 2901,     Training Loss: 0.4579686224460602, Training Acc: 68.35%\n",
      "              Val Loss: 0.8303317427635193, Val Acc: 62.92%\n",
      "Epoch: 2902,     Training Loss: 0.4732709228992462, Training Acc: 68.36%\n",
      "              Val Loss: 0.8330034613609314, Val Acc: 62.93%\n",
      "Epoch: 2903,     Training Loss: 0.4981227219104767, Training Acc: 68.36%\n",
      "              Val Loss: 0.8026680946350098, Val Acc: 62.93%\n",
      "Epoch: 2904,     Training Loss: 0.4609820246696472, Training Acc: 68.37%\n",
      "              Val Loss: 0.7775954604148865, Val Acc: 62.93%\n",
      "Epoch: 2905,     Training Loss: 0.43642494082450867, Training Acc: 68.37%\n",
      "              Val Loss: 0.7857499718666077, Val Acc: 62.94%\n",
      "Epoch: 2906,     Training Loss: 0.43575555086135864, Training Acc: 68.37%\n",
      "              Val Loss: 0.8110886216163635, Val Acc: 62.94%\n",
      "Epoch: 2907,     Training Loss: 0.4502370059490204, Training Acc: 68.38%\n",
      "              Val Loss: 0.819558322429657, Val Acc: 62.94%\n",
      "Epoch: 2908,     Training Loss: 0.47161999344825745, Training Acc: 68.38%\n",
      "              Val Loss: 0.8195157051086426, Val Acc: 62.95%\n",
      "Epoch: 2909,     Training Loss: 0.45953595638275146, Training Acc: 68.39%\n",
      "              Val Loss: 0.8075068593025208, Val Acc: 62.95%\n",
      "Epoch: 2910,     Training Loss: 0.4607008695602417, Training Acc: 68.39%\n",
      "              Val Loss: 0.8028683662414551, Val Acc: 62.95%\n",
      "Epoch: 2911,     Training Loss: 0.4400022029876709, Training Acc: 68.40%\n",
      "              Val Loss: 0.786325991153717, Val Acc: 62.96%\n",
      "Epoch: 2912,     Training Loss: 0.4295767843723297, Training Acc: 68.40%\n",
      "              Val Loss: 0.7879770398139954, Val Acc: 62.96%\n",
      "Epoch: 2913,     Training Loss: 0.4281902611255646, Training Acc: 68.41%\n",
      "              Val Loss: 0.797842800617218, Val Acc: 62.97%\n",
      "Epoch: 2914,     Training Loss: 0.43225613236427307, Training Acc: 68.41%\n",
      "              Val Loss: 0.7991142868995667, Val Acc: 62.97%\n",
      "Epoch: 2915,     Training Loss: 0.4439487159252167, Training Acc: 68.42%\n",
      "              Val Loss: 0.8169199228286743, Val Acc: 62.97%\n",
      "Epoch: 2916,     Training Loss: 0.4523615539073944, Training Acc: 68.42%\n",
      "              Val Loss: 0.8300443291664124, Val Acc: 62.98%\n",
      "Epoch: 2917,     Training Loss: 0.4832560420036316, Training Acc: 68.42%\n",
      "              Val Loss: 0.8430449962615967, Val Acc: 62.98%\n",
      "Epoch: 2918,     Training Loss: 0.47675296664237976, Training Acc: 68.43%\n",
      "              Val Loss: 0.8396807312965393, Val Acc: 62.98%\n",
      "Epoch: 2919,     Training Loss: 0.48640525341033936, Training Acc: 68.43%\n",
      "              Val Loss: 0.8082988262176514, Val Acc: 62.98%\n",
      "Epoch: 2920,     Training Loss: 0.4457409977912903, Training Acc: 68.44%\n",
      "              Val Loss: 0.7895783185958862, Val Acc: 62.99%\n",
      "Epoch: 2921,     Training Loss: 0.42821547389030457, Training Acc: 68.44%\n",
      "              Val Loss: 0.8042228817939758, Val Acc: 62.99%\n",
      "Epoch: 2922,     Training Loss: 0.4448530077934265, Training Acc: 68.45%\n",
      "              Val Loss: 0.8418800234794617, Val Acc: 62.99%\n",
      "Epoch: 2923,     Training Loss: 0.4656188488006592, Training Acc: 68.45%\n",
      "              Val Loss: 0.8621163964271545, Val Acc: 63.00%\n",
      "Epoch: 2924,     Training Loss: 0.5057699680328369, Training Acc: 68.45%\n",
      "              Val Loss: 0.827862024307251, Val Acc: 63.00%\n",
      "Epoch: 2925,     Training Loss: 0.4626655876636505, Training Acc: 68.46%\n",
      "              Val Loss: 0.7878299951553345, Val Acc: 63.00%\n",
      "Epoch: 2926,     Training Loss: 0.4371563196182251, Training Acc: 68.46%\n",
      "              Val Loss: 0.7872243523597717, Val Acc: 63.01%\n",
      "Epoch: 2927,     Training Loss: 0.4268566370010376, Training Acc: 68.47%\n",
      "              Val Loss: 0.8096867203712463, Val Acc: 63.01%\n",
      "Epoch: 2928,     Training Loss: 0.43765953183174133, Training Acc: 68.47%\n",
      "              Val Loss: 0.820244312286377, Val Acc: 63.02%\n",
      "Epoch: 2929,     Training Loss: 0.4614214301109314, Training Acc: 68.48%\n",
      "              Val Loss: 0.8215944766998291, Val Acc: 63.02%\n",
      "Epoch: 2930,     Training Loss: 0.45695480704307556, Training Acc: 68.48%\n",
      "              Val Loss: 0.8121397495269775, Val Acc: 63.02%\n",
      "Epoch: 2931,     Training Loss: 0.46340927481651306, Training Acc: 68.48%\n",
      "              Val Loss: 0.8071658611297607, Val Acc: 63.03%\n",
      "Epoch: 2932,     Training Loss: 0.4395938217639923, Training Acc: 68.49%\n",
      "              Val Loss: 0.7900930643081665, Val Acc: 63.03%\n",
      "Epoch: 2933,     Training Loss: 0.4270278215408325, Training Acc: 68.49%\n",
      "              Val Loss: 0.7913916110992432, Val Acc: 63.03%\n",
      "Epoch: 2934,     Training Loss: 0.4226343631744385, Training Acc: 68.50%\n",
      "              Val Loss: 0.7981740832328796, Val Acc: 63.04%\n",
      "Epoch: 2935,     Training Loss: 0.4261370003223419, Training Acc: 68.50%\n",
      "              Val Loss: 0.8023197650909424, Val Acc: 63.04%\n",
      "Epoch: 2936,     Training Loss: 0.43897637724876404, Training Acc: 68.51%\n",
      "              Val Loss: 0.8184677958488464, Val Acc: 63.04%\n",
      "Epoch: 2937,     Training Loss: 0.4480792284011841, Training Acc: 68.51%\n",
      "              Val Loss: 0.8399112820625305, Val Acc: 63.05%\n",
      "Epoch: 2938,     Training Loss: 0.4842276871204376, Training Acc: 68.52%\n",
      "              Val Loss: 0.8484127521514893, Val Acc: 63.05%\n",
      "Epoch: 2939,     Training Loss: 0.47297269105911255, Training Acc: 68.52%\n",
      "              Val Loss: 0.8589130640029907, Val Acc: 63.05%\n",
      "Epoch: 2940,     Training Loss: 0.49439120292663574, Training Acc: 68.52%\n",
      "              Val Loss: 0.8298546671867371, Val Acc: 63.06%\n",
      "Epoch: 2941,     Training Loss: 0.4538561701774597, Training Acc: 68.53%\n",
      "              Val Loss: 0.7968133687973022, Val Acc: 63.06%\n",
      "Epoch: 2942,     Training Loss: 0.42757466435432434, Training Acc: 68.53%\n",
      "              Val Loss: 0.7968283295631409, Val Acc: 63.06%\n",
      "Epoch: 2943,     Training Loss: 0.4229362905025482, Training Acc: 68.54%\n",
      "              Val Loss: 0.8242775201797485, Val Acc: 63.07%\n",
      "Epoch: 2944,     Training Loss: 0.4409756362438202, Training Acc: 68.54%\n",
      "              Val Loss: 0.8439978957176208, Val Acc: 63.07%\n",
      "Epoch: 2945,     Training Loss: 0.4750553369522095, Training Acc: 68.54%\n",
      "              Val Loss: 0.8450979590415955, Val Acc: 63.07%\n",
      "Epoch: 2946,     Training Loss: 0.4637582302093506, Training Acc: 68.55%\n",
      "              Val Loss: 0.8411791920661926, Val Acc: 63.07%\n",
      "Epoch: 2947,     Training Loss: 0.47742748260498047, Training Acc: 68.55%\n",
      "              Val Loss: 0.8188188672065735, Val Acc: 63.08%\n",
      "Epoch: 2948,     Training Loss: 0.44323495030403137, Training Acc: 68.56%\n",
      "              Val Loss: 0.79430091381073, Val Acc: 63.08%\n",
      "Epoch: 2949,     Training Loss: 0.42386147379875183, Training Acc: 68.56%\n",
      "              Val Loss: 0.8005825281143188, Val Acc: 63.09%\n",
      "Epoch: 2950,     Training Loss: 0.4255065619945526, Training Acc: 68.57%\n",
      "              Val Loss: 0.8326355814933777, Val Acc: 63.09%\n",
      "Epoch: 2951,     Training Loss: 0.44546860456466675, Training Acc: 68.57%\n",
      "              Val Loss: 0.8677420020103455, Val Acc: 63.09%\n",
      "Epoch: 2952,     Training Loss: 0.4964706301689148, Training Acc: 68.57%\n",
      "              Val Loss: 0.8561545610427856, Val Acc: 63.09%\n",
      "Epoch: 2953,     Training Loss: 0.4750823974609375, Training Acc: 68.58%\n",
      "              Val Loss: 0.8428736329078674, Val Acc: 63.10%\n",
      "Epoch: 2954,     Training Loss: 0.47789502143859863, Training Acc: 68.58%\n",
      "              Val Loss: 0.8137735724449158, Val Acc: 63.10%\n",
      "Epoch: 2955,     Training Loss: 0.43775230646133423, Training Acc: 68.59%\n",
      "              Val Loss: 0.7977635860443115, Val Acc: 63.10%\n",
      "Epoch: 2956,     Training Loss: 0.4219342768192291, Training Acc: 68.59%\n",
      "              Val Loss: 0.8041439652442932, Val Acc: 63.11%\n",
      "Epoch: 2957,     Training Loss: 0.42809373140335083, Training Acc: 68.60%\n",
      "              Val Loss: 0.8306005001068115, Val Acc: 63.11%\n",
      "Epoch: 2958,     Training Loss: 0.4465470016002655, Training Acc: 68.60%\n",
      "              Val Loss: 0.8478038907051086, Val Acc: 63.11%\n",
      "Epoch: 2959,     Training Loss: 0.47870934009552, Training Acc: 68.60%\n",
      "              Val Loss: 0.835791826248169, Val Acc: 63.12%\n",
      "Epoch: 2960,     Training Loss: 0.45247021317481995, Training Acc: 68.61%\n",
      "              Val Loss: 0.8146106004714966, Val Acc: 63.12%\n",
      "Epoch: 2961,     Training Loss: 0.44344356656074524, Training Acc: 68.61%\n",
      "              Val Loss: 0.8038823008537292, Val Acc: 63.12%\n",
      "Epoch: 2962,     Training Loss: 0.42419570684432983, Training Acc: 68.62%\n",
      "              Val Loss: 0.7963814735412598, Val Acc: 63.13%\n",
      "Epoch: 2963,     Training Loss: 0.41704827547073364, Training Acc: 68.62%\n",
      "              Val Loss: 0.8041528463363647, Val Acc: 63.13%\n",
      "Epoch: 2964,     Training Loss: 0.4210793972015381, Training Acc: 68.63%\n",
      "              Val Loss: 0.8228347897529602, Val Acc: 63.13%\n",
      "Epoch: 2965,     Training Loss: 0.43148672580718994, Training Acc: 68.63%\n",
      "              Val Loss: 0.8369563817977905, Val Acc: 63.14%\n",
      "Epoch: 2966,     Training Loss: 0.45857441425323486, Training Acc: 68.64%\n",
      "              Val Loss: 0.8532212972640991, Val Acc: 63.14%\n",
      "Epoch: 2967,     Training Loss: 0.4631555676460266, Training Acc: 68.64%\n",
      "              Val Loss: 0.8755612373352051, Val Acc: 63.14%\n",
      "Epoch: 2968,     Training Loss: 0.5023065805435181, Training Acc: 68.64%\n",
      "              Val Loss: 0.8507606387138367, Val Acc: 63.15%\n",
      "Epoch: 2969,     Training Loss: 0.46567076444625854, Training Acc: 68.65%\n",
      "              Val Loss: 0.8124487400054932, Val Acc: 63.15%\n",
      "Epoch: 2970,     Training Loss: 0.438242107629776, Training Acc: 68.65%\n",
      "              Val Loss: 0.8030730485916138, Val Acc: 63.15%\n",
      "Epoch: 2971,     Training Loss: 0.4170146584510803, Training Acc: 68.66%\n",
      "              Val Loss: 0.8234866857528687, Val Acc: 63.16%\n",
      "Epoch: 2972,     Training Loss: 0.4275575280189514, Training Acc: 68.66%\n",
      "              Val Loss: 0.8477169275283813, Val Acc: 63.16%\n",
      "Epoch: 2973,     Training Loss: 0.46525898575782776, Training Acc: 68.66%\n",
      "              Val Loss: 0.8628407120704651, Val Acc: 63.16%\n",
      "Epoch: 2974,     Training Loss: 0.47007715702056885, Training Acc: 68.67%\n",
      "              Val Loss: 0.8815170526504517, Val Acc: 63.16%\n",
      "Epoch: 2975,     Training Loss: 0.5095256567001343, Training Acc: 68.67%\n",
      "              Val Loss: 0.8381510376930237, Val Acc: 63.17%\n",
      "Epoch: 2976,     Training Loss: 0.4532650411128998, Training Acc: 68.68%\n",
      "              Val Loss: 0.7970525622367859, Val Acc: 63.17%\n",
      "Epoch: 2977,     Training Loss: 0.4219176173210144, Training Acc: 68.68%\n",
      "              Val Loss: 0.8051499724388123, Val Acc: 63.17%\n",
      "Epoch: 2978,     Training Loss: 0.42181408405303955, Training Acc: 68.68%\n",
      "              Val Loss: 0.8416429758071899, Val Acc: 63.18%\n",
      "Epoch: 2979,     Training Loss: 0.44528210163116455, Training Acc: 68.69%\n",
      "              Val Loss: 0.8572825789451599, Val Acc: 63.18%\n",
      "Epoch: 2980,     Training Loss: 0.47770142555236816, Training Acc: 68.69%\n",
      "              Val Loss: 0.8350717425346375, Val Acc: 63.18%\n",
      "Epoch: 2981,     Training Loss: 0.4478466510772705, Training Acc: 68.70%\n",
      "              Val Loss: 0.8114296793937683, Val Acc: 63.19%\n",
      "Epoch: 2982,     Training Loss: 0.43500494956970215, Training Acc: 68.70%\n",
      "              Val Loss: 0.8028218150138855, Val Acc: 63.19%\n",
      "Epoch: 2983,     Training Loss: 0.4180344343185425, Training Acc: 68.71%\n",
      "              Val Loss: 0.8013582825660706, Val Acc: 63.19%\n",
      "Epoch: 2984,     Training Loss: 0.413516640663147, Training Acc: 68.71%\n",
      "              Val Loss: 0.8115822076797485, Val Acc: 63.20%\n",
      "Epoch: 2985,     Training Loss: 0.41999340057373047, Training Acc: 68.72%\n",
      "              Val Loss: 0.8291745185852051, Val Acc: 63.20%\n",
      "Epoch: 2986,     Training Loss: 0.43063315749168396, Training Acc: 68.72%\n",
      "              Val Loss: 0.8449113368988037, Val Acc: 63.20%\n",
      "Epoch: 2987,     Training Loss: 0.45974838733673096, Training Acc: 68.72%\n",
      "              Val Loss: 0.8548681139945984, Val Acc: 63.21%\n",
      "Epoch: 2988,     Training Loss: 0.4633082151412964, Training Acc: 68.73%\n",
      "              Val Loss: 0.8816716074943542, Val Acc: 63.21%\n",
      "Epoch: 2989,     Training Loss: 0.5012532472610474, Training Acc: 68.73%\n",
      "              Val Loss: 0.8510611653327942, Val Acc: 63.21%\n",
      "Epoch: 2990,     Training Loss: 0.45733973383903503, Training Acc: 68.74%\n",
      "              Val Loss: 0.8157471418380737, Val Acc: 63.22%\n",
      "Epoch: 2991,     Training Loss: 0.43003135919570923, Training Acc: 68.74%\n",
      "              Val Loss: 0.8090035319328308, Val Acc: 63.22%\n",
      "Epoch: 2992,     Training Loss: 0.41296595335006714, Training Acc: 68.75%\n",
      "              Val Loss: 0.8287956714630127, Val Acc: 63.22%\n",
      "Epoch: 2993,     Training Loss: 0.4254371225833893, Training Acc: 68.75%\n",
      "              Val Loss: 0.8471271991729736, Val Acc: 63.23%\n",
      "Epoch: 2994,     Training Loss: 0.45600634813308716, Training Acc: 68.75%\n",
      "              Val Loss: 0.8539317846298218, Val Acc: 63.23%\n",
      "Epoch: 2995,     Training Loss: 0.45686256885528564, Training Acc: 68.76%\n",
      "              Val Loss: 0.8650949597358704, Val Acc: 63.23%\n",
      "Epoch: 2996,     Training Loss: 0.48355576395988464, Training Acc: 68.76%\n",
      "              Val Loss: 0.8351942300796509, Val Acc: 63.23%\n",
      "Epoch: 2997,     Training Loss: 0.4433401823043823, Training Acc: 68.77%\n",
      "              Val Loss: 0.8019617199897766, Val Acc: 63.24%\n",
      "Epoch: 2998,     Training Loss: 0.41929757595062256, Training Acc: 68.77%\n",
      "              Val Loss: 0.8086255788803101, Val Acc: 63.24%\n",
      "Epoch: 2999,     Training Loss: 0.41452842950820923, Training Acc: 68.78%\n",
      "              Val Loss: 0.8405706286430359, Val Acc: 63.25%\n",
      "Epoch: 3000,     Training Loss: 0.43256333470344543, Training Acc: 68.78%\n",
      "              Val Loss: 0.8580401539802551, Val Acc: 63.25%\n",
      "Epoch: 3001,     Training Loss: 0.46491754055023193, Training Acc: 68.78%\n",
      "              Val Loss: 0.8564990162849426, Val Acc: 63.25%\n",
      "Epoch: 3002,     Training Loss: 0.4594029188156128, Training Acc: 68.79%\n",
      "              Val Loss: 0.8727214336395264, Val Acc: 63.25%\n",
      "Epoch: 3003,     Training Loss: 0.4860755205154419, Training Acc: 68.79%\n",
      "              Val Loss: 0.8398857712745667, Val Acc: 63.26%\n",
      "Epoch: 3004,     Training Loss: 0.4448850154876709, Training Acc: 68.80%\n",
      "              Val Loss: 0.8077484369277954, Val Acc: 63.26%\n",
      "Epoch: 3005,     Training Loss: 0.4206274747848511, Training Acc: 68.80%\n",
      "              Val Loss: 0.8126387000083923, Val Acc: 63.26%\n",
      "Epoch: 3006,     Training Loss: 0.41290149092674255, Training Acc: 68.80%\n",
      "              Val Loss: 0.8417725563049316, Val Acc: 63.27%\n",
      "Epoch: 3007,     Training Loss: 0.43317484855651855, Training Acc: 68.81%\n",
      "              Val Loss: 0.8620190620422363, Val Acc: 63.27%\n",
      "Epoch: 3008,     Training Loss: 0.47008514404296875, Training Acc: 68.81%\n",
      "              Val Loss: 0.8566246628761292, Val Acc: 63.27%\n",
      "Epoch: 3009,     Training Loss: 0.46210572123527527, Training Acc: 68.82%\n",
      "              Val Loss: 0.8701563477516174, Val Acc: 63.28%\n",
      "Epoch: 3010,     Training Loss: 0.48262885212898254, Training Acc: 68.82%\n",
      "              Val Loss: 0.8362282514572144, Val Acc: 63.28%\n",
      "Epoch: 3011,     Training Loss: 0.43832552433013916, Training Acc: 68.82%\n",
      "              Val Loss: 0.8046220541000366, Val Acc: 63.28%\n",
      "Epoch: 3012,     Training Loss: 0.4155749976634979, Training Acc: 68.83%\n",
      "              Val Loss: 0.8147719502449036, Val Acc: 63.29%\n",
      "Epoch: 3013,     Training Loss: 0.4150403141975403, Training Acc: 68.83%\n",
      "              Val Loss: 0.8481684923171997, Val Acc: 63.29%\n",
      "Epoch: 3014,     Training Loss: 0.43689656257629395, Training Acc: 68.84%\n",
      "              Val Loss: 0.8626118302345276, Val Acc: 63.29%\n",
      "Epoch: 3015,     Training Loss: 0.4675959050655365, Training Acc: 68.84%\n",
      "              Val Loss: 0.8517394065856934, Val Acc: 63.29%\n",
      "Epoch: 3016,     Training Loss: 0.45458775758743286, Training Acc: 68.85%\n",
      "              Val Loss: 0.8559276461601257, Val Acc: 63.30%\n",
      "Epoch: 3017,     Training Loss: 0.46436068415641785, Training Acc: 68.85%\n",
      "              Val Loss: 0.8280969858169556, Val Acc: 63.30%\n",
      "Epoch: 3018,     Training Loss: 0.43071335554122925, Training Acc: 68.85%\n",
      "              Val Loss: 0.8041031360626221, Val Acc: 63.30%\n",
      "Epoch: 3019,     Training Loss: 0.41429927945137024, Training Acc: 68.86%\n",
      "              Val Loss: 0.816199779510498, Val Acc: 63.31%\n",
      "Epoch: 3020,     Training Loss: 0.4143829345703125, Training Acc: 68.86%\n",
      "              Val Loss: 0.8455148935317993, Val Acc: 63.31%\n",
      "Epoch: 3021,     Training Loss: 0.43100520968437195, Training Acc: 68.87%\n",
      "              Val Loss: 0.8440966010093689, Val Acc: 63.31%\n",
      "Epoch: 3022,     Training Loss: 0.4476747512817383, Training Acc: 68.87%\n",
      "              Val Loss: 0.8414410948753357, Val Acc: 63.32%\n",
      "Epoch: 3023,     Training Loss: 0.44523170590400696, Training Acc: 68.88%\n",
      "              Val Loss: 0.8502947092056274, Val Acc: 63.32%\n",
      "Epoch: 3024,     Training Loss: 0.45859605073928833, Training Acc: 68.88%\n",
      "              Val Loss: 0.8334023952484131, Val Acc: 63.32%\n",
      "Epoch: 3025,     Training Loss: 0.4334414601325989, Training Acc: 68.88%\n",
      "              Val Loss: 0.8109055161476135, Val Acc: 63.32%\n",
      "Epoch: 3026,     Training Loss: 0.42026615142822266, Training Acc: 68.89%\n",
      "              Val Loss: 0.8160131573677063, Val Acc: 63.33%\n",
      "Epoch: 3027,     Training Loss: 0.41007694602012634, Training Acc: 68.89%\n",
      "              Val Loss: 0.8369239568710327, Val Acc: 63.33%\n",
      "Epoch: 3028,     Training Loss: 0.41882652044296265, Training Acc: 68.90%\n",
      "              Val Loss: 0.8301916718482971, Val Acc: 63.33%\n",
      "Epoch: 3029,     Training Loss: 0.42619872093200684, Training Acc: 68.90%\n",
      "              Val Loss: 0.8474485874176025, Val Acc: 63.34%\n",
      "Epoch: 3030,     Training Loss: 0.44908589124679565, Training Acc: 68.91%\n",
      "              Val Loss: 0.8986939191818237, Val Acc: 63.34%\n",
      "Epoch: 3031,     Training Loss: 0.5024466514587402, Training Acc: 68.91%\n",
      "              Val Loss: 0.8930112719535828, Val Acc: 63.34%\n",
      "Epoch: 3032,     Training Loss: 0.4861032962799072, Training Acc: 68.91%\n",
      "              Val Loss: 0.8837795853614807, Val Acc: 63.34%\n",
      "Epoch: 3033,     Training Loss: 0.49812906980514526, Training Acc: 68.92%\n",
      "              Val Loss: 0.8335355520248413, Val Acc: 63.35%\n",
      "Epoch: 3034,     Training Loss: 0.43369990587234497, Training Acc: 68.92%\n",
      "              Val Loss: 0.8454891443252563, Val Acc: 63.35%\n",
      "Epoch: 3035,     Training Loss: 0.42746803164482117, Training Acc: 68.93%\n",
      "              Val Loss: 0.8466439843177795, Val Acc: 63.35%\n",
      "Epoch: 3036,     Training Loss: 0.4408942461013794, Training Acc: 68.93%\n",
      "              Val Loss: 0.8688573241233826, Val Acc: 63.35%\n",
      "Epoch: 3037,     Training Loss: 0.4719472825527191, Training Acc: 68.93%\n",
      "              Val Loss: 0.9021153450012207, Val Acc: 63.36%\n",
      "Epoch: 3038,     Training Loss: 0.5076225399971008, Training Acc: 68.94%\n",
      "              Val Loss: 0.8726482391357422, Val Acc: 63.36%\n",
      "Epoch: 3039,     Training Loss: 0.467778742313385, Training Acc: 68.94%\n",
      "              Val Loss: 0.8158661723136902, Val Acc: 63.36%\n",
      "Epoch: 3040,     Training Loss: 0.4398432672023773, Training Acc: 68.94%\n",
      "              Val Loss: 0.8079822063446045, Val Acc: 63.37%\n",
      "Epoch: 3041,     Training Loss: 0.4185110330581665, Training Acc: 68.95%\n",
      "              Val Loss: 0.873568594455719, Val Acc: 63.37%\n",
      "Epoch: 3042,     Training Loss: 0.4538556933403015, Training Acc: 68.95%\n",
      "              Val Loss: 0.8823305368423462, Val Acc: 63.37%\n",
      "Epoch: 3043,     Training Loss: 0.4845097064971924, Training Acc: 68.96%\n",
      "              Val Loss: 0.8700041770935059, Val Acc: 63.37%\n",
      "Epoch: 3044,     Training Loss: 0.47045621275901794, Training Acc: 68.96%\n",
      "              Val Loss: 0.8620454668998718, Val Acc: 63.38%\n",
      "Epoch: 3045,     Training Loss: 0.4651270806789398, Training Acc: 68.96%\n",
      "              Val Loss: 0.8378124833106995, Val Acc: 63.38%\n",
      "Epoch: 3046,     Training Loss: 0.43014389276504517, Training Acc: 68.97%\n",
      "              Val Loss: 0.8154541254043579, Val Acc: 63.38%\n",
      "Epoch: 3047,     Training Loss: 0.41869378089904785, Training Acc: 68.97%\n",
      "              Val Loss: 0.8302972316741943, Val Acc: 63.39%\n",
      "Epoch: 3048,     Training Loss: 0.430137038230896, Training Acc: 68.98%\n",
      "              Val Loss: 0.8714669942855835, Val Acc: 63.39%\n",
      "Epoch: 3049,     Training Loss: 0.4503640830516815, Training Acc: 68.98%\n",
      "              Val Loss: 0.8561490774154663, Val Acc: 63.39%\n",
      "Epoch: 3050,     Training Loss: 0.4578532874584198, Training Acc: 68.99%\n",
      "              Val Loss: 0.8343731164932251, Val Acc: 63.39%\n",
      "Epoch: 3051,     Training Loss: 0.4415217936038971, Training Acc: 68.99%\n",
      "              Val Loss: 0.821890115737915, Val Acc: 63.40%\n",
      "Epoch: 3052,     Training Loss: 0.426401287317276, Training Acc: 68.99%\n",
      "              Val Loss: 0.8202391266822815, Val Acc: 63.40%\n",
      "Epoch: 3053,     Training Loss: 0.41625145077705383, Training Acc: 69.00%\n",
      "              Val Loss: 0.8069313168525696, Val Acc: 63.40%\n",
      "Epoch: 3054,     Training Loss: 0.40956565737724304, Training Acc: 69.00%\n",
      "              Val Loss: 0.8200160264968872, Val Acc: 63.41%\n",
      "Epoch: 3055,     Training Loss: 0.4154212474822998, Training Acc: 69.01%\n",
      "              Val Loss: 0.8552333116531372, Val Acc: 63.41%\n",
      "Epoch: 3056,     Training Loss: 0.43032991886138916, Training Acc: 69.01%\n",
      "              Val Loss: 0.8684345483779907, Val Acc: 63.41%\n",
      "Epoch: 3057,     Training Loss: 0.46018925309181213, Training Acc: 69.02%\n",
      "              Val Loss: 0.8685675263404846, Val Acc: 63.42%\n",
      "Epoch: 3058,     Training Loss: 0.4615701735019684, Training Acc: 69.02%\n",
      "              Val Loss: 0.8915877342224121, Val Acc: 63.42%\n",
      "Epoch: 3059,     Training Loss: 0.48634976148605347, Training Acc: 69.02%\n",
      "              Val Loss: 0.8574719429016113, Val Acc: 63.42%\n",
      "Epoch: 3060,     Training Loss: 0.44032028317451477, Training Acc: 69.03%\n",
      "              Val Loss: 0.819366991519928, Val Acc: 63.42%\n",
      "Epoch: 3061,     Training Loss: 0.4135981500148773, Training Acc: 69.03%\n",
      "              Val Loss: 0.8256136178970337, Val Acc: 63.43%\n",
      "Epoch: 3062,     Training Loss: 0.41366592049598694, Training Acc: 69.04%\n",
      "              Val Loss: 0.8621406555175781, Val Acc: 63.43%\n",
      "Epoch: 3063,     Training Loss: 0.4371771216392517, Training Acc: 69.04%\n",
      "              Val Loss: 0.8714063763618469, Val Acc: 63.43%\n",
      "Epoch: 3064,     Training Loss: 0.4658259153366089, Training Acc: 69.04%\n",
      "              Val Loss: 0.8567073345184326, Val Acc: 63.44%\n",
      "Epoch: 3065,     Training Loss: 0.4482237994670868, Training Acc: 69.05%\n",
      "              Val Loss: 0.8475033044815063, Val Acc: 63.44%\n",
      "Epoch: 3066,     Training Loss: 0.43789827823638916, Training Acc: 69.05%\n",
      "              Val Loss: 0.833233654499054, Val Acc: 63.44%\n",
      "Epoch: 3067,     Training Loss: 0.41541019082069397, Training Acc: 69.06%\n",
      "              Val Loss: 0.8183350563049316, Val Acc: 63.44%\n",
      "Epoch: 3068,     Training Loss: 0.40679794549942017, Training Acc: 69.06%\n",
      "              Val Loss: 0.8295340538024902, Val Acc: 63.45%\n",
      "Epoch: 3069,     Training Loss: 0.4125838875770569, Training Acc: 69.07%\n",
      "              Val Loss: 0.8592548370361328, Val Acc: 63.45%\n",
      "Epoch: 3070,     Training Loss: 0.43018609285354614, Training Acc: 69.07%\n",
      "              Val Loss: 0.8714039325714111, Val Acc: 63.45%\n",
      "Epoch: 3071,     Training Loss: 0.45876315236091614, Training Acc: 69.07%\n",
      "              Val Loss: 0.861955463886261, Val Acc: 63.46%\n",
      "Epoch: 3072,     Training Loss: 0.45142367482185364, Training Acc: 69.08%\n",
      "              Val Loss: 0.8819902539253235, Val Acc: 63.46%\n",
      "Epoch: 3073,     Training Loss: 0.47084683179855347, Training Acc: 69.08%\n",
      "              Val Loss: 0.8484602570533752, Val Acc: 63.46%\n",
      "Epoch: 3074,     Training Loss: 0.43093082308769226, Training Acc: 69.09%\n",
      "              Val Loss: 0.8166339993476868, Val Acc: 63.46%\n",
      "Epoch: 3075,     Training Loss: 0.41079434752464294, Training Acc: 69.09%\n",
      "              Val Loss: 0.8225512504577637, Val Acc: 63.47%\n",
      "Epoch: 3076,     Training Loss: 0.4068485498428345, Training Acc: 69.10%\n",
      "              Val Loss: 0.8595085144042969, Val Acc: 63.47%\n",
      "Epoch: 3077,     Training Loss: 0.4297534227371216, Training Acc: 69.10%\n",
      "              Val Loss: 0.8700679540634155, Val Acc: 63.47%\n",
      "Epoch: 3078,     Training Loss: 0.45895126461982727, Training Acc: 69.10%\n",
      "              Val Loss: 0.8634166121482849, Val Acc: 63.48%\n",
      "Epoch: 3079,     Training Loss: 0.44826993346214294, Training Acc: 69.11%\n",
      "              Val Loss: 0.8846074938774109, Val Acc: 63.48%\n",
      "Epoch: 3080,     Training Loss: 0.4677065908908844, Training Acc: 69.11%\n",
      "              Val Loss: 0.8511475324630737, Val Acc: 63.48%\n",
      "Epoch: 3081,     Training Loss: 0.42909783124923706, Training Acc: 69.12%\n",
      "              Val Loss: 0.8233290314674377, Val Acc: 63.48%\n",
      "Epoch: 3082,     Training Loss: 0.4150533676147461, Training Acc: 69.12%\n",
      "              Val Loss: 0.8274096846580505, Val Acc: 63.49%\n",
      "Epoch: 3083,     Training Loss: 0.4056745171546936, Training Acc: 69.12%\n",
      "              Val Loss: 0.8662289977073669, Val Acc: 63.49%\n",
      "Epoch: 3084,     Training Loss: 0.4276520907878876, Training Acc: 69.13%\n",
      "              Val Loss: 0.8601220846176147, Val Acc: 63.49%\n",
      "Epoch: 3085,     Training Loss: 0.4444350004196167, Training Acc: 69.13%\n",
      "              Val Loss: 0.8579419851303101, Val Acc: 63.50%\n",
      "Epoch: 3086,     Training Loss: 0.43888866901397705, Training Acc: 69.14%\n",
      "              Val Loss: 0.8705412149429321, Val Acc: 63.50%\n",
      "Epoch: 3087,     Training Loss: 0.44859734177589417, Training Acc: 69.14%\n",
      "              Val Loss: 0.8457603454589844, Val Acc: 63.50%\n",
      "Epoch: 3088,     Training Loss: 0.41972634196281433, Training Acc: 69.15%\n",
      "              Val Loss: 0.8223639726638794, Val Acc: 63.50%\n",
      "Epoch: 3089,     Training Loss: 0.4139542877674103, Training Acc: 69.15%\n",
      "              Val Loss: 0.8223863244056702, Val Acc: 63.51%\n",
      "Epoch: 3090,     Training Loss: 0.4028436541557312, Training Acc: 69.15%\n",
      "              Val Loss: 0.8677986264228821, Val Acc: 63.51%\n",
      "Epoch: 3091,     Training Loss: 0.4278007447719574, Training Acc: 69.16%\n",
      "              Val Loss: 0.873853862285614, Val Acc: 63.51%\n",
      "Epoch: 3092,     Training Loss: 0.45491209626197815, Training Acc: 69.16%\n",
      "              Val Loss: 0.8881338238716125, Val Acc: 63.52%\n",
      "Epoch: 3093,     Training Loss: 0.4659045338630676, Training Acc: 69.17%\n",
      "              Val Loss: 1.014786958694458, Val Acc: 63.52%\n",
      "Epoch: 3094,     Training Loss: 0.584452211856842, Training Acc: 69.17%\n",
      "              Val Loss: 0.9256597757339478, Val Acc: 63.52%\n",
      "Epoch: 3095,     Training Loss: 0.4989699423313141, Training Acc: 69.17%\n",
      "              Val Loss: 0.862895131111145, Val Acc: 63.52%\n",
      "Epoch: 3096,     Training Loss: 0.4574279487133026, Training Acc: 69.17%\n",
      "              Val Loss: 0.8461565971374512, Val Acc: 63.53%\n",
      "Epoch: 3097,     Training Loss: 0.42446574568748474, Training Acc: 69.18%\n",
      "              Val Loss: 0.9569069147109985, Val Acc: 63.53%\n",
      "Epoch: 3098,     Training Loss: 0.5061408281326294, Training Acc: 69.18%\n",
      "              Val Loss: 0.9782110452651978, Val Acc: 63.53%\n",
      "Epoch: 3099,     Training Loss: 0.5637488961219788, Training Acc: 69.18%\n",
      "              Val Loss: 0.8806906938552856, Val Acc: 63.53%\n",
      "Epoch: 3100,     Training Loss: 0.48474207520484924, Training Acc: 69.19%\n",
      "              Val Loss: 0.855593204498291, Val Acc: 63.53%\n",
      "Epoch: 3101,     Training Loss: 0.44088253378868103, Training Acc: 69.19%\n",
      "              Val Loss: 0.8520596027374268, Val Acc: 63.54%\n",
      "Epoch: 3102,     Training Loss: 0.4324735999107361, Training Acc: 69.19%\n",
      "              Val Loss: 0.8995464444160461, Val Acc: 63.54%\n",
      "Epoch: 3103,     Training Loss: 0.48051968216896057, Training Acc: 69.20%\n",
      "              Val Loss: 0.9077774882316589, Val Acc: 63.54%\n",
      "Epoch: 3104,     Training Loss: 0.4941733479499817, Training Acc: 69.20%\n",
      "              Val Loss: 0.8863912224769592, Val Acc: 63.54%\n",
      "Epoch: 3105,     Training Loss: 0.4516671299934387, Training Acc: 69.20%\n",
      "              Val Loss: 0.8160531520843506, Val Acc: 63.55%\n",
      "Epoch: 3106,     Training Loss: 0.4054156243801117, Training Acc: 69.21%\n",
      "              Val Loss: 0.8326020836830139, Val Acc: 63.55%\n",
      "Epoch: 3107,     Training Loss: 0.4276424050331116, Training Acc: 69.21%\n",
      "              Val Loss: 0.8679149150848389, Val Acc: 63.55%\n",
      "Epoch: 3108,     Training Loss: 0.4322718679904938, Training Acc: 69.22%\n",
      "              Val Loss: 0.8956405520439148, Val Acc: 63.56%\n",
      "Epoch: 3109,     Training Loss: 0.4696693420410156, Training Acc: 69.22%\n",
      "              Val Loss: 0.8571674227714539, Val Acc: 63.56%\n",
      "Epoch: 3110,     Training Loss: 0.431721568107605, Training Acc: 69.23%\n",
      "              Val Loss: 0.8201694488525391, Val Acc: 63.56%\n",
      "Epoch: 3111,     Training Loss: 0.4151122570037842, Training Acc: 69.23%\n",
      "              Val Loss: 0.8294159770011902, Val Acc: 63.57%\n",
      "Epoch: 3112,     Training Loss: 0.406477689743042, Training Acc: 69.23%\n",
      "              Val Loss: 0.8648845553398132, Val Acc: 63.57%\n",
      "Epoch: 3113,     Training Loss: 0.4186999499797821, Training Acc: 69.24%\n",
      "              Val Loss: 0.8659300208091736, Val Acc: 63.57%\n",
      "Epoch: 3114,     Training Loss: 0.4344659149646759, Training Acc: 69.24%\n",
      "              Val Loss: 0.8762593269348145, Val Acc: 63.57%\n",
      "Epoch: 3115,     Training Loss: 0.44734808802604675, Training Acc: 69.25%\n",
      "              Val Loss: 0.9223147034645081, Val Acc: 63.58%\n",
      "Epoch: 3116,     Training Loss: 0.4978756308555603, Training Acc: 69.25%\n",
      "              Val Loss: 0.8800461292266846, Val Acc: 63.58%\n",
      "Epoch: 3117,     Training Loss: 0.45434150099754333, Training Acc: 69.25%\n",
      "              Val Loss: 0.853502094745636, Val Acc: 63.58%\n",
      "Epoch: 3118,     Training Loss: 0.43852460384368896, Training Acc: 69.26%\n",
      "              Val Loss: 0.835487425327301, Val Acc: 63.58%\n",
      "Epoch: 3119,     Training Loss: 0.40340083837509155, Training Acc: 69.26%\n",
      "              Val Loss: 0.878823459148407, Val Acc: 63.59%\n",
      "Epoch: 3120,     Training Loss: 0.4295424520969391, Training Acc: 69.27%\n",
      "              Val Loss: 0.8945463299751282, Val Acc: 63.59%\n",
      "Epoch: 3121,     Training Loss: 0.4647160470485687, Training Acc: 69.27%\n",
      "              Val Loss: 0.876737117767334, Val Acc: 63.59%\n",
      "Epoch: 3122,     Training Loss: 0.454140305519104, Training Acc: 69.27%\n",
      "              Val Loss: 0.879315197467804, Val Acc: 63.59%\n",
      "Epoch: 3123,     Training Loss: 0.44237133860588074, Training Acc: 69.28%\n",
      "              Val Loss: 0.8488073945045471, Val Acc: 63.60%\n",
      "Epoch: 3124,     Training Loss: 0.40673503279685974, Training Acc: 69.28%\n",
      "              Val Loss: 0.855872392654419, Val Acc: 63.60%\n",
      "Epoch: 3125,     Training Loss: 0.42408183217048645, Training Acc: 69.29%\n",
      "              Val Loss: 0.8791764974594116, Val Acc: 63.60%\n",
      "Epoch: 3126,     Training Loss: 0.44605210423469543, Training Acc: 69.29%\n",
      "              Val Loss: 0.9083213210105896, Val Acc: 63.60%\n",
      "Epoch: 3127,     Training Loss: 0.45808303356170654, Training Acc: 69.29%\n",
      "              Val Loss: 0.8730466961860657, Val Acc: 63.61%\n",
      "Epoch: 3128,     Training Loss: 0.4532359838485718, Training Acc: 69.30%\n",
      "              Val Loss: 0.8450818061828613, Val Acc: 63.61%\n",
      "Epoch: 3129,     Training Loss: 0.41769939661026, Training Acc: 69.30%\n",
      "              Val Loss: 0.8460329174995422, Val Acc: 63.61%\n",
      "Epoch: 3130,     Training Loss: 0.4033902883529663, Training Acc: 69.31%\n",
      "              Val Loss: 0.852366030216217, Val Acc: 63.62%\n",
      "Epoch: 3131,     Training Loss: 0.4089130759239197, Training Acc: 69.31%\n",
      "              Val Loss: 0.8777859210968018, Val Acc: 63.62%\n",
      "Epoch: 3132,     Training Loss: 0.43711721897125244, Training Acc: 69.31%\n",
      "              Val Loss: 0.9261971116065979, Val Acc: 63.62%\n",
      "Epoch: 3133,     Training Loss: 0.490188866853714, Training Acc: 69.32%\n",
      "              Val Loss: 0.9097702503204346, Val Acc: 63.62%\n",
      "Epoch: 3134,     Training Loss: 0.470167875289917, Training Acc: 69.32%\n",
      "              Val Loss: 0.8657199144363403, Val Acc: 63.63%\n",
      "Epoch: 3135,     Training Loss: 0.4439500570297241, Training Acc: 69.32%\n",
      "              Val Loss: 0.8437514305114746, Val Acc: 63.63%\n",
      "Epoch: 3136,     Training Loss: 0.4071997106075287, Training Acc: 69.33%\n",
      "              Val Loss: 0.8795424103736877, Val Acc: 63.63%\n",
      "Epoch: 3137,     Training Loss: 0.425059050321579, Training Acc: 69.33%\n",
      "              Val Loss: 0.9037036299705505, Val Acc: 63.63%\n",
      "Epoch: 3138,     Training Loss: 0.46804824471473694, Training Acc: 69.34%\n",
      "              Val Loss: 0.8886330127716064, Val Acc: 63.64%\n",
      "Epoch: 3139,     Training Loss: 0.46162793040275574, Training Acc: 69.34%\n",
      "              Val Loss: 0.8890182971954346, Val Acc: 63.64%\n",
      "Epoch: 3140,     Training Loss: 0.45742329955101013, Training Acc: 69.34%\n",
      "              Val Loss: 0.8571518063545227, Val Acc: 63.64%\n",
      "Epoch: 3141,     Training Loss: 0.41392654180526733, Training Acc: 69.35%\n",
      "              Val Loss: 0.848950207233429, Val Acc: 63.65%\n",
      "Epoch: 3142,     Training Loss: 0.4141061305999756, Training Acc: 69.35%\n",
      "              Val Loss: 0.8686438798904419, Val Acc: 63.65%\n",
      "Epoch: 3143,     Training Loss: 0.4366430938243866, Training Acc: 69.36%\n",
      "              Val Loss: 0.8855074048042297, Val Acc: 63.65%\n",
      "Epoch: 3144,     Training Loss: 0.4383721649646759, Training Acc: 69.36%\n",
      "              Val Loss: 0.8445608615875244, Val Acc: 63.65%\n",
      "Epoch: 3145,     Training Loss: 0.42196646332740784, Training Acc: 69.36%\n",
      "              Val Loss: 0.8308616876602173, Val Acc: 63.66%\n",
      "Epoch: 3146,     Training Loss: 0.4042122960090637, Training Acc: 69.37%\n",
      "              Val Loss: 0.8436475396156311, Val Acc: 63.66%\n",
      "Epoch: 3147,     Training Loss: 0.4002203345298767, Training Acc: 69.37%\n",
      "              Val Loss: 0.8562877774238586, Val Acc: 63.66%\n",
      "Epoch: 3148,     Training Loss: 0.4137851595878601, Training Acc: 69.38%\n",
      "              Val Loss: 0.8728410601615906, Val Acc: 63.67%\n",
      "Epoch: 3149,     Training Loss: 0.4301683008670807, Training Acc: 69.38%\n",
      "              Val Loss: 0.9093918800354004, Val Acc: 63.67%\n",
      "Epoch: 3150,     Training Loss: 0.47135433554649353, Training Acc: 69.39%\n",
      "              Val Loss: 0.8926053047180176, Val Acc: 63.67%\n",
      "Epoch: 3151,     Training Loss: 0.44739794731140137, Training Acc: 69.39%\n",
      "              Val Loss: 0.8608212471008301, Val Acc: 63.67%\n",
      "Epoch: 3152,     Training Loss: 0.4289822280406952, Training Acc: 69.39%\n",
      "              Val Loss: 0.8401319980621338, Val Acc: 63.68%\n",
      "Epoch: 3153,     Training Loss: 0.39807724952697754, Training Acc: 69.40%\n",
      "              Val Loss: 0.8623073101043701, Val Acc: 63.68%\n",
      "Epoch: 3154,     Training Loss: 0.4065622091293335, Training Acc: 69.40%\n",
      "              Val Loss: 0.880147397518158, Val Acc: 63.68%\n",
      "Epoch: 3155,     Training Loss: 0.43634945154190063, Training Acc: 69.41%\n",
      "              Val Loss: 0.8781105279922485, Val Acc: 63.68%\n",
      "Epoch: 3156,     Training Loss: 0.437473326921463, Training Acc: 69.41%\n",
      "              Val Loss: 0.8933718800544739, Val Acc: 63.69%\n",
      "Epoch: 3157,     Training Loss: 0.45786696672439575, Training Acc: 69.41%\n",
      "              Val Loss: 0.8592885732650757, Val Acc: 63.69%\n",
      "Epoch: 3158,     Training Loss: 0.41829344630241394, Training Acc: 69.42%\n",
      "              Val Loss: 0.8350313305854797, Val Acc: 63.69%\n",
      "Epoch: 3159,     Training Loss: 0.39793723821640015, Training Acc: 69.42%\n",
      "              Val Loss: 0.8507172465324402, Val Acc: 63.70%\n",
      "Epoch: 3160,     Training Loss: 0.40519946813583374, Training Acc: 69.43%\n",
      "              Val Loss: 0.8785614967346191, Val Acc: 63.70%\n",
      "Epoch: 3161,     Training Loss: 0.4208866357803345, Training Acc: 69.43%\n",
      "              Val Loss: 0.878763735294342, Val Acc: 63.70%\n",
      "Epoch: 3162,     Training Loss: 0.43874889612197876, Training Acc: 69.43%\n",
      "              Val Loss: 0.8614340424537659, Val Acc: 63.70%\n",
      "Epoch: 3163,     Training Loss: 0.41728705167770386, Training Acc: 69.44%\n",
      "              Val Loss: 0.8552449941635132, Val Acc: 63.71%\n",
      "Epoch: 3164,     Training Loss: 0.4068404734134674, Training Acc: 69.44%\n",
      "              Val Loss: 0.8472354412078857, Val Acc: 63.71%\n",
      "Epoch: 3165,     Training Loss: 0.3938545286655426, Training Acc: 69.45%\n",
      "              Val Loss: 0.8436431288719177, Val Acc: 63.71%\n",
      "Epoch: 3166,     Training Loss: 0.3952602446079254, Training Acc: 69.45%\n",
      "              Val Loss: 0.8509440422058105, Val Acc: 63.72%\n",
      "Epoch: 3167,     Training Loss: 0.3994656801223755, Training Acc: 69.46%\n",
      "              Val Loss: 0.8693717122077942, Val Acc: 63.72%\n",
      "Epoch: 3168,     Training Loss: 0.4106435775756836, Training Acc: 69.46%\n",
      "              Val Loss: 0.8754351139068604, Val Acc: 63.72%\n",
      "Epoch: 3169,     Training Loss: 0.43104326725006104, Training Acc: 69.47%\n",
      "              Val Loss: 0.8883220553398132, Val Acc: 63.72%\n",
      "Epoch: 3170,     Training Loss: 0.4350915253162384, Training Acc: 69.47%\n",
      "              Val Loss: 0.9641543030738831, Val Acc: 63.73%\n",
      "Epoch: 3171,     Training Loss: 0.5122852921485901, Training Acc: 69.47%\n",
      "              Val Loss: 0.9250547885894775, Val Acc: 63.73%\n",
      "Epoch: 3172,     Training Loss: 0.4723835289478302, Training Acc: 69.47%\n",
      "              Val Loss: 0.893329381942749, Val Acc: 63.73%\n",
      "Epoch: 3173,     Training Loss: 0.45926570892333984, Training Acc: 69.48%\n",
      "              Val Loss: 0.8440696597099304, Val Acc: 63.73%\n",
      "Epoch: 3174,     Training Loss: 0.3999895751476288, Training Acc: 69.48%\n",
      "              Val Loss: 0.8870372176170349, Val Acc: 63.74%\n",
      "Epoch: 3175,     Training Loss: 0.42962363362312317, Training Acc: 69.49%\n",
      "              Val Loss: 0.9258869290351868, Val Acc: 63.74%\n",
      "Epoch: 3176,     Training Loss: 0.4814679026603699, Training Acc: 69.49%\n",
      "              Val Loss: 0.8827535510063171, Val Acc: 63.74%\n",
      "Epoch: 3177,     Training Loss: 0.43923038244247437, Training Acc: 69.49%\n",
      "              Val Loss: 0.844021201133728, Val Acc: 63.74%\n",
      "Epoch: 3178,     Training Loss: 0.41002556681632996, Training Acc: 69.50%\n",
      "              Val Loss: 0.8352009654045105, Val Acc: 63.75%\n",
      "Epoch: 3179,     Training Loss: 0.4035298824310303, Training Acc: 69.50%\n",
      "              Val Loss: 0.8632499575614929, Val Acc: 63.75%\n",
      "Epoch: 3180,     Training Loss: 0.4191870391368866, Training Acc: 69.51%\n",
      "              Val Loss: 0.8809698224067688, Val Acc: 63.75%\n",
      "Epoch: 3181,     Training Loss: 0.4363807737827301, Training Acc: 69.51%\n",
      "              Val Loss: 0.8765561580657959, Val Acc: 63.75%\n",
      "Epoch: 3182,     Training Loss: 0.41662320494651794, Training Acc: 69.51%\n",
      "              Val Loss: 0.8457669019699097, Val Acc: 63.76%\n",
      "Epoch: 3183,     Training Loss: 0.3978048264980316, Training Acc: 69.52%\n",
      "              Val Loss: 0.8461098670959473, Val Acc: 63.76%\n",
      "Epoch: 3184,     Training Loss: 0.39755141735076904, Training Acc: 69.52%\n",
      "              Val Loss: 0.8852570056915283, Val Acc: 63.76%\n",
      "Epoch: 3185,     Training Loss: 0.4126353859901428, Training Acc: 69.53%\n",
      "              Val Loss: 0.8925212621688843, Val Acc: 63.76%\n",
      "Epoch: 3186,     Training Loss: 0.43562397360801697, Training Acc: 69.53%\n",
      "              Val Loss: 0.8869733214378357, Val Acc: 63.77%\n",
      "Epoch: 3187,     Training Loss: 0.4274761974811554, Training Acc: 69.54%\n",
      "              Val Loss: 0.9109257459640503, Val Acc: 63.77%\n",
      "Epoch: 3188,     Training Loss: 0.4557414948940277, Training Acc: 69.54%\n",
      "              Val Loss: 0.8856369853019714, Val Acc: 63.77%\n",
      "Epoch: 3189,     Training Loss: 0.4253169596195221, Training Acc: 69.54%\n",
      "              Val Loss: 0.8644485473632812, Val Acc: 63.77%\n",
      "Epoch: 3190,     Training Loss: 0.4122488796710968, Training Acc: 69.55%\n",
      "              Val Loss: 0.8519524335861206, Val Acc: 63.78%\n",
      "Epoch: 3191,     Training Loss: 0.3907788097858429, Training Acc: 69.55%\n",
      "              Val Loss: 0.8601216673851013, Val Acc: 63.78%\n",
      "Epoch: 3192,     Training Loss: 0.3955414891242981, Training Acc: 69.56%\n",
      "              Val Loss: 0.8659858703613281, Val Acc: 63.78%\n",
      "Epoch: 3193,     Training Loss: 0.40981799364089966, Training Acc: 69.56%\n",
      "              Val Loss: 0.8856549859046936, Val Acc: 63.79%\n",
      "Epoch: 3194,     Training Loss: 0.4230296015739441, Training Acc: 69.56%\n",
      "              Val Loss: 0.9124666452407837, Val Acc: 63.79%\n",
      "Epoch: 3195,     Training Loss: 0.45913341641426086, Training Acc: 69.57%\n",
      "              Val Loss: 0.8824929594993591, Val Acc: 63.79%\n",
      "Epoch: 3196,     Training Loss: 0.43076443672180176, Training Acc: 69.57%\n",
      "              Val Loss: 0.8587873578071594, Val Acc: 63.79%\n",
      "Epoch: 3197,     Training Loss: 0.41094452142715454, Training Acc: 69.58%\n",
      "              Val Loss: 0.8608161211013794, Val Acc: 63.80%\n",
      "Epoch: 3198,     Training Loss: 0.3939594626426697, Training Acc: 69.58%\n",
      "              Val Loss: 0.8674324750900269, Val Acc: 63.80%\n",
      "Epoch: 3199,     Training Loss: 0.39861834049224854, Training Acc: 69.59%\n",
      "              Val Loss: 0.8824196457862854, Val Acc: 63.80%\n",
      "Epoch: 3200,     Training Loss: 0.427035927772522, Training Acc: 69.59%\n",
      "              Val Loss: 0.8973886966705322, Val Acc: 63.80%\n",
      "Epoch: 3201,     Training Loss: 0.4368737041950226, Training Acc: 69.59%\n",
      "              Val Loss: 0.9546129107475281, Val Acc: 63.81%\n",
      "Epoch: 3202,     Training Loss: 0.5014341473579407, Training Acc: 69.60%\n",
      "              Val Loss: 0.9096130132675171, Val Acc: 63.81%\n",
      "Epoch: 3203,     Training Loss: 0.4504176080226898, Training Acc: 69.60%\n",
      "              Val Loss: 0.8702321648597717, Val Acc: 63.81%\n",
      "Epoch: 3204,     Training Loss: 0.4177156090736389, Training Acc: 69.60%\n",
      "              Val Loss: 0.867942750453949, Val Acc: 63.81%\n",
      "Epoch: 3205,     Training Loss: 0.40499159693717957, Training Acc: 69.61%\n",
      "              Val Loss: 0.8815356492996216, Val Acc: 63.82%\n",
      "Epoch: 3206,     Training Loss: 0.4172269105911255, Training Acc: 69.61%\n",
      "              Val Loss: 0.903975248336792, Val Acc: 63.82%\n",
      "Epoch: 3207,     Training Loss: 0.45043104887008667, Training Acc: 69.61%\n",
      "              Val Loss: 0.8917908668518066, Val Acc: 63.82%\n",
      "Epoch: 3208,     Training Loss: 0.42385783791542053, Training Acc: 69.62%\n",
      "              Val Loss: 0.8652845621109009, Val Acc: 63.82%\n",
      "Epoch: 3209,     Training Loss: 0.4090871512889862, Training Acc: 69.62%\n",
      "              Val Loss: 0.8565911650657654, Val Acc: 63.83%\n",
      "Epoch: 3210,     Training Loss: 0.39543330669403076, Training Acc: 69.63%\n",
      "              Val Loss: 0.8597779273986816, Val Acc: 63.83%\n",
      "Epoch: 3211,     Training Loss: 0.39194256067276, Training Acc: 69.63%\n",
      "              Val Loss: 0.8597497344017029, Val Acc: 63.83%\n",
      "Epoch: 3212,     Training Loss: 0.40249383449554443, Training Acc: 69.64%\n",
      "              Val Loss: 0.8766176700592041, Val Acc: 63.84%\n",
      "Epoch: 3213,     Training Loss: 0.41239768266677856, Training Acc: 69.64%\n",
      "              Val Loss: 0.8940556049346924, Val Acc: 63.84%\n",
      "Epoch: 3214,     Training Loss: 0.42658939957618713, Training Acc: 69.64%\n",
      "              Val Loss: 0.8871015906333923, Val Acc: 63.84%\n",
      "Epoch: 3215,     Training Loss: 0.41425931453704834, Training Acc: 69.65%\n",
      "              Val Loss: 0.9047341346740723, Val Acc: 63.84%\n",
      "Epoch: 3216,     Training Loss: 0.43942442536354065, Training Acc: 69.65%\n",
      "              Val Loss: 0.8961129784584045, Val Acc: 63.84%\n",
      "Epoch: 3217,     Training Loss: 0.42985954880714417, Training Acc: 69.66%\n",
      "              Val Loss: 0.8715649247169495, Val Acc: 63.85%\n",
      "Epoch: 3218,     Training Loss: 0.42090728878974915, Training Acc: 69.66%\n",
      "              Val Loss: 0.854351818561554, Val Acc: 63.85%\n",
      "Epoch: 3219,     Training Loss: 0.390060156583786, Training Acc: 69.66%\n",
      "              Val Loss: 0.8939100503921509, Val Acc: 63.85%\n",
      "Epoch: 3220,     Training Loss: 0.41482433676719666, Training Acc: 69.67%\n",
      "              Val Loss: 0.9616341590881348, Val Acc: 63.85%\n",
      "Epoch: 3221,     Training Loss: 0.4893565773963928, Training Acc: 69.67%\n",
      "              Val Loss: 0.9456561207771301, Val Acc: 63.86%\n",
      "Epoch: 3222,     Training Loss: 0.47712910175323486, Training Acc: 69.67%\n",
      "              Val Loss: 0.9351038336753845, Val Acc: 63.86%\n",
      "Epoch: 3223,     Training Loss: 0.4978054463863373, Training Acc: 69.68%\n",
      "              Val Loss: 0.9154760241508484, Val Acc: 63.86%\n",
      "Epoch: 3224,     Training Loss: 0.46726593375205994, Training Acc: 69.68%\n",
      "              Val Loss: 0.8935577273368835, Val Acc: 63.86%\n",
      "Epoch: 3225,     Training Loss: 0.4172905683517456, Training Acc: 69.68%\n",
      "              Val Loss: 0.9584676623344421, Val Acc: 63.86%\n",
      "Epoch: 3226,     Training Loss: 0.4996316134929657, Training Acc: 69.69%\n",
      "              Val Loss: 0.9674070477485657, Val Acc: 63.87%\n",
      "Epoch: 3227,     Training Loss: 0.5019026398658752, Training Acc: 69.69%\n",
      "              Val Loss: 0.9029161334037781, Val Acc: 63.87%\n",
      "Epoch: 3228,     Training Loss: 0.45542535185813904, Training Acc: 69.69%\n",
      "              Val Loss: 0.865887463092804, Val Acc: 63.87%\n",
      "Epoch: 3229,     Training Loss: 0.45196664333343506, Training Acc: 69.70%\n",
      "              Val Loss: 0.8780269026756287, Val Acc: 63.87%\n",
      "Epoch: 3230,     Training Loss: 0.4164446294307709, Training Acc: 69.70%\n",
      "              Val Loss: 1.0116543769836426, Val Acc: 63.88%\n",
      "Epoch: 3231,     Training Loss: 0.5123260021209717, Training Acc: 69.70%\n",
      "              Val Loss: 0.9129837155342102, Val Acc: 63.88%\n",
      "Epoch: 3232,     Training Loss: 0.4457131326198578, Training Acc: 69.71%\n",
      "              Val Loss: 0.910993218421936, Val Acc: 63.88%\n",
      "Epoch: 3233,     Training Loss: 0.47520676255226135, Training Acc: 69.71%\n",
      "              Val Loss: 0.8672277331352234, Val Acc: 63.88%\n",
      "Epoch: 3234,     Training Loss: 0.42306050658226013, Training Acc: 69.71%\n",
      "              Val Loss: 0.8855904936790466, Val Acc: 63.89%\n",
      "Epoch: 3235,     Training Loss: 0.41709527373313904, Training Acc: 69.72%\n",
      "              Val Loss: 0.914741575717926, Val Acc: 63.89%\n",
      "Epoch: 3236,     Training Loss: 0.43802085518836975, Training Acc: 69.72%\n",
      "              Val Loss: 0.9116932153701782, Val Acc: 63.89%\n",
      "Epoch: 3237,     Training Loss: 0.4317758083343506, Training Acc: 69.72%\n",
      "              Val Loss: 0.9610702395439148, Val Acc: 63.89%\n",
      "Epoch: 3238,     Training Loss: 0.4895402491092682, Training Acc: 69.73%\n",
      "              Val Loss: 0.8781452178955078, Val Acc: 63.90%\n",
      "Epoch: 3239,     Training Loss: 0.4268828332424164, Training Acc: 69.73%\n",
      "              Val Loss: 0.8618752360343933, Val Acc: 63.90%\n",
      "Epoch: 3240,     Training Loss: 0.42097482085227966, Training Acc: 69.73%\n",
      "              Val Loss: 0.8965813517570496, Val Acc: 63.90%\n",
      "Epoch: 3241,     Training Loss: 0.42686545848846436, Training Acc: 69.74%\n",
      "              Val Loss: 0.9194011092185974, Val Acc: 63.90%\n",
      "Epoch: 3242,     Training Loss: 0.4368238151073456, Training Acc: 69.74%\n",
      "              Val Loss: 0.8881914615631104, Val Acc: 63.91%\n",
      "Epoch: 3243,     Training Loss: 0.45551207661628723, Training Acc: 69.75%\n",
      "              Val Loss: 0.8650703430175781, Val Acc: 63.91%\n",
      "Epoch: 3244,     Training Loss: 0.41513222455978394, Training Acc: 69.75%\n",
      "              Val Loss: 0.8923854827880859, Val Acc: 63.91%\n",
      "Epoch: 3245,     Training Loss: 0.4145904779434204, Training Acc: 69.75%\n",
      "              Val Loss: 0.8768373131752014, Val Acc: 63.91%\n",
      "Epoch: 3246,     Training Loss: 0.41357001662254333, Training Acc: 69.76%\n",
      "              Val Loss: 0.9190507531166077, Val Acc: 63.92%\n",
      "Epoch: 3247,     Training Loss: 0.4360177516937256, Training Acc: 69.76%\n",
      "              Val Loss: 1.053585410118103, Val Acc: 63.92%\n",
      "Epoch: 3248,     Training Loss: 0.5743120312690735, Training Acc: 69.76%\n",
      "              Val Loss: 0.9141335487365723, Val Acc: 63.92%\n",
      "Epoch: 3249,     Training Loss: 0.4757109582424164, Training Acc: 69.77%\n",
      "              Val Loss: 0.8664458990097046, Val Acc: 63.92%\n",
      "Epoch: 3250,     Training Loss: 0.43604716658592224, Training Acc: 69.77%\n",
      "              Val Loss: 0.8704112768173218, Val Acc: 63.92%\n",
      "Epoch: 3251,     Training Loss: 0.40766972303390503, Training Acc: 69.77%\n",
      "              Val Loss: 0.9085635542869568, Val Acc: 63.93%\n",
      "Epoch: 3252,     Training Loss: 0.4384136497974396, Training Acc: 69.78%\n",
      "              Val Loss: 0.9121083617210388, Val Acc: 63.93%\n",
      "Epoch: 3253,     Training Loss: 0.4852766692638397, Training Acc: 69.78%\n",
      "              Val Loss: 0.8428925275802612, Val Acc: 63.93%\n",
      "Epoch: 3254,     Training Loss: 0.41375142335891724, Training Acc: 69.78%\n",
      "              Val Loss: 0.8740829229354858, Val Acc: 63.93%\n",
      "Epoch: 3255,     Training Loss: 0.42417991161346436, Training Acc: 69.79%\n",
      "              Val Loss: 0.862270712852478, Val Acc: 63.94%\n",
      "Epoch: 3256,     Training Loss: 0.4231542646884918, Training Acc: 69.79%\n",
      "              Val Loss: 0.926016628742218, Val Acc: 63.94%\n",
      "Epoch: 3257,     Training Loss: 0.4697558879852295, Training Acc: 69.80%\n",
      "              Val Loss: 1.0041437149047852, Val Acc: 63.94%\n",
      "Epoch: 3258,     Training Loss: 0.5455885529518127, Training Acc: 69.80%\n",
      "              Val Loss: 0.883421003818512, Val Acc: 63.94%\n",
      "Epoch: 3259,     Training Loss: 0.4480031728744507, Training Acc: 69.80%\n",
      "              Val Loss: 0.8729435801506042, Val Acc: 63.94%\n",
      "Epoch: 3260,     Training Loss: 0.4569969177246094, Training Acc: 69.80%\n",
      "              Val Loss: 0.8910021781921387, Val Acc: 63.95%\n",
      "Epoch: 3261,     Training Loss: 0.46903443336486816, Training Acc: 69.81%\n",
      "              Val Loss: 0.9990036487579346, Val Acc: 63.95%\n",
      "Epoch: 3262,     Training Loss: 0.5196083188056946, Training Acc: 69.81%\n",
      "              Val Loss: 0.904105007648468, Val Acc: 63.95%\n",
      "Epoch: 3263,     Training Loss: 0.4766414761543274, Training Acc: 69.81%\n",
      "              Val Loss: 0.8743566274642944, Val Acc: 63.95%\n",
      "Epoch: 3264,     Training Loss: 0.4585922658443451, Training Acc: 69.82%\n",
      "              Val Loss: 0.8501213788986206, Val Acc: 63.95%\n",
      "Epoch: 3265,     Training Loss: 0.4140033721923828, Training Acc: 69.82%\n",
      "              Val Loss: 0.9702306985855103, Val Acc: 63.96%\n",
      "Epoch: 3266,     Training Loss: 0.5139048099517822, Training Acc: 69.82%\n",
      "              Val Loss: 0.9335850477218628, Val Acc: 63.96%\n",
      "Epoch: 3267,     Training Loss: 0.45028239488601685, Training Acc: 69.83%\n",
      "              Val Loss: 0.9006662964820862, Val Acc: 63.96%\n",
      "Epoch: 3268,     Training Loss: 0.4446404278278351, Training Acc: 69.83%\n",
      "              Val Loss: 0.8798481225967407, Val Acc: 63.96%\n",
      "Epoch: 3269,     Training Loss: 0.4345055818557739, Training Acc: 69.83%\n",
      "              Val Loss: 0.956320583820343, Val Acc: 63.96%\n",
      "Epoch: 3270,     Training Loss: 0.4795590341091156, Training Acc: 69.84%\n",
      "              Val Loss: 0.902596116065979, Val Acc: 63.97%\n",
      "Epoch: 3271,     Training Loss: 0.4719582498073578, Training Acc: 69.84%\n",
      "              Val Loss: 0.9598597884178162, Val Acc: 63.97%\n",
      "Epoch: 3272,     Training Loss: 0.5264406204223633, Training Acc: 69.84%\n",
      "              Val Loss: 1.0766980648040771, Val Acc: 63.97%\n",
      "Epoch: 3273,     Training Loss: 0.6126466393470764, Training Acc: 69.84%\n",
      "              Val Loss: 0.9823099374771118, Val Acc: 63.97%\n",
      "Epoch: 3274,     Training Loss: 0.5208867788314819, Training Acc: 69.84%\n",
      "              Val Loss: 1.016517162322998, Val Acc: 63.97%\n",
      "Epoch: 3275,     Training Loss: 0.5690010786056519, Training Acc: 69.85%\n",
      "              Val Loss: 0.948944091796875, Val Acc: 63.97%\n",
      "Epoch: 3276,     Training Loss: 0.5046769976615906, Training Acc: 69.85%\n",
      "              Val Loss: 1.055814504623413, Val Acc: 63.97%\n",
      "Epoch: 3277,     Training Loss: 0.5767804980278015, Training Acc: 69.85%\n",
      "              Val Loss: 0.9564514756202698, Val Acc: 63.97%\n",
      "Epoch: 3278,     Training Loss: 0.5141710042953491, Training Acc: 69.85%\n",
      "              Val Loss: 0.8964222073554993, Val Acc: 63.98%\n",
      "Epoch: 3279,     Training Loss: 0.5115841031074524, Training Acc: 69.86%\n",
      "              Val Loss: 0.8164427280426025, Val Acc: 63.98%\n",
      "Epoch: 3280,     Training Loss: 0.41446149349212646, Training Acc: 69.86%\n",
      "              Val Loss: 0.913168728351593, Val Acc: 63.98%\n",
      "Epoch: 3281,     Training Loss: 0.47302302718162537, Training Acc: 69.86%\n",
      "              Val Loss: 0.8633716106414795, Val Acc: 63.98%\n",
      "Epoch: 3282,     Training Loss: 0.41868478059768677, Training Acc: 69.87%\n",
      "              Val Loss: 0.8659327626228333, Val Acc: 63.99%\n",
      "Epoch: 3283,     Training Loss: 0.4493488371372223, Training Acc: 69.87%\n",
      "              Val Loss: 0.8359018564224243, Val Acc: 63.99%\n",
      "Epoch: 3284,     Training Loss: 0.4293889105319977, Training Acc: 69.87%\n",
      "              Val Loss: 0.901505708694458, Val Acc: 63.99%\n",
      "Epoch: 3285,     Training Loss: 0.4752206802368164, Training Acc: 69.88%\n",
      "              Val Loss: 0.9063205122947693, Val Acc: 63.99%\n",
      "Epoch: 3286,     Training Loss: 0.4792453348636627, Training Acc: 69.88%\n",
      "              Val Loss: 0.9157170653343201, Val Acc: 63.99%\n",
      "Epoch: 3287,     Training Loss: 0.47070634365081787, Training Acc: 69.88%\n",
      "              Val Loss: 0.8746387958526611, Val Acc: 64.00%\n",
      "Epoch: 3288,     Training Loss: 0.44873031973838806, Training Acc: 69.89%\n",
      "              Val Loss: 0.851112425327301, Val Acc: 64.00%\n",
      "Epoch: 3289,     Training Loss: 0.4280443489551544, Training Acc: 69.89%\n",
      "              Val Loss: 0.8246587514877319, Val Acc: 64.00%\n",
      "Epoch: 3290,     Training Loss: 0.4066000282764435, Training Acc: 69.89%\n",
      "              Val Loss: 0.8640663027763367, Val Acc: 64.00%\n",
      "Epoch: 3291,     Training Loss: 0.4426017105579376, Training Acc: 69.90%\n",
      "              Val Loss: 0.8827006816864014, Val Acc: 64.01%\n",
      "Epoch: 3292,     Training Loss: 0.4278385043144226, Training Acc: 69.90%\n",
      "              Val Loss: 0.8728991150856018, Val Acc: 64.01%\n",
      "Epoch: 3293,     Training Loss: 0.41910240054130554, Training Acc: 69.90%\n",
      "              Val Loss: 0.8419430255889893, Val Acc: 64.01%\n",
      "Epoch: 3294,     Training Loss: 0.39482319355010986, Training Acc: 69.91%\n",
      "              Val Loss: 0.8545776605606079, Val Acc: 64.01%\n",
      "Epoch: 3295,     Training Loss: 0.42108023166656494, Training Acc: 69.91%\n",
      "              Val Loss: 0.8888852000236511, Val Acc: 64.02%\n",
      "Epoch: 3296,     Training Loss: 0.4489506483078003, Training Acc: 69.92%\n",
      "              Val Loss: 0.9012367725372314, Val Acc: 64.02%\n",
      "Epoch: 3297,     Training Loss: 0.43868598341941833, Training Acc: 69.92%\n",
      "              Val Loss: 0.8524911999702454, Val Acc: 64.02%\n",
      "Epoch: 3298,     Training Loss: 0.4103175103664398, Training Acc: 69.92%\n",
      "              Val Loss: 0.8383394479751587, Val Acc: 64.03%\n",
      "Epoch: 3299,     Training Loss: 0.3963662087917328, Training Acc: 69.93%\n",
      "              Val Loss: 0.8654447793960571, Val Acc: 64.03%\n",
      "Epoch: 3300,     Training Loss: 0.413024365901947, Training Acc: 69.93%\n",
      "              Val Loss: 0.9083920121192932, Val Acc: 64.03%\n",
      "Epoch: 3301,     Training Loss: 0.4573756158351898, Training Acc: 69.93%\n",
      "              Val Loss: 0.879944920539856, Val Acc: 64.03%\n",
      "Epoch: 3302,     Training Loss: 0.423979252576828, Training Acc: 69.94%\n",
      "              Val Loss: 0.8457954525947571, Val Acc: 64.03%\n",
      "Epoch: 3303,     Training Loss: 0.4104452133178711, Training Acc: 69.94%\n",
      "              Val Loss: 0.8348690271377563, Val Acc: 64.04%\n",
      "Epoch: 3304,     Training Loss: 0.39500921964645386, Training Acc: 69.95%\n",
      "              Val Loss: 0.8350919485092163, Val Acc: 64.04%\n",
      "Epoch: 3305,     Training Loss: 0.3917909562587738, Training Acc: 69.95%\n",
      "              Val Loss: 0.845207929611206, Val Acc: 64.04%\n",
      "Epoch: 3306,     Training Loss: 0.40993908047676086, Training Acc: 69.95%\n",
      "              Val Loss: 0.8697769045829773, Val Acc: 64.04%\n",
      "Epoch: 3307,     Training Loss: 0.41678905487060547, Training Acc: 69.96%\n",
      "              Val Loss: 0.8736392855644226, Val Acc: 64.05%\n",
      "Epoch: 3308,     Training Loss: 0.4216848313808441, Training Acc: 69.96%\n",
      "              Val Loss: 0.8538150191307068, Val Acc: 64.05%\n",
      "Epoch: 3309,     Training Loss: 0.39732101559638977, Training Acc: 69.97%\n",
      "              Val Loss: 0.8403791785240173, Val Acc: 64.05%\n",
      "Epoch: 3310,     Training Loss: 0.39289695024490356, Training Acc: 69.97%\n",
      "              Val Loss: 0.8412551879882812, Val Acc: 64.06%\n",
      "Epoch: 3311,     Training Loss: 0.3913177251815796, Training Acc: 69.97%\n",
      "              Val Loss: 0.8487896919250488, Val Acc: 64.06%\n",
      "Epoch: 3312,     Training Loss: 0.39528176188468933, Training Acc: 69.98%\n",
      "              Val Loss: 0.8393928408622742, Val Acc: 64.06%\n",
      "Epoch: 3313,     Training Loss: 0.3975985050201416, Training Acc: 69.98%\n",
      "              Val Loss: 0.8658206462860107, Val Acc: 64.06%\n",
      "Epoch: 3314,     Training Loss: 0.41788250207901, Training Acc: 69.99%\n",
      "              Val Loss: 0.9471438527107239, Val Acc: 64.06%\n",
      "Epoch: 3315,     Training Loss: 0.4996657073497772, Training Acc: 69.99%\n",
      "              Val Loss: 0.9471620321273804, Val Acc: 64.07%\n",
      "Epoch: 3316,     Training Loss: 0.4958403706550598, Training Acc: 69.99%\n",
      "              Val Loss: 0.9445006847381592, Val Acc: 64.07%\n",
      "Epoch: 3317,     Training Loss: 0.5055683255195618, Training Acc: 69.99%\n",
      "              Val Loss: 0.8594470024108887, Val Acc: 64.07%\n",
      "Epoch: 3318,     Training Loss: 0.4115005135536194, Training Acc: 70.00%\n",
      "              Val Loss: 0.894273579120636, Val Acc: 64.07%\n",
      "Epoch: 3319,     Training Loss: 0.42501193284988403, Training Acc: 70.00%\n",
      "              Val Loss: 0.940991222858429, Val Acc: 64.07%\n",
      "Epoch: 3320,     Training Loss: 0.4897206127643585, Training Acc: 70.00%\n",
      "              Val Loss: 0.9017167091369629, Val Acc: 64.08%\n",
      "Epoch: 3321,     Training Loss: 0.45626944303512573, Training Acc: 70.01%\n",
      "              Val Loss: 0.8725696802139282, Val Acc: 64.08%\n",
      "Epoch: 3322,     Training Loss: 0.4262969493865967, Training Acc: 70.01%\n",
      "              Val Loss: 0.8384281992912292, Val Acc: 64.08%\n",
      "Epoch: 3323,     Training Loss: 0.3920985162258148, Training Acc: 70.02%\n",
      "              Val Loss: 0.8768367171287537, Val Acc: 64.08%\n",
      "Epoch: 3324,     Training Loss: 0.4224192500114441, Training Acc: 70.02%\n",
      "              Val Loss: 0.8866399526596069, Val Acc: 64.08%\n",
      "Epoch: 3325,     Training Loss: 0.4344508647918701, Training Acc: 70.02%\n",
      "              Val Loss: 0.8671238422393799, Val Acc: 64.09%\n",
      "Epoch: 3326,     Training Loss: 0.4056764841079712, Training Acc: 70.03%\n",
      "              Val Loss: 0.8307557702064514, Val Acc: 64.09%\n",
      "Epoch: 3327,     Training Loss: 0.393290251493454, Training Acc: 70.03%\n",
      "              Val Loss: 0.839357852935791, Val Acc: 64.09%\n",
      "Epoch: 3328,     Training Loss: 0.4065868854522705, Training Acc: 70.04%\n",
      "              Val Loss: 0.8815545439720154, Val Acc: 64.09%\n",
      "Epoch: 3329,     Training Loss: 0.41739243268966675, Training Acc: 70.04%\n",
      "              Val Loss: 0.8986272215843201, Val Acc: 64.10%\n",
      "Epoch: 3330,     Training Loss: 0.4454691708087921, Training Acc: 70.04%\n",
      "              Val Loss: 0.870026707649231, Val Acc: 64.10%\n",
      "Epoch: 3331,     Training Loss: 0.41528889536857605, Training Acc: 70.05%\n",
      "              Val Loss: 0.8469750285148621, Val Acc: 64.10%\n",
      "Epoch: 3332,     Training Loss: 0.39994603395462036, Training Acc: 70.05%\n",
      "              Val Loss: 0.8492158651351929, Val Acc: 64.10%\n",
      "Epoch: 3333,     Training Loss: 0.3923201262950897, Training Acc: 70.05%\n",
      "              Val Loss: 0.8681240677833557, Val Acc: 64.11%\n",
      "Epoch: 3334,     Training Loss: 0.400899201631546, Training Acc: 70.06%\n",
      "              Val Loss: 0.8726814389228821, Val Acc: 64.11%\n",
      "Epoch: 3335,     Training Loss: 0.4075889587402344, Training Acc: 70.06%\n",
      "              Val Loss: 0.8643211126327515, Val Acc: 64.11%\n",
      "Epoch: 3336,     Training Loss: 0.39558014273643494, Training Acc: 70.07%\n",
      "              Val Loss: 0.8591404557228088, Val Acc: 64.11%\n",
      "Epoch: 3337,     Training Loss: 0.3982923924922943, Training Acc: 70.07%\n",
      "              Val Loss: 0.8665651082992554, Val Acc: 64.12%\n",
      "Epoch: 3338,     Training Loss: 0.4007212817668915, Training Acc: 70.07%\n",
      "              Val Loss: 0.8459072709083557, Val Acc: 64.12%\n",
      "Epoch: 3339,     Training Loss: 0.38289645314216614, Training Acc: 70.08%\n",
      "              Val Loss: 0.8469756245613098, Val Acc: 64.12%\n",
      "Epoch: 3340,     Training Loss: 0.3797650635242462, Training Acc: 70.08%\n",
      "              Val Loss: 0.8508718609809875, Val Acc: 64.13%\n",
      "Epoch: 3341,     Training Loss: 0.38199496269226074, Training Acc: 70.09%\n",
      "              Val Loss: 0.8490231037139893, Val Acc: 64.13%\n",
      "Epoch: 3342,     Training Loss: 0.3795701563358307, Training Acc: 70.09%\n",
      "              Val Loss: 0.8534594774246216, Val Acc: 64.13%\n",
      "Epoch: 3343,     Training Loss: 0.37930184602737427, Training Acc: 70.10%\n",
      "              Val Loss: 0.8606314063072205, Val Acc: 64.13%\n",
      "Epoch: 3344,     Training Loss: 0.38630542159080505, Training Acc: 70.10%\n",
      "              Val Loss: 0.8745517134666443, Val Acc: 64.14%\n",
      "Epoch: 3345,     Training Loss: 0.39677634835243225, Training Acc: 70.10%\n",
      "              Val Loss: 0.9272375702857971, Val Acc: 64.14%\n",
      "Epoch: 3346,     Training Loss: 0.4514094293117523, Training Acc: 70.11%\n",
      "              Val Loss: 0.9322043061256409, Val Acc: 64.14%\n",
      "Epoch: 3347,     Training Loss: 0.46086910367012024, Training Acc: 70.11%\n",
      "              Val Loss: 0.9643878936767578, Val Acc: 64.14%\n",
      "Epoch: 3348,     Training Loss: 0.4990815818309784, Training Acc: 70.11%\n",
      "              Val Loss: 0.8794805407524109, Val Acc: 64.14%\n",
      "Epoch: 3349,     Training Loss: 0.4129032790660858, Training Acc: 70.12%\n",
      "              Val Loss: 0.8640539050102234, Val Acc: 64.15%\n",
      "Epoch: 3350,     Training Loss: 0.3885481655597687, Training Acc: 70.12%\n",
      "              Val Loss: 0.9283270239830017, Val Acc: 64.15%\n",
      "Epoch: 3351,     Training Loss: 0.4473690390586853, Training Acc: 70.12%\n",
      "              Val Loss: 0.9316724538803101, Val Acc: 64.15%\n",
      "Epoch: 3352,     Training Loss: 0.44428500533103943, Training Acc: 70.13%\n",
      "              Val Loss: 0.879730761051178, Val Acc: 64.15%\n",
      "Epoch: 3353,     Training Loss: 0.4180297553539276, Training Acc: 70.13%\n",
      "              Val Loss: 0.8477176427841187, Val Acc: 64.16%\n",
      "Epoch: 3354,     Training Loss: 0.3842734396457672, Training Acc: 70.13%\n",
      "              Val Loss: 0.8741590976715088, Val Acc: 64.16%\n",
      "Epoch: 3355,     Training Loss: 0.4042735695838928, Training Acc: 70.14%\n",
      "              Val Loss: 0.8953620791435242, Val Acc: 64.16%\n",
      "Epoch: 3356,     Training Loss: 0.4309770464897156, Training Acc: 70.14%\n",
      "              Val Loss: 0.8736907243728638, Val Acc: 64.16%\n",
      "Epoch: 3357,     Training Loss: 0.39883288741111755, Training Acc: 70.15%\n",
      "              Val Loss: 0.8487424254417419, Val Acc: 64.17%\n",
      "Epoch: 3358,     Training Loss: 0.3853415548801422, Training Acc: 70.15%\n",
      "              Val Loss: 0.8475136756896973, Val Acc: 64.17%\n",
      "Epoch: 3359,     Training Loss: 0.3860282897949219, Training Acc: 70.15%\n",
      "              Val Loss: 0.8720341324806213, Val Acc: 64.17%\n",
      "Epoch: 3360,     Training Loss: 0.39841148257255554, Training Acc: 70.16%\n",
      "              Val Loss: 0.9069280028343201, Val Acc: 64.17%\n",
      "Epoch: 3361,     Training Loss: 0.44042667746543884, Training Acc: 70.16%\n",
      "              Val Loss: 0.8959411382675171, Val Acc: 64.18%\n",
      "Epoch: 3362,     Training Loss: 0.4275602400302887, Training Acc: 70.17%\n",
      "              Val Loss: 0.88169264793396, Val Acc: 64.18%\n",
      "Epoch: 3363,     Training Loss: 0.4181849956512451, Training Acc: 70.17%\n",
      "              Val Loss: 0.8545700907707214, Val Acc: 64.18%\n",
      "Epoch: 3364,     Training Loss: 0.38892027735710144, Training Acc: 70.17%\n",
      "              Val Loss: 0.8802911639213562, Val Acc: 64.18%\n",
      "Epoch: 3365,     Training Loss: 0.4054272472858429, Training Acc: 70.18%\n",
      "              Val Loss: 0.9137812852859497, Val Acc: 64.18%\n",
      "Epoch: 3366,     Training Loss: 0.4364214837551117, Training Acc: 70.18%\n",
      "              Val Loss: 0.8918142914772034, Val Acc: 64.19%\n",
      "Epoch: 3367,     Training Loss: 0.4210570454597473, Training Acc: 70.18%\n",
      "              Val Loss: 0.9103105664253235, Val Acc: 64.19%\n",
      "Epoch: 3368,     Training Loss: 0.4514794945716858, Training Acc: 70.19%\n",
      "              Val Loss: 0.9102550745010376, Val Acc: 64.19%\n",
      "Epoch: 3369,     Training Loss: 0.43414291739463806, Training Acc: 70.19%\n",
      "              Val Loss: 0.8601219654083252, Val Acc: 64.19%\n",
      "Epoch: 3370,     Training Loss: 0.3820692300796509, Training Acc: 70.19%\n",
      "              Val Loss: 0.8815815448760986, Val Acc: 64.20%\n",
      "Epoch: 3371,     Training Loss: 0.4079609215259552, Training Acc: 70.20%\n",
      "              Val Loss: 0.8903776407241821, Val Acc: 64.20%\n",
      "Epoch: 3372,     Training Loss: 0.41420406103134155, Training Acc: 70.20%\n",
      "              Val Loss: 0.8868356943130493, Val Acc: 64.20%\n",
      "Epoch: 3373,     Training Loss: 0.41118985414505005, Training Acc: 70.21%\n",
      "              Val Loss: 0.8849422931671143, Val Acc: 64.20%\n",
      "Epoch: 3374,     Training Loss: 0.41335529088974, Training Acc: 70.21%\n",
      "              Val Loss: 0.863974928855896, Val Acc: 64.20%\n",
      "Epoch: 3375,     Training Loss: 0.3874691426753998, Training Acc: 70.21%\n",
      "              Val Loss: 0.8863926529884338, Val Acc: 64.21%\n",
      "Epoch: 3376,     Training Loss: 0.4099549949169159, Training Acc: 70.22%\n",
      "              Val Loss: 0.8963958024978638, Val Acc: 64.21%\n",
      "Epoch: 3377,     Training Loss: 0.4213365912437439, Training Acc: 70.22%\n",
      "              Val Loss: 0.917499840259552, Val Acc: 64.21%\n",
      "Epoch: 3378,     Training Loss: 0.44929829239845276, Training Acc: 70.22%\n",
      "              Val Loss: 0.9502888321876526, Val Acc: 64.21%\n",
      "Epoch: 3379,     Training Loss: 0.46877792477607727, Training Acc: 70.23%\n",
      "              Val Loss: 0.8920285701751709, Val Acc: 64.22%\n",
      "Epoch: 3380,     Training Loss: 0.40091851353645325, Training Acc: 70.23%\n",
      "              Val Loss: 0.89404296875, Val Acc: 64.22%\n",
      "Epoch: 3381,     Training Loss: 0.3974528908729553, Training Acc: 70.23%\n",
      "              Val Loss: 0.8955633044242859, Val Acc: 64.22%\n",
      "Epoch: 3382,     Training Loss: 0.4000304043292999, Training Acc: 70.24%\n",
      "              Val Loss: 0.9060909152030945, Val Acc: 64.22%\n",
      "Epoch: 3383,     Training Loss: 0.4195954501628876, Training Acc: 70.24%\n",
      "              Val Loss: 0.9165542125701904, Val Acc: 64.22%\n",
      "Epoch: 3384,     Training Loss: 0.44336333870887756, Training Acc: 70.24%\n",
      "              Val Loss: 0.8766891360282898, Val Acc: 64.23%\n",
      "Epoch: 3385,     Training Loss: 0.41303932666778564, Training Acc: 70.25%\n",
      "              Val Loss: 0.8666199445724487, Val Acc: 64.23%\n",
      "Epoch: 3386,     Training Loss: 0.39605849981307983, Training Acc: 70.25%\n",
      "              Val Loss: 0.8762046098709106, Val Acc: 64.23%\n",
      "Epoch: 3387,     Training Loss: 0.406652569770813, Training Acc: 70.26%\n",
      "              Val Loss: 0.8944803476333618, Val Acc: 64.23%\n",
      "Epoch: 3388,     Training Loss: 0.4195438325405121, Training Acc: 70.26%\n",
      "              Val Loss: 0.9193338751792908, Val Acc: 64.24%\n",
      "Epoch: 3389,     Training Loss: 0.42863884568214417, Training Acc: 70.26%\n",
      "              Val Loss: 0.9077475070953369, Val Acc: 64.24%\n",
      "Epoch: 3390,     Training Loss: 0.42498016357421875, Training Acc: 70.27%\n",
      "              Val Loss: 0.8985176682472229, Val Acc: 64.24%\n",
      "Epoch: 3391,     Training Loss: 0.41058361530303955, Training Acc: 70.27%\n",
      "              Val Loss: 0.8970328569412231, Val Acc: 64.24%\n",
      "Epoch: 3392,     Training Loss: 0.41364482045173645, Training Acc: 70.27%\n",
      "              Val Loss: 0.8813665509223938, Val Acc: 64.25%\n",
      "Epoch: 3393,     Training Loss: 0.39917537569999695, Training Acc: 70.28%\n",
      "              Val Loss: 0.8725188374519348, Val Acc: 64.25%\n",
      "Epoch: 3394,     Training Loss: 0.39224278926849365, Training Acc: 70.28%\n",
      "              Val Loss: 0.8618451952934265, Val Acc: 64.25%\n",
      "Epoch: 3395,     Training Loss: 0.38156282901763916, Training Acc: 70.29%\n",
      "              Val Loss: 0.8651425242424011, Val Acc: 64.25%\n",
      "Epoch: 3396,     Training Loss: 0.3830573558807373, Training Acc: 70.29%\n",
      "              Val Loss: 0.8772017955780029, Val Acc: 64.26%\n",
      "Epoch: 3397,     Training Loss: 0.3929257094860077, Training Acc: 70.29%\n",
      "              Val Loss: 0.9034818410873413, Val Acc: 64.26%\n",
      "Epoch: 3398,     Training Loss: 0.40505656599998474, Training Acc: 70.30%\n",
      "              Val Loss: 0.9085192680358887, Val Acc: 64.26%\n",
      "Epoch: 3399,     Training Loss: 0.41797757148742676, Training Acc: 70.30%\n",
      "              Val Loss: 0.9117072224617004, Val Acc: 64.26%\n",
      "Epoch: 3400,     Training Loss: 0.42996281385421753, Training Acc: 70.30%\n",
      "              Val Loss: 0.9548114538192749, Val Acc: 64.26%\n",
      "Epoch: 3401,     Training Loss: 0.4648386836051941, Training Acc: 70.31%\n",
      "              Val Loss: 0.9078128337860107, Val Acc: 64.27%\n",
      "Epoch: 3402,     Training Loss: 0.4200607240200043, Training Acc: 70.31%\n",
      "              Val Loss: 0.8864890336990356, Val Acc: 64.27%\n",
      "Epoch: 3403,     Training Loss: 0.40495169162750244, Training Acc: 70.31%\n",
      "              Val Loss: 0.8895204067230225, Val Acc: 64.27%\n",
      "Epoch: 3404,     Training Loss: 0.3940722942352295, Training Acc: 70.32%\n",
      "              Val Loss: 0.8826109170913696, Val Acc: 64.27%\n",
      "Epoch: 3405,     Training Loss: 0.39508959650993347, Training Acc: 70.32%\n",
      "              Val Loss: 0.9078018665313721, Val Acc: 64.28%\n",
      "Epoch: 3406,     Training Loss: 0.4227455258369446, Training Acc: 70.33%\n",
      "              Val Loss: 0.9167229533195496, Val Acc: 64.28%\n",
      "Epoch: 3407,     Training Loss: 0.4180210828781128, Training Acc: 70.33%\n",
      "              Val Loss: 0.8909506797790527, Val Acc: 64.28%\n",
      "Epoch: 3408,     Training Loss: 0.40310946106910706, Training Acc: 70.33%\n",
      "              Val Loss: 0.8966596126556396, Val Acc: 64.28%\n",
      "Epoch: 3409,     Training Loss: 0.3999730944633484, Training Acc: 70.34%\n",
      "              Val Loss: 0.863003671169281, Val Acc: 64.28%\n",
      "Epoch: 3410,     Training Loss: 0.3836645483970642, Training Acc: 70.34%\n",
      "              Val Loss: 0.8650153279304504, Val Acc: 64.29%\n",
      "Epoch: 3411,     Training Loss: 0.3797278106212616, Training Acc: 70.34%\n",
      "              Val Loss: 0.8765777349472046, Val Acc: 64.29%\n",
      "Epoch: 3412,     Training Loss: 0.40360382199287415, Training Acc: 70.35%\n",
      "              Val Loss: 0.9481593370437622, Val Acc: 64.29%\n",
      "Epoch: 3413,     Training Loss: 0.46393585205078125, Training Acc: 70.35%\n",
      "              Val Loss: 0.9519805908203125, Val Acc: 64.29%\n",
      "Epoch: 3414,     Training Loss: 0.4837864935398102, Training Acc: 70.35%\n",
      "              Val Loss: 1.1393238306045532, Val Acc: 64.29%\n",
      "Epoch: 3415,     Training Loss: 0.6603632569313049, Training Acc: 70.35%\n",
      "              Val Loss: 0.9507772922515869, Val Acc: 64.29%\n",
      "Epoch: 3416,     Training Loss: 0.4764992892742157, Training Acc: 70.36%\n",
      "              Val Loss: 0.9099875688552856, Val Acc: 64.30%\n",
      "Epoch: 3417,     Training Loss: 0.42053696513175964, Training Acc: 70.36%\n",
      "              Val Loss: 1.0632197856903076, Val Acc: 64.30%\n",
      "Epoch: 3418,     Training Loss: 0.5757401585578918, Training Acc: 70.36%\n",
      "              Val Loss: 0.9386062026023865, Val Acc: 64.30%\n",
      "Epoch: 3419,     Training Loss: 0.45761433243751526, Training Acc: 70.36%\n",
      "              Val Loss: 0.8739610910415649, Val Acc: 64.30%\n",
      "Epoch: 3420,     Training Loss: 0.4203975200653076, Training Acc: 70.37%\n",
      "              Val Loss: 0.9839735627174377, Val Acc: 64.30%\n",
      "Epoch: 3421,     Training Loss: 0.5111016035079956, Training Acc: 70.37%\n",
      "              Val Loss: 0.9047559499740601, Val Acc: 64.30%\n",
      "Epoch: 3422,     Training Loss: 0.42225414514541626, Training Acc: 70.37%\n",
      "              Val Loss: 0.890153169631958, Val Acc: 64.31%\n",
      "Epoch: 3423,     Training Loss: 0.4120149314403534, Training Acc: 70.38%\n",
      "              Val Loss: 0.9058704376220703, Val Acc: 64.31%\n",
      "Epoch: 3424,     Training Loss: 0.4479407072067261, Training Acc: 70.38%\n",
      "              Val Loss: 0.8575074076652527, Val Acc: 64.31%\n",
      "Epoch: 3425,     Training Loss: 0.40753886103630066, Training Acc: 70.38%\n",
      "              Val Loss: 0.8430473208427429, Val Acc: 64.31%\n",
      "Epoch: 3426,     Training Loss: 0.39849552512168884, Training Acc: 70.39%\n",
      "              Val Loss: 0.8613654375076294, Val Acc: 64.32%\n",
      "Epoch: 3427,     Training Loss: 0.4030102491378784, Training Acc: 70.39%\n",
      "              Val Loss: 0.8758378028869629, Val Acc: 64.32%\n",
      "Epoch: 3428,     Training Loss: 0.4016040861606598, Training Acc: 70.40%\n",
      "              Val Loss: 0.8783727288246155, Val Acc: 64.32%\n",
      "Epoch: 3429,     Training Loss: 0.3957437574863434, Training Acc: 70.40%\n",
      "              Val Loss: 0.8504151701927185, Val Acc: 64.32%\n",
      "Epoch: 3430,     Training Loss: 0.379176527261734, Training Acc: 70.40%\n",
      "              Val Loss: 0.8471938967704773, Val Acc: 64.33%\n",
      "Epoch: 3431,     Training Loss: 0.38652074337005615, Training Acc: 70.41%\n",
      "              Val Loss: 0.8614611029624939, Val Acc: 64.33%\n",
      "Epoch: 3432,     Training Loss: 0.3875156044960022, Training Acc: 70.41%\n",
      "              Val Loss: 0.862273097038269, Val Acc: 64.33%\n",
      "Epoch: 3433,     Training Loss: 0.37923526763916016, Training Acc: 70.42%\n",
      "              Val Loss: 0.8657832145690918, Val Acc: 64.33%\n",
      "Epoch: 3434,     Training Loss: 0.38545912504196167, Training Acc: 70.42%\n",
      "              Val Loss: 0.8673872351646423, Val Acc: 64.34%\n",
      "Epoch: 3435,     Training Loss: 0.3787727653980255, Training Acc: 70.42%\n",
      "              Val Loss: 0.8477544188499451, Val Acc: 64.34%\n",
      "Epoch: 3436,     Training Loss: 0.3732115626335144, Training Acc: 70.43%\n",
      "              Val Loss: 0.8548588752746582, Val Acc: 64.34%\n",
      "Epoch: 3437,     Training Loss: 0.3766564130783081, Training Acc: 70.43%\n",
      "              Val Loss: 0.8698026537895203, Val Acc: 64.34%\n",
      "Epoch: 3438,     Training Loss: 0.37530452013015747, Training Acc: 70.44%\n",
      "              Val Loss: 0.8762955665588379, Val Acc: 64.35%\n",
      "Epoch: 3439,     Training Loss: 0.37384527921676636, Training Acc: 70.44%\n",
      "              Val Loss: 0.8923293948173523, Val Acc: 64.35%\n",
      "Epoch: 3440,     Training Loss: 0.3835776150226593, Training Acc: 70.44%\n",
      "              Val Loss: 0.9381958246231079, Val Acc: 64.35%\n",
      "Epoch: 3441,     Training Loss: 0.42816460132598877, Training Acc: 70.45%\n",
      "              Val Loss: 0.9239503741264343, Val Acc: 64.35%\n",
      "Epoch: 3442,     Training Loss: 0.4237108528614044, Training Acc: 70.45%\n",
      "              Val Loss: 0.9357016086578369, Val Acc: 64.36%\n",
      "Epoch: 3443,     Training Loss: 0.43366891145706177, Training Acc: 70.45%\n",
      "              Val Loss: 0.9176448583602905, Val Acc: 64.36%\n",
      "Epoch: 3444,     Training Loss: 0.39822664856910706, Training Acc: 70.46%\n",
      "              Val Loss: 0.8989099860191345, Val Acc: 64.36%\n",
      "Epoch: 3445,     Training Loss: 0.3776084780693054, Training Acc: 70.46%\n",
      "              Val Loss: 0.9382668137550354, Val Acc: 64.36%\n",
      "Epoch: 3446,     Training Loss: 0.42288097739219666, Training Acc: 70.47%\n",
      "              Val Loss: 0.9580151438713074, Val Acc: 64.36%\n",
      "Epoch: 3447,     Training Loss: 0.44687870144844055, Training Acc: 70.47%\n",
      "              Val Loss: 0.9351969957351685, Val Acc: 64.37%\n",
      "Epoch: 3448,     Training Loss: 0.4400614798069, Training Acc: 70.47%\n",
      "              Val Loss: 0.9218905568122864, Val Acc: 64.37%\n",
      "Epoch: 3449,     Training Loss: 0.42391690611839294, Training Acc: 70.48%\n",
      "              Val Loss: 0.8760215640068054, Val Acc: 64.37%\n",
      "Epoch: 3450,     Training Loss: 0.38698115944862366, Training Acc: 70.48%\n",
      "              Val Loss: 0.8937762975692749, Val Acc: 64.37%\n",
      "Epoch: 3451,     Training Loss: 0.3902933895587921, Training Acc: 70.48%\n",
      "              Val Loss: 0.901763916015625, Val Acc: 64.37%\n",
      "Epoch: 3452,     Training Loss: 0.4075380265712738, Training Acc: 70.49%\n",
      "              Val Loss: 0.9034637212753296, Val Acc: 64.38%\n",
      "Epoch: 3453,     Training Loss: 0.41364216804504395, Training Acc: 70.49%\n",
      "              Val Loss: 0.8996421694755554, Val Acc: 64.38%\n",
      "Epoch: 3454,     Training Loss: 0.40648365020751953, Training Acc: 70.49%\n",
      "              Val Loss: 0.8916784524917603, Val Acc: 64.38%\n",
      "Epoch: 3455,     Training Loss: 0.4144156277179718, Training Acc: 70.50%\n",
      "              Val Loss: 0.9017536044120789, Val Acc: 64.38%\n",
      "Epoch: 3456,     Training Loss: 0.3920367360115051, Training Acc: 70.50%\n",
      "              Val Loss: 0.9057061076164246, Val Acc: 64.38%\n",
      "Epoch: 3457,     Training Loss: 0.3941989541053772, Training Acc: 70.50%\n",
      "              Val Loss: 0.9079450964927673, Val Acc: 64.39%\n",
      "Epoch: 3458,     Training Loss: 0.3874598443508148, Training Acc: 70.51%\n",
      "              Val Loss: 0.8856980204582214, Val Acc: 64.39%\n",
      "Epoch: 3459,     Training Loss: 0.3911561965942383, Training Acc: 70.51%\n",
      "              Val Loss: 0.9128670692443848, Val Acc: 64.39%\n",
      "Epoch: 3460,     Training Loss: 0.3982974588871002, Training Acc: 70.52%\n",
      "              Val Loss: 0.8841024041175842, Val Acc: 64.39%\n",
      "Epoch: 3461,     Training Loss: 0.38584330677986145, Training Acc: 70.52%\n",
      "              Val Loss: 0.9151960611343384, Val Acc: 64.40%\n",
      "Epoch: 3462,     Training Loss: 0.4147661626338959, Training Acc: 70.52%\n",
      "              Val Loss: 0.9254281520843506, Val Acc: 64.40%\n",
      "Epoch: 3463,     Training Loss: 0.4159415364265442, Training Acc: 70.53%\n",
      "              Val Loss: 0.9469887018203735, Val Acc: 64.40%\n",
      "Epoch: 3464,     Training Loss: 0.4345240294933319, Training Acc: 70.53%\n",
      "              Val Loss: 0.917458713054657, Val Acc: 64.40%\n",
      "Epoch: 3465,     Training Loss: 0.4069799482822418, Training Acc: 70.53%\n",
      "              Val Loss: 0.8886470794677734, Val Acc: 64.41%\n",
      "Epoch: 3466,     Training Loss: 0.38431331515312195, Training Acc: 70.54%\n",
      "              Val Loss: 0.878315269947052, Val Acc: 64.41%\n",
      "Epoch: 3467,     Training Loss: 0.36988207697868347, Training Acc: 70.54%\n",
      "              Val Loss: 0.9042646288871765, Val Acc: 64.41%\n",
      "Epoch: 3468,     Training Loss: 0.396716833114624, Training Acc: 70.55%\n",
      "              Val Loss: 0.9660972356796265, Val Acc: 64.41%\n",
      "Epoch: 3469,     Training Loss: 0.44577357172966003, Training Acc: 70.55%\n",
      "              Val Loss: 0.9232243299484253, Val Acc: 64.41%\n",
      "Epoch: 3470,     Training Loss: 0.41643717885017395, Training Acc: 70.55%\n",
      "              Val Loss: 0.9036985635757446, Val Acc: 64.42%\n",
      "Epoch: 3471,     Training Loss: 0.4076557457447052, Training Acc: 70.56%\n",
      "              Val Loss: 0.8750416040420532, Val Acc: 64.42%\n",
      "Epoch: 3472,     Training Loss: 0.3796529769897461, Training Acc: 70.56%\n",
      "              Val Loss: 0.8775936961174011, Val Acc: 64.42%\n",
      "Epoch: 3473,     Training Loss: 0.3839128911495209, Training Acc: 70.56%\n",
      "              Val Loss: 0.9256322979927063, Val Acc: 64.42%\n",
      "Epoch: 3474,     Training Loss: 0.4219663739204407, Training Acc: 70.57%\n",
      "              Val Loss: 0.921471118927002, Val Acc: 64.42%\n",
      "Epoch: 3475,     Training Loss: 0.4094821810722351, Training Acc: 70.57%\n",
      "              Val Loss: 0.8835515379905701, Val Acc: 64.43%\n",
      "Epoch: 3476,     Training Loss: 0.3815668225288391, Training Acc: 70.57%\n",
      "              Val Loss: 0.8727253675460815, Val Acc: 64.43%\n",
      "Epoch: 3477,     Training Loss: 0.3702167868614197, Training Acc: 70.58%\n",
      "              Val Loss: 0.8907010555267334, Val Acc: 64.43%\n",
      "Epoch: 3478,     Training Loss: 0.374501496553421, Training Acc: 70.58%\n",
      "              Val Loss: 0.9068050980567932, Val Acc: 64.43%\n",
      "Epoch: 3479,     Training Loss: 0.3902951180934906, Training Acc: 70.59%\n",
      "              Val Loss: 0.9081764221191406, Val Acc: 64.44%\n",
      "Epoch: 3480,     Training Loss: 0.3866654336452484, Training Acc: 70.59%\n",
      "              Val Loss: 0.9070851802825928, Val Acc: 64.44%\n",
      "Epoch: 3481,     Training Loss: 0.3924478590488434, Training Acc: 70.59%\n",
      "              Val Loss: 0.8888766765594482, Val Acc: 64.44%\n",
      "Epoch: 3482,     Training Loss: 0.3838927447795868, Training Acc: 70.60%\n",
      "              Val Loss: 0.893906831741333, Val Acc: 64.44%\n",
      "Epoch: 3483,     Training Loss: 0.38808009028434753, Training Acc: 70.60%\n",
      "              Val Loss: 0.8912374377250671, Val Acc: 64.45%\n",
      "Epoch: 3484,     Training Loss: 0.38368239998817444, Training Acc: 70.60%\n",
      "              Val Loss: 0.9079421162605286, Val Acc: 64.45%\n",
      "Epoch: 3485,     Training Loss: 0.3845888078212738, Training Acc: 70.61%\n",
      "              Val Loss: 0.9086195230484009, Val Acc: 64.45%\n",
      "Epoch: 3486,     Training Loss: 0.39339762926101685, Training Acc: 70.61%\n",
      "              Val Loss: 0.927367091178894, Val Acc: 64.45%\n",
      "Epoch: 3487,     Training Loss: 0.39512908458709717, Training Acc: 70.62%\n",
      "              Val Loss: 0.9182055592536926, Val Acc: 64.45%\n",
      "Epoch: 3488,     Training Loss: 0.41206714510917664, Training Acc: 70.62%\n",
      "              Val Loss: 0.907210111618042, Val Acc: 64.46%\n",
      "Epoch: 3489,     Training Loss: 0.38858139514923096, Training Acc: 70.62%\n",
      "              Val Loss: 0.8951424360275269, Val Acc: 64.46%\n",
      "Epoch: 3490,     Training Loss: 0.38961952924728394, Training Acc: 70.63%\n",
      "              Val Loss: 0.9122050404548645, Val Acc: 64.46%\n",
      "Epoch: 3491,     Training Loss: 0.4064527750015259, Training Acc: 70.63%\n",
      "              Val Loss: 1.0796643495559692, Val Acc: 64.46%\n",
      "Epoch: 3492,     Training Loss: 0.546384334564209, Training Acc: 70.63%\n",
      "              Val Loss: 1.0293570756912231, Val Acc: 64.46%\n",
      "Epoch: 3493,     Training Loss: 0.5332306027412415, Training Acc: 70.63%\n",
      "              Val Loss: 1.068981647491455, Val Acc: 64.46%\n",
      "Epoch: 3494,     Training Loss: 0.5529449582099915, Training Acc: 70.64%\n",
      "              Val Loss: 0.9120001196861267, Val Acc: 64.46%\n",
      "Epoch: 3495,     Training Loss: 0.41297218203544617, Training Acc: 70.64%\n",
      "              Val Loss: 0.9479316473007202, Val Acc: 64.47%\n",
      "Epoch: 3496,     Training Loss: 0.45878174901008606, Training Acc: 70.64%\n",
      "              Val Loss: 1.0363976955413818, Val Acc: 64.47%\n",
      "Epoch: 3497,     Training Loss: 0.5117762684822083, Training Acc: 70.64%\n",
      "              Val Loss: 0.9358049035072327, Val Acc: 64.47%\n",
      "Epoch: 3498,     Training Loss: 0.42093443870544434, Training Acc: 70.65%\n",
      "              Val Loss: 0.9865376949310303, Val Acc: 64.47%\n",
      "Epoch: 3499,     Training Loss: 0.503705620765686, Training Acc: 70.65%\n",
      "              Val Loss: 1.0070856809616089, Val Acc: 64.47%\n",
      "Epoch: 3500,     Training Loss: 0.5263524055480957, Training Acc: 70.65%\n",
      "              Val Loss: 0.9669883847236633, Val Acc: 64.47%\n",
      "Epoch: 3501,     Training Loss: 0.4947342574596405, Training Acc: 70.65%\n",
      "              Val Loss: 1.0850363969802856, Val Acc: 64.47%\n",
      "Epoch: 3502,     Training Loss: 0.6354210376739502, Training Acc: 70.66%\n",
      "              Val Loss: 0.9205070734024048, Val Acc: 64.48%\n",
      "Epoch: 3503,     Training Loss: 0.4525105655193329, Training Acc: 70.66%\n",
      "              Val Loss: 1.0960969924926758, Val Acc: 64.48%\n",
      "Epoch: 3504,     Training Loss: 0.5929054617881775, Training Acc: 70.66%\n",
      "              Val Loss: 1.0015486478805542, Val Acc: 64.48%\n",
      "Epoch: 3505,     Training Loss: 0.5355167984962463, Training Acc: 70.66%\n",
      "              Val Loss: 0.9918283224105835, Val Acc: 64.48%\n",
      "Epoch: 3506,     Training Loss: 0.5409606099128723, Training Acc: 70.66%\n",
      "              Val Loss: 1.0497419834136963, Val Acc: 64.48%\n",
      "Epoch: 3507,     Training Loss: 0.6187333464622498, Training Acc: 70.66%\n",
      "              Val Loss: 1.0606603622436523, Val Acc: 64.48%\n",
      "Epoch: 3508,     Training Loss: 0.5470399856567383, Training Acc: 70.66%\n",
      "              Val Loss: 0.9795382022857666, Val Acc: 64.48%\n",
      "Epoch: 3509,     Training Loss: 0.5152967572212219, Training Acc: 70.67%\n",
      "              Val Loss: 0.8848549723625183, Val Acc: 64.48%\n",
      "Epoch: 3510,     Training Loss: 0.4723791778087616, Training Acc: 70.67%\n",
      "              Val Loss: 0.9539708495140076, Val Acc: 64.48%\n",
      "Epoch: 3511,     Training Loss: 0.4946568012237549, Training Acc: 70.67%\n",
      "              Val Loss: 0.9705116152763367, Val Acc: 64.49%\n",
      "Epoch: 3512,     Training Loss: 0.4646513760089874, Training Acc: 70.67%\n",
      "              Val Loss: 0.888733983039856, Val Acc: 64.49%\n",
      "Epoch: 3513,     Training Loss: 0.4360307455062866, Training Acc: 70.68%\n",
      "              Val Loss: 0.8902608752250671, Val Acc: 64.49%\n",
      "Epoch: 3514,     Training Loss: 0.45980384945869446, Training Acc: 70.68%\n",
      "              Val Loss: 0.9171730279922485, Val Acc: 64.49%\n",
      "Epoch: 3515,     Training Loss: 0.4938874840736389, Training Acc: 70.68%\n",
      "              Val Loss: 0.9227449297904968, Val Acc: 64.49%\n",
      "Epoch: 3516,     Training Loss: 0.4610537588596344, Training Acc: 70.69%\n",
      "              Val Loss: 1.010311245918274, Val Acc: 64.50%\n",
      "Epoch: 3517,     Training Loss: 0.5457316637039185, Training Acc: 70.69%\n",
      "              Val Loss: 0.9268349409103394, Val Acc: 64.50%\n",
      "Epoch: 3518,     Training Loss: 0.4577820301055908, Training Acc: 70.69%\n",
      "              Val Loss: 0.9233201742172241, Val Acc: 64.50%\n",
      "Epoch: 3519,     Training Loss: 0.4728257656097412, Training Acc: 70.69%\n",
      "              Val Loss: 0.9010661244392395, Val Acc: 64.50%\n",
      "Epoch: 3520,     Training Loss: 0.41897159814834595, Training Acc: 70.70%\n",
      "              Val Loss: 0.9728935360908508, Val Acc: 64.50%\n",
      "Epoch: 3521,     Training Loss: 0.4670633375644684, Training Acc: 70.70%\n",
      "              Val Loss: 0.847669243812561, Val Acc: 64.51%\n",
      "Epoch: 3522,     Training Loss: 0.4027572572231293, Training Acc: 70.70%\n",
      "              Val Loss: 0.875318169593811, Val Acc: 64.51%\n",
      "Epoch: 3523,     Training Loss: 0.4470498561859131, Training Acc: 70.71%\n",
      "              Val Loss: 0.863010585308075, Val Acc: 64.51%\n",
      "Epoch: 3524,     Training Loss: 0.42249980568885803, Training Acc: 70.71%\n",
      "              Val Loss: 0.9488186836242676, Val Acc: 64.51%\n",
      "Epoch: 3525,     Training Loss: 0.48830777406692505, Training Acc: 70.71%\n",
      "              Val Loss: 0.97906893491745, Val Acc: 64.51%\n",
      "Epoch: 3526,     Training Loss: 0.5040649175643921, Training Acc: 70.71%\n",
      "              Val Loss: 0.9999750256538391, Val Acc: 64.51%\n",
      "Epoch: 3527,     Training Loss: 0.546150803565979, Training Acc: 70.72%\n",
      "              Val Loss: 0.9406579732894897, Val Acc: 64.52%\n",
      "Epoch: 3528,     Training Loss: 0.453016996383667, Training Acc: 70.72%\n",
      "              Val Loss: 0.9591873288154602, Val Acc: 64.52%\n",
      "Epoch: 3529,     Training Loss: 0.4278929829597473, Training Acc: 70.72%\n",
      "              Val Loss: 0.9655355215072632, Val Acc: 64.52%\n",
      "Epoch: 3530,     Training Loss: 0.44707736372947693, Training Acc: 70.72%\n",
      "              Val Loss: 0.9517427086830139, Val Acc: 64.52%\n",
      "Epoch: 3531,     Training Loss: 0.45344096422195435, Training Acc: 70.73%\n",
      "              Val Loss: 0.921384334564209, Val Acc: 64.52%\n",
      "Epoch: 3532,     Training Loss: 0.44860324263572693, Training Acc: 70.73%\n",
      "              Val Loss: 0.9064461588859558, Val Acc: 64.53%\n",
      "Epoch: 3533,     Training Loss: 0.4178313910961151, Training Acc: 70.73%\n",
      "              Val Loss: 0.8733637928962708, Val Acc: 64.53%\n",
      "Epoch: 3534,     Training Loss: 0.3877764642238617, Training Acc: 70.74%\n",
      "              Val Loss: 0.894986629486084, Val Acc: 64.53%\n",
      "Epoch: 3535,     Training Loss: 0.40696826577186584, Training Acc: 70.74%\n",
      "              Val Loss: 0.9081050157546997, Val Acc: 64.53%\n",
      "Epoch: 3536,     Training Loss: 0.40028780698776245, Training Acc: 70.74%\n",
      "              Val Loss: 0.9201174378395081, Val Acc: 64.53%\n",
      "Epoch: 3537,     Training Loss: 0.4131843149662018, Training Acc: 70.75%\n",
      "              Val Loss: 0.8854966759681702, Val Acc: 64.54%\n",
      "Epoch: 3538,     Training Loss: 0.3842160105705261, Training Acc: 70.75%\n",
      "              Val Loss: 0.8902651071548462, Val Acc: 64.54%\n",
      "Epoch: 3539,     Training Loss: 0.38993996381759644, Training Acc: 70.75%\n",
      "              Val Loss: 0.8917925953865051, Val Acc: 64.54%\n",
      "Epoch: 3540,     Training Loss: 0.38890698552131653, Training Acc: 70.76%\n",
      "              Val Loss: 0.920581042766571, Val Acc: 64.54%\n",
      "Epoch: 3541,     Training Loss: 0.41164645552635193, Training Acc: 70.76%\n",
      "              Val Loss: 0.9317724704742432, Val Acc: 64.55%\n",
      "Epoch: 3542,     Training Loss: 0.45174625515937805, Training Acc: 70.76%\n",
      "              Val Loss: 0.9230158925056458, Val Acc: 64.55%\n",
      "Epoch: 3543,     Training Loss: 0.4599546492099762, Training Acc: 70.77%\n",
      "              Val Loss: 1.0114072561264038, Val Acc: 64.55%\n",
      "Epoch: 3544,     Training Loss: 0.5433666110038757, Training Acc: 70.77%\n",
      "              Val Loss: 0.9332998394966125, Val Acc: 64.55%\n",
      "Epoch: 3545,     Training Loss: 0.4541643559932709, Training Acc: 70.77%\n",
      "              Val Loss: 0.8959865570068359, Val Acc: 64.55%\n",
      "Epoch: 3546,     Training Loss: 0.4125387668609619, Training Acc: 70.78%\n",
      "              Val Loss: 0.9257194995880127, Val Acc: 64.55%\n",
      "Epoch: 3547,     Training Loss: 0.433488130569458, Training Acc: 70.78%\n",
      "              Val Loss: 0.9896618723869324, Val Acc: 64.55%\n",
      "Epoch: 3548,     Training Loss: 0.48150837421417236, Training Acc: 70.78%\n",
      "              Val Loss: 0.9255130887031555, Val Acc: 64.56%\n",
      "Epoch: 3549,     Training Loss: 0.4489152431488037, Training Acc: 70.78%\n",
      "              Val Loss: 0.8710960149765015, Val Acc: 64.56%\n",
      "Epoch: 3550,     Training Loss: 0.4096847474575043, Training Acc: 70.79%\n",
      "              Val Loss: 0.8806325793266296, Val Acc: 64.56%\n",
      "Epoch: 3551,     Training Loss: 0.3956242799758911, Training Acc: 70.79%\n",
      "              Val Loss: 0.9458897113800049, Val Acc: 64.56%\n",
      "Epoch: 3552,     Training Loss: 0.45019540190696716, Training Acc: 70.79%\n",
      "              Val Loss: 0.9028175473213196, Val Acc: 64.56%\n",
      "Epoch: 3553,     Training Loss: 0.4042706787586212, Training Acc: 70.80%\n",
      "              Val Loss: 0.8696002960205078, Val Acc: 64.57%\n",
      "Epoch: 3554,     Training Loss: 0.3891981840133667, Training Acc: 70.80%\n",
      "              Val Loss: 0.8577884435653687, Val Acc: 64.57%\n",
      "Epoch: 3555,     Training Loss: 0.3809233009815216, Training Acc: 70.80%\n",
      "              Val Loss: 0.8845331072807312, Val Acc: 64.57%\n",
      "Epoch: 3556,     Training Loss: 0.3941112458705902, Training Acc: 70.81%\n",
      "              Val Loss: 0.8850435614585876, Val Acc: 64.57%\n",
      "Epoch: 3557,     Training Loss: 0.41683050990104675, Training Acc: 70.81%\n",
      "              Val Loss: 0.9015194177627563, Val Acc: 64.58%\n",
      "Epoch: 3558,     Training Loss: 0.4270395040512085, Training Acc: 70.81%\n",
      "              Val Loss: 0.9598256945610046, Val Acc: 64.58%\n",
      "Epoch: 3559,     Training Loss: 0.4827651083469391, Training Acc: 70.82%\n",
      "              Val Loss: 0.9233891367912292, Val Acc: 64.58%\n",
      "Epoch: 3560,     Training Loss: 0.4377487897872925, Training Acc: 70.82%\n",
      "              Val Loss: 0.896635890007019, Val Acc: 64.58%\n",
      "Epoch: 3561,     Training Loss: 0.41259774565696716, Training Acc: 70.82%\n",
      "              Val Loss: 0.9031606912612915, Val Acc: 64.58%\n",
      "Epoch: 3562,     Training Loss: 0.3993302583694458, Training Acc: 70.83%\n",
      "              Val Loss: 0.9732650518417358, Val Acc: 64.58%\n",
      "Epoch: 3563,     Training Loss: 0.45558860898017883, Training Acc: 70.83%\n",
      "              Val Loss: 0.9646278619766235, Val Acc: 64.59%\n",
      "Epoch: 3564,     Training Loss: 0.4747689366340637, Training Acc: 70.83%\n",
      "              Val Loss: 0.898166835308075, Val Acc: 64.59%\n",
      "Epoch: 3565,     Training Loss: 0.42714256048202515, Training Acc: 70.84%\n",
      "              Val Loss: 0.8681834936141968, Val Acc: 64.59%\n",
      "Epoch: 3566,     Training Loss: 0.3809109032154083, Training Acc: 70.84%\n",
      "              Val Loss: 0.9056443572044373, Val Acc: 64.59%\n",
      "Epoch: 3567,     Training Loss: 0.3957853615283966, Training Acc: 70.84%\n",
      "              Val Loss: 0.9314310550689697, Val Acc: 64.59%\n",
      "Epoch: 3568,     Training Loss: 0.4029169976711273, Training Acc: 70.85%\n",
      "              Val Loss: 0.9269562363624573, Val Acc: 64.60%\n",
      "Epoch: 3569,     Training Loss: 0.3983740210533142, Training Acc: 70.85%\n",
      "              Val Loss: 0.907645046710968, Val Acc: 64.60%\n",
      "Epoch: 3570,     Training Loss: 0.3777681291103363, Training Acc: 70.85%\n",
      "              Val Loss: 0.8935549259185791, Val Acc: 64.60%\n",
      "Epoch: 3571,     Training Loss: 0.37242385745048523, Training Acc: 70.86%\n",
      "              Val Loss: 0.8940731287002563, Val Acc: 64.60%\n",
      "Epoch: 3572,     Training Loss: 0.38905879855155945, Training Acc: 70.86%\n",
      "              Val Loss: 0.9110377430915833, Val Acc: 64.60%\n",
      "Epoch: 3573,     Training Loss: 0.40508225560188293, Training Acc: 70.86%\n",
      "              Val Loss: 0.9924877882003784, Val Acc: 64.61%\n",
      "Epoch: 3574,     Training Loss: 0.48845064640045166, Training Acc: 70.87%\n",
      "              Val Loss: 0.982788622379303, Val Acc: 64.61%\n",
      "Epoch: 3575,     Training Loss: 0.47552192211151123, Training Acc: 70.87%\n",
      "              Val Loss: 0.972455620765686, Val Acc: 64.61%\n",
      "Epoch: 3576,     Training Loss: 0.4858591556549072, Training Acc: 70.87%\n",
      "              Val Loss: 0.9000470042228699, Val Acc: 64.61%\n",
      "Epoch: 3577,     Training Loss: 0.40351536870002747, Training Acc: 70.87%\n",
      "              Val Loss: 0.9612987637519836, Val Acc: 64.61%\n",
      "Epoch: 3578,     Training Loss: 0.4382808804512024, Training Acc: 70.88%\n",
      "              Val Loss: 1.0025168657302856, Val Acc: 64.61%\n",
      "Epoch: 3579,     Training Loss: 0.4984983503818512, Training Acc: 70.88%\n",
      "              Val Loss: 0.9524607062339783, Val Acc: 64.61%\n",
      "Epoch: 3580,     Training Loss: 0.45584654808044434, Training Acc: 70.88%\n",
      "              Val Loss: 0.8835515379905701, Val Acc: 64.62%\n",
      "Epoch: 3581,     Training Loss: 0.3866291046142578, Training Acc: 70.89%\n",
      "              Val Loss: 0.9084227085113525, Val Acc: 64.62%\n",
      "Epoch: 3582,     Training Loss: 0.40602874755859375, Training Acc: 70.89%\n",
      "              Val Loss: 0.9176565408706665, Val Acc: 64.62%\n",
      "Epoch: 3583,     Training Loss: 0.4088941514492035, Training Acc: 70.89%\n",
      "              Val Loss: 0.917805552482605, Val Acc: 64.62%\n",
      "Epoch: 3584,     Training Loss: 0.41053155064582825, Training Acc: 70.90%\n",
      "              Val Loss: 0.8865001201629639, Val Acc: 64.63%\n",
      "Epoch: 3585,     Training Loss: 0.3771570324897766, Training Acc: 70.90%\n",
      "              Val Loss: 0.8983055353164673, Val Acc: 64.63%\n",
      "Epoch: 3586,     Training Loss: 0.39067986607551575, Training Acc: 70.90%\n",
      "              Val Loss: 0.9083602428436279, Val Acc: 64.63%\n",
      "Epoch: 3587,     Training Loss: 0.4104360342025757, Training Acc: 70.91%\n",
      "              Val Loss: 0.9268478155136108, Val Acc: 64.63%\n",
      "Epoch: 3588,     Training Loss: 0.4119299352169037, Training Acc: 70.91%\n",
      "              Val Loss: 0.9604529738426208, Val Acc: 64.63%\n",
      "Epoch: 3589,     Training Loss: 0.4482114315032959, Training Acc: 70.91%\n",
      "              Val Loss: 0.9209812879562378, Val Acc: 64.64%\n",
      "Epoch: 3590,     Training Loss: 0.40214332938194275, Training Acc: 70.92%\n",
      "              Val Loss: 0.9182512760162354, Val Acc: 64.64%\n",
      "Epoch: 3591,     Training Loss: 0.4007166624069214, Training Acc: 70.92%\n",
      "              Val Loss: 0.9251163005828857, Val Acc: 64.64%\n",
      "Epoch: 3592,     Training Loss: 0.3941824734210968, Training Acc: 70.92%\n",
      "              Val Loss: 0.9422408938407898, Val Acc: 64.64%\n",
      "Epoch: 3593,     Training Loss: 0.4096643924713135, Training Acc: 70.93%\n",
      "              Val Loss: 0.9262731075286865, Val Acc: 64.64%\n",
      "Epoch: 3594,     Training Loss: 0.41997969150543213, Training Acc: 70.93%\n",
      "              Val Loss: 0.8949028849601746, Val Acc: 64.65%\n",
      "Epoch: 3595,     Training Loss: 0.4044041335582733, Training Acc: 70.93%\n",
      "              Val Loss: 0.8851110935211182, Val Acc: 64.65%\n",
      "Epoch: 3596,     Training Loss: 0.3792147934436798, Training Acc: 70.94%\n",
      "              Val Loss: 0.9131572842597961, Val Acc: 64.65%\n",
      "Epoch: 3597,     Training Loss: 0.38469964265823364, Training Acc: 70.94%\n",
      "              Val Loss: 0.9093633890151978, Val Acc: 64.65%\n",
      "Epoch: 3598,     Training Loss: 0.37285739183425903, Training Acc: 70.94%\n",
      "              Val Loss: 0.9362194538116455, Val Acc: 64.66%\n",
      "Epoch: 3599,     Training Loss: 0.3874467611312866, Training Acc: 70.95%\n",
      "              Val Loss: 0.9323735237121582, Val Acc: 64.66%\n",
      "Epoch: 3600,     Training Loss: 0.3805862367153168, Training Acc: 70.95%\n",
      "              Val Loss: 0.918378472328186, Val Acc: 64.66%\n",
      "Epoch: 3601,     Training Loss: 0.37982434034347534, Training Acc: 70.95%\n",
      "              Val Loss: 0.9168846011161804, Val Acc: 64.66%\n",
      "Epoch: 3602,     Training Loss: 0.3947583734989166, Training Acc: 70.96%\n",
      "              Val Loss: 0.9587481617927551, Val Acc: 64.66%\n",
      "Epoch: 3603,     Training Loss: 0.4343205988407135, Training Acc: 70.96%\n",
      "              Val Loss: 1.0117602348327637, Val Acc: 64.66%\n",
      "Epoch: 3604,     Training Loss: 0.47519081830978394, Training Acc: 70.96%\n",
      "              Val Loss: 1.1325713396072388, Val Acc: 64.66%\n",
      "Epoch: 3605,     Training Loss: 0.6007663607597351, Training Acc: 70.96%\n",
      "              Val Loss: 0.9690843820571899, Val Acc: 64.67%\n",
      "Epoch: 3606,     Training Loss: 0.45693692564964294, Training Acc: 70.97%\n",
      "              Val Loss: 0.8931260108947754, Val Acc: 64.67%\n",
      "Epoch: 3607,     Training Loss: 0.4041174650192261, Training Acc: 70.97%\n",
      "              Val Loss: 0.9371512532234192, Val Acc: 64.67%\n",
      "Epoch: 3608,     Training Loss: 0.446814626455307, Training Acc: 70.97%\n",
      "              Val Loss: 0.9183415770530701, Val Acc: 64.67%\n",
      "Epoch: 3609,     Training Loss: 0.4329650402069092, Training Acc: 70.98%\n",
      "              Val Loss: 0.8832217454910278, Val Acc: 64.67%\n",
      "Epoch: 3610,     Training Loss: 0.3938228189945221, Training Acc: 70.98%\n",
      "              Val Loss: 0.8848490118980408, Val Acc: 64.68%\n",
      "Epoch: 3611,     Training Loss: 0.385191947221756, Training Acc: 70.98%\n",
      "              Val Loss: 0.9212654232978821, Val Acc: 64.68%\n",
      "Epoch: 3612,     Training Loss: 0.4061566889286041, Training Acc: 70.99%\n",
      "              Val Loss: 0.9153887033462524, Val Acc: 64.68%\n",
      "Epoch: 3613,     Training Loss: 0.4237930178642273, Training Acc: 70.99%\n",
      "              Val Loss: 0.8797869682312012, Val Acc: 64.68%\n",
      "Epoch: 3614,     Training Loss: 0.38383427262306213, Training Acc: 70.99%\n",
      "              Val Loss: 0.8998838663101196, Val Acc: 64.68%\n",
      "Epoch: 3615,     Training Loss: 0.39432910084724426, Training Acc: 71.00%\n",
      "              Val Loss: 0.8944053649902344, Val Acc: 64.69%\n",
      "Epoch: 3616,     Training Loss: 0.40287643671035767, Training Acc: 71.00%\n",
      "              Val Loss: 0.9105120897293091, Val Acc: 64.69%\n",
      "Epoch: 3617,     Training Loss: 0.3985517919063568, Training Acc: 71.00%\n",
      "              Val Loss: 0.9063007831573486, Val Acc: 64.69%\n",
      "Epoch: 3618,     Training Loss: 0.38881585001945496, Training Acc: 71.01%\n",
      "              Val Loss: 0.9024128913879395, Val Acc: 64.69%\n",
      "Epoch: 3619,     Training Loss: 0.37682002782821655, Training Acc: 71.01%\n",
      "              Val Loss: 0.8936710953712463, Val Acc: 64.70%\n",
      "Epoch: 3620,     Training Loss: 0.3754194676876068, Training Acc: 71.01%\n",
      "              Val Loss: 0.906613290309906, Val Acc: 64.70%\n",
      "Epoch: 3621,     Training Loss: 0.39125025272369385, Training Acc: 71.02%\n",
      "              Val Loss: 0.9208624958992004, Val Acc: 64.70%\n",
      "Epoch: 3622,     Training Loss: 0.39630669355392456, Training Acc: 71.02%\n",
      "              Val Loss: 0.8966548442840576, Val Acc: 64.70%\n",
      "Epoch: 3623,     Training Loss: 0.3774349093437195, Training Acc: 71.03%\n",
      "              Val Loss: 0.9203231334686279, Val Acc: 64.70%\n",
      "Epoch: 3624,     Training Loss: 0.39324820041656494, Training Acc: 71.03%\n",
      "              Val Loss: 0.9128842353820801, Val Acc: 64.71%\n",
      "Epoch: 3625,     Training Loss: 0.3926342725753784, Training Acc: 71.03%\n",
      "              Val Loss: 0.9036740064620972, Val Acc: 64.71%\n",
      "Epoch: 3626,     Training Loss: 0.38240882754325867, Training Acc: 71.04%\n",
      "              Val Loss: 0.9037581086158752, Val Acc: 64.71%\n",
      "Epoch: 3627,     Training Loss: 0.3860132098197937, Training Acc: 71.04%\n",
      "              Val Loss: 0.9057908058166504, Val Acc: 64.71%\n",
      "Epoch: 3628,     Training Loss: 0.3848223090171814, Training Acc: 71.04%\n",
      "              Val Loss: 0.928275465965271, Val Acc: 64.71%\n",
      "Epoch: 3629,     Training Loss: 0.3926425576210022, Training Acc: 71.05%\n",
      "              Val Loss: 0.9553373456001282, Val Acc: 64.72%\n",
      "Epoch: 3630,     Training Loss: 0.4245395362377167, Training Acc: 71.05%\n",
      "              Val Loss: 0.9435955882072449, Val Acc: 64.72%\n",
      "Epoch: 3631,     Training Loss: 0.4149499237537384, Training Acc: 71.05%\n",
      "              Val Loss: 0.9478381276130676, Val Acc: 64.72%\n",
      "Epoch: 3632,     Training Loss: 0.4104066491127014, Training Acc: 71.05%\n",
      "              Val Loss: 0.9267127513885498, Val Acc: 64.72%\n",
      "Epoch: 3633,     Training Loss: 0.3760296106338501, Training Acc: 71.06%\n",
      "              Val Loss: 0.9142335653305054, Val Acc: 64.72%\n",
      "Epoch: 3634,     Training Loss: 0.36833199858665466, Training Acc: 71.06%\n",
      "              Val Loss: 0.9219332933425903, Val Acc: 64.73%\n",
      "Epoch: 3635,     Training Loss: 0.387716680765152, Training Acc: 71.07%\n",
      "              Val Loss: 0.9231610298156738, Val Acc: 64.73%\n",
      "Epoch: 3636,     Training Loss: 0.3947560787200928, Training Acc: 71.07%\n",
      "              Val Loss: 0.9052939414978027, Val Acc: 64.73%\n",
      "Epoch: 3637,     Training Loss: 0.39399176836013794, Training Acc: 71.07%\n",
      "              Val Loss: 0.8786272406578064, Val Acc: 64.73%\n",
      "Epoch: 3638,     Training Loss: 0.3704429566860199, Training Acc: 71.08%\n",
      "              Val Loss: 0.8935497999191284, Val Acc: 64.73%\n",
      "Epoch: 3639,     Training Loss: 0.3678048849105835, Training Acc: 71.08%\n",
      "              Val Loss: 0.9144720435142517, Val Acc: 64.74%\n",
      "Epoch: 3640,     Training Loss: 0.38167130947113037, Training Acc: 71.08%\n",
      "              Val Loss: 0.9198188185691833, Val Acc: 64.74%\n",
      "Epoch: 3641,     Training Loss: 0.37751033902168274, Training Acc: 71.09%\n",
      "              Val Loss: 0.9311621189117432, Val Acc: 64.74%\n",
      "Epoch: 3642,     Training Loss: 0.39005330204963684, Training Acc: 71.09%\n",
      "              Val Loss: 0.9250701665878296, Val Acc: 64.74%\n",
      "Epoch: 3643,     Training Loss: 0.37654492259025574, Training Acc: 71.09%\n",
      "              Val Loss: 0.918973982334137, Val Acc: 64.74%\n",
      "Epoch: 3644,     Training Loss: 0.3724951446056366, Training Acc: 71.10%\n",
      "              Val Loss: 0.9155023694038391, Val Acc: 64.75%\n",
      "Epoch: 3645,     Training Loss: 0.3624383211135864, Training Acc: 71.10%\n",
      "              Val Loss: 0.9068892598152161, Val Acc: 64.75%\n",
      "Epoch: 3646,     Training Loss: 0.358541339635849, Training Acc: 71.11%\n",
      "              Val Loss: 0.9027115702629089, Val Acc: 64.75%\n",
      "Epoch: 3647,     Training Loss: 0.3593771457672119, Training Acc: 71.11%\n",
      "              Val Loss: 0.9049710035324097, Val Acc: 64.75%\n",
      "Epoch: 3648,     Training Loss: 0.36644333600997925, Training Acc: 71.11%\n",
      "              Val Loss: 0.9443010687828064, Val Acc: 64.76%\n",
      "Epoch: 3649,     Training Loss: 0.41005784273147583, Training Acc: 71.12%\n",
      "              Val Loss: 0.9704822301864624, Val Acc: 64.76%\n",
      "Epoch: 3650,     Training Loss: 0.43734169006347656, Training Acc: 71.12%\n",
      "              Val Loss: 1.117490291595459, Val Acc: 64.76%\n",
      "Epoch: 3651,     Training Loss: 0.588191568851471, Training Acc: 71.12%\n",
      "              Val Loss: 0.9526548981666565, Val Acc: 64.76%\n",
      "Epoch: 3652,     Training Loss: 0.43290284276008606, Training Acc: 71.12%\n",
      "              Val Loss: 0.8988421559333801, Val Acc: 64.76%\n",
      "Epoch: 3653,     Training Loss: 0.37792107462882996, Training Acc: 71.13%\n",
      "              Val Loss: 0.9850640296936035, Val Acc: 64.76%\n",
      "Epoch: 3654,     Training Loss: 0.44684723019599915, Training Acc: 71.13%\n",
      "              Val Loss: 0.9438363909721375, Val Acc: 64.76%\n",
      "Epoch: 3655,     Training Loss: 0.41355571150779724, Training Acc: 71.13%\n",
      "              Val Loss: 0.889545738697052, Val Acc: 64.77%\n",
      "Epoch: 3656,     Training Loss: 0.3785662055015564, Training Acc: 71.14%\n",
      "              Val Loss: 0.8993205428123474, Val Acc: 64.77%\n",
      "Epoch: 3657,     Training Loss: 0.3884241580963135, Training Acc: 71.14%\n",
      "              Val Loss: 0.9313029646873474, Val Acc: 64.77%\n",
      "Epoch: 3658,     Training Loss: 0.4010756015777588, Training Acc: 71.14%\n",
      "              Val Loss: 0.9189302325248718, Val Acc: 64.77%\n",
      "Epoch: 3659,     Training Loss: 0.3985372483730316, Training Acc: 71.15%\n",
      "              Val Loss: 0.8937472701072693, Val Acc: 64.77%\n",
      "Epoch: 3660,     Training Loss: 0.36601412296295166, Training Acc: 71.15%\n",
      "              Val Loss: 0.9118295311927795, Val Acc: 64.78%\n",
      "Epoch: 3661,     Training Loss: 0.37941277027130127, Training Acc: 71.15%\n",
      "              Val Loss: 0.9327251315116882, Val Acc: 64.78%\n",
      "Epoch: 3662,     Training Loss: 0.4138481020927429, Training Acc: 71.16%\n",
      "              Val Loss: 0.9315896034240723, Val Acc: 64.78%\n",
      "Epoch: 3663,     Training Loss: 0.3953978419303894, Training Acc: 71.16%\n",
      "              Val Loss: 0.9343855977058411, Val Acc: 64.78%\n",
      "Epoch: 3664,     Training Loss: 0.40438011288642883, Training Acc: 71.16%\n",
      "              Val Loss: 0.9091014266014099, Val Acc: 64.78%\n",
      "Epoch: 3665,     Training Loss: 0.3702259957790375, Training Acc: 71.17%\n",
      "              Val Loss: 0.9164019227027893, Val Acc: 64.79%\n",
      "Epoch: 3666,     Training Loss: 0.3729074001312256, Training Acc: 71.17%\n",
      "              Val Loss: 0.9387103319168091, Val Acc: 64.79%\n",
      "Epoch: 3667,     Training Loss: 0.3884912133216858, Training Acc: 71.17%\n",
      "              Val Loss: 0.9369201064109802, Val Acc: 64.79%\n",
      "Epoch: 3668,     Training Loss: 0.38548511266708374, Training Acc: 71.18%\n",
      "              Val Loss: 0.9129804968833923, Val Acc: 64.79%\n",
      "Epoch: 3669,     Training Loss: 0.3783095180988312, Training Acc: 71.18%\n",
      "              Val Loss: 0.8967037796974182, Val Acc: 64.79%\n",
      "Epoch: 3670,     Training Loss: 0.363554984331131, Training Acc: 71.19%\n",
      "              Val Loss: 0.9151204824447632, Val Acc: 64.80%\n",
      "Epoch: 3671,     Training Loss: 0.37291350960731506, Training Acc: 71.19%\n",
      "              Val Loss: 0.9147167205810547, Val Acc: 64.80%\n",
      "Epoch: 3672,     Training Loss: 0.3882898688316345, Training Acc: 71.19%\n",
      "              Val Loss: 0.9289810657501221, Val Acc: 64.80%\n",
      "Epoch: 3673,     Training Loss: 0.40274181962013245, Training Acc: 71.20%\n",
      "              Val Loss: 1.003274917602539, Val Acc: 64.80%\n",
      "Epoch: 3674,     Training Loss: 0.46422362327575684, Training Acc: 71.20%\n",
      "              Val Loss: 0.9451144933700562, Val Acc: 64.80%\n",
      "Epoch: 3675,     Training Loss: 0.4020884037017822, Training Acc: 71.20%\n",
      "              Val Loss: 0.9262744188308716, Val Acc: 64.81%\n",
      "Epoch: 3676,     Training Loss: 0.3791556656360626, Training Acc: 71.20%\n",
      "              Val Loss: 0.9508636593818665, Val Acc: 64.81%\n",
      "Epoch: 3677,     Training Loss: 0.3844972848892212, Training Acc: 71.21%\n",
      "              Val Loss: 0.9999964237213135, Val Acc: 64.81%\n",
      "Epoch: 3678,     Training Loss: 0.4158655107021332, Training Acc: 71.21%\n",
      "              Val Loss: 0.9641866087913513, Val Acc: 64.81%\n",
      "Epoch: 3679,     Training Loss: 0.4173091948032379, Training Acc: 71.21%\n",
      "              Val Loss: 0.9504411816596985, Val Acc: 64.81%\n",
      "Epoch: 3680,     Training Loss: 0.41426756978034973, Training Acc: 71.22%\n",
      "              Val Loss: 0.9243801236152649, Val Acc: 64.81%\n",
      "Epoch: 3681,     Training Loss: 0.39360561966896057, Training Acc: 71.22%\n",
      "              Val Loss: 0.9076633453369141, Val Acc: 64.82%\n",
      "Epoch: 3682,     Training Loss: 0.3903898000717163, Training Acc: 71.22%\n",
      "              Val Loss: 0.9401291608810425, Val Acc: 64.82%\n",
      "Epoch: 3683,     Training Loss: 0.4099947214126587, Training Acc: 71.23%\n",
      "              Val Loss: 0.9301463961601257, Val Acc: 64.82%\n",
      "Epoch: 3684,     Training Loss: 0.4007225036621094, Training Acc: 71.23%\n",
      "              Val Loss: 0.9843811988830566, Val Acc: 64.82%\n",
      "Epoch: 3685,     Training Loss: 0.427701860666275, Training Acc: 71.23%\n",
      "              Val Loss: 0.9366155862808228, Val Acc: 64.82%\n",
      "Epoch: 3686,     Training Loss: 0.3885592520236969, Training Acc: 71.24%\n",
      "              Val Loss: 0.952114999294281, Val Acc: 64.83%\n",
      "Epoch: 3687,     Training Loss: 0.4080865979194641, Training Acc: 71.24%\n",
      "              Val Loss: 0.9168486595153809, Val Acc: 64.83%\n",
      "Epoch: 3688,     Training Loss: 0.3868788480758667, Training Acc: 71.24%\n",
      "              Val Loss: 0.9324947595596313, Val Acc: 64.83%\n",
      "Epoch: 3689,     Training Loss: 0.3820570409297943, Training Acc: 71.25%\n",
      "              Val Loss: 0.9134843945503235, Val Acc: 64.83%\n",
      "Epoch: 3690,     Training Loss: 0.364633172750473, Training Acc: 71.25%\n",
      "              Val Loss: 0.928260326385498, Val Acc: 64.83%\n",
      "Epoch: 3691,     Training Loss: 0.37726661562919617, Training Acc: 71.25%\n",
      "              Val Loss: 0.9452449679374695, Val Acc: 64.84%\n",
      "Epoch: 3692,     Training Loss: 0.3755171298980713, Training Acc: 71.26%\n",
      "              Val Loss: 0.9616420269012451, Val Acc: 64.84%\n",
      "Epoch: 3693,     Training Loss: 0.393123060464859, Training Acc: 71.26%\n",
      "              Val Loss: 0.9145469069480896, Val Acc: 64.84%\n",
      "Epoch: 3694,     Training Loss: 0.37240952253341675, Training Acc: 71.26%\n",
      "              Val Loss: 0.9093319177627563, Val Acc: 64.84%\n",
      "Epoch: 3695,     Training Loss: 0.36792099475860596, Training Acc: 71.27%\n",
      "              Val Loss: 0.9372901916503906, Val Acc: 64.84%\n",
      "Epoch: 3696,     Training Loss: 0.3695145845413208, Training Acc: 71.27%\n",
      "              Val Loss: 0.9245098829269409, Val Acc: 64.85%\n",
      "Epoch: 3697,     Training Loss: 0.36079859733581543, Training Acc: 71.28%\n",
      "              Val Loss: 0.9303712248802185, Val Acc: 64.85%\n",
      "Epoch: 3698,     Training Loss: 0.3737918436527252, Training Acc: 71.28%\n",
      "              Val Loss: 0.9685339331626892, Val Acc: 64.85%\n",
      "Epoch: 3699,     Training Loss: 0.4062119424343109, Training Acc: 71.28%\n",
      "              Val Loss: 0.9734018445014954, Val Acc: 64.85%\n",
      "Epoch: 3700,     Training Loss: 0.4157845675945282, Training Acc: 71.28%\n",
      "              Val Loss: 0.9891022443771362, Val Acc: 64.85%\n",
      "Epoch: 3701,     Training Loss: 0.4491245746612549, Training Acc: 71.29%\n",
      "              Val Loss: 0.9332680702209473, Val Acc: 64.85%\n",
      "Epoch: 3702,     Training Loss: 0.3897493779659271, Training Acc: 71.29%\n",
      "              Val Loss: 0.9249325394630432, Val Acc: 64.86%\n",
      "Epoch: 3703,     Training Loss: 0.3740466833114624, Training Acc: 71.29%\n",
      "              Val Loss: 0.9221922159194946, Val Acc: 64.86%\n",
      "Epoch: 3704,     Training Loss: 0.3803458511829376, Training Acc: 71.30%\n",
      "              Val Loss: 0.9624334573745728, Val Acc: 64.86%\n",
      "Epoch: 3705,     Training Loss: 0.40987706184387207, Training Acc: 71.30%\n",
      "              Val Loss: 0.9897068738937378, Val Acc: 64.86%\n",
      "Epoch: 3706,     Training Loss: 0.4364781677722931, Training Acc: 71.30%\n",
      "              Val Loss: 0.9499952793121338, Val Acc: 64.86%\n",
      "Epoch: 3707,     Training Loss: 0.3978517949581146, Training Acc: 71.31%\n",
      "              Val Loss: 0.9237644076347351, Val Acc: 64.87%\n",
      "Epoch: 3708,     Training Loss: 0.39388707280158997, Training Acc: 71.31%\n",
      "              Val Loss: 0.905200719833374, Val Acc: 64.87%\n",
      "Epoch: 3709,     Training Loss: 0.36333203315734863, Training Acc: 71.31%\n",
      "              Val Loss: 0.9745252728462219, Val Acc: 64.87%\n",
      "Epoch: 3710,     Training Loss: 0.40015631914138794, Training Acc: 71.32%\n",
      "              Val Loss: 0.9514009952545166, Val Acc: 64.87%\n",
      "Epoch: 3711,     Training Loss: 0.41357725858688354, Training Acc: 71.32%\n",
      "              Val Loss: 0.9948531985282898, Val Acc: 64.87%\n",
      "Epoch: 3712,     Training Loss: 0.47092533111572266, Training Acc: 71.32%\n",
      "              Val Loss: 1.2980716228485107, Val Acc: 64.87%\n",
      "Epoch: 3713,     Training Loss: 0.7400788068771362, Training Acc: 71.32%\n",
      "              Val Loss: 1.02072274684906, Val Acc: 64.87%\n",
      "Epoch: 3714,     Training Loss: 0.4842317998409271, Training Acc: 71.32%\n",
      "              Val Loss: 1.0932291746139526, Val Acc: 64.87%\n",
      "Epoch: 3715,     Training Loss: 0.5708405375480652, Training Acc: 71.32%\n",
      "              Val Loss: 1.1634570360183716, Val Acc: 64.87%\n",
      "Epoch: 3716,     Training Loss: 0.5969951152801514, Training Acc: 71.32%\n",
      "              Val Loss: 1.0825622081756592, Val Acc: 64.87%\n",
      "Epoch: 3717,     Training Loss: 0.5454561114311218, Training Acc: 71.33%\n",
      "              Val Loss: 0.9173076748847961, Val Acc: 64.88%\n",
      "Epoch: 3718,     Training Loss: 0.4596620202064514, Training Acc: 71.33%\n",
      "              Val Loss: 1.038815975189209, Val Acc: 64.88%\n",
      "Epoch: 3719,     Training Loss: 0.5564706921577454, Training Acc: 71.33%\n",
      "              Val Loss: 0.9356120228767395, Val Acc: 64.88%\n",
      "Epoch: 3720,     Training Loss: 0.4200417399406433, Training Acc: 71.33%\n",
      "              Val Loss: 1.009568214416504, Val Acc: 64.88%\n",
      "Epoch: 3721,     Training Loss: 0.49412813782691956, Training Acc: 71.34%\n",
      "              Val Loss: 0.9729356169700623, Val Acc: 64.88%\n",
      "Epoch: 3722,     Training Loss: 0.48777902126312256, Training Acc: 71.34%\n",
      "              Val Loss: 0.9899319410324097, Val Acc: 64.88%\n",
      "Epoch: 3723,     Training Loss: 0.48923859000205994, Training Acc: 71.34%\n",
      "              Val Loss: 0.9253584146499634, Val Acc: 64.88%\n",
      "Epoch: 3724,     Training Loss: 0.42216721177101135, Training Acc: 71.34%\n",
      "              Val Loss: 1.0317327976226807, Val Acc: 64.88%\n",
      "Epoch: 3725,     Training Loss: 0.4990537762641907, Training Acc: 71.34%\n",
      "              Val Loss: 0.9025420546531677, Val Acc: 64.89%\n",
      "Epoch: 3726,     Training Loss: 0.41568896174430847, Training Acc: 71.35%\n",
      "              Val Loss: 0.9265697002410889, Val Acc: 64.89%\n",
      "Epoch: 3727,     Training Loss: 0.4425978362560272, Training Acc: 71.35%\n",
      "              Val Loss: 0.9010137915611267, Val Acc: 64.89%\n",
      "Epoch: 3728,     Training Loss: 0.422900915145874, Training Acc: 71.35%\n",
      "              Val Loss: 0.915264904499054, Val Acc: 64.89%\n",
      "Epoch: 3729,     Training Loss: 0.4266555905342102, Training Acc: 71.36%\n",
      "              Val Loss: 0.9058367013931274, Val Acc: 64.89%\n",
      "Epoch: 3730,     Training Loss: 0.4323994815349579, Training Acc: 71.36%\n",
      "              Val Loss: 0.8436445593833923, Val Acc: 64.90%\n",
      "Epoch: 3731,     Training Loss: 0.38987576961517334, Training Acc: 71.36%\n",
      "              Val Loss: 0.8901846408843994, Val Acc: 64.90%\n",
      "Epoch: 3732,     Training Loss: 0.42029112577438354, Training Acc: 71.36%\n",
      "              Val Loss: 0.9299384951591492, Val Acc: 64.90%\n",
      "Epoch: 3733,     Training Loss: 0.43542784452438354, Training Acc: 71.37%\n",
      "              Val Loss: 0.9679229855537415, Val Acc: 64.90%\n",
      "Epoch: 3734,     Training Loss: 0.44536682963371277, Training Acc: 71.37%\n",
      "              Val Loss: 0.9406681656837463, Val Acc: 64.90%\n",
      "Epoch: 3735,     Training Loss: 0.44299107789993286, Training Acc: 71.37%\n",
      "              Val Loss: 0.8823130130767822, Val Acc: 64.91%\n",
      "Epoch: 3736,     Training Loss: 0.39901217818260193, Training Acc: 71.38%\n",
      "              Val Loss: 0.8734561800956726, Val Acc: 64.91%\n",
      "Epoch: 3737,     Training Loss: 0.39307937026023865, Training Acc: 71.38%\n",
      "              Val Loss: 0.8831470608711243, Val Acc: 64.91%\n",
      "Epoch: 3738,     Training Loss: 0.3900783061981201, Training Acc: 71.38%\n",
      "              Val Loss: 0.9116466045379639, Val Acc: 64.91%\n",
      "Epoch: 3739,     Training Loss: 0.40129774808883667, Training Acc: 71.38%\n",
      "              Val Loss: 0.906507670879364, Val Acc: 64.91%\n",
      "Epoch: 3740,     Training Loss: 0.41965579986572266, Training Acc: 71.39%\n",
      "              Val Loss: 0.870720624923706, Val Acc: 64.92%\n",
      "Epoch: 3741,     Training Loss: 0.3937675952911377, Training Acc: 71.39%\n",
      "              Val Loss: 0.871222972869873, Val Acc: 64.92%\n",
      "Epoch: 3742,     Training Loss: 0.37976357340812683, Training Acc: 71.39%\n",
      "              Val Loss: 0.8962908983230591, Val Acc: 64.92%\n",
      "Epoch: 3743,     Training Loss: 0.376001238822937, Training Acc: 71.40%\n",
      "              Val Loss: 0.9030849933624268, Val Acc: 64.92%\n",
      "Epoch: 3744,     Training Loss: 0.37036633491516113, Training Acc: 71.40%\n",
      "              Val Loss: 0.9229231476783752, Val Acc: 64.92%\n",
      "Epoch: 3745,     Training Loss: 0.37850722670555115, Training Acc: 71.40%\n",
      "              Val Loss: 0.9233999848365784, Val Acc: 64.93%\n",
      "Epoch: 3746,     Training Loss: 0.3819882273674011, Training Acc: 71.41%\n",
      "              Val Loss: 0.9018459916114807, Val Acc: 64.93%\n",
      "Epoch: 3747,     Training Loss: 0.37826669216156006, Training Acc: 71.41%\n",
      "              Val Loss: 0.8924318552017212, Val Acc: 64.93%\n",
      "Epoch: 3748,     Training Loss: 0.3646598756313324, Training Acc: 71.41%\n",
      "              Val Loss: 0.916300356388092, Val Acc: 64.93%\n",
      "Epoch: 3749,     Training Loss: 0.371953547000885, Training Acc: 71.42%\n",
      "              Val Loss: 0.9331300258636475, Val Acc: 64.93%\n",
      "Epoch: 3750,     Training Loss: 0.3776814639568329, Training Acc: 71.42%\n",
      "              Val Loss: 0.9320864081382751, Val Acc: 64.94%\n",
      "Epoch: 3751,     Training Loss: 0.37756142020225525, Training Acc: 71.43%\n",
      "              Val Loss: 0.9310749173164368, Val Acc: 64.94%\n",
      "Epoch: 3752,     Training Loss: 0.38743481040000916, Training Acc: 71.43%\n",
      "              Val Loss: 0.9452345967292786, Val Acc: 64.94%\n",
      "Epoch: 3753,     Training Loss: 0.4160604178905487, Training Acc: 71.43%\n",
      "              Val Loss: 0.912855863571167, Val Acc: 64.94%\n",
      "Epoch: 3754,     Training Loss: 0.3816797137260437, Training Acc: 71.43%\n",
      "              Val Loss: 0.8878026604652405, Val Acc: 64.94%\n",
      "Epoch: 3755,     Training Loss: 0.3630063533782959, Training Acc: 71.44%\n",
      "              Val Loss: 0.8968857526779175, Val Acc: 64.95%\n",
      "Epoch: 3756,     Training Loss: 0.36733874678611755, Training Acc: 71.44%\n",
      "              Val Loss: 0.9192150831222534, Val Acc: 64.95%\n",
      "Epoch: 3757,     Training Loss: 0.3775276839733124, Training Acc: 71.45%\n",
      "              Val Loss: 0.9147725105285645, Val Acc: 64.95%\n",
      "Epoch: 3758,     Training Loss: 0.3909240961074829, Training Acc: 71.45%\n",
      "              Val Loss: 0.9131582379341125, Val Acc: 64.95%\n",
      "Epoch: 3759,     Training Loss: 0.3969396650791168, Training Acc: 71.45%\n",
      "              Val Loss: 0.9467734694480896, Val Acc: 64.95%\n",
      "Epoch: 3760,     Training Loss: 0.4242251515388489, Training Acc: 71.45%\n",
      "              Val Loss: 0.9162192344665527, Val Acc: 64.95%\n",
      "Epoch: 3761,     Training Loss: 0.3808196187019348, Training Acc: 71.46%\n",
      "              Val Loss: 0.9068779945373535, Val Acc: 64.96%\n",
      "Epoch: 3762,     Training Loss: 0.3634019196033478, Training Acc: 71.46%\n",
      "              Val Loss: 0.9417694211006165, Val Acc: 64.96%\n",
      "Epoch: 3763,     Training Loss: 0.38118305802345276, Training Acc: 71.46%\n",
      "              Val Loss: 0.9654072523117065, Val Acc: 64.96%\n",
      "Epoch: 3764,     Training Loss: 0.3952997922897339, Training Acc: 71.47%\n",
      "              Val Loss: 1.0024082660675049, Val Acc: 64.96%\n",
      "Epoch: 3765,     Training Loss: 0.4584793746471405, Training Acc: 71.47%\n",
      "              Val Loss: 1.0224316120147705, Val Acc: 64.96%\n",
      "Epoch: 3766,     Training Loss: 0.47918596863746643, Training Acc: 71.47%\n",
      "              Val Loss: 1.0280247926712036, Val Acc: 64.96%\n",
      "Epoch: 3767,     Training Loss: 0.5086556077003479, Training Acc: 71.47%\n",
      "              Val Loss: 0.945361316204071, Val Acc: 64.97%\n",
      "Epoch: 3768,     Training Loss: 0.4035412073135376, Training Acc: 71.48%\n",
      "              Val Loss: 0.9874712228775024, Val Acc: 64.97%\n",
      "Epoch: 3769,     Training Loss: 0.42550206184387207, Training Acc: 71.48%\n",
      "              Val Loss: 1.0600272417068481, Val Acc: 64.97%\n",
      "Epoch: 3770,     Training Loss: 0.5053879022598267, Training Acc: 71.48%\n",
      "              Val Loss: 0.9464908838272095, Val Acc: 64.97%\n",
      "Epoch: 3771,     Training Loss: 0.4249545931816101, Training Acc: 71.48%\n",
      "              Val Loss: 0.9303795695304871, Val Acc: 64.97%\n",
      "Epoch: 3772,     Training Loss: 0.40448376536369324, Training Acc: 71.49%\n",
      "              Val Loss: 0.9948722124099731, Val Acc: 64.97%\n",
      "Epoch: 3773,     Training Loss: 0.48320120573043823, Training Acc: 71.49%\n",
      "              Val Loss: 1.0225977897644043, Val Acc: 64.97%\n",
      "Epoch: 3774,     Training Loss: 0.4731127619743347, Training Acc: 71.49%\n",
      "              Val Loss: 1.043003797531128, Val Acc: 64.97%\n",
      "Epoch: 3775,     Training Loss: 0.4840480387210846, Training Acc: 71.49%\n",
      "              Val Loss: 0.9081140160560608, Val Acc: 64.98%\n",
      "Epoch: 3776,     Training Loss: 0.39089012145996094, Training Acc: 71.50%\n",
      "              Val Loss: 0.9836950898170471, Val Acc: 64.98%\n",
      "Epoch: 3777,     Training Loss: 0.4913834035396576, Training Acc: 71.50%\n",
      "              Val Loss: 0.9637451171875, Val Acc: 64.98%\n",
      "Epoch: 3778,     Training Loss: 0.45295077562332153, Training Acc: 71.50%\n",
      "              Val Loss: 0.986238420009613, Val Acc: 64.98%\n",
      "Epoch: 3779,     Training Loss: 0.4187735319137573, Training Acc: 71.50%\n",
      "              Val Loss: 0.9675447344779968, Val Acc: 64.98%\n",
      "Epoch: 3780,     Training Loss: 0.41089144349098206, Training Acc: 71.51%\n",
      "              Val Loss: 0.965796947479248, Val Acc: 64.98%\n",
      "Epoch: 3781,     Training Loss: 0.44909149408340454, Training Acc: 71.51%\n",
      "              Val Loss: 0.9161773920059204, Val Acc: 64.99%\n",
      "Epoch: 3782,     Training Loss: 0.3942791819572449, Training Acc: 71.51%\n",
      "              Val Loss: 0.9093364477157593, Val Acc: 64.99%\n",
      "Epoch: 3783,     Training Loss: 0.39773595333099365, Training Acc: 71.51%\n",
      "              Val Loss: 0.9022080302238464, Val Acc: 64.99%\n",
      "Epoch: 3784,     Training Loss: 0.38167527318000793, Training Acc: 71.52%\n",
      "              Val Loss: 0.9622194766998291, Val Acc: 64.99%\n",
      "Epoch: 3785,     Training Loss: 0.3974645733833313, Training Acc: 71.52%\n",
      "              Val Loss: 0.9752467274665833, Val Acc: 64.99%\n",
      "Epoch: 3786,     Training Loss: 0.38112199306488037, Training Acc: 71.52%\n",
      "              Val Loss: 0.9632543325424194, Val Acc: 64.99%\n",
      "Epoch: 3787,     Training Loss: 0.38220933079719543, Training Acc: 71.53%\n",
      "              Val Loss: 0.9097635746002197, Val Acc: 65.00%\n",
      "Epoch: 3788,     Training Loss: 0.3683893084526062, Training Acc: 71.53%\n",
      "              Val Loss: 0.9047052264213562, Val Acc: 65.00%\n",
      "Epoch: 3789,     Training Loss: 0.3788449764251709, Training Acc: 71.53%\n",
      "              Val Loss: 0.9068548083305359, Val Acc: 65.00%\n",
      "Epoch: 3790,     Training Loss: 0.3634406626224518, Training Acc: 71.54%\n",
      "              Val Loss: 0.9434154629707336, Val Acc: 65.00%\n",
      "Epoch: 3791,     Training Loss: 0.37175095081329346, Training Acc: 71.54%\n",
      "              Val Loss: 0.931754469871521, Val Acc: 65.01%\n",
      "Epoch: 3792,     Training Loss: 0.3658480942249298, Training Acc: 71.55%\n",
      "              Val Loss: 0.928199827671051, Val Acc: 65.01%\n",
      "Epoch: 3793,     Training Loss: 0.36491259932518005, Training Acc: 71.55%\n",
      "              Val Loss: 0.9222602248191833, Val Acc: 65.01%\n",
      "Epoch: 3794,     Training Loss: 0.36455851793289185, Training Acc: 71.55%\n",
      "              Val Loss: 0.9019603133201599, Val Acc: 65.01%\n",
      "Epoch: 3795,     Training Loss: 0.3559182286262512, Training Acc: 71.56%\n",
      "              Val Loss: 0.8991190195083618, Val Acc: 65.01%\n",
      "Epoch: 3796,     Training Loss: 0.3641015291213989, Training Acc: 71.56%\n",
      "              Val Loss: 0.9096540808677673, Val Acc: 65.02%\n",
      "Epoch: 3797,     Training Loss: 0.3611017167568207, Training Acc: 71.56%\n",
      "              Val Loss: 0.9424305558204651, Val Acc: 65.02%\n",
      "Epoch: 3798,     Training Loss: 0.383330374956131, Training Acc: 71.57%\n",
      "              Val Loss: 0.9357861876487732, Val Acc: 65.02%\n",
      "Epoch: 3799,     Training Loss: 0.38479936122894287, Training Acc: 71.57%\n",
      "              Val Loss: 0.9498993158340454, Val Acc: 65.02%\n",
      "Epoch: 3800,     Training Loss: 0.4078703224658966, Training Acc: 71.57%\n",
      "              Val Loss: 0.9243245124816895, Val Acc: 65.02%\n",
      "Epoch: 3801,     Training Loss: 0.37230902910232544, Training Acc: 71.58%\n",
      "              Val Loss: 0.9166949987411499, Val Acc: 65.03%\n",
      "Epoch: 3802,     Training Loss: 0.35845765471458435, Training Acc: 71.58%\n",
      "              Val Loss: 0.9484575390815735, Val Acc: 65.03%\n",
      "Epoch: 3803,     Training Loss: 0.39124247431755066, Training Acc: 71.58%\n",
      "              Val Loss: 0.9672338366508484, Val Acc: 65.03%\n",
      "Epoch: 3804,     Training Loss: 0.4082152545452118, Training Acc: 71.59%\n",
      "              Val Loss: 1.0711477994918823, Val Acc: 65.03%\n",
      "Epoch: 3805,     Training Loss: 0.5076751708984375, Training Acc: 71.59%\n",
      "              Val Loss: 1.0122498273849487, Val Acc: 65.03%\n",
      "Epoch: 3806,     Training Loss: 0.4670668840408325, Training Acc: 71.59%\n",
      "              Val Loss: 0.9616729617118835, Val Acc: 65.03%\n",
      "Epoch: 3807,     Training Loss: 0.46989089250564575, Training Acc: 71.59%\n",
      "              Val Loss: 0.8874800801277161, Val Acc: 65.03%\n",
      "Epoch: 3808,     Training Loss: 0.3704943060874939, Training Acc: 71.59%\n",
      "              Val Loss: 1.028659701347351, Val Acc: 65.04%\n",
      "Epoch: 3809,     Training Loss: 0.48162952065467834, Training Acc: 71.60%\n",
      "              Val Loss: 1.0984116792678833, Val Acc: 65.04%\n",
      "Epoch: 3810,     Training Loss: 0.5885151624679565, Training Acc: 71.60%\n",
      "              Val Loss: 0.9129778146743774, Val Acc: 65.04%\n",
      "Epoch: 3811,     Training Loss: 0.4034144878387451, Training Acc: 71.60%\n",
      "              Val Loss: 1.094456434249878, Val Acc: 65.04%\n",
      "Epoch: 3812,     Training Loss: 0.5484569072723389, Training Acc: 71.60%\n",
      "              Val Loss: 1.270250916481018, Val Acc: 65.04%\n",
      "Epoch: 3813,     Training Loss: 0.7846535444259644, Training Acc: 71.60%\n",
      "              Val Loss: 0.9349430799484253, Val Acc: 65.04%\n",
      "Epoch: 3814,     Training Loss: 0.4514988958835602, Training Acc: 71.60%\n",
      "              Val Loss: 1.3593096733093262, Val Acc: 65.04%\n",
      "Epoch: 3815,     Training Loss: 0.819456160068512, Training Acc: 71.60%\n",
      "              Val Loss: 1.9323252439498901, Val Acc: 65.03%\n",
      "Epoch: 3816,     Training Loss: 1.4989488124847412, Training Acc: 71.60%\n",
      "              Val Loss: 1.274841070175171, Val Acc: 65.03%\n",
      "Epoch: 3817,     Training Loss: 0.8828395009040833, Training Acc: 71.60%\n",
      "              Val Loss: 1.7700657844543457, Val Acc: 65.02%\n",
      "Epoch: 3818,     Training Loss: 1.3933316469192505, Training Acc: 71.59%\n",
      "              Val Loss: 0.9920728206634521, Val Acc: 65.03%\n",
      "Epoch: 3819,     Training Loss: 0.5365278124809265, Training Acc: 71.59%\n",
      "              Val Loss: 1.4378584623336792, Val Acc: 65.02%\n",
      "Epoch: 3820,     Training Loss: 1.0368987321853638, Training Acc: 71.59%\n",
      "              Val Loss: 1.0729289054870605, Val Acc: 65.02%\n",
      "Epoch: 3821,     Training Loss: 0.6791738271713257, Training Acc: 71.59%\n",
      "              Val Loss: 1.1610114574432373, Val Acc: 65.02%\n",
      "Epoch: 3822,     Training Loss: 0.8005005121231079, Training Acc: 71.59%\n",
      "              Val Loss: 1.1028718948364258, Val Acc: 65.02%\n",
      "Epoch: 3823,     Training Loss: 0.7976377606391907, Training Acc: 71.59%\n",
      "              Val Loss: 1.038295865058899, Val Acc: 65.02%\n",
      "Epoch: 3824,     Training Loss: 0.6697703003883362, Training Acc: 71.59%\n",
      "              Val Loss: 1.1686861515045166, Val Acc: 65.02%\n",
      "Epoch: 3825,     Training Loss: 0.7749764323234558, Training Acc: 71.59%\n",
      "              Val Loss: 1.077450156211853, Val Acc: 65.02%\n",
      "Epoch: 3826,     Training Loss: 0.6816604137420654, Training Acc: 71.59%\n",
      "              Val Loss: 0.9565302133560181, Val Acc: 65.02%\n",
      "Epoch: 3827,     Training Loss: 0.5873268246650696, Training Acc: 71.59%\n",
      "              Val Loss: 1.0966023206710815, Val Acc: 65.02%\n",
      "Epoch: 3828,     Training Loss: 0.7214102745056152, Training Acc: 71.59%\n",
      "              Val Loss: 0.9756854176521301, Val Acc: 65.02%\n",
      "Epoch: 3829,     Training Loss: 0.6020517945289612, Training Acc: 71.59%\n",
      "              Val Loss: 0.9750316739082336, Val Acc: 65.02%\n",
      "Epoch: 3830,     Training Loss: 0.5904732346534729, Training Acc: 71.59%\n",
      "              Val Loss: 1.0052897930145264, Val Acc: 65.03%\n",
      "Epoch: 3831,     Training Loss: 0.6349083185195923, Training Acc: 71.59%\n",
      "              Val Loss: 0.9082157611846924, Val Acc: 65.03%\n",
      "Epoch: 3832,     Training Loss: 0.5520960092544556, Training Acc: 71.59%\n",
      "              Val Loss: 0.9456392526626587, Val Acc: 65.03%\n",
      "Epoch: 3833,     Training Loss: 0.5917160511016846, Training Acc: 71.59%\n",
      "              Val Loss: 0.895139753818512, Val Acc: 65.03%\n",
      "Epoch: 3834,     Training Loss: 0.5425726175308228, Training Acc: 71.59%\n",
      "              Val Loss: 0.9029789566993713, Val Acc: 65.03%\n",
      "Epoch: 3835,     Training Loss: 0.5361098051071167, Training Acc: 71.60%\n",
      "              Val Loss: 0.9182760715484619, Val Acc: 65.03%\n",
      "Epoch: 3836,     Training Loss: 0.5251283049583435, Training Acc: 71.60%\n",
      "              Val Loss: 0.9338098168373108, Val Acc: 65.03%\n",
      "Epoch: 3837,     Training Loss: 0.5111432075500488, Training Acc: 71.60%\n",
      "              Val Loss: 0.9350747466087341, Val Acc: 65.03%\n",
      "Epoch: 3838,     Training Loss: 0.5185890197753906, Training Acc: 71.60%\n",
      "              Val Loss: 0.8891525268554688, Val Acc: 65.04%\n",
      "Epoch: 3839,     Training Loss: 0.495624840259552, Training Acc: 71.60%\n",
      "              Val Loss: 0.8672850728034973, Val Acc: 65.04%\n",
      "Epoch: 3840,     Training Loss: 0.4799818694591522, Training Acc: 71.61%\n",
      "              Val Loss: 0.8593026995658875, Val Acc: 65.04%\n",
      "Epoch: 3841,     Training Loss: 0.48052069544792175, Training Acc: 71.61%\n",
      "              Val Loss: 0.8195890188217163, Val Acc: 65.04%\n",
      "Epoch: 3842,     Training Loss: 0.4475645124912262, Training Acc: 71.61%\n",
      "              Val Loss: 0.8368895649909973, Val Acc: 65.04%\n",
      "Epoch: 3843,     Training Loss: 0.4515007734298706, Training Acc: 71.61%\n",
      "              Val Loss: 0.8407120704650879, Val Acc: 65.04%\n",
      "Epoch: 3844,     Training Loss: 0.4483935534954071, Training Acc: 71.61%\n",
      "              Val Loss: 0.7969657778739929, Val Acc: 65.05%\n",
      "Epoch: 3845,     Training Loss: 0.42378684878349304, Training Acc: 71.62%\n",
      "              Val Loss: 0.8053361773490906, Val Acc: 65.05%\n",
      "Epoch: 3846,     Training Loss: 0.429994136095047, Training Acc: 71.62%\n",
      "              Val Loss: 0.8195632100105286, Val Acc: 65.05%\n",
      "Epoch: 3847,     Training Loss: 0.4215170741081238, Training Acc: 71.62%\n",
      "              Val Loss: 0.8313127160072327, Val Acc: 65.05%\n",
      "Epoch: 3848,     Training Loss: 0.41688159108161926, Training Acc: 71.63%\n",
      "              Val Loss: 0.840369701385498, Val Acc: 65.05%\n",
      "Epoch: 3849,     Training Loss: 0.4122966527938843, Training Acc: 71.63%\n",
      "              Val Loss: 0.8367502689361572, Val Acc: 65.06%\n",
      "Epoch: 3850,     Training Loss: 0.40655991435050964, Training Acc: 71.63%\n",
      "              Val Loss: 0.83249831199646, Val Acc: 65.06%\n",
      "Epoch: 3851,     Training Loss: 0.4037363827228546, Training Acc: 71.64%\n",
      "              Val Loss: 0.8302626609802246, Val Acc: 65.06%\n",
      "Epoch: 3852,     Training Loss: 0.3967643082141876, Training Acc: 71.64%\n",
      "              Val Loss: 0.8471598625183105, Val Acc: 65.06%\n",
      "Epoch: 3853,     Training Loss: 0.3979893922805786, Training Acc: 71.64%\n",
      "              Val Loss: 0.8582841753959656, Val Acc: 65.07%\n",
      "Epoch: 3854,     Training Loss: 0.3875458240509033, Training Acc: 71.64%\n",
      "              Val Loss: 0.8845430016517639, Val Acc: 65.07%\n",
      "Epoch: 3855,     Training Loss: 0.3927704095840454, Training Acc: 71.65%\n",
      "              Val Loss: 0.8668140172958374, Val Acc: 65.07%\n",
      "Epoch: 3856,     Training Loss: 0.3826352059841156, Training Acc: 71.65%\n",
      "              Val Loss: 0.8682392835617065, Val Acc: 65.07%\n",
      "Epoch: 3857,     Training Loss: 0.3838379681110382, Training Acc: 71.65%\n",
      "              Val Loss: 0.8654412031173706, Val Acc: 65.07%\n",
      "Epoch: 3858,     Training Loss: 0.38044852018356323, Training Acc: 71.66%\n",
      "              Val Loss: 0.8735694885253906, Val Acc: 65.08%\n",
      "Epoch: 3859,     Training Loss: 0.37671035528182983, Training Acc: 71.66%\n",
      "              Val Loss: 0.8825635313987732, Val Acc: 65.08%\n",
      "Epoch: 3860,     Training Loss: 0.37492311000823975, Training Acc: 71.66%\n",
      "              Val Loss: 0.8833007216453552, Val Acc: 65.08%\n",
      "Epoch: 3861,     Training Loss: 0.3728858232498169, Training Acc: 71.67%\n",
      "              Val Loss: 0.8793675899505615, Val Acc: 65.08%\n",
      "Epoch: 3862,     Training Loss: 0.3710864186286926, Training Acc: 71.67%\n",
      "              Val Loss: 0.8728139400482178, Val Acc: 65.08%\n",
      "Epoch: 3863,     Training Loss: 0.37113064527511597, Training Acc: 71.67%\n",
      "              Val Loss: 0.867205023765564, Val Acc: 65.09%\n",
      "Epoch: 3864,     Training Loss: 0.36761802434921265, Training Acc: 71.68%\n",
      "              Val Loss: 0.8646187782287598, Val Acc: 65.09%\n",
      "Epoch: 3865,     Training Loss: 0.36656731367111206, Training Acc: 71.68%\n",
      "              Val Loss: 0.8645493984222412, Val Acc: 65.09%\n",
      "Epoch: 3866,     Training Loss: 0.36495867371559143, Training Acc: 71.68%\n",
      "              Val Loss: 0.8608897924423218, Val Acc: 65.09%\n",
      "Epoch: 3867,     Training Loss: 0.36461010575294495, Training Acc: 71.69%\n",
      "              Val Loss: 0.8591333627700806, Val Acc: 65.10%\n",
      "Epoch: 3868,     Training Loss: 0.3641381561756134, Training Acc: 71.69%\n",
      "              Val Loss: 0.8611728549003601, Val Acc: 65.10%\n",
      "Epoch: 3869,     Training Loss: 0.3630947470664978, Training Acc: 71.70%\n",
      "              Val Loss: 0.8595091104507446, Val Acc: 65.10%\n",
      "Epoch: 3870,     Training Loss: 0.363582581281662, Training Acc: 71.70%\n",
      "              Val Loss: 0.872955322265625, Val Acc: 65.10%\n",
      "Epoch: 3871,     Training Loss: 0.36652499437332153, Training Acc: 71.70%\n",
      "              Val Loss: 0.8695512413978577, Val Acc: 65.10%\n",
      "Epoch: 3872,     Training Loss: 0.3746633529663086, Training Acc: 71.71%\n",
      "              Val Loss: 0.8868759870529175, Val Acc: 65.11%\n",
      "Epoch: 3873,     Training Loss: 0.37902113795280457, Training Acc: 71.71%\n",
      "              Val Loss: 0.8790661692619324, Val Acc: 65.11%\n",
      "Epoch: 3874,     Training Loss: 0.38192257285118103, Training Acc: 71.71%\n",
      "              Val Loss: 0.8804835677146912, Val Acc: 65.11%\n",
      "Epoch: 3875,     Training Loss: 0.3651859760284424, Training Acc: 71.72%\n",
      "              Val Loss: 0.8719407916069031, Val Acc: 65.11%\n",
      "Epoch: 3876,     Training Loss: 0.35746341943740845, Training Acc: 71.72%\n",
      "              Val Loss: 0.8744258880615234, Val Acc: 65.11%\n",
      "Epoch: 3877,     Training Loss: 0.36317020654678345, Training Acc: 71.72%\n",
      "              Val Loss: 0.8978284597396851, Val Acc: 65.12%\n",
      "Epoch: 3878,     Training Loss: 0.3725314736366272, Training Acc: 71.73%\n",
      "              Val Loss: 0.8850721716880798, Val Acc: 65.12%\n",
      "Epoch: 3879,     Training Loss: 0.38038599491119385, Training Acc: 71.73%\n",
      "              Val Loss: 0.8884904384613037, Val Acc: 65.12%\n",
      "Epoch: 3880,     Training Loss: 0.37189745903015137, Training Acc: 71.73%\n",
      "              Val Loss: 0.874448835849762, Val Acc: 65.12%\n",
      "Epoch: 3881,     Training Loss: 0.3689657151699066, Training Acc: 71.74%\n",
      "              Val Loss: 0.8775162696838379, Val Acc: 65.12%\n",
      "Epoch: 3882,     Training Loss: 0.358541876077652, Training Acc: 71.74%\n",
      "              Val Loss: 0.8783720135688782, Val Acc: 65.13%\n",
      "Epoch: 3883,     Training Loss: 0.3532851040363312, Training Acc: 71.74%\n",
      "              Val Loss: 0.8784918189048767, Val Acc: 65.13%\n",
      "Epoch: 3884,     Training Loss: 0.3578462600708008, Training Acc: 71.75%\n",
      "              Val Loss: 0.8911576271057129, Val Acc: 65.13%\n",
      "Epoch: 3885,     Training Loss: 0.3662666082382202, Training Acc: 71.75%\n",
      "              Val Loss: 0.8977964520454407, Val Acc: 65.13%\n",
      "Epoch: 3886,     Training Loss: 0.3885224163532257, Training Acc: 71.75%\n",
      "              Val Loss: 0.9027063250541687, Val Acc: 65.13%\n",
      "Epoch: 3887,     Training Loss: 0.3832978308200836, Training Acc: 71.76%\n",
      "              Val Loss: 0.8835790157318115, Val Acc: 65.13%\n",
      "Epoch: 3888,     Training Loss: 0.37541186809539795, Training Acc: 71.76%\n",
      "              Val Loss: 0.885098934173584, Val Acc: 65.14%\n",
      "Epoch: 3889,     Training Loss: 0.35506126284599304, Training Acc: 71.76%\n",
      "              Val Loss: 0.8962260484695435, Val Acc: 65.14%\n",
      "Epoch: 3890,     Training Loss: 0.3570255637168884, Training Acc: 71.77%\n",
      "              Val Loss: 0.9024649262428284, Val Acc: 65.14%\n",
      "Epoch: 3891,     Training Loss: 0.377526193857193, Training Acc: 71.77%\n",
      "              Val Loss: 0.9115064144134521, Val Acc: 65.14%\n",
      "Epoch: 3892,     Training Loss: 0.3763883709907532, Training Acc: 71.77%\n",
      "              Val Loss: 0.8998789191246033, Val Acc: 65.14%\n",
      "Epoch: 3893,     Training Loss: 0.3860095143318176, Training Acc: 71.78%\n",
      "              Val Loss: 0.8856178522109985, Val Acc: 65.15%\n",
      "Epoch: 3894,     Training Loss: 0.36292514204978943, Training Acc: 71.78%\n",
      "              Val Loss: 0.8766965270042419, Val Acc: 65.15%\n",
      "Epoch: 3895,     Training Loss: 0.35068684816360474, Training Acc: 71.78%\n",
      "              Val Loss: 0.8910437226295471, Val Acc: 65.15%\n",
      "Epoch: 3896,     Training Loss: 0.3607737421989441, Training Acc: 71.79%\n",
      "              Val Loss: 0.9167017340660095, Val Acc: 65.15%\n",
      "Epoch: 3897,     Training Loss: 0.37248334288597107, Training Acc: 71.79%\n",
      "              Val Loss: 0.9163456559181213, Val Acc: 65.15%\n",
      "Epoch: 3898,     Training Loss: 0.3914163112640381, Training Acc: 71.79%\n",
      "              Val Loss: 0.9059879779815674, Val Acc: 65.16%\n",
      "Epoch: 3899,     Training Loss: 0.37291866540908813, Training Acc: 71.80%\n",
      "              Val Loss: 0.8838660717010498, Val Acc: 65.16%\n",
      "Epoch: 3900,     Training Loss: 0.35397398471832275, Training Acc: 71.80%\n",
      "              Val Loss: 0.8867866396903992, Val Acc: 65.16%\n",
      "Epoch: 3901,     Training Loss: 0.3526022434234619, Training Acc: 71.80%\n",
      "              Val Loss: 0.9184460639953613, Val Acc: 65.16%\n",
      "Epoch: 3902,     Training Loss: 0.3693903386592865, Training Acc: 71.81%\n",
      "              Val Loss: 0.9356971979141235, Val Acc: 65.16%\n",
      "Epoch: 3903,     Training Loss: 0.3969542980194092, Training Acc: 71.81%\n",
      "              Val Loss: 0.9224230051040649, Val Acc: 65.16%\n",
      "Epoch: 3904,     Training Loss: 0.36870670318603516, Training Acc: 71.81%\n",
      "              Val Loss: 0.8892885446548462, Val Acc: 65.17%\n",
      "Epoch: 3905,     Training Loss: 0.3507393002510071, Training Acc: 71.82%\n",
      "              Val Loss: 0.893330454826355, Val Acc: 65.17%\n",
      "Epoch: 3906,     Training Loss: 0.3520950376987457, Training Acc: 71.82%\n",
      "              Val Loss: 0.9075285196304321, Val Acc: 65.17%\n",
      "Epoch: 3907,     Training Loss: 0.3655167520046234, Training Acc: 71.82%\n",
      "              Val Loss: 0.9072801470756531, Val Acc: 65.17%\n",
      "Epoch: 3908,     Training Loss: 0.36990469694137573, Training Acc: 71.83%\n",
      "              Val Loss: 0.9124467968940735, Val Acc: 65.17%\n",
      "Epoch: 3909,     Training Loss: 0.36199137568473816, Training Acc: 71.83%\n",
      "              Val Loss: 0.9039135575294495, Val Acc: 65.18%\n",
      "Epoch: 3910,     Training Loss: 0.36857450008392334, Training Acc: 71.83%\n",
      "              Val Loss: 0.903425395488739, Val Acc: 65.18%\n",
      "Epoch: 3911,     Training Loss: 0.3568727374076843, Training Acc: 71.84%\n",
      "              Val Loss: 0.8877358436584473, Val Acc: 65.18%\n",
      "Epoch: 3912,     Training Loss: 0.34986576437950134, Training Acc: 71.84%\n",
      "              Val Loss: 0.8900309205055237, Val Acc: 65.18%\n",
      "Epoch: 3913,     Training Loss: 0.35263508558273315, Training Acc: 71.84%\n",
      "              Val Loss: 0.921099841594696, Val Acc: 65.18%\n",
      "Epoch: 3914,     Training Loss: 0.35865822434425354, Training Acc: 71.85%\n",
      "              Val Loss: 0.8980050086975098, Val Acc: 65.19%\n",
      "Epoch: 3915,     Training Loss: 0.35337769985198975, Training Acc: 71.85%\n",
      "              Val Loss: 0.8906644582748413, Val Acc: 65.19%\n",
      "Epoch: 3916,     Training Loss: 0.3479825556278229, Training Acc: 71.85%\n",
      "              Val Loss: 0.8980062007904053, Val Acc: 65.19%\n",
      "Epoch: 3917,     Training Loss: 0.3599776327610016, Training Acc: 71.86%\n",
      "              Val Loss: 0.8930091857910156, Val Acc: 65.19%\n",
      "Epoch: 3918,     Training Loss: 0.36279720067977905, Training Acc: 71.86%\n",
      "              Val Loss: 0.8873711228370667, Val Acc: 65.20%\n",
      "Epoch: 3919,     Training Loss: 0.35004761815071106, Training Acc: 71.86%\n",
      "              Val Loss: 0.9010078310966492, Val Acc: 65.20%\n",
      "Epoch: 3920,     Training Loss: 0.347665935754776, Training Acc: 71.87%\n",
      "              Val Loss: 0.9033598303794861, Val Acc: 65.20%\n",
      "Epoch: 3921,     Training Loss: 0.35330742597579956, Training Acc: 71.87%\n",
      "              Val Loss: 0.9108766913414001, Val Acc: 65.20%\n",
      "Epoch: 3922,     Training Loss: 0.35186493396759033, Training Acc: 71.87%\n",
      "              Val Loss: 0.9022017121315002, Val Acc: 65.20%\n",
      "Epoch: 3923,     Training Loss: 0.35875412821769714, Training Acc: 71.88%\n",
      "              Val Loss: 0.9124995470046997, Val Acc: 65.21%\n",
      "Epoch: 3924,     Training Loss: 0.3627496659755707, Training Acc: 71.88%\n",
      "              Val Loss: 0.9119539856910706, Val Acc: 65.21%\n",
      "Epoch: 3925,     Training Loss: 0.36092430353164673, Training Acc: 71.89%\n",
      "              Val Loss: 0.9052608013153076, Val Acc: 65.21%\n",
      "Epoch: 3926,     Training Loss: 0.34886500239372253, Training Acc: 71.89%\n",
      "              Val Loss: 0.9063153862953186, Val Acc: 65.21%\n",
      "Epoch: 3927,     Training Loss: 0.34334683418273926, Training Acc: 71.89%\n",
      "              Val Loss: 0.9018071889877319, Val Acc: 65.21%\n",
      "Epoch: 3928,     Training Loss: 0.3431969881057739, Training Acc: 71.90%\n",
      "              Val Loss: 0.9079839587211609, Val Acc: 65.22%\n",
      "Epoch: 3929,     Training Loss: 0.35375407338142395, Training Acc: 71.90%\n",
      "              Val Loss: 0.9399380683898926, Val Acc: 65.22%\n",
      "Epoch: 3930,     Training Loss: 0.3966936767101288, Training Acc: 71.90%\n",
      "              Val Loss: 0.9748554825782776, Val Acc: 65.22%\n",
      "Epoch: 3931,     Training Loss: 0.4208572506904602, Training Acc: 71.90%\n",
      "              Val Loss: 1.023195743560791, Val Acc: 65.22%\n",
      "Epoch: 3932,     Training Loss: 0.4870137870311737, Training Acc: 71.91%\n",
      "              Val Loss: 0.9369559288024902, Val Acc: 65.22%\n",
      "Epoch: 3933,     Training Loss: 0.3820880949497223, Training Acc: 71.91%\n",
      "              Val Loss: 0.918405294418335, Val Acc: 65.22%\n",
      "Epoch: 3934,     Training Loss: 0.36768394708633423, Training Acc: 71.91%\n",
      "              Val Loss: 0.9770687818527222, Val Acc: 65.22%\n",
      "Epoch: 3935,     Training Loss: 0.4269134998321533, Training Acc: 71.92%\n",
      "              Val Loss: 0.9512550830841064, Val Acc: 65.22%\n",
      "Epoch: 3936,     Training Loss: 0.3850778341293335, Training Acc: 71.92%\n",
      "              Val Loss: 0.9028082489967346, Val Acc: 65.23%\n",
      "Epoch: 3937,     Training Loss: 0.3586915135383606, Training Acc: 71.92%\n",
      "              Val Loss: 0.9122965335845947, Val Acc: 65.23%\n",
      "Epoch: 3938,     Training Loss: 0.3720006048679352, Training Acc: 71.93%\n",
      "              Val Loss: 0.9513750672340393, Val Acc: 65.23%\n",
      "Epoch: 3939,     Training Loss: 0.38731849193573, Training Acc: 71.93%\n",
      "              Val Loss: 0.9154466986656189, Val Acc: 65.23%\n",
      "Epoch: 3940,     Training Loss: 0.3773522675037384, Training Acc: 71.93%\n",
      "              Val Loss: 0.907956063747406, Val Acc: 65.23%\n",
      "Epoch: 3941,     Training Loss: 0.35135459899902344, Training Acc: 71.94%\n",
      "              Val Loss: 0.94341641664505, Val Acc: 65.24%\n",
      "Epoch: 3942,     Training Loss: 0.37687045335769653, Training Acc: 71.94%\n",
      "              Val Loss: 0.9648208022117615, Val Acc: 65.24%\n",
      "Epoch: 3943,     Training Loss: 0.4273185431957245, Training Acc: 71.94%\n",
      "              Val Loss: 0.970126748085022, Val Acc: 65.24%\n",
      "Epoch: 3944,     Training Loss: 0.42134925723075867, Training Acc: 71.94%\n",
      "              Val Loss: 1.0246576070785522, Val Acc: 65.24%\n",
      "Epoch: 3945,     Training Loss: 0.4942329525947571, Training Acc: 71.94%\n",
      "              Val Loss: 0.9466108679771423, Val Acc: 65.24%\n",
      "Epoch: 3946,     Training Loss: 0.41111472249031067, Training Acc: 71.95%\n",
      "              Val Loss: 0.95606529712677, Val Acc: 65.24%\n",
      "Epoch: 3947,     Training Loss: 0.41145825386047363, Training Acc: 71.95%\n",
      "              Val Loss: 1.0505253076553345, Val Acc: 65.24%\n",
      "Epoch: 3948,     Training Loss: 0.49040135741233826, Training Acc: 71.95%\n",
      "              Val Loss: 0.9722740650177002, Val Acc: 65.24%\n",
      "Epoch: 3949,     Training Loss: 0.40840572118759155, Training Acc: 71.95%\n",
      "              Val Loss: 0.9508348107337952, Val Acc: 65.25%\n",
      "Epoch: 3950,     Training Loss: 0.39929720759391785, Training Acc: 71.96%\n",
      "              Val Loss: 1.0450515747070312, Val Acc: 65.25%\n",
      "Epoch: 3951,     Training Loss: 0.522106409072876, Training Acc: 71.96%\n",
      "              Val Loss: 0.9103118777275085, Val Acc: 65.25%\n",
      "Epoch: 3952,     Training Loss: 0.3814792335033417, Training Acc: 71.96%\n",
      "              Val Loss: 1.012402057647705, Val Acc: 65.25%\n",
      "Epoch: 3953,     Training Loss: 0.4555719494819641, Training Acc: 71.96%\n",
      "              Val Loss: 1.122654676437378, Val Acc: 65.25%\n",
      "Epoch: 3954,     Training Loss: 0.5979976654052734, Training Acc: 71.96%\n",
      "              Val Loss: 0.9396570324897766, Val Acc: 65.25%\n",
      "Epoch: 3955,     Training Loss: 0.39409810304641724, Training Acc: 71.97%\n",
      "              Val Loss: 1.1049578189849854, Val Acc: 65.25%\n",
      "Epoch: 3956,     Training Loss: 0.5434340834617615, Training Acc: 71.97%\n",
      "              Val Loss: 1.3791978359222412, Val Acc: 65.25%\n",
      "Epoch: 3957,     Training Loss: 0.8730146288871765, Training Acc: 71.97%\n",
      "              Val Loss: 0.9404746294021606, Val Acc: 65.25%\n",
      "Epoch: 3958,     Training Loss: 0.4379236698150635, Training Acc: 71.97%\n",
      "              Val Loss: 1.6780791282653809, Val Acc: 65.25%\n",
      "Epoch: 3959,     Training Loss: 1.1622648239135742, Training Acc: 71.97%\n",
      "              Val Loss: 2.2465457916259766, Val Acc: 65.24%\n",
      "Epoch: 3960,     Training Loss: 1.773881435394287, Training Acc: 71.96%\n",
      "              Val Loss: 1.844173789024353, Val Acc: 65.24%\n",
      "Epoch: 3961,     Training Loss: 1.501876711845398, Training Acc: 71.95%\n",
      "              Val Loss: 1.1427264213562012, Val Acc: 65.23%\n",
      "Epoch: 3962,     Training Loss: 0.7195802927017212, Training Acc: 71.95%\n",
      "              Val Loss: 1.8411120176315308, Val Acc: 65.23%\n",
      "Epoch: 3963,     Training Loss: 1.4031007289886475, Training Acc: 71.95%\n",
      "              Val Loss: 1.406760811805725, Val Acc: 65.23%\n",
      "Epoch: 3964,     Training Loss: 0.9845697283744812, Training Acc: 71.95%\n",
      "              Val Loss: 1.594505786895752, Val Acc: 65.23%\n",
      "Epoch: 3965,     Training Loss: 1.1640654802322388, Training Acc: 71.94%\n",
      "              Val Loss: 1.4276399612426758, Val Acc: 65.22%\n",
      "Epoch: 3966,     Training Loss: 1.0929248332977295, Training Acc: 71.94%\n",
      "              Val Loss: 1.5596473217010498, Val Acc: 65.22%\n",
      "Epoch: 3967,     Training Loss: 1.1826142072677612, Training Acc: 71.94%\n",
      "              Val Loss: 1.2158458232879639, Val Acc: 65.22%\n",
      "Epoch: 3968,     Training Loss: 0.8568960428237915, Training Acc: 71.94%\n",
      "              Val Loss: 1.3169232606887817, Val Acc: 65.22%\n",
      "Epoch: 3969,     Training Loss: 0.9871281385421753, Training Acc: 71.93%\n",
      "              Val Loss: 1.4003164768218994, Val Acc: 65.22%\n",
      "Epoch: 3970,     Training Loss: 1.0694760084152222, Training Acc: 71.93%\n",
      "              Val Loss: 1.1177889108657837, Val Acc: 65.21%\n",
      "Epoch: 3971,     Training Loss: 0.7624748945236206, Training Acc: 71.93%\n",
      "              Val Loss: 1.2741668224334717, Val Acc: 65.21%\n",
      "Epoch: 3972,     Training Loss: 0.898918092250824, Training Acc: 71.93%\n",
      "              Val Loss: 1.221980333328247, Val Acc: 65.21%\n",
      "Epoch: 3973,     Training Loss: 0.8835067749023438, Training Acc: 71.93%\n",
      "              Val Loss: 1.036857008934021, Val Acc: 65.21%\n",
      "Epoch: 3974,     Training Loss: 0.7466613054275513, Training Acc: 71.92%\n",
      "              Val Loss: 0.9849060773849487, Val Acc: 65.21%\n",
      "Epoch: 3975,     Training Loss: 0.726193904876709, Training Acc: 71.92%\n",
      "              Val Loss: 1.071865200996399, Val Acc: 65.21%\n",
      "Epoch: 3976,     Training Loss: 0.7981294989585876, Training Acc: 71.92%\n",
      "              Val Loss: 1.0158283710479736, Val Acc: 65.21%\n",
      "Epoch: 3977,     Training Loss: 0.7184094786643982, Training Acc: 71.92%\n",
      "              Val Loss: 1.1111100912094116, Val Acc: 65.21%\n",
      "Epoch: 3978,     Training Loss: 0.6948410868644714, Training Acc: 71.92%\n",
      "              Val Loss: 0.9743500351905823, Val Acc: 65.21%\n",
      "Epoch: 3979,     Training Loss: 0.6595571637153625, Training Acc: 71.92%\n",
      "              Val Loss: 0.9913433790206909, Val Acc: 65.21%\n",
      "Epoch: 3980,     Training Loss: 0.6812174916267395, Training Acc: 71.92%\n",
      "              Val Loss: 0.9460855722427368, Val Acc: 65.21%\n",
      "Epoch: 3981,     Training Loss: 0.6814234852790833, Training Acc: 71.92%\n",
      "              Val Loss: 0.8833264112472534, Val Acc: 65.21%\n",
      "Epoch: 3982,     Training Loss: 0.6633443236351013, Training Acc: 71.92%\n",
      "              Val Loss: 0.8233702182769775, Val Acc: 65.21%\n",
      "Epoch: 3983,     Training Loss: 0.6117565035820007, Training Acc: 71.92%\n",
      "              Val Loss: 0.8799612522125244, Val Acc: 65.21%\n",
      "Epoch: 3984,     Training Loss: 0.6301707029342651, Training Acc: 71.92%\n",
      "              Val Loss: 0.8744015693664551, Val Acc: 65.22%\n",
      "Epoch: 3985,     Training Loss: 0.6042577624320984, Training Acc: 71.92%\n",
      "              Val Loss: 0.8439834713935852, Val Acc: 65.22%\n",
      "Epoch: 3986,     Training Loss: 0.565052330493927, Training Acc: 71.92%\n",
      "              Val Loss: 0.8917340636253357, Val Acc: 65.22%\n",
      "Epoch: 3987,     Training Loss: 0.5811414122581482, Training Acc: 71.92%\n",
      "              Val Loss: 0.8801056146621704, Val Acc: 65.22%\n",
      "Epoch: 3988,     Training Loss: 0.5609354972839355, Training Acc: 71.93%\n",
      "              Val Loss: 0.8715368509292603, Val Acc: 65.22%\n",
      "Epoch: 3989,     Training Loss: 0.5457643866539001, Training Acc: 71.93%\n",
      "              Val Loss: 0.8837733268737793, Val Acc: 65.22%\n",
      "Epoch: 3990,     Training Loss: 0.5545810461044312, Training Acc: 71.93%\n",
      "              Val Loss: 0.836235523223877, Val Acc: 65.22%\n",
      "Epoch: 3991,     Training Loss: 0.5277013182640076, Training Acc: 71.93%\n",
      "              Val Loss: 0.8056225776672363, Val Acc: 65.23%\n",
      "Epoch: 3992,     Training Loss: 0.5194025039672852, Training Acc: 71.93%\n",
      "              Val Loss: 0.8081867694854736, Val Acc: 65.23%\n",
      "Epoch: 3993,     Training Loss: 0.518149197101593, Training Acc: 71.93%\n",
      "              Val Loss: 0.8033905029296875, Val Acc: 65.23%\n",
      "Epoch: 3994,     Training Loss: 0.5090321898460388, Training Acc: 71.93%\n",
      "              Val Loss: 0.8281437754631042, Val Acc: 65.23%\n",
      "Epoch: 3995,     Training Loss: 0.5073021054267883, Training Acc: 71.94%\n",
      "              Val Loss: 0.8098108172416687, Val Acc: 65.23%\n",
      "Epoch: 3996,     Training Loss: 0.4929419755935669, Training Acc: 71.94%\n",
      "              Val Loss: 0.8089093565940857, Val Acc: 65.23%\n",
      "Epoch: 3997,     Training Loss: 0.48584723472595215, Training Acc: 71.94%\n",
      "              Val Loss: 0.8084648251533508, Val Acc: 65.24%\n",
      "Epoch: 3998,     Training Loss: 0.48355740308761597, Training Acc: 71.94%\n",
      "              Val Loss: 0.8147545456886292, Val Acc: 65.24%\n",
      "Epoch: 3999,     Training Loss: 0.47722288966178894, Training Acc: 71.94%\n",
      "              Val Loss: 0.8385367393493652, Val Acc: 65.24%\n",
      "Epoch: 4000,     Training Loss: 0.4844534695148468, Training Acc: 71.95%\n",
      "              Val Loss: 0.854218065738678, Val Acc: 65.24%\n",
      "Epoch: 4001,     Training Loss: 0.4975935220718384, Training Acc: 71.95%\n",
      "              Val Loss: 0.8493165373802185, Val Acc: 65.24%\n",
      "Epoch: 4002,     Training Loss: 0.47007468342781067, Training Acc: 71.95%\n",
      "              Val Loss: 0.8473554849624634, Val Acc: 65.25%\n",
      "Epoch: 4003,     Training Loss: 0.46150070428848267, Training Acc: 71.95%\n",
      "              Val Loss: 0.8539488315582275, Val Acc: 65.25%\n",
      "Epoch: 4004,     Training Loss: 0.4571784734725952, Training Acc: 71.96%\n",
      "              Val Loss: 0.8768110871315002, Val Acc: 65.25%\n",
      "Epoch: 4005,     Training Loss: 0.4621638357639313, Training Acc: 71.96%\n",
      "              Val Loss: 0.8783698081970215, Val Acc: 65.25%\n",
      "Epoch: 4006,     Training Loss: 0.47297537326812744, Training Acc: 71.96%\n",
      "              Val Loss: 0.8671056628227234, Val Acc: 65.25%\n",
      "Epoch: 4007,     Training Loss: 0.4550550580024719, Training Acc: 71.96%\n",
      "              Val Loss: 0.8491689562797546, Val Acc: 65.26%\n",
      "Epoch: 4008,     Training Loss: 0.4435454308986664, Training Acc: 71.96%\n",
      "              Val Loss: 0.8504793643951416, Val Acc: 65.26%\n",
      "Epoch: 4009,     Training Loss: 0.4484586715698242, Training Acc: 71.97%\n",
      "              Val Loss: 0.8598912954330444, Val Acc: 65.26%\n",
      "Epoch: 4010,     Training Loss: 0.44967377185821533, Training Acc: 71.97%\n",
      "              Val Loss: 0.8523075580596924, Val Acc: 65.26%\n",
      "Epoch: 4011,     Training Loss: 0.44532036781311035, Training Acc: 71.97%\n",
      "              Val Loss: 0.8425695300102234, Val Acc: 65.26%\n",
      "Epoch: 4012,     Training Loss: 0.43441373109817505, Training Acc: 71.98%\n",
      "              Val Loss: 0.8407543301582336, Val Acc: 65.26%\n",
      "Epoch: 4013,     Training Loss: 0.43316951394081116, Training Acc: 71.98%\n",
      "              Val Loss: 0.8516544103622437, Val Acc: 65.27%\n",
      "Epoch: 4014,     Training Loss: 0.4457385540008545, Training Acc: 71.98%\n",
      "              Val Loss: 0.8558955192565918, Val Acc: 65.27%\n",
      "Epoch: 4015,     Training Loss: 0.4388938546180725, Training Acc: 71.98%\n",
      "              Val Loss: 0.840201199054718, Val Acc: 65.27%\n",
      "Epoch: 4016,     Training Loss: 0.42629921436309814, Training Acc: 71.99%\n",
      "              Val Loss: 0.8375979065895081, Val Acc: 65.27%\n",
      "Epoch: 4017,     Training Loss: 0.4201372265815735, Training Acc: 71.99%\n",
      "              Val Loss: 0.8423534631729126, Val Acc: 65.27%\n",
      "Epoch: 4018,     Training Loss: 0.4209815263748169, Training Acc: 71.99%\n",
      "              Val Loss: 0.8479959964752197, Val Acc: 65.28%\n",
      "Epoch: 4019,     Training Loss: 0.42912304401397705, Training Acc: 71.99%\n",
      "              Val Loss: 0.864540696144104, Val Acc: 65.28%\n",
      "Epoch: 4020,     Training Loss: 0.43588724732398987, Training Acc: 72.00%\n",
      "              Val Loss: 0.8931149840354919, Val Acc: 65.28%\n",
      "Epoch: 4021,     Training Loss: 0.4662497341632843, Training Acc: 72.00%\n",
      "              Val Loss: 0.8755847215652466, Val Acc: 65.28%\n",
      "Epoch: 4022,     Training Loss: 0.4326801300048828, Training Acc: 72.00%\n",
      "              Val Loss: 0.8539888858795166, Val Acc: 65.28%\n",
      "Epoch: 4023,     Training Loss: 0.41553348302841187, Training Acc: 72.00%\n",
      "              Val Loss: 0.8518635034561157, Val Acc: 65.28%\n",
      "Epoch: 4024,     Training Loss: 0.40936100482940674, Training Acc: 72.01%\n",
      "              Val Loss: 0.858712375164032, Val Acc: 65.29%\n",
      "Epoch: 4025,     Training Loss: 0.41084566712379456, Training Acc: 72.01%\n",
      "              Val Loss: 0.8697726726531982, Val Acc: 65.29%\n",
      "Epoch: 4026,     Training Loss: 0.4196220636367798, Training Acc: 72.01%\n",
      "              Val Loss: 0.8829944729804993, Val Acc: 65.29%\n",
      "Epoch: 4027,     Training Loss: 0.42901259660720825, Training Acc: 72.01%\n",
      "              Val Loss: 0.9190441966056824, Val Acc: 65.29%\n",
      "Epoch: 4028,     Training Loss: 0.4663164019584656, Training Acc: 72.02%\n",
      "              Val Loss: 0.8807533979415894, Val Acc: 65.29%\n",
      "Epoch: 4029,     Training Loss: 0.4223412573337555, Training Acc: 72.02%\n",
      "              Val Loss: 0.8733885884284973, Val Acc: 65.30%\n",
      "Epoch: 4030,     Training Loss: 0.40976861119270325, Training Acc: 72.02%\n",
      "              Val Loss: 0.8731984496116638, Val Acc: 65.30%\n",
      "Epoch: 4031,     Training Loss: 0.4039630889892578, Training Acc: 72.03%\n",
      "              Val Loss: 0.8684781789779663, Val Acc: 65.30%\n",
      "Epoch: 4032,     Training Loss: 0.40017661452293396, Training Acc: 72.03%\n",
      "              Val Loss: 0.8667700290679932, Val Acc: 65.30%\n",
      "Epoch: 4033,     Training Loss: 0.39778685569763184, Training Acc: 72.03%\n",
      "              Val Loss: 0.8736017346382141, Val Acc: 65.30%\n",
      "Epoch: 4034,     Training Loss: 0.40160202980041504, Training Acc: 72.03%\n",
      "              Val Loss: 0.8830256462097168, Val Acc: 65.31%\n",
      "Epoch: 4035,     Training Loss: 0.4142783284187317, Training Acc: 72.04%\n",
      "              Val Loss: 0.9192350506782532, Val Acc: 65.31%\n",
      "Epoch: 4036,     Training Loss: 0.4549511671066284, Training Acc: 72.04%\n",
      "              Val Loss: 1.18174409866333, Val Acc: 65.31%\n",
      "Epoch: 4037,     Training Loss: 0.7155601978302002, Training Acc: 72.04%\n",
      "              Val Loss: 0.9163388013839722, Val Acc: 65.31%\n",
      "Epoch: 4038,     Training Loss: 0.4434284567832947, Training Acc: 72.04%\n",
      "              Val Loss: 1.1129536628723145, Val Acc: 65.31%\n",
      "Epoch: 4039,     Training Loss: 0.6073750257492065, Training Acc: 72.04%\n",
      "              Val Loss: 1.3997139930725098, Val Acc: 65.31%\n",
      "Epoch: 4040,     Training Loss: 0.9505972862243652, Training Acc: 72.04%\n",
      "              Val Loss: 1.0047320127487183, Val Acc: 65.31%\n",
      "Epoch: 4041,     Training Loss: 0.5700851082801819, Training Acc: 72.04%\n",
      "              Val Loss: 1.8474242687225342, Val Acc: 65.30%\n",
      "Epoch: 4042,     Training Loss: 1.281692624092102, Training Acc: 72.04%\n",
      "              Val Loss: 1.492641568183899, Val Acc: 65.30%\n",
      "Epoch: 4043,     Training Loss: 1.0949939489364624, Training Acc: 72.03%\n",
      "              Val Loss: 1.6849337816238403, Val Acc: 65.30%\n",
      "Epoch: 4044,     Training Loss: 1.3037492036819458, Training Acc: 72.03%\n",
      "              Val Loss: 1.0102858543395996, Val Acc: 65.30%\n",
      "Epoch: 4045,     Training Loss: 0.5890688896179199, Training Acc: 72.03%\n",
      "              Val Loss: 1.9081615209579468, Val Acc: 65.29%\n",
      "Epoch: 4046,     Training Loss: 1.4574857950210571, Training Acc: 72.03%\n",
      "              Val Loss: 1.312743067741394, Val Acc: 65.29%\n",
      "Epoch: 4047,     Training Loss: 0.8910307884216309, Training Acc: 72.02%\n",
      "              Val Loss: 1.5683642625808716, Val Acc: 65.29%\n",
      "Epoch: 4048,     Training Loss: 1.1658560037612915, Training Acc: 72.02%\n",
      "              Val Loss: 1.2305874824523926, Val Acc: 65.29%\n",
      "Epoch: 4049,     Training Loss: 0.8357460498809814, Training Acc: 72.02%\n",
      "              Val Loss: 1.3423364162445068, Val Acc: 65.29%\n",
      "Epoch: 4050,     Training Loss: 0.9265305399894714, Training Acc: 72.02%\n",
      "              Val Loss: 1.263185977935791, Val Acc: 65.28%\n",
      "Epoch: 4051,     Training Loss: 0.9002079963684082, Training Acc: 72.02%\n",
      "              Val Loss: 1.1348223686218262, Val Acc: 65.28%\n",
      "Epoch: 4052,     Training Loss: 0.7736608386039734, Training Acc: 72.02%\n",
      "              Val Loss: 1.232369303703308, Val Acc: 65.28%\n",
      "Epoch: 4053,     Training Loss: 0.8155093193054199, Training Acc: 72.01%\n",
      "              Val Loss: 1.2412303686141968, Val Acc: 65.28%\n",
      "Epoch: 4054,     Training Loss: 0.8262593746185303, Training Acc: 72.01%\n",
      "              Val Loss: 0.9743534326553345, Val Acc: 65.28%\n",
      "Epoch: 4055,     Training Loss: 0.6258633732795715, Training Acc: 72.01%\n",
      "              Val Loss: 1.0784426927566528, Val Acc: 65.28%\n",
      "Epoch: 4056,     Training Loss: 0.7542582154273987, Training Acc: 72.01%\n",
      "              Val Loss: 1.051557183265686, Val Acc: 65.28%\n",
      "Epoch: 4057,     Training Loss: 0.7344297170639038, Training Acc: 72.01%\n",
      "              Val Loss: 0.901500403881073, Val Acc: 65.28%\n",
      "Epoch: 4058,     Training Loss: 0.5786728858947754, Training Acc: 72.01%\n",
      "              Val Loss: 1.060748815536499, Val Acc: 65.28%\n",
      "Epoch: 4059,     Training Loss: 0.6965649127960205, Training Acc: 72.01%\n",
      "              Val Loss: 0.996198832988739, Val Acc: 65.29%\n",
      "Epoch: 4060,     Training Loss: 0.6333690881729126, Training Acc: 72.01%\n",
      "              Val Loss: 1.0176674127578735, Val Acc: 65.29%\n",
      "Epoch: 4061,     Training Loss: 0.6350923776626587, Training Acc: 72.01%\n",
      "              Val Loss: 0.9514037370681763, Val Acc: 65.29%\n",
      "Epoch: 4062,     Training Loss: 0.58842533826828, Training Acc: 72.01%\n",
      "              Val Loss: 0.9910594820976257, Val Acc: 65.29%\n",
      "Epoch: 4063,     Training Loss: 0.6106294393539429, Training Acc: 72.01%\n",
      "              Val Loss: 0.9809344410896301, Val Acc: 65.29%\n",
      "Epoch: 4064,     Training Loss: 0.6042499542236328, Training Acc: 72.02%\n",
      "              Val Loss: 0.9745244383811951, Val Acc: 65.29%\n",
      "Epoch: 4065,     Training Loss: 0.6009363532066345, Training Acc: 72.02%\n",
      "              Val Loss: 0.943901002407074, Val Acc: 65.29%\n",
      "Epoch: 4066,     Training Loss: 0.5577465295791626, Training Acc: 72.02%\n",
      "              Val Loss: 0.9370595812797546, Val Acc: 65.29%\n",
      "Epoch: 4067,     Training Loss: 0.5338356494903564, Training Acc: 72.02%\n",
      "              Val Loss: 0.9862138628959656, Val Acc: 65.29%\n",
      "Epoch: 4068,     Training Loss: 0.5572565197944641, Training Acc: 72.02%\n",
      "              Val Loss: 0.9299095869064331, Val Acc: 65.30%\n",
      "Epoch: 4069,     Training Loss: 0.5222554206848145, Training Acc: 72.02%\n",
      "              Val Loss: 0.9046799540519714, Val Acc: 65.30%\n",
      "Epoch: 4070,     Training Loss: 0.5274731516838074, Training Acc: 72.02%\n",
      "              Val Loss: 0.8861895203590393, Val Acc: 65.30%\n",
      "Epoch: 4071,     Training Loss: 0.515372633934021, Training Acc: 72.03%\n",
      "              Val Loss: 0.887692391872406, Val Acc: 65.30%\n",
      "Epoch: 4072,     Training Loss: 0.4967121183872223, Training Acc: 72.03%\n",
      "              Val Loss: 0.9118137955665588, Val Acc: 65.30%\n",
      "Epoch: 4073,     Training Loss: 0.4929298460483551, Training Acc: 72.03%\n",
      "              Val Loss: 0.9419683218002319, Val Acc: 65.30%\n",
      "Epoch: 4074,     Training Loss: 0.487946480512619, Training Acc: 72.03%\n",
      "              Val Loss: 0.9205635190010071, Val Acc: 65.31%\n",
      "Epoch: 4075,     Training Loss: 0.47105902433395386, Training Acc: 72.03%\n",
      "              Val Loss: 0.9041492342948914, Val Acc: 65.31%\n",
      "Epoch: 4076,     Training Loss: 0.47004684805870056, Training Acc: 72.04%\n",
      "              Val Loss: 0.8785340189933777, Val Acc: 65.31%\n",
      "Epoch: 4077,     Training Loss: 0.4609505534172058, Training Acc: 72.04%\n",
      "              Val Loss: 0.8757839202880859, Val Acc: 65.31%\n",
      "Epoch: 4078,     Training Loss: 0.46469685435295105, Training Acc: 72.04%\n",
      "              Val Loss: 0.8744637966156006, Val Acc: 65.31%\n",
      "Epoch: 4079,     Training Loss: 0.45166102051734924, Training Acc: 72.04%\n",
      "              Val Loss: 0.8916209936141968, Val Acc: 65.31%\n",
      "Epoch: 4080,     Training Loss: 0.44645214080810547, Training Acc: 72.05%\n",
      "              Val Loss: 0.9074708819389343, Val Acc: 65.32%\n",
      "Epoch: 4081,     Training Loss: 0.44940078258514404, Training Acc: 72.05%\n",
      "              Val Loss: 0.8890441656112671, Val Acc: 65.32%\n",
      "Epoch: 4082,     Training Loss: 0.4364142119884491, Training Acc: 72.05%\n",
      "              Val Loss: 0.8770101070404053, Val Acc: 65.32%\n",
      "Epoch: 4083,     Training Loss: 0.4364207983016968, Training Acc: 72.05%\n",
      "              Val Loss: 0.8637484908103943, Val Acc: 65.32%\n",
      "Epoch: 4084,     Training Loss: 0.4307994544506073, Training Acc: 72.06%\n",
      "              Val Loss: 0.8571022748947144, Val Acc: 65.32%\n",
      "Epoch: 4085,     Training Loss: 0.42765986919403076, Training Acc: 72.06%\n",
      "              Val Loss: 0.8582520484924316, Val Acc: 65.33%\n",
      "Epoch: 4086,     Training Loss: 0.42689037322998047, Training Acc: 72.06%\n",
      "              Val Loss: 0.8553373217582703, Val Acc: 65.33%\n",
      "Epoch: 4087,     Training Loss: 0.4194561243057251, Training Acc: 72.06%\n",
      "              Val Loss: 0.8619458079338074, Val Acc: 65.33%\n",
      "Epoch: 4088,     Training Loss: 0.42065533995628357, Training Acc: 72.07%\n",
      "              Val Loss: 0.8682158589363098, Val Acc: 65.33%\n",
      "Epoch: 4089,     Training Loss: 0.4158754348754883, Training Acc: 72.07%\n",
      "              Val Loss: 0.878709614276886, Val Acc: 65.34%\n",
      "Epoch: 4090,     Training Loss: 0.41432198882102966, Training Acc: 72.07%\n",
      "              Val Loss: 0.8814723491668701, Val Acc: 65.34%\n",
      "Epoch: 4091,     Training Loss: 0.41401124000549316, Training Acc: 72.07%\n",
      "              Val Loss: 0.870130181312561, Val Acc: 65.34%\n",
      "Epoch: 4092,     Training Loss: 0.40790680050849915, Training Acc: 72.08%\n",
      "              Val Loss: 0.8690030574798584, Val Acc: 65.34%\n",
      "Epoch: 4093,     Training Loss: 0.40971943736076355, Training Acc: 72.08%\n",
      "              Val Loss: 0.872211754322052, Val Acc: 65.34%\n",
      "Epoch: 4094,     Training Loss: 0.40679675340652466, Training Acc: 72.08%\n",
      "              Val Loss: 0.8800234794616699, Val Acc: 65.35%\n",
      "Epoch: 4095,     Training Loss: 0.4038316607475281, Training Acc: 72.09%\n",
      "              Val Loss: 0.8845958709716797, Val Acc: 65.35%\n",
      "Epoch: 4096,     Training Loss: 0.4017208516597748, Training Acc: 72.09%\n",
      "              Val Loss: 0.8827394247055054, Val Acc: 65.35%\n",
      "Epoch: 4097,     Training Loss: 0.40062853693962097, Training Acc: 72.09%\n",
      "              Val Loss: 0.8801231384277344, Val Acc: 65.35%\n",
      "Epoch: 4098,     Training Loss: 0.3999803960323334, Training Acc: 72.09%\n",
      "              Val Loss: 0.8755670785903931, Val Acc: 65.35%\n",
      "Epoch: 4099,     Training Loss: 0.396354079246521, Training Acc: 72.10%\n",
      "              Val Loss: 0.8743864297866821, Val Acc: 65.36%\n",
      "Epoch: 4100,     Training Loss: 0.39527538418769836, Training Acc: 72.10%\n",
      "              Val Loss: 0.8739493489265442, Val Acc: 65.36%\n",
      "Epoch: 4101,     Training Loss: 0.3942490518093109, Training Acc: 72.10%\n",
      "              Val Loss: 0.8765003085136414, Val Acc: 65.36%\n",
      "Epoch: 4102,     Training Loss: 0.3936116397380829, Training Acc: 72.11%\n",
      "              Val Loss: 0.8834673166275024, Val Acc: 65.36%\n",
      "Epoch: 4103,     Training Loss: 0.39112597703933716, Training Acc: 72.11%\n",
      "              Val Loss: 0.8921988606452942, Val Acc: 65.37%\n",
      "Epoch: 4104,     Training Loss: 0.39143770933151245, Training Acc: 72.11%\n",
      "              Val Loss: 0.8934453725814819, Val Acc: 65.37%\n",
      "Epoch: 4105,     Training Loss: 0.39044198393821716, Training Acc: 72.11%\n",
      "              Val Loss: 0.892372727394104, Val Acc: 65.37%\n",
      "Epoch: 4106,     Training Loss: 0.3934268057346344, Training Acc: 72.12%\n",
      "              Val Loss: 0.8922083973884583, Val Acc: 65.37%\n",
      "Epoch: 4107,     Training Loss: 0.39533618092536926, Training Acc: 72.12%\n",
      "              Val Loss: 0.896821916103363, Val Acc: 65.38%\n",
      "Epoch: 4108,     Training Loss: 0.4031275808811188, Training Acc: 72.12%\n",
      "              Val Loss: 0.8909648060798645, Val Acc: 65.38%\n",
      "Epoch: 4109,     Training Loss: 0.3958624303340912, Training Acc: 72.13%\n",
      "              Val Loss: 0.8845165371894836, Val Acc: 65.38%\n",
      "Epoch: 4110,     Training Loss: 0.39213940501213074, Training Acc: 72.13%\n",
      "              Val Loss: 0.8790127038955688, Val Acc: 65.38%\n",
      "Epoch: 4111,     Training Loss: 0.3840283453464508, Training Acc: 72.13%\n",
      "              Val Loss: 0.8782550692558289, Val Acc: 65.38%\n",
      "Epoch: 4112,     Training Loss: 0.3820064067840576, Training Acc: 72.14%\n",
      "              Val Loss: 0.8779118061065674, Val Acc: 65.39%\n",
      "Epoch: 4113,     Training Loss: 0.38516056537628174, Training Acc: 72.14%\n",
      "              Val Loss: 0.8793573975563049, Val Acc: 65.39%\n",
      "Epoch: 4114,     Training Loss: 0.3909800350666046, Training Acc: 72.14%\n",
      "              Val Loss: 0.8899969458580017, Val Acc: 65.39%\n",
      "Epoch: 4115,     Training Loss: 0.40528255701065063, Training Acc: 72.14%\n",
      "              Val Loss: 0.8800681233406067, Val Acc: 65.39%\n",
      "Epoch: 4116,     Training Loss: 0.39468902349472046, Training Acc: 72.15%\n",
      "              Val Loss: 0.8769521117210388, Val Acc: 65.39%\n",
      "Epoch: 4117,     Training Loss: 0.3900534510612488, Training Acc: 72.15%\n",
      "              Val Loss: 0.8673394918441772, Val Acc: 65.40%\n",
      "Epoch: 4118,     Training Loss: 0.37980490922927856, Training Acc: 72.15%\n",
      "              Val Loss: 0.8683769702911377, Val Acc: 65.40%\n",
      "Epoch: 4119,     Training Loss: 0.37858477234840393, Training Acc: 72.16%\n",
      "              Val Loss: 0.8770983219146729, Val Acc: 65.40%\n",
      "Epoch: 4120,     Training Loss: 0.38496702909469604, Training Acc: 72.16%\n",
      "              Val Loss: 0.8860955834388733, Val Acc: 65.40%\n",
      "Epoch: 4121,     Training Loss: 0.39380374550819397, Training Acc: 72.16%\n",
      "              Val Loss: 0.9134282469749451, Val Acc: 65.41%\n",
      "Epoch: 4122,     Training Loss: 0.42276516556739807, Training Acc: 72.16%\n",
      "              Val Loss: 0.8845657110214233, Val Acc: 65.41%\n",
      "Epoch: 4123,     Training Loss: 0.39344242215156555, Training Acc: 72.17%\n",
      "              Val Loss: 0.8735678195953369, Val Acc: 65.41%\n",
      "Epoch: 4124,     Training Loss: 0.37953871488571167, Training Acc: 72.17%\n",
      "              Val Loss: 0.8741967678070068, Val Acc: 65.41%\n",
      "Epoch: 4125,     Training Loss: 0.376090407371521, Training Acc: 72.17%\n",
      "              Val Loss: 0.8848522901535034, Val Acc: 65.41%\n",
      "Epoch: 4126,     Training Loss: 0.3820938169956207, Training Acc: 72.18%\n",
      "              Val Loss: 0.9006714820861816, Val Acc: 65.42%\n",
      "Epoch: 4127,     Training Loss: 0.396799236536026, Training Acc: 72.18%\n",
      "              Val Loss: 0.8962172865867615, Val Acc: 65.42%\n",
      "Epoch: 4128,     Training Loss: 0.3903476297855377, Training Acc: 72.18%\n",
      "              Val Loss: 0.8901275396347046, Val Acc: 65.42%\n",
      "Epoch: 4129,     Training Loss: 0.3888131082057953, Training Acc: 72.18%\n",
      "              Val Loss: 0.8756376504898071, Val Acc: 65.42%\n",
      "Epoch: 4130,     Training Loss: 0.3790122866630554, Training Acc: 72.19%\n",
      "              Val Loss: 0.8699047565460205, Val Acc: 65.42%\n",
      "Epoch: 4131,     Training Loss: 0.3741984963417053, Training Acc: 72.19%\n",
      "              Val Loss: 0.875995934009552, Val Acc: 65.43%\n",
      "Epoch: 4132,     Training Loss: 0.37145426869392395, Training Acc: 72.19%\n",
      "              Val Loss: 0.8828885555267334, Val Acc: 65.43%\n",
      "Epoch: 4133,     Training Loss: 0.3731336295604706, Training Acc: 72.20%\n",
      "              Val Loss: 0.8841533660888672, Val Acc: 65.43%\n",
      "Epoch: 4134,     Training Loss: 0.3785668909549713, Training Acc: 72.20%\n",
      "              Val Loss: 0.889150083065033, Val Acc: 65.43%\n",
      "Epoch: 4135,     Training Loss: 0.3842030465602875, Training Acc: 72.20%\n",
      "              Val Loss: 0.9128788113594055, Val Acc: 65.43%\n",
      "Epoch: 4136,     Training Loss: 0.4118472635746002, Training Acc: 72.20%\n",
      "              Val Loss: 0.9054151773452759, Val Acc: 65.44%\n",
      "Epoch: 4137,     Training Loss: 0.40537258982658386, Training Acc: 72.21%\n",
      "              Val Loss: 0.9089733362197876, Val Acc: 65.44%\n",
      "Epoch: 4138,     Training Loss: 0.4108753204345703, Training Acc: 72.21%\n",
      "              Val Loss: 0.8857037425041199, Val Acc: 65.44%\n",
      "Epoch: 4139,     Training Loss: 0.3771347105503082, Training Acc: 72.21%\n",
      "              Val Loss: 0.8990275859832764, Val Acc: 65.44%\n",
      "Epoch: 4140,     Training Loss: 0.38129428029060364, Training Acc: 72.22%\n",
      "              Val Loss: 0.9254869222640991, Val Acc: 65.44%\n",
      "Epoch: 4141,     Training Loss: 0.41713351011276245, Training Acc: 72.22%\n",
      "              Val Loss: 0.9116321802139282, Val Acc: 65.44%\n",
      "Epoch: 4142,     Training Loss: 0.40081170201301575, Training Acc: 72.22%\n",
      "              Val Loss: 0.8984797596931458, Val Acc: 65.45%\n",
      "Epoch: 4143,     Training Loss: 0.39284396171569824, Training Acc: 72.22%\n",
      "              Val Loss: 0.8746204376220703, Val Acc: 65.45%\n",
      "Epoch: 4144,     Training Loss: 0.3722095489501953, Training Acc: 72.23%\n",
      "              Val Loss: 0.8762403130531311, Val Acc: 65.45%\n",
      "Epoch: 4145,     Training Loss: 0.3770638704299927, Training Acc: 72.23%\n",
      "              Val Loss: 0.8996259570121765, Val Acc: 65.45%\n",
      "Epoch: 4146,     Training Loss: 0.4026292562484741, Training Acc: 72.23%\n",
      "              Val Loss: 0.8998841643333435, Val Acc: 65.45%\n",
      "Epoch: 4147,     Training Loss: 0.38991284370422363, Training Acc: 72.24%\n",
      "              Val Loss: 0.8949056267738342, Val Acc: 65.46%\n",
      "Epoch: 4148,     Training Loss: 0.3850766718387604, Training Acc: 72.24%\n",
      "              Val Loss: 0.8833375573158264, Val Acc: 65.46%\n",
      "Epoch: 4149,     Training Loss: 0.37096107006073, Training Acc: 72.24%\n",
      "              Val Loss: 0.8843599557876587, Val Acc: 65.46%\n",
      "Epoch: 4150,     Training Loss: 0.36991652846336365, Training Acc: 72.24%\n",
      "              Val Loss: 0.8948176503181458, Val Acc: 65.46%\n",
      "Epoch: 4151,     Training Loss: 0.38647887110710144, Training Acc: 72.25%\n",
      "              Val Loss: 0.9032028317451477, Val Acc: 65.46%\n",
      "Epoch: 4152,     Training Loss: 0.39277493953704834, Training Acc: 72.25%\n",
      "              Val Loss: 0.9220834970474243, Val Acc: 65.46%\n",
      "Epoch: 4153,     Training Loss: 0.4144012928009033, Training Acc: 72.25%\n",
      "              Val Loss: 0.9038537740707397, Val Acc: 65.47%\n",
      "Epoch: 4154,     Training Loss: 0.38455408811569214, Training Acc: 72.26%\n",
      "              Val Loss: 0.8825052380561829, Val Acc: 65.47%\n",
      "Epoch: 4155,     Training Loss: 0.3694603741168976, Training Acc: 72.26%\n",
      "              Val Loss: 0.8784451484680176, Val Acc: 65.47%\n",
      "Epoch: 4156,     Training Loss: 0.3696580231189728, Training Acc: 72.26%\n",
      "              Val Loss: 0.8926359415054321, Val Acc: 65.47%\n",
      "Epoch: 4157,     Training Loss: 0.3770657777786255, Training Acc: 72.26%\n",
      "              Val Loss: 0.8986623883247375, Val Acc: 65.47%\n",
      "Epoch: 4158,     Training Loss: 0.3892483413219452, Training Acc: 72.27%\n",
      "              Val Loss: 0.8964628577232361, Val Acc: 65.48%\n",
      "Epoch: 4159,     Training Loss: 0.38533928990364075, Training Acc: 72.27%\n",
      "              Val Loss: 0.8910844326019287, Val Acc: 65.48%\n",
      "Epoch: 4160,     Training Loss: 0.38488447666168213, Training Acc: 72.27%\n",
      "              Val Loss: 0.8809016346931458, Val Acc: 65.48%\n",
      "Epoch: 4161,     Training Loss: 0.37101486325263977, Training Acc: 72.28%\n",
      "              Val Loss: 0.8741471767425537, Val Acc: 65.48%\n",
      "Epoch: 4162,     Training Loss: 0.3654942810535431, Training Acc: 72.28%\n",
      "              Val Loss: 0.8789756894111633, Val Acc: 65.48%\n",
      "Epoch: 4163,     Training Loss: 0.3637579083442688, Training Acc: 72.28%\n",
      "              Val Loss: 0.8922116756439209, Val Acc: 65.49%\n",
      "Epoch: 4164,     Training Loss: 0.36855462193489075, Training Acc: 72.28%\n",
      "              Val Loss: 0.893858790397644, Val Acc: 65.49%\n",
      "Epoch: 4165,     Training Loss: 0.37940287590026855, Training Acc: 72.29%\n",
      "              Val Loss: 0.8940707445144653, Val Acc: 65.49%\n",
      "Epoch: 4166,     Training Loss: 0.38138726353645325, Training Acc: 72.29%\n",
      "              Val Loss: 0.9137899875640869, Val Acc: 65.49%\n",
      "Epoch: 4167,     Training Loss: 0.4063434898853302, Training Acc: 72.29%\n",
      "              Val Loss: 0.9019868969917297, Val Acc: 65.49%\n",
      "Epoch: 4168,     Training Loss: 0.38962632417678833, Training Acc: 72.30%\n",
      "              Val Loss: 0.8953039646148682, Val Acc: 65.49%\n",
      "Epoch: 4169,     Training Loss: 0.3814452886581421, Training Acc: 72.30%\n",
      "              Val Loss: 0.8878165483474731, Val Acc: 65.50%\n",
      "Epoch: 4170,     Training Loss: 0.36484119296073914, Training Acc: 72.30%\n",
      "              Val Loss: 0.902407169342041, Val Acc: 65.50%\n",
      "Epoch: 4171,     Training Loss: 0.37396204471588135, Training Acc: 72.31%\n",
      "              Val Loss: 0.9231131672859192, Val Acc: 65.50%\n",
      "Epoch: 4172,     Training Loss: 0.40407928824424744, Training Acc: 72.31%\n",
      "              Val Loss: 0.9081912040710449, Val Acc: 65.50%\n",
      "Epoch: 4173,     Training Loss: 0.38756027817726135, Training Acc: 72.31%\n",
      "              Val Loss: 0.8970137238502502, Val Acc: 65.50%\n",
      "Epoch: 4174,     Training Loss: 0.3819471001625061, Training Acc: 72.31%\n",
      "              Val Loss: 0.8784382343292236, Val Acc: 65.50%\n",
      "Epoch: 4175,     Training Loss: 0.36282235383987427, Training Acc: 72.32%\n",
      "              Val Loss: 0.8892290592193604, Val Acc: 65.51%\n",
      "Epoch: 4176,     Training Loss: 0.367742121219635, Training Acc: 72.32%\n",
      "              Val Loss: 0.9162425398826599, Val Acc: 65.51%\n",
      "Epoch: 4177,     Training Loss: 0.3955139219760895, Training Acc: 72.32%\n",
      "              Val Loss: 0.9185118675231934, Val Acc: 65.51%\n",
      "Epoch: 4178,     Training Loss: 0.39007285237312317, Training Acc: 72.32%\n",
      "              Val Loss: 0.9158527851104736, Val Acc: 65.51%\n",
      "Epoch: 4179,     Training Loss: 0.391772985458374, Training Acc: 72.33%\n",
      "              Val Loss: 0.8877489566802979, Val Acc: 65.51%\n",
      "Epoch: 4180,     Training Loss: 0.3652418851852417, Training Acc: 72.33%\n",
      "              Val Loss: 0.8892005085945129, Val Acc: 65.51%\n",
      "Epoch: 4181,     Training Loss: 0.3652683198451996, Training Acc: 72.33%\n",
      "              Val Loss: 0.9099283814430237, Val Acc: 65.52%\n",
      "Epoch: 4182,     Training Loss: 0.3900010287761688, Training Acc: 72.34%\n",
      "              Val Loss: 0.9178009629249573, Val Acc: 65.52%\n",
      "Epoch: 4183,     Training Loss: 0.3896963894367218, Training Acc: 72.34%\n",
      "              Val Loss: 0.919182538986206, Val Acc: 65.52%\n",
      "Epoch: 4184,     Training Loss: 0.39723289012908936, Training Acc: 72.34%\n",
      "              Val Loss: 0.8894410133361816, Val Acc: 65.52%\n",
      "Epoch: 4185,     Training Loss: 0.3672165274620056, Training Acc: 72.34%\n",
      "              Val Loss: 0.8852912187576294, Val Acc: 65.52%\n",
      "Epoch: 4186,     Training Loss: 0.36323243379592896, Training Acc: 72.35%\n",
      "              Val Loss: 0.9025943875312805, Val Acc: 65.52%\n",
      "Epoch: 4187,     Training Loss: 0.38349005579948425, Training Acc: 72.35%\n",
      "              Val Loss: 0.9090426564216614, Val Acc: 65.53%\n",
      "Epoch: 4188,     Training Loss: 0.38505348563194275, Training Acc: 72.35%\n",
      "              Val Loss: 0.9145680069923401, Val Acc: 65.53%\n",
      "Epoch: 4189,     Training Loss: 0.3919200599193573, Training Acc: 72.36%\n",
      "              Val Loss: 0.8983014822006226, Val Acc: 65.53%\n",
      "Epoch: 4190,     Training Loss: 0.3675948977470398, Training Acc: 72.36%\n",
      "              Val Loss: 0.8860471248626709, Val Acc: 65.53%\n",
      "Epoch: 4191,     Training Loss: 0.3580954670906067, Training Acc: 72.36%\n",
      "              Val Loss: 0.8912084102630615, Val Acc: 65.53%\n",
      "Epoch: 4192,     Training Loss: 0.3638724088668823, Training Acc: 72.37%\n",
      "              Val Loss: 0.9064086079597473, Val Acc: 65.53%\n",
      "Epoch: 4193,     Training Loss: 0.37255772948265076, Training Acc: 72.37%\n",
      "              Val Loss: 0.9202766418457031, Val Acc: 65.54%\n",
      "Epoch: 4194,     Training Loss: 0.39066898822784424, Training Acc: 72.37%\n",
      "              Val Loss: 0.9155303835868835, Val Acc: 65.54%\n",
      "Epoch: 4195,     Training Loss: 0.381760835647583, Training Acc: 72.37%\n",
      "              Val Loss: 0.9052146077156067, Val Acc: 65.54%\n",
      "Epoch: 4196,     Training Loss: 0.3777546286582947, Training Acc: 72.38%\n",
      "              Val Loss: 0.8895707130432129, Val Acc: 65.54%\n",
      "Epoch: 4197,     Training Loss: 0.3636201024055481, Training Acc: 72.38%\n",
      "              Val Loss: 0.8909555077552795, Val Acc: 65.54%\n",
      "Epoch: 4198,     Training Loss: 0.35774803161621094, Training Acc: 72.38%\n",
      "              Val Loss: 0.9001491069793701, Val Acc: 65.54%\n",
      "Epoch: 4199,     Training Loss: 0.3639223575592041, Training Acc: 72.39%\n",
      "              Val Loss: 0.9169231653213501, Val Acc: 65.55%\n",
      "Epoch: 4200,     Training Loss: 0.3798524737358093, Training Acc: 72.39%\n",
      "              Val Loss: 0.9459707736968994, Val Acc: 65.55%\n",
      "Epoch: 4201,     Training Loss: 0.41911476850509644, Training Acc: 72.39%\n",
      "              Val Loss: 0.9201300740242004, Val Acc: 65.55%\n",
      "Epoch: 4202,     Training Loss: 0.39382728934288025, Training Acc: 72.39%\n",
      "              Val Loss: 0.9016265273094177, Val Acc: 65.55%\n",
      "Epoch: 4203,     Training Loss: 0.37871524691581726, Training Acc: 72.40%\n",
      "              Val Loss: 0.8901727199554443, Val Acc: 65.55%\n",
      "Epoch: 4204,     Training Loss: 0.3598864674568176, Training Acc: 72.40%\n",
      "              Val Loss: 0.9108276963233948, Val Acc: 65.55%\n",
      "Epoch: 4205,     Training Loss: 0.3702719211578369, Training Acc: 72.40%\n",
      "              Val Loss: 0.9247117042541504, Val Acc: 65.55%\n",
      "Epoch: 4206,     Training Loss: 0.3901778757572174, Training Acc: 72.41%\n",
      "              Val Loss: 0.9089603424072266, Val Acc: 65.56%\n",
      "Epoch: 4207,     Training Loss: 0.3720851540565491, Training Acc: 72.41%\n",
      "              Val Loss: 0.8951942920684814, Val Acc: 65.56%\n",
      "Epoch: 4208,     Training Loss: 0.3623916208744049, Training Acc: 72.41%\n",
      "              Val Loss: 0.8850535750389099, Val Acc: 65.56%\n",
      "Epoch: 4209,     Training Loss: 0.3562069833278656, Training Acc: 72.42%\n",
      "              Val Loss: 0.8938388824462891, Val Acc: 65.56%\n",
      "Epoch: 4210,     Training Loss: 0.36076706647872925, Training Acc: 72.42%\n",
      "              Val Loss: 0.9148082733154297, Val Acc: 65.56%\n",
      "Epoch: 4211,     Training Loss: 0.37868940830230713, Training Acc: 72.42%\n",
      "              Val Loss: 0.9234871864318848, Val Acc: 65.57%\n",
      "Epoch: 4212,     Training Loss: 0.38033077120780945, Training Acc: 72.42%\n",
      "              Val Loss: 0.9360264539718628, Val Acc: 65.57%\n",
      "Epoch: 4213,     Training Loss: 0.39718201756477356, Training Acc: 72.43%\n",
      "              Val Loss: 0.9131425619125366, Val Acc: 65.57%\n",
      "Epoch: 4214,     Training Loss: 0.37351858615875244, Training Acc: 72.43%\n",
      "              Val Loss: 0.8969277143478394, Val Acc: 65.57%\n",
      "Epoch: 4215,     Training Loss: 0.35985955595970154, Training Acc: 72.43%\n",
      "              Val Loss: 0.8949683308601379, Val Acc: 65.57%\n",
      "Epoch: 4216,     Training Loss: 0.354763001203537, Training Acc: 72.44%\n",
      "              Val Loss: 0.9079301357269287, Val Acc: 65.57%\n",
      "Epoch: 4217,     Training Loss: 0.3610205352306366, Training Acc: 72.44%\n",
      "              Val Loss: 0.9182974100112915, Val Acc: 65.58%\n",
      "Epoch: 4218,     Training Loss: 0.3767312169075012, Training Acc: 72.44%\n",
      "              Val Loss: 0.9168771505355835, Val Acc: 65.58%\n",
      "Epoch: 4219,     Training Loss: 0.3746728003025055, Training Acc: 72.44%\n",
      "              Val Loss: 0.9150760769844055, Val Acc: 65.58%\n",
      "Epoch: 4220,     Training Loss: 0.38096845149993896, Training Acc: 72.45%\n",
      "              Val Loss: 0.893078625202179, Val Acc: 65.58%\n",
      "Epoch: 4221,     Training Loss: 0.36194464564323425, Training Acc: 72.45%\n",
      "              Val Loss: 0.8900237083435059, Val Acc: 65.58%\n",
      "Epoch: 4222,     Training Loss: 0.35411012172698975, Training Acc: 72.45%\n",
      "              Val Loss: 0.9030711650848389, Val Acc: 65.58%\n",
      "Epoch: 4223,     Training Loss: 0.35935351252555847, Training Acc: 72.46%\n",
      "              Val Loss: 0.9178646802902222, Val Acc: 65.59%\n",
      "Epoch: 4224,     Training Loss: 0.36998677253723145, Training Acc: 72.46%\n",
      "              Val Loss: 0.9359802007675171, Val Acc: 65.59%\n",
      "Epoch: 4225,     Training Loss: 0.39419424533843994, Training Acc: 72.46%\n",
      "              Val Loss: 0.9241227507591248, Val Acc: 65.59%\n",
      "Epoch: 4226,     Training Loss: 0.37934210896492004, Training Acc: 72.46%\n",
      "              Val Loss: 0.9162709712982178, Val Acc: 65.59%\n",
      "Epoch: 4227,     Training Loss: 0.37778812646865845, Training Acc: 72.47%\n",
      "              Val Loss: 0.900591254234314, Val Acc: 65.59%\n",
      "Epoch: 4228,     Training Loss: 0.35755065083503723, Training Acc: 72.47%\n",
      "              Val Loss: 0.9078661203384399, Val Acc: 65.59%\n",
      "Epoch: 4229,     Training Loss: 0.3556419312953949, Training Acc: 72.47%\n",
      "              Val Loss: 0.9203061461448669, Val Acc: 65.60%\n",
      "Epoch: 4230,     Training Loss: 0.36988773941993713, Training Acc: 72.48%\n",
      "              Val Loss: 0.93520188331604, Val Acc: 65.60%\n",
      "Epoch: 4231,     Training Loss: 0.3764832615852356, Training Acc: 72.48%\n",
      "              Val Loss: 0.9461339712142944, Val Acc: 65.60%\n",
      "Epoch: 4232,     Training Loss: 0.39935019612312317, Training Acc: 72.48%\n",
      "              Val Loss: 0.9193328022956848, Val Acc: 65.60%\n",
      "Epoch: 4233,     Training Loss: 0.3774701654911041, Training Acc: 72.48%\n",
      "              Val Loss: 0.9000056982040405, Val Acc: 65.60%\n",
      "Epoch: 4234,     Training Loss: 0.3613867163658142, Training Acc: 72.49%\n",
      "              Val Loss: 0.9020363688468933, Val Acc: 65.60%\n",
      "Epoch: 4235,     Training Loss: 0.35337021946907043, Training Acc: 72.49%\n",
      "              Val Loss: 0.9128613471984863, Val Acc: 65.61%\n",
      "Epoch: 4236,     Training Loss: 0.36031827330589294, Training Acc: 72.49%\n",
      "              Val Loss: 0.9270276427268982, Val Acc: 65.61%\n",
      "Epoch: 4237,     Training Loss: 0.37076061964035034, Training Acc: 72.50%\n",
      "              Val Loss: 0.9357084631919861, Val Acc: 65.61%\n",
      "Epoch: 4238,     Training Loss: 0.37206101417541504, Training Acc: 72.50%\n",
      "              Val Loss: 0.9329562187194824, Val Acc: 65.61%\n",
      "Epoch: 4239,     Training Loss: 0.39168694615364075, Training Acc: 72.50%\n",
      "              Val Loss: 0.9164658188819885, Val Acc: 65.61%\n",
      "Epoch: 4240,     Training Loss: 0.37099140882492065, Training Acc: 72.51%\n",
      "              Val Loss: 0.9047524929046631, Val Acc: 65.61%\n",
      "Epoch: 4241,     Training Loss: 0.35866081714630127, Training Acc: 72.51%\n",
      "              Val Loss: 0.9006456136703491, Val Acc: 65.62%\n",
      "Epoch: 4242,     Training Loss: 0.35323917865753174, Training Acc: 72.51%\n",
      "              Val Loss: 0.9179447293281555, Val Acc: 65.62%\n",
      "Epoch: 4243,     Training Loss: 0.3562976121902466, Training Acc: 72.51%\n",
      "              Val Loss: 0.9220044016838074, Val Acc: 65.62%\n",
      "Epoch: 4244,     Training Loss: 0.3678008019924164, Training Acc: 72.52%\n",
      "              Val Loss: 0.9265989661216736, Val Acc: 65.62%\n",
      "Epoch: 4245,     Training Loss: 0.371888667345047, Training Acc: 72.52%\n",
      "              Val Loss: 0.9329280257225037, Val Acc: 65.62%\n",
      "Epoch: 4246,     Training Loss: 0.3894456923007965, Training Acc: 72.52%\n",
      "              Val Loss: 0.9246638417243958, Val Acc: 65.62%\n",
      "Epoch: 4247,     Training Loss: 0.37917786836624146, Training Acc: 72.53%\n",
      "              Val Loss: 0.9148536920547485, Val Acc: 65.62%\n",
      "Epoch: 4248,     Training Loss: 0.37308353185653687, Training Acc: 72.53%\n",
      "              Val Loss: 0.9188185930252075, Val Acc: 65.63%\n",
      "Epoch: 4249,     Training Loss: 0.3557107448577881, Training Acc: 72.53%\n",
      "              Val Loss: 0.9227644205093384, Val Acc: 65.63%\n",
      "Epoch: 4250,     Training Loss: 0.3605109453201294, Training Acc: 72.53%\n",
      "              Val Loss: 0.939487099647522, Val Acc: 65.63%\n",
      "Epoch: 4251,     Training Loss: 0.38119828701019287, Training Acc: 72.54%\n",
      "              Val Loss: 0.9418389201164246, Val Acc: 65.63%\n",
      "Epoch: 4252,     Training Loss: 0.3808349668979645, Training Acc: 72.54%\n",
      "              Val Loss: 0.9464369416236877, Val Acc: 65.63%\n",
      "Epoch: 4253,     Training Loss: 0.4049830138683319, Training Acc: 72.54%\n",
      "              Val Loss: 0.9223746657371521, Val Acc: 65.63%\n",
      "Epoch: 4254,     Training Loss: 0.3698887526988983, Training Acc: 72.55%\n",
      "              Val Loss: 0.9078168272972107, Val Acc: 65.64%\n",
      "Epoch: 4255,     Training Loss: 0.3528537452220917, Training Acc: 72.55%\n",
      "              Val Loss: 0.9111804962158203, Val Acc: 65.64%\n",
      "Epoch: 4256,     Training Loss: 0.36295491456985474, Training Acc: 72.55%\n",
      "              Val Loss: 0.9379093647003174, Val Acc: 65.64%\n",
      "Epoch: 4257,     Training Loss: 0.36900755763053894, Training Acc: 72.55%\n",
      "              Val Loss: 0.9432952404022217, Val Acc: 65.64%\n",
      "Epoch: 4258,     Training Loss: 0.38322508335113525, Training Acc: 72.56%\n",
      "              Val Loss: 0.9366061687469482, Val Acc: 65.64%\n",
      "Epoch: 4259,     Training Loss: 0.3834916651248932, Training Acc: 72.56%\n",
      "              Val Loss: 0.9161579012870789, Val Acc: 65.64%\n",
      "Epoch: 4260,     Training Loss: 0.3581438362598419, Training Acc: 72.56%\n",
      "              Val Loss: 0.9120360016822815, Val Acc: 65.65%\n",
      "Epoch: 4261,     Training Loss: 0.35259371995925903, Training Acc: 72.57%\n",
      "              Val Loss: 0.9181268215179443, Val Acc: 65.65%\n",
      "Epoch: 4262,     Training Loss: 0.36440643668174744, Training Acc: 72.57%\n",
      "              Val Loss: 0.9283761382102966, Val Acc: 65.65%\n",
      "Epoch: 4263,     Training Loss: 0.36538249254226685, Training Acc: 72.57%\n",
      "              Val Loss: 0.9506517648696899, Val Acc: 65.65%\n",
      "Epoch: 4264,     Training Loss: 0.374637633562088, Training Acc: 72.57%\n",
      "              Val Loss: 0.946132481098175, Val Acc: 65.65%\n",
      "Epoch: 4265,     Training Loss: 0.39562511444091797, Training Acc: 72.58%\n",
      "              Val Loss: 0.9223729968070984, Val Acc: 65.65%\n",
      "Epoch: 4266,     Training Loss: 0.3639448881149292, Training Acc: 72.58%\n",
      "              Val Loss: 0.9187186360359192, Val Acc: 65.65%\n",
      "Epoch: 4267,     Training Loss: 0.3561439514160156, Training Acc: 72.58%\n",
      "              Val Loss: 0.9138797521591187, Val Acc: 65.66%\n",
      "Epoch: 4268,     Training Loss: 0.3587937653064728, Training Acc: 72.59%\n",
      "              Val Loss: 0.9246273636817932, Val Acc: 65.66%\n",
      "Epoch: 4269,     Training Loss: 0.3546905815601349, Training Acc: 72.59%\n",
      "              Val Loss: 0.9504902362823486, Val Acc: 65.66%\n",
      "Epoch: 4270,     Training Loss: 0.382638543844223, Training Acc: 72.59%\n",
      "              Val Loss: 0.9544287323951721, Val Acc: 65.66%\n",
      "Epoch: 4271,     Training Loss: 0.4000830054283142, Training Acc: 72.59%\n",
      "              Val Loss: 0.9343640804290771, Val Acc: 65.66%\n",
      "Epoch: 4272,     Training Loss: 0.3868909180164337, Training Acc: 72.60%\n",
      "              Val Loss: 0.9554495811462402, Val Acc: 65.66%\n",
      "Epoch: 4273,     Training Loss: 0.38966506719589233, Training Acc: 72.60%\n",
      "              Val Loss: 0.9071924686431885, Val Acc: 65.67%\n",
      "Epoch: 4274,     Training Loss: 0.3692001402378082, Training Acc: 72.60%\n",
      "              Val Loss: 0.9131495952606201, Val Acc: 65.67%\n",
      "Epoch: 4275,     Training Loss: 0.3603721857070923, Training Acc: 72.61%\n",
      "              Val Loss: 0.9552339911460876, Val Acc: 65.67%\n",
      "Epoch: 4276,     Training Loss: 0.37682631611824036, Training Acc: 72.61%\n",
      "              Val Loss: 0.9217842817306519, Val Acc: 65.67%\n",
      "Epoch: 4277,     Training Loss: 0.36450889706611633, Training Acc: 72.61%\n",
      "              Val Loss: 0.9251971244812012, Val Acc: 65.67%\n",
      "Epoch: 4278,     Training Loss: 0.3751215636730194, Training Acc: 72.61%\n",
      "              Val Loss: 0.9234115481376648, Val Acc: 65.67%\n",
      "Epoch: 4279,     Training Loss: 0.3697165548801422, Training Acc: 72.62%\n",
      "              Val Loss: 0.9267514944076538, Val Acc: 65.68%\n",
      "Epoch: 4280,     Training Loss: 0.36588287353515625, Training Acc: 72.62%\n",
      "              Val Loss: 0.9190230369567871, Val Acc: 65.68%\n",
      "Epoch: 4281,     Training Loss: 0.37792712450027466, Training Acc: 72.62%\n",
      "              Val Loss: 0.9190821051597595, Val Acc: 65.68%\n",
      "Epoch: 4282,     Training Loss: 0.3545636236667633, Training Acc: 72.63%\n",
      "              Val Loss: 0.9420503377914429, Val Acc: 65.68%\n",
      "Epoch: 4283,     Training Loss: 0.35789263248443604, Training Acc: 72.63%\n",
      "              Val Loss: 0.9268873333930969, Val Acc: 65.68%\n",
      "Epoch: 4284,     Training Loss: 0.3564453125, Training Acc: 72.63%\n",
      "              Val Loss: 0.9131227731704712, Val Acc: 65.68%\n",
      "Epoch: 4285,     Training Loss: 0.35080406069755554, Training Acc: 72.63%\n",
      "              Val Loss: 0.9213727712631226, Val Acc: 65.69%\n",
      "Epoch: 4286,     Training Loss: 0.3653758764266968, Training Acc: 72.64%\n",
      "              Val Loss: 0.930263876914978, Val Acc: 65.69%\n",
      "Epoch: 4287,     Training Loss: 0.38396400213241577, Training Acc: 72.64%\n",
      "              Val Loss: 0.9448609352111816, Val Acc: 65.69%\n",
      "Epoch: 4288,     Training Loss: 0.40542393922805786, Training Acc: 72.64%\n",
      "              Val Loss: 0.9632960557937622, Val Acc: 65.69%\n",
      "Epoch: 4289,     Training Loss: 0.40037184953689575, Training Acc: 72.64%\n",
      "              Val Loss: 0.9302681088447571, Val Acc: 65.69%\n",
      "Epoch: 4290,     Training Loss: 0.390460729598999, Training Acc: 72.65%\n",
      "              Val Loss: 0.9151489734649658, Val Acc: 65.69%\n",
      "Epoch: 4291,     Training Loss: 0.3606746792793274, Training Acc: 72.65%\n",
      "              Val Loss: 0.9248239994049072, Val Acc: 65.69%\n",
      "Epoch: 4292,     Training Loss: 0.36107486486434937, Training Acc: 72.65%\n",
      "              Val Loss: 0.9332482814788818, Val Acc: 65.70%\n",
      "Epoch: 4293,     Training Loss: 0.384268194437027, Training Acc: 72.66%\n",
      "              Val Loss: 0.9545536637306213, Val Acc: 65.70%\n",
      "Epoch: 4294,     Training Loss: 0.400919646024704, Training Acc: 72.66%\n",
      "              Val Loss: 0.9752297401428223, Val Acc: 65.70%\n",
      "Epoch: 4295,     Training Loss: 0.41693416237831116, Training Acc: 72.66%\n",
      "              Val Loss: 0.9430471658706665, Val Acc: 65.70%\n",
      "Epoch: 4296,     Training Loss: 0.3687961995601654, Training Acc: 72.66%\n",
      "              Val Loss: 0.9110655784606934, Val Acc: 65.70%\n",
      "Epoch: 4297,     Training Loss: 0.3564179539680481, Training Acc: 72.67%\n",
      "              Val Loss: 0.9241602420806885, Val Acc: 65.70%\n",
      "Epoch: 4298,     Training Loss: 0.35845717787742615, Training Acc: 72.67%\n",
      "              Val Loss: 0.9783347845077515, Val Acc: 65.70%\n",
      "Epoch: 4299,     Training Loss: 0.38824886083602905, Training Acc: 72.67%\n",
      "              Val Loss: 0.9977126121520996, Val Acc: 65.71%\n",
      "Epoch: 4300,     Training Loss: 0.44328534603118896, Training Acc: 72.67%\n",
      "              Val Loss: 0.9558127522468567, Val Acc: 65.71%\n",
      "Epoch: 4301,     Training Loss: 0.3989943265914917, Training Acc: 72.68%\n",
      "              Val Loss: 0.920146107673645, Val Acc: 65.71%\n",
      "Epoch: 4302,     Training Loss: 0.36159348487854004, Training Acc: 72.68%\n",
      "              Val Loss: 0.9137006998062134, Val Acc: 65.71%\n",
      "Epoch: 4303,     Training Loss: 0.36301127076148987, Training Acc: 72.68%\n",
      "              Val Loss: 0.9408895373344421, Val Acc: 65.71%\n",
      "Epoch: 4304,     Training Loss: 0.37508800625801086, Training Acc: 72.68%\n",
      "              Val Loss: 0.9601941108703613, Val Acc: 65.71%\n",
      "Epoch: 4305,     Training Loss: 0.4026781916618347, Training Acc: 72.69%\n",
      "              Val Loss: 0.9389566779136658, Val Acc: 65.71%\n",
      "Epoch: 4306,     Training Loss: 0.38227421045303345, Training Acc: 72.69%\n",
      "              Val Loss: 0.9104560017585754, Val Acc: 65.71%\n",
      "Epoch: 4307,     Training Loss: 0.355195552110672, Training Acc: 72.69%\n",
      "              Val Loss: 0.9339359402656555, Val Acc: 65.72%\n",
      "Epoch: 4308,     Training Loss: 0.37414246797561646, Training Acc: 72.69%\n",
      "              Val Loss: 0.9533042907714844, Val Acc: 65.72%\n",
      "Epoch: 4309,     Training Loss: 0.3952226936817169, Training Acc: 72.70%\n",
      "              Val Loss: 0.9717391133308411, Val Acc: 65.72%\n",
      "Epoch: 4310,     Training Loss: 0.42812949419021606, Training Acc: 72.70%\n",
      "              Val Loss: 0.9732205867767334, Val Acc: 65.72%\n",
      "Epoch: 4311,     Training Loss: 0.3922477662563324, Training Acc: 72.70%\n",
      "              Val Loss: 0.9121742844581604, Val Acc: 65.72%\n",
      "Epoch: 4312,     Training Loss: 0.35558319091796875, Training Acc: 72.71%\n",
      "              Val Loss: 0.9219676852226257, Val Acc: 65.72%\n",
      "Epoch: 4313,     Training Loss: 0.3706297278404236, Training Acc: 72.71%\n",
      "              Val Loss: 0.9697485566139221, Val Acc: 65.72%\n",
      "Epoch: 4314,     Training Loss: 0.3779318630695343, Training Acc: 72.71%\n",
      "              Val Loss: 0.9619341492652893, Val Acc: 65.73%\n",
      "Epoch: 4315,     Training Loss: 0.3936353623867035, Training Acc: 72.71%\n",
      "              Val Loss: 0.9479569792747498, Val Acc: 65.73%\n",
      "Epoch: 4316,     Training Loss: 0.38852256536483765, Training Acc: 72.72%\n",
      "              Val Loss: 0.9253446459770203, Val Acc: 65.73%\n",
      "Epoch: 4317,     Training Loss: 0.36020949482917786, Training Acc: 72.72%\n",
      "              Val Loss: 0.9165847897529602, Val Acc: 65.73%\n",
      "Epoch: 4318,     Training Loss: 0.3469572961330414, Training Acc: 72.72%\n",
      "              Val Loss: 0.9281503558158875, Val Acc: 65.73%\n",
      "Epoch: 4319,     Training Loss: 0.3582362234592438, Training Acc: 72.72%\n",
      "              Val Loss: 0.9460097551345825, Val Acc: 65.73%\n",
      "Epoch: 4320,     Training Loss: 0.37943530082702637, Training Acc: 72.73%\n",
      "              Val Loss: 0.9501070976257324, Val Acc: 65.73%\n",
      "Epoch: 4321,     Training Loss: 0.3732333779335022, Training Acc: 72.73%\n",
      "              Val Loss: 0.9438607096672058, Val Acc: 65.74%\n",
      "Epoch: 4322,     Training Loss: 0.39239463210105896, Training Acc: 72.73%\n",
      "              Val Loss: 0.9225995540618896, Val Acc: 65.74%\n",
      "Epoch: 4323,     Training Loss: 0.3580588102340698, Training Acc: 72.73%\n",
      "              Val Loss: 0.9134630560874939, Val Acc: 65.74%\n",
      "Epoch: 4324,     Training Loss: 0.34719061851501465, Training Acc: 72.74%\n",
      "              Val Loss: 0.9226373434066772, Val Acc: 65.74%\n",
      "Epoch: 4325,     Training Loss: 0.3633680045604706, Training Acc: 72.74%\n",
      "              Val Loss: 0.9476310014724731, Val Acc: 65.74%\n",
      "Epoch: 4326,     Training Loss: 0.363949179649353, Training Acc: 72.74%\n",
      "              Val Loss: 0.9559082984924316, Val Acc: 65.74%\n",
      "Epoch: 4327,     Training Loss: 0.384690523147583, Training Acc: 72.75%\n",
      "              Val Loss: 0.9543970227241516, Val Acc: 65.74%\n",
      "Epoch: 4328,     Training Loss: 0.39347779750823975, Training Acc: 72.75%\n",
      "              Val Loss: 0.932930588722229, Val Acc: 65.75%\n",
      "Epoch: 4329,     Training Loss: 0.36332952976226807, Training Acc: 72.75%\n",
      "              Val Loss: 0.9330293536186218, Val Acc: 65.75%\n",
      "Epoch: 4330,     Training Loss: 0.3515653610229492, Training Acc: 72.75%\n",
      "              Val Loss: 0.9327027797698975, Val Acc: 65.75%\n",
      "Epoch: 4331,     Training Loss: 0.36022496223449707, Training Acc: 72.76%\n",
      "              Val Loss: 0.9389015436172485, Val Acc: 65.75%\n",
      "Epoch: 4332,     Training Loss: 0.3680482804775238, Training Acc: 72.76%\n",
      "              Val Loss: 0.9706993699073792, Val Acc: 65.75%\n",
      "Epoch: 4333,     Training Loss: 0.38795965909957886, Training Acc: 72.76%\n",
      "              Val Loss: 0.9646026492118835, Val Acc: 65.75%\n",
      "Epoch: 4334,     Training Loss: 0.4164930582046509, Training Acc: 72.76%\n",
      "              Val Loss: 0.9223012328147888, Val Acc: 65.75%\n",
      "Epoch: 4335,     Training Loss: 0.36532047390937805, Training Acc: 72.77%\n",
      "              Val Loss: 0.9321496486663818, Val Acc: 65.76%\n",
      "Epoch: 4336,     Training Loss: 0.35871490836143494, Training Acc: 72.77%\n",
      "              Val Loss: 0.9226054549217224, Val Acc: 65.76%\n",
      "Epoch: 4337,     Training Loss: 0.3614619970321655, Training Acc: 72.77%\n",
      "              Val Loss: 0.9362753033638, Val Acc: 65.76%\n",
      "Epoch: 4338,     Training Loss: 0.36169159412384033, Training Acc: 72.78%\n",
      "              Val Loss: 0.9759918451309204, Val Acc: 65.76%\n",
      "Epoch: 4339,     Training Loss: 0.4000891447067261, Training Acc: 72.78%\n",
      "              Val Loss: 0.9606194496154785, Val Acc: 65.76%\n",
      "Epoch: 4340,     Training Loss: 0.3949117958545685, Training Acc: 72.78%\n",
      "              Val Loss: 0.9100929498672485, Val Acc: 65.76%\n",
      "Epoch: 4341,     Training Loss: 0.35592129826545715, Training Acc: 72.78%\n",
      "              Val Loss: 0.9624233841896057, Val Acc: 65.76%\n",
      "Epoch: 4342,     Training Loss: 0.38545483350753784, Training Acc: 72.79%\n",
      "              Val Loss: 0.9168433547019958, Val Acc: 65.77%\n",
      "Epoch: 4343,     Training Loss: 0.35861483216285706, Training Acc: 72.79%\n",
      "              Val Loss: 0.9297657608985901, Val Acc: 65.77%\n",
      "Epoch: 4344,     Training Loss: 0.36765167117118835, Training Acc: 72.79%\n",
      "              Val Loss: 0.9500055909156799, Val Acc: 65.77%\n",
      "Epoch: 4345,     Training Loss: 0.3692004084587097, Training Acc: 72.79%\n",
      "              Val Loss: 0.9472782015800476, Val Acc: 65.77%\n",
      "Epoch: 4346,     Training Loss: 0.3823147118091583, Training Acc: 72.80%\n",
      "              Val Loss: 0.9434313774108887, Val Acc: 65.77%\n",
      "Epoch: 4347,     Training Loss: 0.38893207907676697, Training Acc: 72.80%\n",
      "              Val Loss: 0.9596337080001831, Val Acc: 65.77%\n",
      "Epoch: 4348,     Training Loss: 0.4109419882297516, Training Acc: 72.80%\n",
      "              Val Loss: 0.970598578453064, Val Acc: 65.77%\n",
      "Epoch: 4349,     Training Loss: 0.38989710807800293, Training Acc: 72.80%\n",
      "              Val Loss: 0.9330562353134155, Val Acc: 65.78%\n",
      "Epoch: 4350,     Training Loss: 0.3731263279914856, Training Acc: 72.81%\n",
      "              Val Loss: 0.9262039065361023, Val Acc: 65.78%\n",
      "Epoch: 4351,     Training Loss: 0.365082710981369, Training Acc: 72.81%\n",
      "              Val Loss: 0.9715824723243713, Val Acc: 65.78%\n",
      "Epoch: 4352,     Training Loss: 0.37296104431152344, Training Acc: 72.81%\n",
      "              Val Loss: 0.9701530337333679, Val Acc: 65.78%\n",
      "Epoch: 4353,     Training Loss: 0.39108455181121826, Training Acc: 72.81%\n",
      "              Val Loss: 0.9793617725372314, Val Acc: 65.78%\n",
      "Epoch: 4354,     Training Loss: 0.42993631958961487, Training Acc: 72.82%\n",
      "              Val Loss: 0.9706773161888123, Val Acc: 65.78%\n",
      "Epoch: 4355,     Training Loss: 0.4306892156600952, Training Acc: 72.82%\n",
      "              Val Loss: 0.9742587208747864, Val Acc: 65.78%\n",
      "Epoch: 4356,     Training Loss: 0.3993259370326996, Training Acc: 72.82%\n",
      "              Val Loss: 0.9100679159164429, Val Acc: 65.79%\n",
      "Epoch: 4357,     Training Loss: 0.3576214611530304, Training Acc: 72.82%\n",
      "              Val Loss: 0.9349868297576904, Val Acc: 65.79%\n",
      "Epoch: 4358,     Training Loss: 0.37336868047714233, Training Acc: 72.83%\n",
      "              Val Loss: 0.984872579574585, Val Acc: 65.79%\n",
      "Epoch: 4359,     Training Loss: 0.3879671096801758, Training Acc: 72.83%\n",
      "              Val Loss: 0.9575541019439697, Val Acc: 65.79%\n",
      "Epoch: 4360,     Training Loss: 0.399153470993042, Training Acc: 72.83%\n",
      "              Val Loss: 0.9527275562286377, Val Acc: 65.79%\n",
      "Epoch: 4361,     Training Loss: 0.3950768709182739, Training Acc: 72.83%\n",
      "              Val Loss: 0.9411433935165405, Val Acc: 65.79%\n",
      "Epoch: 4362,     Training Loss: 0.3679414987564087, Training Acc: 72.84%\n",
      "              Val Loss: 0.9274070858955383, Val Acc: 65.79%\n",
      "Epoch: 4363,     Training Loss: 0.3465975821018219, Training Acc: 72.84%\n",
      "              Val Loss: 0.9390048980712891, Val Acc: 65.80%\n",
      "Epoch: 4364,     Training Loss: 0.35163819789886475, Training Acc: 72.84%\n",
      "              Val Loss: 0.9578322768211365, Val Acc: 65.80%\n",
      "Epoch: 4365,     Training Loss: 0.36915960907936096, Training Acc: 72.84%\n",
      "              Val Loss: 0.9467043280601501, Val Acc: 65.80%\n",
      "Epoch: 4366,     Training Loss: 0.3631303906440735, Training Acc: 72.85%\n",
      "              Val Loss: 0.9250449538230896, Val Acc: 65.80%\n",
      "Epoch: 4367,     Training Loss: 0.3676985800266266, Training Acc: 72.85%\n",
      "              Val Loss: 0.9081107974052429, Val Acc: 65.80%\n",
      "Epoch: 4368,     Training Loss: 0.34573107957839966, Training Acc: 72.85%\n",
      "              Val Loss: 0.9000647664070129, Val Acc: 65.80%\n",
      "Epoch: 4369,     Training Loss: 0.3386215567588806, Training Acc: 72.86%\n",
      "              Val Loss: 0.9167670607566833, Val Acc: 65.80%\n",
      "Epoch: 4370,     Training Loss: 0.3485229015350342, Training Acc: 72.86%\n",
      "              Val Loss: 0.95400071144104, Val Acc: 65.81%\n",
      "Epoch: 4371,     Training Loss: 0.36299264430999756, Training Acc: 72.86%\n",
      "              Val Loss: 0.9777330160140991, Val Acc: 65.81%\n",
      "Epoch: 4372,     Training Loss: 0.40944233536720276, Training Acc: 72.86%\n",
      "              Val Loss: 0.9650838971138, Val Acc: 65.81%\n",
      "Epoch: 4373,     Training Loss: 0.3971373736858368, Training Acc: 72.87%\n",
      "              Val Loss: 0.9425047039985657, Val Acc: 65.81%\n",
      "Epoch: 4374,     Training Loss: 0.3737408518791199, Training Acc: 72.87%\n",
      "              Val Loss: 0.9161133766174316, Val Acc: 65.81%\n",
      "Epoch: 4375,     Training Loss: 0.34272536635398865, Training Acc: 72.87%\n",
      "              Val Loss: 0.9475734829902649, Val Acc: 65.81%\n",
      "Epoch: 4376,     Training Loss: 0.3635714650154114, Training Acc: 72.88%\n",
      "              Val Loss: 0.9838026165962219, Val Acc: 65.81%\n",
      "Epoch: 4377,     Training Loss: 0.4018595814704895, Training Acc: 72.88%\n",
      "              Val Loss: 0.9671449065208435, Val Acc: 65.81%\n",
      "Epoch: 4378,     Training Loss: 0.37433937191963196, Training Acc: 72.88%\n",
      "              Val Loss: 0.9170414209365845, Val Acc: 65.82%\n",
      "Epoch: 4379,     Training Loss: 0.34760791063308716, Training Acc: 72.88%\n",
      "              Val Loss: 0.9123079180717468, Val Acc: 65.82%\n",
      "Epoch: 4380,     Training Loss: 0.34534263610839844, Training Acc: 72.89%\n",
      "              Val Loss: 0.938948392868042, Val Acc: 65.82%\n",
      "Epoch: 4381,     Training Loss: 0.35973262786865234, Training Acc: 72.89%\n",
      "              Val Loss: 0.9582227468490601, Val Acc: 65.82%\n",
      "Epoch: 4382,     Training Loss: 0.3797071874141693, Training Acc: 72.89%\n",
      "              Val Loss: 0.9790001511573792, Val Acc: 65.82%\n",
      "Epoch: 4383,     Training Loss: 0.3752425014972687, Training Acc: 72.89%\n",
      "              Val Loss: 0.9462506175041199, Val Acc: 65.82%\n",
      "Epoch: 4384,     Training Loss: 0.3691466152667999, Training Acc: 72.90%\n",
      "              Val Loss: 0.9268025755882263, Val Acc: 65.82%\n",
      "Epoch: 4385,     Training Loss: 0.34119126200675964, Training Acc: 72.90%\n",
      "              Val Loss: 0.930039644241333, Val Acc: 65.83%\n",
      "Epoch: 4386,     Training Loss: 0.3460088074207306, Training Acc: 72.90%\n",
      "              Val Loss: 0.9295120239257812, Val Acc: 65.83%\n",
      "Epoch: 4387,     Training Loss: 0.3624769449234009, Training Acc: 72.91%\n",
      "              Val Loss: 0.9534891247749329, Val Acc: 65.83%\n",
      "Epoch: 4388,     Training Loss: 0.364857941865921, Training Acc: 72.91%\n",
      "              Val Loss: 0.9849796295166016, Val Acc: 65.83%\n",
      "Epoch: 4389,     Training Loss: 0.40342286229133606, Training Acc: 72.91%\n",
      "              Val Loss: 0.9709779620170593, Val Acc: 65.83%\n",
      "Epoch: 4390,     Training Loss: 0.39027974009513855, Training Acc: 72.91%\n",
      "              Val Loss: 0.9286449551582336, Val Acc: 65.83%\n",
      "Epoch: 4391,     Training Loss: 0.35591819882392883, Training Acc: 72.92%\n",
      "              Val Loss: 0.9467684030532837, Val Acc: 65.83%\n",
      "Epoch: 4392,     Training Loss: 0.3582003712654114, Training Acc: 72.92%\n",
      "              Val Loss: 0.9345824718475342, Val Acc: 65.84%\n",
      "Epoch: 4393,     Training Loss: 0.35837313532829285, Training Acc: 72.92%\n",
      "              Val Loss: 0.9448215365409851, Val Acc: 65.84%\n",
      "Epoch: 4394,     Training Loss: 0.37280386686325073, Training Acc: 72.92%\n",
      "              Val Loss: 0.9777816534042358, Val Acc: 65.84%\n",
      "Epoch: 4395,     Training Loss: 0.3808300793170929, Training Acc: 72.93%\n",
      "              Val Loss: 0.9159185886383057, Val Acc: 65.84%\n",
      "Epoch: 4396,     Training Loss: 0.3483183681964874, Training Acc: 72.93%\n",
      "              Val Loss: 0.9157627820968628, Val Acc: 65.84%\n",
      "Epoch: 4397,     Training Loss: 0.34529444575309753, Training Acc: 72.93%\n",
      "              Val Loss: 0.9406470656394958, Val Acc: 65.84%\n",
      "Epoch: 4398,     Training Loss: 0.35312068462371826, Training Acc: 72.94%\n",
      "              Val Loss: 0.920240581035614, Val Acc: 65.84%\n",
      "Epoch: 4399,     Training Loss: 0.34467852115631104, Training Acc: 72.94%\n",
      "              Val Loss: 0.9472565650939941, Val Acc: 65.85%\n",
      "Epoch: 4400,     Training Loss: 0.3640580475330353, Training Acc: 72.94%\n",
      "              Val Loss: 0.976518452167511, Val Acc: 65.85%\n",
      "Epoch: 4401,     Training Loss: 0.38675814867019653, Training Acc: 72.94%\n",
      "              Val Loss: 0.9775637984275818, Val Acc: 65.85%\n",
      "Epoch: 4402,     Training Loss: 0.3876993656158447, Training Acc: 72.95%\n",
      "              Val Loss: 1.0415481328964233, Val Acc: 65.85%\n",
      "Epoch: 4403,     Training Loss: 0.4828782379627228, Training Acc: 72.95%\n",
      "              Val Loss: 0.956794261932373, Val Acc: 65.85%\n",
      "Epoch: 4404,     Training Loss: 0.37641793489456177, Training Acc: 72.95%\n",
      "              Val Loss: 0.9417452216148376, Val Acc: 65.85%\n",
      "Epoch: 4405,     Training Loss: 0.3563910722732544, Training Acc: 72.95%\n",
      "              Val Loss: 0.9782932996749878, Val Acc: 65.85%\n",
      "Epoch: 4406,     Training Loss: 0.4124037027359009, Training Acc: 72.95%\n",
      "              Val Loss: 0.9620407819747925, Val Acc: 65.85%\n",
      "Epoch: 4407,     Training Loss: 0.37681037187576294, Training Acc: 72.96%\n",
      "              Val Loss: 0.9327220916748047, Val Acc: 65.85%\n",
      "Epoch: 4408,     Training Loss: 0.3474721908569336, Training Acc: 72.96%\n",
      "              Val Loss: 0.9272618889808655, Val Acc: 65.86%\n",
      "Epoch: 4409,     Training Loss: 0.36279621720314026, Training Acc: 72.96%\n",
      "              Val Loss: 0.9452109336853027, Val Acc: 65.86%\n",
      "Epoch: 4410,     Training Loss: 0.3683696687221527, Training Acc: 72.97%\n",
      "              Val Loss: 0.9545285105705261, Val Acc: 65.86%\n",
      "Epoch: 4411,     Training Loss: 0.3773438632488251, Training Acc: 72.97%\n",
      "              Val Loss: 0.9455149173736572, Val Acc: 65.86%\n",
      "Epoch: 4412,     Training Loss: 0.36124783754348755, Training Acc: 72.97%\n",
      "              Val Loss: 0.9377567768096924, Val Acc: 65.86%\n",
      "Epoch: 4413,     Training Loss: 0.3424346446990967, Training Acc: 72.97%\n",
      "              Val Loss: 0.961266279220581, Val Acc: 65.86%\n",
      "Epoch: 4414,     Training Loss: 0.37724772095680237, Training Acc: 72.98%\n",
      "              Val Loss: 0.9711157083511353, Val Acc: 65.86%\n",
      "Epoch: 4415,     Training Loss: 0.3963770568370819, Training Acc: 72.98%\n",
      "              Val Loss: 0.9886656999588013, Val Acc: 65.86%\n",
      "Epoch: 4416,     Training Loss: 0.42776402831077576, Training Acc: 72.98%\n",
      "              Val Loss: 0.9941839575767517, Val Acc: 65.87%\n",
      "Epoch: 4417,     Training Loss: 0.3992173373699188, Training Acc: 72.98%\n",
      "              Val Loss: 0.9253717660903931, Val Acc: 65.87%\n",
      "Epoch: 4418,     Training Loss: 0.35314351320266724, Training Acc: 72.99%\n",
      "              Val Loss: 0.9424977898597717, Val Acc: 65.87%\n",
      "Epoch: 4419,     Training Loss: 0.35772019624710083, Training Acc: 72.99%\n",
      "              Val Loss: 1.0041800737380981, Val Acc: 65.87%\n",
      "Epoch: 4420,     Training Loss: 0.3936419188976288, Training Acc: 72.99%\n",
      "              Val Loss: 0.9774028062820435, Val Acc: 65.87%\n",
      "Epoch: 4421,     Training Loss: 0.41427910327911377, Training Acc: 72.99%\n",
      "              Val Loss: 0.9515596032142639, Val Acc: 65.87%\n",
      "Epoch: 4422,     Training Loss: 0.3884943127632141, Training Acc: 73.00%\n",
      "              Val Loss: 0.9324047565460205, Val Acc: 65.87%\n",
      "Epoch: 4423,     Training Loss: 0.34900379180908203, Training Acc: 73.00%\n",
      "              Val Loss: 0.9438144564628601, Val Acc: 65.88%\n",
      "Epoch: 4424,     Training Loss: 0.35565781593322754, Training Acc: 73.00%\n",
      "              Val Loss: 0.994006335735321, Val Acc: 65.88%\n",
      "Epoch: 4425,     Training Loss: 0.3978606164455414, Training Acc: 73.00%\n",
      "              Val Loss: 0.9807436466217041, Val Acc: 65.88%\n",
      "Epoch: 4426,     Training Loss: 0.40421557426452637, Training Acc: 73.01%\n",
      "              Val Loss: 0.9779891967773438, Val Acc: 65.88%\n",
      "Epoch: 4427,     Training Loss: 0.3781830668449402, Training Acc: 73.01%\n",
      "              Val Loss: 0.9126328229904175, Val Acc: 65.88%\n",
      "Epoch: 4428,     Training Loss: 0.35170450806617737, Training Acc: 73.01%\n",
      "              Val Loss: 0.9131749868392944, Val Acc: 65.88%\n",
      "Epoch: 4429,     Training Loss: 0.34620270133018494, Training Acc: 73.01%\n",
      "              Val Loss: 0.9819815754890442, Val Acc: 65.88%\n",
      "Epoch: 4430,     Training Loss: 0.37953564524650574, Training Acc: 73.02%\n",
      "              Val Loss: 0.9835155010223389, Val Acc: 65.88%\n",
      "Epoch: 4431,     Training Loss: 0.4182843863964081, Training Acc: 73.02%\n",
      "              Val Loss: 0.9626846313476562, Val Acc: 65.89%\n",
      "Epoch: 4432,     Training Loss: 0.3805426359176636, Training Acc: 73.02%\n",
      "              Val Loss: 0.9475317597389221, Val Acc: 65.89%\n",
      "Epoch: 4433,     Training Loss: 0.36244285106658936, Training Acc: 73.02%\n",
      "              Val Loss: 0.9217245578765869, Val Acc: 65.89%\n",
      "Epoch: 4434,     Training Loss: 0.3497006595134735, Training Acc: 73.03%\n",
      "              Val Loss: 0.9572460651397705, Val Acc: 65.89%\n",
      "Epoch: 4435,     Training Loss: 0.3629814386367798, Training Acc: 73.03%\n",
      "              Val Loss: 0.9823640584945679, Val Acc: 65.89%\n",
      "Epoch: 4436,     Training Loss: 0.3916873037815094, Training Acc: 73.03%\n",
      "              Val Loss: 0.9518208503723145, Val Acc: 65.89%\n",
      "Epoch: 4437,     Training Loss: 0.36495769023895264, Training Acc: 73.03%\n",
      "              Val Loss: 0.9172458052635193, Val Acc: 65.89%\n",
      "Epoch: 4438,     Training Loss: 0.3463623821735382, Training Acc: 73.04%\n",
      "              Val Loss: 0.9400195479393005, Val Acc: 65.89%\n",
      "Epoch: 4439,     Training Loss: 0.3546884059906006, Training Acc: 73.04%\n",
      "              Val Loss: 0.9440978169441223, Val Acc: 65.90%\n",
      "Epoch: 4440,     Training Loss: 0.3577635884284973, Training Acc: 73.04%\n",
      "              Val Loss: 0.9703443646430969, Val Acc: 65.90%\n",
      "Epoch: 4441,     Training Loss: 0.39721718430519104, Training Acc: 73.04%\n",
      "              Val Loss: 0.9935452938079834, Val Acc: 65.90%\n",
      "Epoch: 4442,     Training Loss: 0.3819600045681, Training Acc: 73.05%\n",
      "              Val Loss: 0.9447174072265625, Val Acc: 65.90%\n",
      "Epoch: 4443,     Training Loss: 0.3675520420074463, Training Acc: 73.05%\n",
      "              Val Loss: 0.9302710890769958, Val Acc: 65.90%\n",
      "Epoch: 4444,     Training Loss: 0.34609973430633545, Training Acc: 73.05%\n",
      "              Val Loss: 0.9575708508491516, Val Acc: 65.90%\n",
      "Epoch: 4445,     Training Loss: 0.3487129211425781, Training Acc: 73.06%\n",
      "              Val Loss: 0.9640323519706726, Val Acc: 65.90%\n",
      "Epoch: 4446,     Training Loss: 0.37249383330345154, Training Acc: 73.06%\n",
      "              Val Loss: 0.979291558265686, Val Acc: 65.90%\n",
      "Epoch: 4447,     Training Loss: 0.38568314909935, Training Acc: 73.06%\n",
      "              Val Loss: 0.9736989736557007, Val Acc: 65.91%\n",
      "Epoch: 4448,     Training Loss: 0.3890928626060486, Training Acc: 73.06%\n",
      "              Val Loss: 0.9401847124099731, Val Acc: 65.91%\n",
      "Epoch: 4449,     Training Loss: 0.349623441696167, Training Acc: 73.07%\n",
      "              Val Loss: 0.9213045239448547, Val Acc: 65.91%\n",
      "Epoch: 4450,     Training Loss: 0.34475070238113403, Training Acc: 73.07%\n",
      "              Val Loss: 0.9402791857719421, Val Acc: 65.91%\n",
      "Epoch: 4451,     Training Loss: 0.35425353050231934, Training Acc: 73.07%\n",
      "              Val Loss: 0.9797378778457642, Val Acc: 65.91%\n",
      "Epoch: 4452,     Training Loss: 0.36904624104499817, Training Acc: 73.07%\n",
      "              Val Loss: 0.9827913641929626, Val Acc: 65.91%\n",
      "Epoch: 4453,     Training Loss: 0.40327444672584534, Training Acc: 73.08%\n",
      "              Val Loss: 0.968540370464325, Val Acc: 65.91%\n",
      "Epoch: 4454,     Training Loss: 0.3691001534461975, Training Acc: 73.08%\n",
      "              Val Loss: 0.9443982839584351, Val Acc: 65.91%\n",
      "Epoch: 4455,     Training Loss: 0.3485918939113617, Training Acc: 73.08%\n",
      "              Val Loss: 0.930732011795044, Val Acc: 65.92%\n",
      "Epoch: 4456,     Training Loss: 0.3409286439418793, Training Acc: 73.08%\n",
      "              Val Loss: 0.970591127872467, Val Acc: 65.92%\n",
      "Epoch: 4457,     Training Loss: 0.3603166341781616, Training Acc: 73.09%\n",
      "              Val Loss: 0.9757710099220276, Val Acc: 65.92%\n",
      "Epoch: 4458,     Training Loss: 0.3776567876338959, Training Acc: 73.09%\n",
      "              Val Loss: 0.9768323302268982, Val Acc: 65.92%\n",
      "Epoch: 4459,     Training Loss: 0.3730841875076294, Training Acc: 73.09%\n",
      "              Val Loss: 0.9365729689598083, Val Acc: 65.92%\n",
      "Epoch: 4460,     Training Loss: 0.3574291169643402, Training Acc: 73.09%\n",
      "              Val Loss: 0.9135048389434814, Val Acc: 65.92%\n",
      "Epoch: 4461,     Training Loss: 0.33506783843040466, Training Acc: 73.10%\n",
      "              Val Loss: 0.9474778771400452, Val Acc: 65.92%\n",
      "Epoch: 4462,     Training Loss: 0.35649406909942627, Training Acc: 73.10%\n",
      "              Val Loss: 0.9798332452774048, Val Acc: 65.93%\n",
      "Epoch: 4463,     Training Loss: 0.40087443590164185, Training Acc: 73.10%\n",
      "              Val Loss: 1.002001166343689, Val Acc: 65.93%\n",
      "Epoch: 4464,     Training Loss: 0.3978200852870941, Training Acc: 73.10%\n",
      "              Val Loss: 0.9909549951553345, Val Acc: 65.93%\n",
      "Epoch: 4465,     Training Loss: 0.40676432847976685, Training Acc: 73.11%\n",
      "              Val Loss: 0.9474331140518188, Val Acc: 65.93%\n",
      "Epoch: 4466,     Training Loss: 0.34909647703170776, Training Acc: 73.11%\n",
      "              Val Loss: 0.9552915692329407, Val Acc: 65.93%\n",
      "Epoch: 4467,     Training Loss: 0.3530438244342804, Training Acc: 73.11%\n",
      "              Val Loss: 0.9815162420272827, Val Acc: 65.93%\n",
      "Epoch: 4468,     Training Loss: 0.39445626735687256, Training Acc: 73.11%\n",
      "              Val Loss: 0.9884058237075806, Val Acc: 65.93%\n",
      "Epoch: 4469,     Training Loss: 0.3773500323295593, Training Acc: 73.12%\n",
      "              Val Loss: 0.9345767498016357, Val Acc: 65.93%\n",
      "Epoch: 4470,     Training Loss: 0.34363818168640137, Training Acc: 73.12%\n",
      "              Val Loss: 0.9200408458709717, Val Acc: 65.94%\n",
      "Epoch: 4471,     Training Loss: 0.3366008698940277, Training Acc: 73.12%\n",
      "              Val Loss: 0.951495885848999, Val Acc: 65.94%\n",
      "Epoch: 4472,     Training Loss: 0.3571167290210724, Training Acc: 73.12%\n",
      "              Val Loss: 0.9616822004318237, Val Acc: 65.94%\n",
      "Epoch: 4473,     Training Loss: 0.380819708108902, Training Acc: 73.13%\n",
      "              Val Loss: 0.9537773728370667, Val Acc: 65.94%\n",
      "Epoch: 4474,     Training Loss: 0.35048678517341614, Training Acc: 73.13%\n",
      "              Val Loss: 0.9307324290275574, Val Acc: 65.94%\n",
      "Epoch: 4475,     Training Loss: 0.3342064619064331, Training Acc: 73.13%\n",
      "              Val Loss: 0.9400820732116699, Val Acc: 65.94%\n",
      "Epoch: 4476,     Training Loss: 0.3316406011581421, Training Acc: 73.14%\n",
      "              Val Loss: 0.9565754532814026, Val Acc: 65.94%\n",
      "Epoch: 4477,     Training Loss: 0.3433647155761719, Training Acc: 73.14%\n",
      "              Val Loss: 0.9679579138755798, Val Acc: 65.94%\n",
      "Epoch: 4478,     Training Loss: 0.3792191743850708, Training Acc: 73.14%\n",
      "              Val Loss: 0.9722899794578552, Val Acc: 65.95%\n",
      "Epoch: 4479,     Training Loss: 0.3660951554775238, Training Acc: 73.14%\n",
      "              Val Loss: 0.9587249159812927, Val Acc: 65.95%\n",
      "Epoch: 4480,     Training Loss: 0.3660813271999359, Training Acc: 73.15%\n",
      "              Val Loss: 0.9382335543632507, Val Acc: 65.95%\n",
      "Epoch: 4481,     Training Loss: 0.3376047611236572, Training Acc: 73.15%\n",
      "              Val Loss: 0.9504572153091431, Val Acc: 65.95%\n",
      "Epoch: 4482,     Training Loss: 0.3345453143119812, Training Acc: 73.15%\n",
      "              Val Loss: 0.9662520885467529, Val Acc: 65.95%\n",
      "Epoch: 4483,     Training Loss: 0.36264047026634216, Training Acc: 73.15%\n",
      "              Val Loss: 0.9731137752532959, Val Acc: 65.95%\n",
      "Epoch: 4484,     Training Loss: 0.3681984841823578, Training Acc: 73.16%\n",
      "              Val Loss: 0.9503703117370605, Val Acc: 65.95%\n",
      "Epoch: 4485,     Training Loss: 0.36200520396232605, Training Acc: 73.16%\n",
      "              Val Loss: 0.9375601410865784, Val Acc: 65.95%\n",
      "Epoch: 4486,     Training Loss: 0.3356902301311493, Training Acc: 73.16%\n",
      "              Val Loss: 0.9378517866134644, Val Acc: 65.96%\n",
      "Epoch: 4487,     Training Loss: 0.3405677378177643, Training Acc: 73.17%\n",
      "              Val Loss: 0.9636645317077637, Val Acc: 65.96%\n",
      "Epoch: 4488,     Training Loss: 0.3690117597579956, Training Acc: 73.17%\n",
      "              Val Loss: 0.9844772219657898, Val Acc: 65.96%\n",
      "Epoch: 4489,     Training Loss: 0.3675878643989563, Training Acc: 73.17%\n",
      "              Val Loss: 0.9833142757415771, Val Acc: 65.96%\n",
      "Epoch: 4490,     Training Loss: 0.397493451833725, Training Acc: 73.17%\n",
      "              Val Loss: 0.9661456942558289, Val Acc: 65.96%\n",
      "Epoch: 4491,     Training Loss: 0.3532710671424866, Training Acc: 73.18%\n",
      "              Val Loss: 0.9317457675933838, Val Acc: 65.96%\n",
      "Epoch: 4492,     Training Loss: 0.3278990685939789, Training Acc: 73.18%\n",
      "              Val Loss: 0.947479248046875, Val Acc: 65.96%\n",
      "Epoch: 4493,     Training Loss: 0.34624525904655457, Training Acc: 73.18%\n",
      "              Val Loss: 0.978305459022522, Val Acc: 65.96%\n",
      "Epoch: 4494,     Training Loss: 0.3593893349170685, Training Acc: 73.18%\n",
      "              Val Loss: 0.9825552105903625, Val Acc: 65.97%\n",
      "Epoch: 4495,     Training Loss: 0.38915538787841797, Training Acc: 73.19%\n",
      "              Val Loss: 0.9766203165054321, Val Acc: 65.97%\n",
      "Epoch: 4496,     Training Loss: 0.3685237467288971, Training Acc: 73.19%\n",
      "              Val Loss: 0.9393015503883362, Val Acc: 65.97%\n",
      "Epoch: 4497,     Training Loss: 0.33865877985954285, Training Acc: 73.19%\n",
      "              Val Loss: 0.9293796420097351, Val Acc: 65.97%\n",
      "Epoch: 4498,     Training Loss: 0.3372589349746704, Training Acc: 73.19%\n",
      "              Val Loss: 0.9768741726875305, Val Acc: 65.97%\n",
      "Epoch: 4499,     Training Loss: 0.36035382747650146, Training Acc: 73.20%\n",
      "              Val Loss: 0.9908522963523865, Val Acc: 65.97%\n",
      "Epoch: 4500,     Training Loss: 0.39652159810066223, Training Acc: 73.20%\n",
      "              Val Loss: 0.999114453792572, Val Acc: 65.97%\n",
      "Epoch: 4501,     Training Loss: 0.3898676037788391, Training Acc: 73.20%\n",
      "              Val Loss: 0.9624236226081848, Val Acc: 65.97%\n",
      "Epoch: 4502,     Training Loss: 0.36258262395858765, Training Acc: 73.20%\n",
      "              Val Loss: 0.9309650659561157, Val Acc: 65.98%\n",
      "Epoch: 4503,     Training Loss: 0.327646940946579, Training Acc: 73.21%\n",
      "              Val Loss: 0.979503870010376, Val Acc: 65.98%\n",
      "Epoch: 4504,     Training Loss: 0.3625868260860443, Training Acc: 73.21%\n",
      "              Val Loss: 1.0156892538070679, Val Acc: 65.98%\n",
      "Epoch: 4505,     Training Loss: 0.4116624891757965, Training Acc: 73.21%\n",
      "              Val Loss: 0.9995702505111694, Val Acc: 65.98%\n",
      "Epoch: 4506,     Training Loss: 0.3816647231578827, Training Acc: 73.21%\n",
      "              Val Loss: 0.9460786581039429, Val Acc: 65.98%\n",
      "Epoch: 4507,     Training Loss: 0.35669082403182983, Training Acc: 73.22%\n",
      "              Val Loss: 0.9362435340881348, Val Acc: 65.98%\n",
      "Epoch: 4508,     Training Loss: 0.3346184194087982, Training Acc: 73.22%\n",
      "              Val Loss: 0.981950581073761, Val Acc: 65.98%\n",
      "Epoch: 4509,     Training Loss: 0.3721618354320526, Training Acc: 73.22%\n",
      "              Val Loss: 0.9956653118133545, Val Acc: 65.98%\n",
      "Epoch: 4510,     Training Loss: 0.41388988494873047, Training Acc: 73.22%\n",
      "              Val Loss: 0.9900152087211609, Val Acc: 65.98%\n",
      "Epoch: 4511,     Training Loss: 0.3708467483520508, Training Acc: 73.23%\n",
      "              Val Loss: 0.9555112719535828, Val Acc: 65.99%\n",
      "Epoch: 4512,     Training Loss: 0.36726802587509155, Training Acc: 73.23%\n",
      "              Val Loss: 0.9325470924377441, Val Acc: 65.99%\n",
      "Epoch: 4513,     Training Loss: 0.3406735956668854, Training Acc: 73.23%\n",
      "              Val Loss: 1.0077403783798218, Val Acc: 65.99%\n",
      "Epoch: 4514,     Training Loss: 0.3834189474582672, Training Acc: 73.23%\n",
      "              Val Loss: 0.9613257050514221, Val Acc: 65.99%\n",
      "Epoch: 4515,     Training Loss: 0.3805348575115204, Training Acc: 73.24%\n",
      "              Val Loss: 0.9643917679786682, Val Acc: 65.99%\n",
      "Epoch: 4516,     Training Loss: 0.35819679498672485, Training Acc: 73.24%\n",
      "              Val Loss: 0.9626117944717407, Val Acc: 65.99%\n",
      "Epoch: 4517,     Training Loss: 0.3574966788291931, Training Acc: 73.24%\n",
      "              Val Loss: 0.932447612285614, Val Acc: 65.99%\n",
      "Epoch: 4518,     Training Loss: 0.3469661474227905, Training Acc: 73.24%\n",
      "              Val Loss: 0.9457100033760071, Val Acc: 66.00%\n",
      "Epoch: 4519,     Training Loss: 0.34622496366500854, Training Acc: 73.25%\n",
      "              Val Loss: 0.9406237006187439, Val Acc: 66.00%\n",
      "Epoch: 4520,     Training Loss: 0.33367085456848145, Training Acc: 73.25%\n",
      "              Val Loss: 0.9493914246559143, Val Acc: 66.00%\n",
      "Epoch: 4521,     Training Loss: 0.34928473830223083, Training Acc: 73.25%\n",
      "              Val Loss: 0.930844783782959, Val Acc: 66.00%\n",
      "Epoch: 4522,     Training Loss: 0.33383992314338684, Training Acc: 73.26%\n",
      "              Val Loss: 0.9803525805473328, Val Acc: 66.00%\n",
      "Epoch: 4523,     Training Loss: 0.3639094829559326, Training Acc: 73.26%\n",
      "              Val Loss: 0.9786543846130371, Val Acc: 66.00%\n",
      "Epoch: 4524,     Training Loss: 0.3904883563518524, Training Acc: 73.26%\n",
      "              Val Loss: 0.9883062839508057, Val Acc: 66.00%\n",
      "Epoch: 4525,     Training Loss: 0.384952574968338, Training Acc: 73.26%\n",
      "              Val Loss: 1.0014524459838867, Val Acc: 66.01%\n",
      "Epoch: 4526,     Training Loss: 0.3945547342300415, Training Acc: 73.26%\n",
      "              Val Loss: 0.9529662132263184, Val Acc: 66.01%\n",
      "Epoch: 4527,     Training Loss: 0.34022560715675354, Training Acc: 73.27%\n",
      "              Val Loss: 0.9654036164283752, Val Acc: 66.01%\n",
      "Epoch: 4528,     Training Loss: 0.3576332926750183, Training Acc: 73.27%\n",
      "              Val Loss: 0.9872540235519409, Val Acc: 66.01%\n",
      "Epoch: 4529,     Training Loss: 0.3774506449699402, Training Acc: 73.27%\n",
      "              Val Loss: 1.0058566331863403, Val Acc: 66.01%\n",
      "Epoch: 4530,     Training Loss: 0.3906613290309906, Training Acc: 73.27%\n",
      "              Val Loss: 0.954905092716217, Val Acc: 66.01%\n",
      "Epoch: 4531,     Training Loss: 0.38364046812057495, Training Acc: 73.28%\n",
      "              Val Loss: 0.9832392334938049, Val Acc: 66.01%\n",
      "Epoch: 4532,     Training Loss: 0.376517117023468, Training Acc: 73.28%\n",
      "              Val Loss: 0.9788644909858704, Val Acc: 66.01%\n",
      "Epoch: 4533,     Training Loss: 0.3826034963130951, Training Acc: 73.28%\n",
      "              Val Loss: 0.9666216969490051, Val Acc: 66.01%\n",
      "Epoch: 4534,     Training Loss: 0.38782772421836853, Training Acc: 73.28%\n",
      "              Val Loss: 1.0262837409973145, Val Acc: 66.02%\n",
      "Epoch: 4535,     Training Loss: 0.41288742423057556, Training Acc: 73.29%\n",
      "              Val Loss: 1.0158790349960327, Val Acc: 66.02%\n",
      "Epoch: 4536,     Training Loss: 0.4240496754646301, Training Acc: 73.29%\n",
      "              Val Loss: 1.01872980594635, Val Acc: 66.02%\n",
      "Epoch: 4537,     Training Loss: 0.4136906564235687, Training Acc: 73.29%\n",
      "              Val Loss: 0.941210150718689, Val Acc: 66.02%\n",
      "Epoch: 4538,     Training Loss: 0.3674551844596863, Training Acc: 73.29%\n",
      "              Val Loss: 0.9910614490509033, Val Acc: 66.02%\n",
      "Epoch: 4539,     Training Loss: 0.37779200077056885, Training Acc: 73.29%\n",
      "              Val Loss: 0.9772712588310242, Val Acc: 66.02%\n",
      "Epoch: 4540,     Training Loss: 0.37587347626686096, Training Acc: 73.30%\n",
      "              Val Loss: 1.0476199388504028, Val Acc: 66.02%\n",
      "Epoch: 4541,     Training Loss: 0.47669368982315063, Training Acc: 73.30%\n",
      "              Val Loss: 0.990530788898468, Val Acc: 66.02%\n",
      "Epoch: 4542,     Training Loss: 0.377725213766098, Training Acc: 73.30%\n",
      "              Val Loss: 0.9723148345947266, Val Acc: 66.02%\n",
      "Epoch: 4543,     Training Loss: 0.3616572618484497, Training Acc: 73.30%\n",
      "              Val Loss: 0.9319621324539185, Val Acc: 66.03%\n",
      "Epoch: 4544,     Training Loss: 0.3565433621406555, Training Acc: 73.31%\n",
      "              Val Loss: 0.9898979663848877, Val Acc: 66.03%\n",
      "Epoch: 4545,     Training Loss: 0.3747738003730774, Training Acc: 73.31%\n",
      "              Val Loss: 0.9743114709854126, Val Acc: 66.03%\n",
      "Epoch: 4546,     Training Loss: 0.37866008281707764, Training Acc: 73.31%\n",
      "              Val Loss: 0.960427463054657, Val Acc: 66.03%\n",
      "Epoch: 4547,     Training Loss: 0.3798574209213257, Training Acc: 73.31%\n",
      "              Val Loss: 0.9542654156684875, Val Acc: 66.03%\n",
      "Epoch: 4548,     Training Loss: 0.3540186285972595, Training Acc: 73.31%\n",
      "              Val Loss: 0.9573559761047363, Val Acc: 66.03%\n",
      "Epoch: 4549,     Training Loss: 0.3400479853153229, Training Acc: 73.32%\n",
      "              Val Loss: 0.9624481201171875, Val Acc: 66.03%\n",
      "Epoch: 4550,     Training Loss: 0.3577721416950226, Training Acc: 73.32%\n",
      "              Val Loss: 0.9585118889808655, Val Acc: 66.04%\n",
      "Epoch: 4551,     Training Loss: 0.3699766993522644, Training Acc: 73.32%\n",
      "              Val Loss: 0.9884774088859558, Val Acc: 66.04%\n",
      "Epoch: 4552,     Training Loss: 0.3861615061759949, Training Acc: 73.33%\n",
      "              Val Loss: 0.9653885364532471, Val Acc: 66.04%\n",
      "Epoch: 4553,     Training Loss: 0.4084445834159851, Training Acc: 73.33%\n",
      "              Val Loss: 0.9389179944992065, Val Acc: 66.04%\n",
      "Epoch: 4554,     Training Loss: 0.3516191244125366, Training Acc: 73.33%\n",
      "              Val Loss: 0.9650179147720337, Val Acc: 66.04%\n",
      "Epoch: 4555,     Training Loss: 0.35093215107917786, Training Acc: 73.33%\n",
      "              Val Loss: 0.9946473836898804, Val Acc: 66.04%\n",
      "Epoch: 4556,     Training Loss: 0.3995845913887024, Training Acc: 73.33%\n",
      "              Val Loss: 1.0120147466659546, Val Acc: 66.04%\n",
      "Epoch: 4557,     Training Loss: 0.39731621742248535, Training Acc: 73.34%\n",
      "              Val Loss: 0.9841160774230957, Val Acc: 66.04%\n",
      "Epoch: 4558,     Training Loss: 0.3977932333946228, Training Acc: 73.34%\n",
      "              Val Loss: 0.9494593143463135, Val Acc: 66.04%\n",
      "Epoch: 4559,     Training Loss: 0.34719258546829224, Training Acc: 73.34%\n",
      "              Val Loss: 0.9749646186828613, Val Acc: 66.05%\n",
      "Epoch: 4560,     Training Loss: 0.36468639969825745, Training Acc: 73.34%\n",
      "              Val Loss: 0.9879739880561829, Val Acc: 66.05%\n",
      "Epoch: 4561,     Training Loss: 0.39711666107177734, Training Acc: 73.35%\n",
      "              Val Loss: 1.000678539276123, Val Acc: 66.05%\n",
      "Epoch: 4562,     Training Loss: 0.366578072309494, Training Acc: 73.35%\n",
      "              Val Loss: 0.9401394724845886, Val Acc: 66.05%\n",
      "Epoch: 4563,     Training Loss: 0.33458569645881653, Training Acc: 73.35%\n",
      "              Val Loss: 0.9344152808189392, Val Acc: 66.05%\n",
      "Epoch: 4564,     Training Loss: 0.335506796836853, Training Acc: 73.35%\n",
      "              Val Loss: 0.9601696133613586, Val Acc: 66.05%\n",
      "Epoch: 4565,     Training Loss: 0.34515875577926636, Training Acc: 73.36%\n",
      "              Val Loss: 0.9426052570343018, Val Acc: 66.05%\n",
      "Epoch: 4566,     Training Loss: 0.34255313873291016, Training Acc: 73.36%\n",
      "              Val Loss: 0.9585503935813904, Val Acc: 66.05%\n",
      "Epoch: 4567,     Training Loss: 0.34239211678504944, Training Acc: 73.36%\n",
      "              Val Loss: 0.9536069631576538, Val Acc: 66.06%\n",
      "Epoch: 4568,     Training Loss: 0.3270188868045807, Training Acc: 73.37%\n",
      "              Val Loss: 0.9514082074165344, Val Acc: 66.06%\n",
      "Epoch: 4569,     Training Loss: 0.3290598690509796, Training Acc: 73.37%\n",
      "              Val Loss: 0.9541501402854919, Val Acc: 66.06%\n",
      "Epoch: 4570,     Training Loss: 0.33076056838035583, Training Acc: 73.37%\n",
      "              Val Loss: 0.9500314593315125, Val Acc: 66.06%\n",
      "Epoch: 4571,     Training Loss: 0.3411784768104553, Training Acc: 73.37%\n",
      "              Val Loss: 0.9713410139083862, Val Acc: 66.06%\n",
      "Epoch: 4572,     Training Loss: 0.364960253238678, Training Acc: 73.38%\n",
      "              Val Loss: 1.0019633769989014, Val Acc: 66.06%\n",
      "Epoch: 4573,     Training Loss: 0.41824856400489807, Training Acc: 73.38%\n",
      "              Val Loss: 1.00566565990448, Val Acc: 66.06%\n",
      "Epoch: 4574,     Training Loss: 0.3864372968673706, Training Acc: 73.38%\n",
      "              Val Loss: 0.9497410655021667, Val Acc: 66.06%\n",
      "Epoch: 4575,     Training Loss: 0.348032683134079, Training Acc: 73.38%\n",
      "              Val Loss: 0.9514397978782654, Val Acc: 66.07%\n",
      "Epoch: 4576,     Training Loss: 0.3354150652885437, Training Acc: 73.39%\n",
      "              Val Loss: 0.9983862042427063, Val Acc: 66.07%\n",
      "Epoch: 4577,     Training Loss: 0.3689398467540741, Training Acc: 73.39%\n",
      "              Val Loss: 0.9745457172393799, Val Acc: 66.07%\n",
      "Epoch: 4578,     Training Loss: 0.38170963525772095, Training Acc: 73.39%\n",
      "              Val Loss: 0.9592641592025757, Val Acc: 66.07%\n",
      "Epoch: 4579,     Training Loss: 0.34385132789611816, Training Acc: 73.39%\n",
      "              Val Loss: 0.9456018805503845, Val Acc: 66.07%\n",
      "Epoch: 4580,     Training Loss: 0.33714568614959717, Training Acc: 73.40%\n",
      "              Val Loss: 0.9391523003578186, Val Acc: 66.07%\n",
      "Epoch: 4581,     Training Loss: 0.35726848244667053, Training Acc: 73.40%\n",
      "              Val Loss: 0.9677670001983643, Val Acc: 66.07%\n",
      "Epoch: 4582,     Training Loss: 0.34391433000564575, Training Acc: 73.40%\n",
      "              Val Loss: 0.948514997959137, Val Acc: 66.08%\n",
      "Epoch: 4583,     Training Loss: 0.33912768959999084, Training Acc: 73.40%\n",
      "              Val Loss: 0.9557145833969116, Val Acc: 66.08%\n",
      "Epoch: 4584,     Training Loss: 0.35843396186828613, Training Acc: 73.41%\n",
      "              Val Loss: 0.9593856334686279, Val Acc: 66.08%\n",
      "Epoch: 4585,     Training Loss: 0.3504016101360321, Training Acc: 73.41%\n",
      "              Val Loss: 0.9543339014053345, Val Acc: 66.08%\n",
      "Epoch: 4586,     Training Loss: 0.33427637815475464, Training Acc: 73.41%\n",
      "              Val Loss: 0.9483364224433899, Val Acc: 66.08%\n",
      "Epoch: 4587,     Training Loss: 0.3464012145996094, Training Acc: 73.41%\n",
      "              Val Loss: 0.9531660676002502, Val Acc: 66.08%\n",
      "Epoch: 4588,     Training Loss: 0.3237910866737366, Training Acc: 73.42%\n",
      "              Val Loss: 0.9628293514251709, Val Acc: 66.08%\n",
      "Epoch: 4589,     Training Loss: 0.33036133646965027, Training Acc: 73.42%\n",
      "              Val Loss: 0.9439078569412231, Val Acc: 66.08%\n",
      "Epoch: 4590,     Training Loss: 0.33744528889656067, Training Acc: 73.42%\n",
      "              Val Loss: 0.963473916053772, Val Acc: 66.09%\n",
      "Epoch: 4591,     Training Loss: 0.34030354022979736, Training Acc: 73.43%\n",
      "              Val Loss: 0.9718336462974548, Val Acc: 66.09%\n",
      "Epoch: 4592,     Training Loss: 0.3618525564670563, Training Acc: 73.43%\n",
      "              Val Loss: 0.9792172908782959, Val Acc: 66.09%\n",
      "Epoch: 4593,     Training Loss: 0.35095223784446716, Training Acc: 73.43%\n",
      "              Val Loss: 0.9881882667541504, Val Acc: 66.09%\n",
      "Epoch: 4594,     Training Loss: 0.3665074110031128, Training Acc: 73.43%\n",
      "              Val Loss: 0.9585647583007812, Val Acc: 66.09%\n",
      "Epoch: 4595,     Training Loss: 0.3337491750717163, Training Acc: 73.44%\n",
      "              Val Loss: 0.9546031951904297, Val Acc: 66.09%\n",
      "Epoch: 4596,     Training Loss: 0.33053845167160034, Training Acc: 73.44%\n",
      "              Val Loss: 0.9457597136497498, Val Acc: 66.09%\n",
      "Epoch: 4597,     Training Loss: 0.33381888270378113, Training Acc: 73.44%\n",
      "              Val Loss: 0.9661152362823486, Val Acc: 66.09%\n",
      "Epoch: 4598,     Training Loss: 0.3604810833930969, Training Acc: 73.44%\n",
      "              Val Loss: 1.0329079627990723, Val Acc: 66.10%\n",
      "Epoch: 4599,     Training Loss: 0.4328974187374115, Training Acc: 73.45%\n",
      "              Val Loss: 1.0395228862762451, Val Acc: 66.10%\n",
      "Epoch: 4600,     Training Loss: 0.4118848443031311, Training Acc: 73.45%\n",
      "              Val Loss: 1.0742518901824951, Val Acc: 66.10%\n",
      "Epoch: 4601,     Training Loss: 0.48617613315582275, Training Acc: 73.45%\n",
      "              Val Loss: 0.9568032026290894, Val Acc: 66.10%\n",
      "Epoch: 4602,     Training Loss: 0.341500848531723, Training Acc: 73.45%\n",
      "              Val Loss: 1.0769625902175903, Val Acc: 66.10%\n",
      "Epoch: 4603,     Training Loss: 0.4363546073436737, Training Acc: 73.45%\n",
      "              Val Loss: 1.1801239252090454, Val Acc: 66.10%\n",
      "Epoch: 4604,     Training Loss: 0.5939615368843079, Training Acc: 73.45%\n",
      "              Val Loss: 0.9714978933334351, Val Acc: 66.10%\n",
      "Epoch: 4605,     Training Loss: 0.37462183833122253, Training Acc: 73.46%\n",
      "              Val Loss: 1.1946513652801514, Val Acc: 66.10%\n",
      "Epoch: 4606,     Training Loss: 0.5613332986831665, Training Acc: 73.46%\n",
      "              Val Loss: 1.406659722328186, Val Acc: 66.10%\n",
      "Epoch: 4607,     Training Loss: 0.8661724328994751, Training Acc: 73.46%\n",
      "              Val Loss: 1.072983980178833, Val Acc: 66.10%\n",
      "Epoch: 4608,     Training Loss: 0.4995296001434326, Training Acc: 73.46%\n",
      "              Val Loss: 1.61366868019104, Val Acc: 66.09%\n",
      "Epoch: 4609,     Training Loss: 1.0560096502304077, Training Acc: 73.45%\n",
      "              Val Loss: 1.8029365539550781, Val Acc: 66.09%\n",
      "Epoch: 4610,     Training Loss: 1.2969763278961182, Training Acc: 73.45%\n",
      "              Val Loss: 1.682987928390503, Val Acc: 66.09%\n",
      "Epoch: 4611,     Training Loss: 1.1976741552352905, Training Acc: 73.45%\n",
      "              Val Loss: 1.1590940952301025, Val Acc: 66.09%\n",
      "Epoch: 4612,     Training Loss: 0.675701916217804, Training Acc: 73.45%\n",
      "              Val Loss: 1.5992523431777954, Val Acc: 66.09%\n",
      "Epoch: 4613,     Training Loss: 1.1300554275512695, Training Acc: 73.44%\n",
      "              Val Loss: 1.3315298557281494, Val Acc: 66.08%\n",
      "Epoch: 4614,     Training Loss: 0.8567085266113281, Training Acc: 73.44%\n",
      "              Val Loss: 1.2562109231948853, Val Acc: 66.08%\n",
      "Epoch: 4615,     Training Loss: 0.8743983507156372, Training Acc: 73.44%\n",
      "              Val Loss: 1.2426530122756958, Val Acc: 66.08%\n",
      "Epoch: 4616,     Training Loss: 0.8777267336845398, Training Acc: 73.44%\n",
      "              Val Loss: 1.0183837413787842, Val Acc: 66.08%\n",
      "Epoch: 4617,     Training Loss: 0.6811213493347168, Training Acc: 73.44%\n",
      "              Val Loss: 1.1685066223144531, Val Acc: 66.08%\n",
      "Epoch: 4618,     Training Loss: 0.808083176612854, Training Acc: 73.44%\n",
      "              Val Loss: 1.1838884353637695, Val Acc: 66.08%\n",
      "Epoch: 4619,     Training Loss: 0.7652710676193237, Training Acc: 73.44%\n",
      "              Val Loss: 1.0693652629852295, Val Acc: 66.08%\n",
      "Epoch: 4620,     Training Loss: 0.672514021396637, Training Acc: 73.43%\n",
      "              Val Loss: 1.0081406831741333, Val Acc: 66.08%\n",
      "Epoch: 4621,     Training Loss: 0.6833845376968384, Training Acc: 73.43%\n",
      "              Val Loss: 0.9819709658622742, Val Acc: 66.08%\n",
      "Epoch: 4622,     Training Loss: 0.6991816163063049, Training Acc: 73.43%\n",
      "              Val Loss: 0.9451460242271423, Val Acc: 66.08%\n",
      "Epoch: 4623,     Training Loss: 0.6407529711723328, Training Acc: 73.43%\n",
      "              Val Loss: 0.9945471882820129, Val Acc: 66.08%\n",
      "Epoch: 4624,     Training Loss: 0.6186972260475159, Training Acc: 73.43%\n",
      "              Val Loss: 1.056832194328308, Val Acc: 66.08%\n",
      "Epoch: 4625,     Training Loss: 0.6182435750961304, Training Acc: 73.43%\n",
      "              Val Loss: 1.0201332569122314, Val Acc: 66.08%\n",
      "Epoch: 4626,     Training Loss: 0.6025780439376831, Training Acc: 73.44%\n",
      "              Val Loss: 0.9042140245437622, Val Acc: 66.09%\n",
      "Epoch: 4627,     Training Loss: 0.5446605086326599, Training Acc: 73.44%\n",
      "              Val Loss: 0.8514429330825806, Val Acc: 66.09%\n",
      "Epoch: 4628,     Training Loss: 0.5269524455070496, Training Acc: 73.44%\n",
      "              Val Loss: 0.8905017971992493, Val Acc: 66.09%\n",
      "Epoch: 4629,     Training Loss: 0.5576631426811218, Training Acc: 73.44%\n",
      "              Val Loss: 0.8814713358879089, Val Acc: 66.09%\n",
      "Epoch: 4630,     Training Loss: 0.530750572681427, Training Acc: 73.44%\n",
      "              Val Loss: 0.8518057465553284, Val Acc: 66.09%\n",
      "Epoch: 4631,     Training Loss: 0.48577073216438293, Training Acc: 73.44%\n",
      "              Val Loss: 0.8698453307151794, Val Acc: 66.09%\n",
      "Epoch: 4632,     Training Loss: 0.4976522922515869, Training Acc: 73.44%\n",
      "              Val Loss: 0.8794500231742859, Val Acc: 66.09%\n",
      "Epoch: 4633,     Training Loss: 0.5017592310905457, Training Acc: 73.44%\n",
      "              Val Loss: 0.8452026844024658, Val Acc: 66.09%\n",
      "Epoch: 4634,     Training Loss: 0.4655267298221588, Training Acc: 73.45%\n",
      "              Val Loss: 0.8408527374267578, Val Acc: 66.09%\n",
      "Epoch: 4635,     Training Loss: 0.45913705229759216, Training Acc: 73.45%\n",
      "              Val Loss: 0.8384568095207214, Val Acc: 66.10%\n",
      "Epoch: 4636,     Training Loss: 0.4560762345790863, Training Acc: 73.45%\n",
      "              Val Loss: 0.8287311792373657, Val Acc: 66.10%\n",
      "Epoch: 4637,     Training Loss: 0.44067326188087463, Training Acc: 73.45%\n",
      "              Val Loss: 0.8379101753234863, Val Acc: 66.10%\n",
      "Epoch: 4638,     Training Loss: 0.4381786286830902, Training Acc: 73.45%\n",
      "              Val Loss: 0.8320832848548889, Val Acc: 66.10%\n",
      "Epoch: 4639,     Training Loss: 0.4258144795894623, Training Acc: 73.45%\n",
      "              Val Loss: 0.8304778337478638, Val Acc: 66.10%\n",
      "Epoch: 4640,     Training Loss: 0.42049044370651245, Training Acc: 73.46%\n",
      "              Val Loss: 0.8408164381980896, Val Acc: 66.10%\n",
      "Epoch: 4641,     Training Loss: 0.4181092083454132, Training Acc: 73.46%\n",
      "              Val Loss: 0.8329659104347229, Val Acc: 66.10%\n",
      "Epoch: 4642,     Training Loss: 0.4038740396499634, Training Acc: 73.46%\n",
      "              Val Loss: 0.8395510315895081, Val Acc: 66.11%\n",
      "Epoch: 4643,     Training Loss: 0.4018353521823883, Training Acc: 73.46%\n",
      "              Val Loss: 0.848584771156311, Val Acc: 66.11%\n",
      "Epoch: 4644,     Training Loss: 0.4007531404495239, Training Acc: 73.47%\n",
      "              Val Loss: 0.8546972870826721, Val Acc: 66.11%\n",
      "Epoch: 4645,     Training Loss: 0.39211440086364746, Training Acc: 73.47%\n",
      "              Val Loss: 0.8736225962638855, Val Acc: 66.11%\n",
      "Epoch: 4646,     Training Loss: 0.39261549711227417, Training Acc: 73.47%\n",
      "              Val Loss: 0.8676452040672302, Val Acc: 66.11%\n",
      "Epoch: 4647,     Training Loss: 0.38557684421539307, Training Acc: 73.47%\n",
      "              Val Loss: 0.8592665195465088, Val Acc: 66.11%\n",
      "Epoch: 4648,     Training Loss: 0.3819766938686371, Training Acc: 73.47%\n",
      "              Val Loss: 0.8450902700424194, Val Acc: 66.11%\n",
      "Epoch: 4649,     Training Loss: 0.379495769739151, Training Acc: 73.48%\n",
      "              Val Loss: 0.8407247066497803, Val Acc: 66.11%\n",
      "Epoch: 4650,     Training Loss: 0.3810586929321289, Training Acc: 73.48%\n",
      "              Val Loss: 0.8560563921928406, Val Acc: 66.12%\n",
      "Epoch: 4651,     Training Loss: 0.37927329540252686, Training Acc: 73.48%\n",
      "              Val Loss: 0.8643313050270081, Val Acc: 66.12%\n",
      "Epoch: 4652,     Training Loss: 0.3831039071083069, Training Acc: 73.48%\n",
      "              Val Loss: 0.875583827495575, Val Acc: 66.12%\n",
      "Epoch: 4653,     Training Loss: 0.3841310143470764, Training Acc: 73.49%\n",
      "              Val Loss: 0.8688313961029053, Val Acc: 66.12%\n",
      "Epoch: 4654,     Training Loss: 0.3929477632045746, Training Acc: 73.49%\n",
      "              Val Loss: 0.8702393174171448, Val Acc: 66.12%\n",
      "Epoch: 4655,     Training Loss: 0.38251519203186035, Training Acc: 73.49%\n",
      "              Val Loss: 0.8616665601730347, Val Acc: 66.12%\n",
      "Epoch: 4656,     Training Loss: 0.38035956025123596, Training Acc: 73.49%\n",
      "              Val Loss: 0.8539099097251892, Val Acc: 66.12%\n",
      "Epoch: 4657,     Training Loss: 0.36695778369903564, Training Acc: 73.50%\n",
      "              Val Loss: 0.8454355001449585, Val Acc: 66.13%\n",
      "Epoch: 4658,     Training Loss: 0.35988399386405945, Training Acc: 73.50%\n",
      "              Val Loss: 0.8604991436004639, Val Acc: 66.13%\n",
      "Epoch: 4659,     Training Loss: 0.35660937428474426, Training Acc: 73.50%\n",
      "              Val Loss: 0.8885699510574341, Val Acc: 66.13%\n",
      "Epoch: 4660,     Training Loss: 0.3607006072998047, Training Acc: 73.50%\n",
      "              Val Loss: 0.8805899024009705, Val Acc: 66.13%\n",
      "Epoch: 4661,     Training Loss: 0.36575865745544434, Training Acc: 73.51%\n",
      "              Val Loss: 0.8993651866912842, Val Acc: 66.13%\n",
      "Epoch: 4662,     Training Loss: 0.37383267283439636, Training Acc: 73.51%\n",
      "              Val Loss: 0.9060382843017578, Val Acc: 66.13%\n",
      "Epoch: 4663,     Training Loss: 0.4021013677120209, Training Acc: 73.51%\n",
      "              Val Loss: 0.9081521034240723, Val Acc: 66.13%\n",
      "Epoch: 4664,     Training Loss: 0.37444841861724854, Training Acc: 73.51%\n",
      "              Val Loss: 0.8778147101402283, Val Acc: 66.14%\n",
      "Epoch: 4665,     Training Loss: 0.3571394383907318, Training Acc: 73.51%\n",
      "              Val Loss: 0.8777127861976624, Val Acc: 66.14%\n",
      "Epoch: 4666,     Training Loss: 0.3481607437133789, Training Acc: 73.52%\n",
      "              Val Loss: 0.9067878723144531, Val Acc: 66.14%\n",
      "Epoch: 4667,     Training Loss: 0.3579385280609131, Training Acc: 73.52%\n",
      "              Val Loss: 0.9279792904853821, Val Acc: 66.14%\n",
      "Epoch: 4668,     Training Loss: 0.39682427048683167, Training Acc: 73.52%\n",
      "              Val Loss: 0.9396625757217407, Val Acc: 66.14%\n",
      "Epoch: 4669,     Training Loss: 0.38104698061943054, Training Acc: 73.52%\n",
      "              Val Loss: 0.9047878980636597, Val Acc: 66.14%\n",
      "Epoch: 4670,     Training Loss: 0.3841763734817505, Training Acc: 73.53%\n",
      "              Val Loss: 0.8877438306808472, Val Acc: 66.14%\n",
      "Epoch: 4671,     Training Loss: 0.34890592098236084, Training Acc: 73.53%\n",
      "              Val Loss: 0.891203761100769, Val Acc: 66.14%\n",
      "Epoch: 4672,     Training Loss: 0.3485472798347473, Training Acc: 73.53%\n",
      "              Val Loss: 0.8980486989021301, Val Acc: 66.15%\n",
      "Epoch: 4673,     Training Loss: 0.3735106587409973, Training Acc: 73.53%\n",
      "              Val Loss: 0.9083418250083923, Val Acc: 66.15%\n",
      "Epoch: 4674,     Training Loss: 0.35915905237197876, Training Acc: 73.54%\n",
      "              Val Loss: 0.8812970519065857, Val Acc: 66.15%\n",
      "Epoch: 4675,     Training Loss: 0.3455685079097748, Training Acc: 73.54%\n",
      "              Val Loss: 0.8675501942634583, Val Acc: 66.15%\n",
      "Epoch: 4676,     Training Loss: 0.33889877796173096, Training Acc: 73.54%\n",
      "              Val Loss: 0.8705931305885315, Val Acc: 66.15%\n",
      "Epoch: 4677,     Training Loss: 0.3402862846851349, Training Acc: 73.55%\n",
      "              Val Loss: 0.8785059452056885, Val Acc: 66.15%\n",
      "Epoch: 4678,     Training Loss: 0.34711262583732605, Training Acc: 73.55%\n",
      "              Val Loss: 0.9024996161460876, Val Acc: 66.15%\n",
      "Epoch: 4679,     Training Loss: 0.3503877520561218, Training Acc: 73.55%\n",
      "              Val Loss: 0.8851786255836487, Val Acc: 66.16%\n",
      "Epoch: 4680,     Training Loss: 0.3576938509941101, Training Acc: 73.55%\n",
      "              Val Loss: 0.9016907215118408, Val Acc: 66.16%\n",
      "Epoch: 4681,     Training Loss: 0.351379930973053, Training Acc: 73.56%\n",
      "              Val Loss: 0.8898389935493469, Val Acc: 66.16%\n",
      "Epoch: 4682,     Training Loss: 0.353841096162796, Training Acc: 73.56%\n",
      "              Val Loss: 0.9011776447296143, Val Acc: 66.16%\n",
      "Epoch: 4683,     Training Loss: 0.34706956148147583, Training Acc: 73.56%\n",
      "              Val Loss: 0.8834613561630249, Val Acc: 66.16%\n",
      "Epoch: 4684,     Training Loss: 0.3443948030471802, Training Acc: 73.56%\n",
      "              Val Loss: 0.8929201364517212, Val Acc: 66.16%\n",
      "Epoch: 4685,     Training Loss: 0.3344997465610504, Training Acc: 73.57%\n",
      "              Val Loss: 0.8830642700195312, Val Acc: 66.16%\n",
      "Epoch: 4686,     Training Loss: 0.33111417293548584, Training Acc: 73.57%\n",
      "              Val Loss: 0.8807113766670227, Val Acc: 66.17%\n",
      "Epoch: 4687,     Training Loss: 0.33026111125946045, Training Acc: 73.57%\n",
      "              Val Loss: 0.8895069360733032, Val Acc: 66.17%\n",
      "Epoch: 4688,     Training Loss: 0.33066871762275696, Training Acc: 73.57%\n",
      "              Val Loss: 0.887499988079071, Val Acc: 66.17%\n",
      "Epoch: 4689,     Training Loss: 0.3352378010749817, Training Acc: 73.58%\n",
      "              Val Loss: 0.9053529500961304, Val Acc: 66.17%\n",
      "Epoch: 4690,     Training Loss: 0.3421594202518463, Training Acc: 73.58%\n",
      "              Val Loss: 0.912034809589386, Val Acc: 66.17%\n",
      "Epoch: 4691,     Training Loss: 0.36603599786758423, Training Acc: 73.58%\n",
      "              Val Loss: 0.9460002779960632, Val Acc: 66.17%\n",
      "Epoch: 4692,     Training Loss: 0.37068480253219604, Training Acc: 73.58%\n",
      "              Val Loss: 0.9611086249351501, Val Acc: 66.17%\n",
      "Epoch: 4693,     Training Loss: 0.42629551887512207, Training Acc: 73.59%\n",
      "              Val Loss: 0.9255491495132446, Val Acc: 66.17%\n",
      "Epoch: 4694,     Training Loss: 0.3547784090042114, Training Acc: 73.59%\n",
      "              Val Loss: 0.9072326421737671, Val Acc: 66.17%\n",
      "Epoch: 4695,     Training Loss: 0.3403288722038269, Training Acc: 73.59%\n",
      "              Val Loss: 0.9144899845123291, Val Acc: 66.18%\n",
      "Epoch: 4696,     Training Loss: 0.37826406955718994, Training Acc: 73.59%\n",
      "              Val Loss: 0.920692503452301, Val Acc: 66.18%\n",
      "Epoch: 4697,     Training Loss: 0.35657551884651184, Training Acc: 73.60%\n",
      "              Val Loss: 0.8904712796211243, Val Acc: 66.18%\n",
      "Epoch: 4698,     Training Loss: 0.3359966576099396, Training Acc: 73.60%\n",
      "              Val Loss: 0.8909866809844971, Val Acc: 66.18%\n",
      "Epoch: 4699,     Training Loss: 0.3373274505138397, Training Acc: 73.60%\n",
      "              Val Loss: 0.910725474357605, Val Acc: 66.18%\n",
      "Epoch: 4700,     Training Loss: 0.3427121639251709, Training Acc: 73.60%\n",
      "              Val Loss: 0.8993582725524902, Val Acc: 66.18%\n",
      "Epoch: 4701,     Training Loss: 0.3435092270374298, Training Acc: 73.61%\n",
      "              Val Loss: 0.9011474847793579, Val Acc: 66.18%\n",
      "Epoch: 4702,     Training Loss: 0.3350452184677124, Training Acc: 73.61%\n",
      "              Val Loss: 0.897454023361206, Val Acc: 66.19%\n",
      "Epoch: 4703,     Training Loss: 0.3265056908130646, Training Acc: 73.61%\n",
      "              Val Loss: 0.9080309271812439, Val Acc: 66.19%\n",
      "Epoch: 4704,     Training Loss: 0.33770060539245605, Training Acc: 73.62%\n",
      "              Val Loss: 0.9249833822250366, Val Acc: 66.19%\n",
      "Epoch: 4705,     Training Loss: 0.34788399934768677, Training Acc: 73.62%\n",
      "              Val Loss: 0.9255994558334351, Val Acc: 66.19%\n",
      "Epoch: 4706,     Training Loss: 0.37084996700286865, Training Acc: 73.62%\n",
      "              Val Loss: 0.9415422081947327, Val Acc: 66.19%\n",
      "Epoch: 4707,     Training Loss: 0.3681333065032959, Training Acc: 73.62%\n",
      "              Val Loss: 0.9498198628425598, Val Acc: 66.19%\n",
      "Epoch: 4708,     Training Loss: 0.41409987211227417, Training Acc: 73.62%\n",
      "              Val Loss: 0.9287300705909729, Val Acc: 66.19%\n",
      "Epoch: 4709,     Training Loss: 0.35400623083114624, Training Acc: 73.63%\n",
      "              Val Loss: 0.9161165356636047, Val Acc: 66.19%\n",
      "Epoch: 4710,     Training Loss: 0.3393206000328064, Training Acc: 73.63%\n",
      "              Val Loss: 0.9388332366943359, Val Acc: 66.19%\n",
      "Epoch: 4711,     Training Loss: 0.3777565658092499, Training Acc: 73.63%\n",
      "              Val Loss: 0.9378133416175842, Val Acc: 66.20%\n",
      "Epoch: 4712,     Training Loss: 0.3521125316619873, Training Acc: 73.63%\n",
      "              Val Loss: 0.9134305715560913, Val Acc: 66.20%\n",
      "Epoch: 4713,     Training Loss: 0.33091112971305847, Training Acc: 73.64%\n",
      "              Val Loss: 0.9089977741241455, Val Acc: 66.20%\n",
      "Epoch: 4714,     Training Loss: 0.3396788537502289, Training Acc: 73.64%\n",
      "              Val Loss: 0.9331378936767578, Val Acc: 66.20%\n",
      "Epoch: 4715,     Training Loss: 0.34645217657089233, Training Acc: 73.64%\n",
      "              Val Loss: 0.9152689576148987, Val Acc: 66.20%\n",
      "Epoch: 4716,     Training Loss: 0.3386455774307251, Training Acc: 73.65%\n",
      "              Val Loss: 0.9098248481750488, Val Acc: 66.20%\n",
      "Epoch: 4717,     Training Loss: 0.3262759745121002, Training Acc: 73.65%\n",
      "              Val Loss: 0.941830039024353, Val Acc: 66.20%\n",
      "Epoch: 4718,     Training Loss: 0.34128043055534363, Training Acc: 73.65%\n",
      "              Val Loss: 0.9529731869697571, Val Acc: 66.20%\n",
      "Epoch: 4719,     Training Loss: 0.3830178380012512, Training Acc: 73.65%\n",
      "              Val Loss: 0.9463937878608704, Val Acc: 66.21%\n",
      "Epoch: 4720,     Training Loss: 0.3554014563560486, Training Acc: 73.66%\n",
      "              Val Loss: 0.9138157367706299, Val Acc: 66.21%\n",
      "Epoch: 4721,     Training Loss: 0.34872105717658997, Training Acc: 73.66%\n",
      "              Val Loss: 0.8938645720481873, Val Acc: 66.21%\n",
      "Epoch: 4722,     Training Loss: 0.32578814029693604, Training Acc: 73.66%\n",
      "              Val Loss: 0.9283182621002197, Val Acc: 66.21%\n",
      "Epoch: 4723,     Training Loss: 0.3410506546497345, Training Acc: 73.66%\n",
      "              Val Loss: 0.9469297528266907, Val Acc: 66.21%\n",
      "Epoch: 4724,     Training Loss: 0.37933972477912903, Training Acc: 73.67%\n",
      "              Val Loss: 0.9512392282485962, Val Acc: 66.21%\n",
      "Epoch: 4725,     Training Loss: 0.3536407947540283, Training Acc: 73.67%\n",
      "              Val Loss: 0.9289570450782776, Val Acc: 66.21%\n",
      "Epoch: 4726,     Training Loss: 0.33492016792297363, Training Acc: 73.67%\n",
      "              Val Loss: 0.9091973900794983, Val Acc: 66.21%\n",
      "Epoch: 4727,     Training Loss: 0.3249901235103607, Training Acc: 73.67%\n",
      "              Val Loss: 0.9454410672187805, Val Acc: 66.21%\n",
      "Epoch: 4728,     Training Loss: 0.3458636403083801, Training Acc: 73.68%\n",
      "              Val Loss: 0.9545858502388, Val Acc: 66.22%\n",
      "Epoch: 4729,     Training Loss: 0.3740960657596588, Training Acc: 73.68%\n",
      "              Val Loss: 0.9436061978340149, Val Acc: 66.22%\n",
      "Epoch: 4730,     Training Loss: 0.3412572145462036, Training Acc: 73.68%\n",
      "              Val Loss: 0.919269323348999, Val Acc: 66.22%\n",
      "Epoch: 4731,     Training Loss: 0.3230603039264679, Training Acc: 73.68%\n",
      "              Val Loss: 0.917863667011261, Val Acc: 66.22%\n",
      "Epoch: 4732,     Training Loss: 0.33033862709999084, Training Acc: 73.69%\n",
      "              Val Loss: 0.9518234133720398, Val Acc: 66.22%\n",
      "Epoch: 4733,     Training Loss: 0.34864795207977295, Training Acc: 73.69%\n",
      "              Val Loss: 0.9560010433197021, Val Acc: 66.22%\n",
      "Epoch: 4734,     Training Loss: 0.37282511591911316, Training Acc: 73.69%\n",
      "              Val Loss: 0.951815664768219, Val Acc: 66.22%\n",
      "Epoch: 4735,     Training Loss: 0.3417145907878876, Training Acc: 73.69%\n",
      "              Val Loss: 0.9176272749900818, Val Acc: 66.22%\n",
      "Epoch: 4736,     Training Loss: 0.3233087956905365, Training Acc: 73.70%\n",
      "              Val Loss: 0.9179508090019226, Val Acc: 66.23%\n",
      "Epoch: 4737,     Training Loss: 0.3227980434894562, Training Acc: 73.70%\n",
      "              Val Loss: 0.9470165371894836, Val Acc: 66.23%\n",
      "Epoch: 4738,     Training Loss: 0.3360360264778137, Training Acc: 73.70%\n",
      "              Val Loss: 0.9440451264381409, Val Acc: 66.23%\n",
      "Epoch: 4739,     Training Loss: 0.35316479206085205, Training Acc: 73.70%\n",
      "              Val Loss: 0.9698746204376221, Val Acc: 66.23%\n",
      "Epoch: 4740,     Training Loss: 0.3480358421802521, Training Acc: 73.71%\n",
      "              Val Loss: 0.9406877756118774, Val Acc: 66.23%\n",
      "Epoch: 4741,     Training Loss: 0.34873074293136597, Training Acc: 73.71%\n",
      "              Val Loss: 0.9266093969345093, Val Acc: 66.23%\n",
      "Epoch: 4742,     Training Loss: 0.328499972820282, Training Acc: 73.71%\n",
      "              Val Loss: 0.9461990594863892, Val Acc: 66.23%\n",
      "Epoch: 4743,     Training Loss: 0.33055755496025085, Training Acc: 73.71%\n",
      "              Val Loss: 0.9334185123443604, Val Acc: 66.23%\n",
      "Epoch: 4744,     Training Loss: 0.3341394066810608, Training Acc: 73.72%\n",
      "              Val Loss: 0.9648529291152954, Val Acc: 66.24%\n",
      "Epoch: 4745,     Training Loss: 0.34545859694480896, Training Acc: 73.72%\n",
      "              Val Loss: 0.9792088866233826, Val Acc: 66.24%\n",
      "Epoch: 4746,     Training Loss: 0.372130811214447, Training Acc: 73.72%\n",
      "              Val Loss: 0.9576423764228821, Val Acc: 66.24%\n",
      "Epoch: 4747,     Training Loss: 0.3432448208332062, Training Acc: 73.72%\n",
      "              Val Loss: 0.9294610619544983, Val Acc: 66.24%\n",
      "Epoch: 4748,     Training Loss: 0.33445289731025696, Training Acc: 73.73%\n",
      "              Val Loss: 0.9339030385017395, Val Acc: 66.24%\n",
      "Epoch: 4749,     Training Loss: 0.32167041301727295, Training Acc: 73.73%\n",
      "              Val Loss: 0.9437384009361267, Val Acc: 66.24%\n",
      "Epoch: 4750,     Training Loss: 0.3303831219673157, Training Acc: 73.73%\n",
      "              Val Loss: 0.9493591785430908, Val Acc: 66.24%\n",
      "Epoch: 4751,     Training Loss: 0.34086188673973083, Training Acc: 73.73%\n",
      "              Val Loss: 0.970115065574646, Val Acc: 66.24%\n",
      "Epoch: 4752,     Training Loss: 0.3418124318122864, Training Acc: 73.74%\n",
      "              Val Loss: 0.9514151215553284, Val Acc: 66.24%\n",
      "Epoch: 4753,     Training Loss: 0.35911789536476135, Training Acc: 73.74%\n",
      "              Val Loss: 0.952497661113739, Val Acc: 66.25%\n",
      "Epoch: 4754,     Training Loss: 0.333014577627182, Training Acc: 73.74%\n",
      "              Val Loss: 0.9354814291000366, Val Acc: 66.25%\n",
      "Epoch: 4755,     Training Loss: 0.3277713656425476, Training Acc: 73.74%\n",
      "              Val Loss: 0.9377797842025757, Val Acc: 66.25%\n",
      "Epoch: 4756,     Training Loss: 0.3194512724876404, Training Acc: 73.75%\n",
      "              Val Loss: 0.958244800567627, Val Acc: 66.25%\n",
      "Epoch: 4757,     Training Loss: 0.3222652077674866, Training Acc: 73.75%\n",
      "              Val Loss: 0.9496238827705383, Val Acc: 66.25%\n",
      "Epoch: 4758,     Training Loss: 0.33738765120506287, Training Acc: 73.75%\n",
      "              Val Loss: 0.9691522717475891, Val Acc: 66.25%\n",
      "Epoch: 4759,     Training Loss: 0.3505828380584717, Training Acc: 73.76%\n",
      "              Val Loss: 1.0312443971633911, Val Acc: 66.25%\n",
      "Epoch: 4760,     Training Loss: 0.42745575308799744, Training Acc: 73.76%\n",
      "              Val Loss: 1.0014276504516602, Val Acc: 66.25%\n",
      "Epoch: 4761,     Training Loss: 0.37736037373542786, Training Acc: 73.76%\n",
      "              Val Loss: 0.9463939070701599, Val Acc: 66.25%\n",
      "Epoch: 4762,     Training Loss: 0.3398716449737549, Training Acc: 73.76%\n",
      "              Val Loss: 0.9494031667709351, Val Acc: 66.26%\n",
      "Epoch: 4763,     Training Loss: 0.33108189702033997, Training Acc: 73.76%\n",
      "              Val Loss: 0.9949755072593689, Val Acc: 66.26%\n",
      "Epoch: 4764,     Training Loss: 0.35946419835090637, Training Acc: 73.77%\n",
      "              Val Loss: 0.9964393377304077, Val Acc: 66.26%\n",
      "Epoch: 4765,     Training Loss: 0.38633668422698975, Training Acc: 73.77%\n",
      "              Val Loss: 0.9698804616928101, Val Acc: 66.26%\n",
      "Epoch: 4766,     Training Loss: 0.34338393807411194, Training Acc: 73.77%\n",
      "              Val Loss: 0.9474670886993408, Val Acc: 66.26%\n",
      "Epoch: 4767,     Training Loss: 0.33467158675193787, Training Acc: 73.77%\n",
      "              Val Loss: 0.948138952255249, Val Acc: 66.26%\n",
      "Epoch: 4768,     Training Loss: 0.3466850221157074, Training Acc: 73.78%\n",
      "              Val Loss: 0.9824249744415283, Val Acc: 66.26%\n",
      "Epoch: 4769,     Training Loss: 0.3514690399169922, Training Acc: 73.78%\n",
      "              Val Loss: 0.95978182554245, Val Acc: 66.26%\n",
      "Epoch: 4770,     Training Loss: 0.3418711721897125, Training Acc: 73.78%\n",
      "              Val Loss: 0.9759191274642944, Val Acc: 66.26%\n",
      "Epoch: 4771,     Training Loss: 0.32776355743408203, Training Acc: 73.78%\n",
      "              Val Loss: 0.966752290725708, Val Acc: 66.26%\n",
      "Epoch: 4772,     Training Loss: 0.3301644027233124, Training Acc: 73.79%\n",
      "              Val Loss: 0.9462491869926453, Val Acc: 66.27%\n",
      "Epoch: 4773,     Training Loss: 0.3280588984489441, Training Acc: 73.79%\n",
      "              Val Loss: 0.9800137877464294, Val Acc: 66.27%\n",
      "Epoch: 4774,     Training Loss: 0.3537819981575012, Training Acc: 73.79%\n",
      "              Val Loss: 0.9970291256904602, Val Acc: 66.27%\n",
      "Epoch: 4775,     Training Loss: 0.4072980582714081, Training Acc: 73.79%\n",
      "              Val Loss: 0.9927409291267395, Val Acc: 66.27%\n",
      "Epoch: 4776,     Training Loss: 0.37167853116989136, Training Acc: 73.80%\n",
      "              Val Loss: 0.9995337128639221, Val Acc: 66.27%\n",
      "Epoch: 4777,     Training Loss: 0.3620799779891968, Training Acc: 73.80%\n",
      "              Val Loss: 0.9639229774475098, Val Acc: 66.27%\n",
      "Epoch: 4778,     Training Loss: 0.34105873107910156, Training Acc: 73.80%\n",
      "              Val Loss: 1.044472336769104, Val Acc: 66.27%\n",
      "Epoch: 4779,     Training Loss: 0.38183221220970154, Training Acc: 73.80%\n",
      "              Val Loss: 1.0349681377410889, Val Acc: 66.27%\n",
      "Epoch: 4780,     Training Loss: 0.4113788306713104, Training Acc: 73.80%\n",
      "              Val Loss: 0.9707827568054199, Val Acc: 66.27%\n",
      "Epoch: 4781,     Training Loss: 0.33573174476623535, Training Acc: 73.81%\n",
      "              Val Loss: 0.9924619793891907, Val Acc: 66.27%\n",
      "Epoch: 4782,     Training Loss: 0.369872510433197, Training Acc: 73.81%\n",
      "              Val Loss: 0.9905407428741455, Val Acc: 66.28%\n",
      "Epoch: 4783,     Training Loss: 0.39592936635017395, Training Acc: 73.81%\n",
      "              Val Loss: 1.026137351989746, Val Acc: 66.28%\n",
      "Epoch: 4784,     Training Loss: 0.38313400745391846, Training Acc: 73.81%\n",
      "              Val Loss: 0.9964218735694885, Val Acc: 66.28%\n",
      "Epoch: 4785,     Training Loss: 0.3932543098926544, Training Acc: 73.81%\n",
      "              Val Loss: 0.9463356733322144, Val Acc: 66.28%\n",
      "Epoch: 4786,     Training Loss: 0.3277082145214081, Training Acc: 73.82%\n",
      "              Val Loss: 1.0667988061904907, Val Acc: 66.28%\n",
      "Epoch: 4787,     Training Loss: 0.42061251401901245, Training Acc: 73.82%\n",
      "              Val Loss: 1.0992884635925293, Val Acc: 66.28%\n",
      "Epoch: 4788,     Training Loss: 0.5213420391082764, Training Acc: 73.82%\n",
      "              Val Loss: 1.0611933469772339, Val Acc: 66.28%\n",
      "Epoch: 4789,     Training Loss: 0.4336565434932709, Training Acc: 73.82%\n",
      "              Val Loss: 1.0646229982376099, Val Acc: 66.28%\n",
      "Epoch: 4790,     Training Loss: 0.44586944580078125, Training Acc: 73.82%\n",
      "              Val Loss: 0.9866292476654053, Val Acc: 66.28%\n",
      "Epoch: 4791,     Training Loss: 0.3951984643936157, Training Acc: 73.82%\n",
      "              Val Loss: 1.1451900005340576, Val Acc: 66.28%\n",
      "Epoch: 4792,     Training Loss: 0.48040449619293213, Training Acc: 73.83%\n",
      "              Val Loss: 1.0193425416946411, Val Acc: 66.28%\n",
      "Epoch: 4793,     Training Loss: 0.4125362038612366, Training Acc: 73.83%\n",
      "              Val Loss: 1.0771229267120361, Val Acc: 66.28%\n",
      "Epoch: 4794,     Training Loss: 0.447791188955307, Training Acc: 73.83%\n",
      "              Val Loss: 0.9655105471611023, Val Acc: 66.28%\n",
      "Epoch: 4795,     Training Loss: 0.3850834369659424, Training Acc: 73.83%\n",
      "              Val Loss: 1.026545524597168, Val Acc: 66.29%\n",
      "Epoch: 4796,     Training Loss: 0.42558223009109497, Training Acc: 73.83%\n",
      "              Val Loss: 0.9700399041175842, Val Acc: 66.29%\n",
      "Epoch: 4797,     Training Loss: 0.35955479741096497, Training Acc: 73.83%\n",
      "              Val Loss: 1.0260319709777832, Val Acc: 66.29%\n",
      "Epoch: 4798,     Training Loss: 0.410325825214386, Training Acc: 73.84%\n",
      "              Val Loss: 0.9443399310112, Val Acc: 66.29%\n",
      "Epoch: 4799,     Training Loss: 0.3519979417324066, Training Acc: 73.84%\n",
      "              Val Loss: 1.0334537029266357, Val Acc: 66.29%\n",
      "Epoch: 4800,     Training Loss: 0.4156067967414856, Training Acc: 73.84%\n",
      "              Val Loss: 0.9236006736755371, Val Acc: 66.29%\n",
      "Epoch: 4801,     Training Loss: 0.34372231364250183, Training Acc: 73.84%\n",
      "              Val Loss: 0.981351912021637, Val Acc: 66.29%\n",
      "Epoch: 4802,     Training Loss: 0.40168607234954834, Training Acc: 73.84%\n",
      "              Val Loss: 0.9164643883705139, Val Acc: 66.29%\n",
      "Epoch: 4803,     Training Loss: 0.33865833282470703, Training Acc: 73.85%\n",
      "              Val Loss: 0.9861286282539368, Val Acc: 66.29%\n",
      "Epoch: 4804,     Training Loss: 0.37782591581344604, Training Acc: 73.85%\n",
      "              Val Loss: 0.9498658776283264, Val Acc: 66.30%\n",
      "Epoch: 4805,     Training Loss: 0.33792728185653687, Training Acc: 73.85%\n",
      "              Val Loss: 0.9838363528251648, Val Acc: 66.30%\n",
      "Epoch: 4806,     Training Loss: 0.3679746985435486, Training Acc: 73.85%\n",
      "              Val Loss: 0.9560222625732422, Val Acc: 66.30%\n",
      "Epoch: 4807,     Training Loss: 0.3690616488456726, Training Acc: 73.86%\n",
      "              Val Loss: 0.976900577545166, Val Acc: 66.30%\n",
      "Epoch: 4808,     Training Loss: 0.36849862337112427, Training Acc: 73.86%\n",
      "              Val Loss: 0.9808701872825623, Val Acc: 66.30%\n",
      "Epoch: 4809,     Training Loss: 0.3835003674030304, Training Acc: 73.86%\n",
      "              Val Loss: 0.9658641219139099, Val Acc: 66.30%\n",
      "Epoch: 4810,     Training Loss: 0.3683219254016876, Training Acc: 73.86%\n",
      "              Val Loss: 0.956284761428833, Val Acc: 66.30%\n",
      "Epoch: 4811,     Training Loss: 0.3593592941761017, Training Acc: 73.86%\n",
      "              Val Loss: 0.9670157432556152, Val Acc: 66.30%\n",
      "Epoch: 4812,     Training Loss: 0.33779415488243103, Training Acc: 73.87%\n",
      "              Val Loss: 0.9856158494949341, Val Acc: 66.31%\n",
      "Epoch: 4813,     Training Loss: 0.35116568207740784, Training Acc: 73.87%\n",
      "              Val Loss: 0.9613516330718994, Val Acc: 66.31%\n",
      "Epoch: 4814,     Training Loss: 0.3395407795906067, Training Acc: 73.87%\n",
      "              Val Loss: 1.009594440460205, Val Acc: 66.31%\n",
      "Epoch: 4815,     Training Loss: 0.3649578094482422, Training Acc: 73.87%\n",
      "              Val Loss: 0.9828628301620483, Val Acc: 66.31%\n",
      "Epoch: 4816,     Training Loss: 0.38237738609313965, Training Acc: 73.88%\n",
      "              Val Loss: 0.987548828125, Val Acc: 66.31%\n",
      "Epoch: 4817,     Training Loss: 0.3813442587852478, Training Acc: 73.88%\n",
      "              Val Loss: 0.9872046113014221, Val Acc: 66.31%\n",
      "Epoch: 4818,     Training Loss: 0.3709298074245453, Training Acc: 73.88%\n",
      "              Val Loss: 0.9687739014625549, Val Acc: 66.31%\n",
      "Epoch: 4819,     Training Loss: 0.34158775210380554, Training Acc: 73.88%\n",
      "              Val Loss: 0.9690461754798889, Val Acc: 66.31%\n",
      "Epoch: 4820,     Training Loss: 0.3424195945262909, Training Acc: 73.88%\n",
      "              Val Loss: 1.0189034938812256, Val Acc: 66.31%\n",
      "Epoch: 4821,     Training Loss: 0.3647627532482147, Training Acc: 73.89%\n",
      "              Val Loss: 0.9893583059310913, Val Acc: 66.32%\n",
      "Epoch: 4822,     Training Loss: 0.3731380105018616, Training Acc: 73.89%\n",
      "              Val Loss: 1.0342403650283813, Val Acc: 66.32%\n",
      "Epoch: 4823,     Training Loss: 0.48142021894454956, Training Acc: 73.89%\n",
      "              Val Loss: 0.9918814897537231, Val Acc: 66.32%\n",
      "Epoch: 4824,     Training Loss: 0.38183143734931946, Training Acc: 73.89%\n",
      "              Val Loss: 0.9446963667869568, Val Acc: 66.32%\n",
      "Epoch: 4825,     Training Loss: 0.3353981673717499, Training Acc: 73.90%\n",
      "              Val Loss: 0.9672440886497498, Val Acc: 66.32%\n",
      "Epoch: 4826,     Training Loss: 0.36014190316200256, Training Acc: 73.90%\n",
      "              Val Loss: 1.0139516592025757, Val Acc: 66.32%\n",
      "Epoch: 4827,     Training Loss: 0.35898199677467346, Training Acc: 73.90%\n",
      "              Val Loss: 1.013779878616333, Val Acc: 66.32%\n",
      "Epoch: 4828,     Training Loss: 0.372183233499527, Training Acc: 73.90%\n",
      "              Val Loss: 0.9805540442466736, Val Acc: 66.32%\n",
      "Epoch: 4829,     Training Loss: 0.3662568926811218, Training Acc: 73.90%\n",
      "              Val Loss: 0.968720018863678, Val Acc: 66.32%\n",
      "Epoch: 4830,     Training Loss: 0.34128543734550476, Training Acc: 73.91%\n",
      "              Val Loss: 0.9605712294578552, Val Acc: 66.32%\n",
      "Epoch: 4831,     Training Loss: 0.3259931206703186, Training Acc: 73.91%\n",
      "              Val Loss: 0.9902303814888, Val Acc: 66.33%\n",
      "Epoch: 4832,     Training Loss: 0.35518181324005127, Training Acc: 73.91%\n",
      "              Val Loss: 1.0019248723983765, Val Acc: 66.33%\n",
      "Epoch: 4833,     Training Loss: 0.3589121699333191, Training Acc: 73.91%\n",
      "              Val Loss: 1.034013032913208, Val Acc: 66.33%\n",
      "Epoch: 4834,     Training Loss: 0.3800717890262604, Training Acc: 73.92%\n",
      "              Val Loss: 1.0413914918899536, Val Acc: 66.33%\n",
      "Epoch: 4835,     Training Loss: 0.4350701570510864, Training Acc: 73.92%\n",
      "              Val Loss: 0.9986853003501892, Val Acc: 66.33%\n",
      "Epoch: 4836,     Training Loss: 0.36825811862945557, Training Acc: 73.92%\n",
      "              Val Loss: 0.9548647403717041, Val Acc: 66.33%\n",
      "Epoch: 4837,     Training Loss: 0.3374703526496887, Training Acc: 73.92%\n",
      "              Val Loss: 0.9667422771453857, Val Acc: 66.33%\n",
      "Epoch: 4838,     Training Loss: 0.3551695942878723, Training Acc: 73.92%\n",
      "              Val Loss: 1.0070106983184814, Val Acc: 66.33%\n",
      "Epoch: 4839,     Training Loss: 0.35548362135887146, Training Acc: 73.93%\n",
      "              Val Loss: 0.9711728692054749, Val Acc: 66.33%\n",
      "Epoch: 4840,     Training Loss: 0.340218722820282, Training Acc: 73.93%\n",
      "              Val Loss: 0.9704486131668091, Val Acc: 66.33%\n",
      "Epoch: 4841,     Training Loss: 0.3373289108276367, Training Acc: 73.93%\n",
      "              Val Loss: 0.9469419121742249, Val Acc: 66.34%\n",
      "Epoch: 4842,     Training Loss: 0.32180142402648926, Training Acc: 73.93%\n",
      "              Val Loss: 0.9605185985565186, Val Acc: 66.34%\n",
      "Epoch: 4843,     Training Loss: 0.34428223967552185, Training Acc: 73.94%\n",
      "              Val Loss: 0.9536265730857849, Val Acc: 66.34%\n",
      "Epoch: 4844,     Training Loss: 0.3342839777469635, Training Acc: 73.94%\n",
      "              Val Loss: 0.9650595784187317, Val Acc: 66.34%\n",
      "Epoch: 4845,     Training Loss: 0.3380056321620941, Training Acc: 73.94%\n",
      "              Val Loss: 0.960237979888916, Val Acc: 66.34%\n",
      "Epoch: 4846,     Training Loss: 0.3209036588668823, Training Acc: 73.94%\n",
      "              Val Loss: 0.9641323685646057, Val Acc: 66.34%\n",
      "Epoch: 4847,     Training Loss: 0.3322317600250244, Training Acc: 73.95%\n",
      "              Val Loss: 0.9545904397964478, Val Acc: 66.34%\n",
      "Epoch: 4848,     Training Loss: 0.31290045380592346, Training Acc: 73.95%\n",
      "              Val Loss: 0.958678662776947, Val Acc: 66.35%\n",
      "Epoch: 4849,     Training Loss: 0.32240158319473267, Training Acc: 73.95%\n",
      "              Val Loss: 0.937666118144989, Val Acc: 66.35%\n",
      "Epoch: 4850,     Training Loss: 0.3189663887023926, Training Acc: 73.95%\n",
      "              Val Loss: 0.9853412508964539, Val Acc: 66.35%\n",
      "Epoch: 4851,     Training Loss: 0.3419136106967926, Training Acc: 73.96%\n",
      "              Val Loss: 1.0031943321228027, Val Acc: 66.35%\n",
      "Epoch: 4852,     Training Loss: 0.3810923397541046, Training Acc: 73.96%\n",
      "              Val Loss: 1.0204598903656006, Val Acc: 66.35%\n",
      "Epoch: 4853,     Training Loss: 0.36132898926734924, Training Acc: 73.96%\n",
      "              Val Loss: 0.9970994591712952, Val Acc: 66.35%\n",
      "Epoch: 4854,     Training Loss: 0.3550112247467041, Training Acc: 73.96%\n",
      "              Val Loss: 0.9677555561065674, Val Acc: 66.35%\n",
      "Epoch: 4855,     Training Loss: 0.3293803930282593, Training Acc: 73.97%\n",
      "              Val Loss: 0.9689734578132629, Val Acc: 66.35%\n",
      "Epoch: 4856,     Training Loss: 0.32901835441589355, Training Acc: 73.97%\n",
      "              Val Loss: 0.9635154008865356, Val Acc: 66.35%\n",
      "Epoch: 4857,     Training Loss: 0.3342711627483368, Training Acc: 73.97%\n",
      "              Val Loss: 0.97989821434021, Val Acc: 66.36%\n",
      "Epoch: 4858,     Training Loss: 0.3378772437572479, Training Acc: 73.97%\n",
      "              Val Loss: 0.9637066125869751, Val Acc: 66.36%\n",
      "Epoch: 4859,     Training Loss: 0.319476455450058, Training Acc: 73.98%\n",
      "              Val Loss: 0.9765385389328003, Val Acc: 66.36%\n",
      "Epoch: 4860,     Training Loss: 0.32448574900627136, Training Acc: 73.98%\n",
      "              Val Loss: 0.952271044254303, Val Acc: 66.36%\n",
      "Epoch: 4861,     Training Loss: 0.3193114101886749, Training Acc: 73.98%\n",
      "              Val Loss: 0.9686825275421143, Val Acc: 66.36%\n",
      "Epoch: 4862,     Training Loss: 0.3229050040245056, Training Acc: 73.98%\n",
      "              Val Loss: 0.9651557207107544, Val Acc: 66.36%\n",
      "Epoch: 4863,     Training Loss: 0.32709240913391113, Training Acc: 73.99%\n",
      "              Val Loss: 0.9885274767875671, Val Acc: 66.36%\n",
      "Epoch: 4864,     Training Loss: 0.3270118832588196, Training Acc: 73.99%\n",
      "              Val Loss: 1.0014766454696655, Val Acc: 66.36%\n",
      "Epoch: 4865,     Training Loss: 0.35273855924606323, Training Acc: 73.99%\n",
      "              Val Loss: 1.021816611289978, Val Acc: 66.36%\n",
      "Epoch: 4866,     Training Loss: 0.3671354651451111, Training Acc: 73.99%\n",
      "              Val Loss: 1.080118179321289, Val Acc: 66.36%\n",
      "Epoch: 4867,     Training Loss: 0.46148380637168884, Training Acc: 73.99%\n",
      "              Val Loss: 1.011206030845642, Val Acc: 66.37%\n",
      "Epoch: 4868,     Training Loss: 0.3697277307510376, Training Acc: 74.00%\n",
      "              Val Loss: 0.9599940776824951, Val Acc: 66.37%\n",
      "Epoch: 4869,     Training Loss: 0.33179837465286255, Training Acc: 74.00%\n",
      "              Val Loss: 0.9981653690338135, Val Acc: 66.37%\n",
      "Epoch: 4870,     Training Loss: 0.36261358857154846, Training Acc: 74.00%\n",
      "              Val Loss: 1.0385111570358276, Val Acc: 66.37%\n",
      "Epoch: 4871,     Training Loss: 0.3778829872608185, Training Acc: 74.00%\n",
      "              Val Loss: 0.9717071056365967, Val Acc: 66.37%\n",
      "Epoch: 4872,     Training Loss: 0.34560516476631165, Training Acc: 74.00%\n",
      "              Val Loss: 1.0386260747909546, Val Acc: 66.37%\n",
      "Epoch: 4873,     Training Loss: 0.3777690529823303, Training Acc: 74.01%\n",
      "              Val Loss: 1.0497182607650757, Val Acc: 66.37%\n",
      "Epoch: 4874,     Training Loss: 0.4377385377883911, Training Acc: 74.01%\n",
      "              Val Loss: 0.9643540978431702, Val Acc: 66.37%\n",
      "Epoch: 4875,     Training Loss: 0.3700980246067047, Training Acc: 74.01%\n",
      "              Val Loss: 1.0370666980743408, Val Acc: 66.37%\n",
      "Epoch: 4876,     Training Loss: 0.39918965101242065, Training Acc: 74.01%\n",
      "              Val Loss: 1.0027663707733154, Val Acc: 66.37%\n",
      "Epoch: 4877,     Training Loss: 0.3743628263473511, Training Acc: 74.01%\n",
      "              Val Loss: 0.9974120259284973, Val Acc: 66.38%\n",
      "Epoch: 4878,     Training Loss: 0.35594794154167175, Training Acc: 74.02%\n",
      "              Val Loss: 1.0159478187561035, Val Acc: 66.38%\n",
      "Epoch: 4879,     Training Loss: 0.37532421946525574, Training Acc: 74.02%\n",
      "              Val Loss: 0.9435752630233765, Val Acc: 66.38%\n",
      "Epoch: 4880,     Training Loss: 0.3386188745498657, Training Acc: 74.02%\n",
      "              Val Loss: 1.0114359855651855, Val Acc: 66.38%\n",
      "Epoch: 4881,     Training Loss: 0.4099714159965515, Training Acc: 74.02%\n",
      "              Val Loss: 1.0697612762451172, Val Acc: 66.38%\n",
      "Epoch: 4882,     Training Loss: 0.4929232895374298, Training Acc: 74.02%\n",
      "              Val Loss: 1.1059222221374512, Val Acc: 66.38%\n",
      "Epoch: 4883,     Training Loss: 0.483911395072937, Training Acc: 74.02%\n",
      "              Val Loss: 1.0554707050323486, Val Acc: 66.38%\n",
      "Epoch: 4884,     Training Loss: 0.4611087143421173, Training Acc: 74.03%\n",
      "              Val Loss: 1.0693347454071045, Val Acc: 66.38%\n",
      "Epoch: 4885,     Training Loss: 0.400887668132782, Training Acc: 74.03%\n",
      "              Val Loss: 1.1115132570266724, Val Acc: 66.38%\n",
      "Epoch: 4886,     Training Loss: 0.4390391409397125, Training Acc: 74.03%\n",
      "              Val Loss: 1.2037161588668823, Val Acc: 66.38%\n",
      "Epoch: 4887,     Training Loss: 0.6186524033546448, Training Acc: 74.03%\n",
      "              Val Loss: 0.9746505618095398, Val Acc: 66.38%\n",
      "Epoch: 4888,     Training Loss: 0.3651472330093384, Training Acc: 74.03%\n",
      "              Val Loss: 1.1751619577407837, Val Acc: 66.38%\n",
      "Epoch: 4889,     Training Loss: 0.5432122349739075, Training Acc: 74.03%\n",
      "              Val Loss: 1.3337740898132324, Val Acc: 66.38%\n",
      "Epoch: 4890,     Training Loss: 0.7646554708480835, Training Acc: 74.03%\n",
      "              Val Loss: 1.040725588798523, Val Acc: 66.38%\n",
      "Epoch: 4891,     Training Loss: 0.4250086843967438, Training Acc: 74.03%\n",
      "              Val Loss: 1.6295608282089233, Val Acc: 66.38%\n",
      "Epoch: 4892,     Training Loss: 0.9355618953704834, Training Acc: 74.03%\n",
      "              Val Loss: 1.9243898391723633, Val Acc: 66.38%\n",
      "Epoch: 4893,     Training Loss: 1.3738878965377808, Training Acc: 74.03%\n",
      "              Val Loss: 1.6754772663116455, Val Acc: 66.37%\n",
      "Epoch: 4894,     Training Loss: 1.2463477849960327, Training Acc: 74.02%\n",
      "              Val Loss: 1.3481271266937256, Val Acc: 66.37%\n",
      "Epoch: 4895,     Training Loss: 0.8450685143470764, Training Acc: 74.02%\n",
      "              Val Loss: 1.3569560050964355, Val Acc: 66.37%\n",
      "Epoch: 4896,     Training Loss: 0.8347686529159546, Training Acc: 74.02%\n",
      "              Val Loss: 1.4035730361938477, Val Acc: 66.37%\n",
      "Epoch: 4897,     Training Loss: 0.8792352080345154, Training Acc: 74.02%\n",
      "              Val Loss: 1.4526758193969727, Val Acc: 66.37%\n",
      "Epoch: 4898,     Training Loss: 0.9000549912452698, Training Acc: 74.02%\n",
      "              Val Loss: 1.1322318315505981, Val Acc: 66.37%\n",
      "Epoch: 4899,     Training Loss: 0.6269109845161438, Training Acc: 74.02%\n",
      "              Val Loss: 1.3245117664337158, Val Acc: 66.37%\n",
      "Epoch: 4900,     Training Loss: 0.8683956861495972, Training Acc: 74.02%\n",
      "              Val Loss: 1.0698305368423462, Val Acc: 66.37%\n",
      "Epoch: 4901,     Training Loss: 0.6207062602043152, Training Acc: 74.02%\n",
      "              Val Loss: 1.1083838939666748, Val Acc: 66.37%\n",
      "Epoch: 4902,     Training Loss: 0.649696409702301, Training Acc: 74.02%\n",
      "              Val Loss: 1.154441475868225, Val Acc: 66.37%\n",
      "Epoch: 4903,     Training Loss: 0.669455349445343, Training Acc: 74.02%\n",
      "              Val Loss: 1.0948140621185303, Val Acc: 66.37%\n",
      "Epoch: 4904,     Training Loss: 0.6197090148925781, Training Acc: 74.02%\n",
      "              Val Loss: 1.07581627368927, Val Acc: 66.37%\n",
      "Epoch: 4905,     Training Loss: 0.6161710619926453, Training Acc: 74.02%\n",
      "              Val Loss: 0.9820690751075745, Val Acc: 66.37%\n",
      "Epoch: 4906,     Training Loss: 0.5447196364402771, Training Acc: 74.02%\n",
      "              Val Loss: 1.000983476638794, Val Acc: 66.37%\n",
      "Epoch: 4907,     Training Loss: 0.6020331382751465, Training Acc: 74.02%\n",
      "              Val Loss: 0.9681704044342041, Val Acc: 66.37%\n",
      "Epoch: 4908,     Training Loss: 0.5577328205108643, Training Acc: 74.02%\n",
      "              Val Loss: 0.9537326097488403, Val Acc: 66.37%\n",
      "Epoch: 4909,     Training Loss: 0.5159797072410583, Training Acc: 74.02%\n",
      "              Val Loss: 1.029125690460205, Val Acc: 66.37%\n",
      "Epoch: 4910,     Training Loss: 0.5625362992286682, Training Acc: 74.02%\n",
      "              Val Loss: 0.9639778733253479, Val Acc: 66.37%\n",
      "Epoch: 4911,     Training Loss: 0.4930173456668854, Training Acc: 74.02%\n",
      "              Val Loss: 0.9779287576675415, Val Acc: 66.37%\n",
      "Epoch: 4912,     Training Loss: 0.5131533145904541, Training Acc: 74.02%\n",
      "              Val Loss: 0.9271595478057861, Val Acc: 66.37%\n",
      "Epoch: 4913,     Training Loss: 0.47991669178009033, Training Acc: 74.02%\n",
      "              Val Loss: 0.9211701154708862, Val Acc: 66.37%\n",
      "Epoch: 4914,     Training Loss: 0.4731168746948242, Training Acc: 74.02%\n",
      "              Val Loss: 0.9011660218238831, Val Acc: 66.37%\n",
      "Epoch: 4915,     Training Loss: 0.4600231945514679, Training Acc: 74.02%\n",
      "              Val Loss: 0.892168402671814, Val Acc: 66.37%\n",
      "Epoch: 4916,     Training Loss: 0.4317491948604584, Training Acc: 74.03%\n",
      "              Val Loss: 0.9548497200012207, Val Acc: 66.37%\n",
      "Epoch: 4917,     Training Loss: 0.4473305642604828, Training Acc: 74.03%\n",
      "              Val Loss: 0.9336681365966797, Val Acc: 66.38%\n",
      "Epoch: 4918,     Training Loss: 0.4142001271247864, Training Acc: 74.03%\n",
      "              Val Loss: 0.9624821543693542, Val Acc: 66.38%\n",
      "Epoch: 4919,     Training Loss: 0.42886799573898315, Training Acc: 74.03%\n",
      "              Val Loss: 0.9306724667549133, Val Acc: 66.38%\n",
      "Epoch: 4920,     Training Loss: 0.3986319303512573, Training Acc: 74.03%\n",
      "              Val Loss: 0.9529163241386414, Val Acc: 66.38%\n",
      "Epoch: 4921,     Training Loss: 0.4074167013168335, Training Acc: 74.04%\n",
      "              Val Loss: 0.933737576007843, Val Acc: 66.38%\n",
      "Epoch: 4922,     Training Loss: 0.3884964883327484, Training Acc: 74.04%\n",
      "              Val Loss: 0.9380683302879333, Val Acc: 66.38%\n",
      "Epoch: 4923,     Training Loss: 0.3933238685131073, Training Acc: 74.04%\n",
      "              Val Loss: 0.9480195045471191, Val Acc: 66.38%\n",
      "Epoch: 4924,     Training Loss: 0.3736846148967743, Training Acc: 74.04%\n",
      "              Val Loss: 0.9704483151435852, Val Acc: 66.38%\n",
      "Epoch: 4925,     Training Loss: 0.378770649433136, Training Acc: 74.04%\n",
      "              Val Loss: 0.953438937664032, Val Acc: 66.38%\n",
      "Epoch: 4926,     Training Loss: 0.36964404582977295, Training Acc: 74.05%\n",
      "              Val Loss: 0.9604608416557312, Val Acc: 66.38%\n",
      "Epoch: 4927,     Training Loss: 0.3676511347293854, Training Acc: 74.05%\n",
      "              Val Loss: 0.9978513121604919, Val Acc: 66.39%\n",
      "Epoch: 4928,     Training Loss: 0.36735865473747253, Training Acc: 74.05%\n",
      "              Val Loss: 0.9827457666397095, Val Acc: 66.39%\n",
      "Epoch: 4929,     Training Loss: 0.36251139640808105, Training Acc: 74.05%\n",
      "              Val Loss: 0.9766685962677002, Val Acc: 66.39%\n",
      "Epoch: 4930,     Training Loss: 0.3687423765659332, Training Acc: 74.05%\n",
      "              Val Loss: 0.9734113812446594, Val Acc: 66.39%\n",
      "Epoch: 4931,     Training Loss: 0.35010042786598206, Training Acc: 74.06%\n",
      "              Val Loss: 0.983094334602356, Val Acc: 66.39%\n",
      "Epoch: 4932,     Training Loss: 0.3544068932533264, Training Acc: 74.06%\n",
      "              Val Loss: 0.9714162945747375, Val Acc: 66.39%\n",
      "Epoch: 4933,     Training Loss: 0.3626565635204315, Training Acc: 74.06%\n",
      "              Val Loss: 0.9627446532249451, Val Acc: 66.39%\n",
      "Epoch: 4934,     Training Loss: 0.35866856575012207, Training Acc: 74.06%\n",
      "              Val Loss: 0.9579070806503296, Val Acc: 66.39%\n",
      "Epoch: 4935,     Training Loss: 0.34446612000465393, Training Acc: 74.07%\n",
      "              Val Loss: 0.9610522389411926, Val Acc: 66.39%\n",
      "Epoch: 4936,     Training Loss: 0.34418946504592896, Training Acc: 74.07%\n",
      "              Val Loss: 0.9496745467185974, Val Acc: 66.40%\n",
      "Epoch: 4937,     Training Loss: 0.3473562002182007, Training Acc: 74.07%\n",
      "              Val Loss: 0.9571437835693359, Val Acc: 66.40%\n",
      "Epoch: 4938,     Training Loss: 0.3507940173149109, Training Acc: 74.07%\n",
      "              Val Loss: 0.9686495065689087, Val Acc: 66.40%\n",
      "Epoch: 4939,     Training Loss: 0.34333136677742004, Training Acc: 74.08%\n",
      "              Val Loss: 0.9497231841087341, Val Acc: 66.40%\n",
      "Epoch: 4940,     Training Loss: 0.33463919162750244, Training Acc: 74.08%\n",
      "              Val Loss: 0.938814640045166, Val Acc: 66.40%\n",
      "Epoch: 4941,     Training Loss: 0.33556076884269714, Training Acc: 74.08%\n",
      "              Val Loss: 0.9473223090171814, Val Acc: 66.40%\n",
      "Epoch: 4942,     Training Loss: 0.33527636528015137, Training Acc: 74.08%\n",
      "              Val Loss: 0.9555870890617371, Val Acc: 66.40%\n",
      "Epoch: 4943,     Training Loss: 0.3383232355117798, Training Acc: 74.09%\n",
      "              Val Loss: 0.9431277513504028, Val Acc: 66.40%\n",
      "Epoch: 4944,     Training Loss: 0.34194791316986084, Training Acc: 74.09%\n",
      "              Val Loss: 0.9447370171546936, Val Acc: 66.41%\n",
      "Epoch: 4945,     Training Loss: 0.33341121673583984, Training Acc: 74.09%\n",
      "              Val Loss: 0.956483006477356, Val Acc: 66.41%\n",
      "Epoch: 4946,     Training Loss: 0.3330180048942566, Training Acc: 74.09%\n",
      "              Val Loss: 0.9352689385414124, Val Acc: 66.41%\n",
      "Epoch: 4947,     Training Loss: 0.3276216387748718, Training Acc: 74.10%\n",
      "              Val Loss: 0.9370850920677185, Val Acc: 66.41%\n",
      "Epoch: 4948,     Training Loss: 0.3249669373035431, Training Acc: 74.10%\n",
      "              Val Loss: 0.960703432559967, Val Acc: 66.41%\n",
      "Epoch: 4949,     Training Loss: 0.33123674988746643, Training Acc: 74.10%\n",
      "              Val Loss: 0.942716121673584, Val Acc: 66.41%\n",
      "Epoch: 4950,     Training Loss: 0.3288748562335968, Training Acc: 74.10%\n",
      "              Val Loss: 0.9461866021156311, Val Acc: 66.41%\n",
      "Epoch: 4951,     Training Loss: 0.3270014822483063, Training Acc: 74.11%\n",
      "              Val Loss: 0.9688357710838318, Val Acc: 66.41%\n",
      "Epoch: 4952,     Training Loss: 0.33182400465011597, Training Acc: 74.11%\n",
      "              Val Loss: 0.9485484957695007, Val Acc: 66.42%\n",
      "Epoch: 4953,     Training Loss: 0.32743412256240845, Training Acc: 74.11%\n",
      "              Val Loss: 0.9461377859115601, Val Acc: 66.42%\n",
      "Epoch: 4954,     Training Loss: 0.33192241191864014, Training Acc: 74.11%\n",
      "              Val Loss: 0.9538652896881104, Val Acc: 66.42%\n",
      "Epoch: 4955,     Training Loss: 0.3251423239707947, Training Acc: 74.12%\n",
      "              Val Loss: 0.9479970335960388, Val Acc: 66.42%\n",
      "Epoch: 4956,     Training Loss: 0.3215197026729584, Training Acc: 74.12%\n",
      "              Val Loss: 0.938513994216919, Val Acc: 66.42%\n",
      "Epoch: 4957,     Training Loss: 0.32255563139915466, Training Acc: 74.12%\n",
      "              Val Loss: 0.9414819478988647, Val Acc: 66.42%\n",
      "Epoch: 4958,     Training Loss: 0.31815123558044434, Training Acc: 74.12%\n",
      "              Val Loss: 0.9458874464035034, Val Acc: 66.42%\n",
      "Epoch: 4959,     Training Loss: 0.31884562969207764, Training Acc: 74.13%\n",
      "              Val Loss: 0.9340525269508362, Val Acc: 66.43%\n",
      "Epoch: 4960,     Training Loss: 0.3196001946926117, Training Acc: 74.13%\n",
      "              Val Loss: 0.9392586350440979, Val Acc: 66.43%\n",
      "Epoch: 4961,     Training Loss: 0.31690630316734314, Training Acc: 74.13%\n",
      "              Val Loss: 0.9562833309173584, Val Acc: 66.43%\n",
      "Epoch: 4962,     Training Loss: 0.3214547634124756, Training Acc: 74.13%\n",
      "              Val Loss: 0.9485313892364502, Val Acc: 66.43%\n",
      "Epoch: 4963,     Training Loss: 0.3237515985965729, Training Acc: 74.14%\n",
      "              Val Loss: 0.9565941095352173, Val Acc: 66.43%\n",
      "Epoch: 4964,     Training Loss: 0.3281167149543762, Training Acc: 74.14%\n",
      "              Val Loss: 0.9809191226959229, Val Acc: 66.43%\n",
      "Epoch: 4965,     Training Loss: 0.34848541021347046, Training Acc: 74.14%\n",
      "              Val Loss: 0.9666008949279785, Val Acc: 66.43%\n",
      "Epoch: 4966,     Training Loss: 0.34715259075164795, Training Acc: 74.14%\n",
      "              Val Loss: 0.9627342224121094, Val Acc: 66.43%\n",
      "Epoch: 4967,     Training Loss: 0.3489631712436676, Training Acc: 74.15%\n",
      "              Val Loss: 0.9613668322563171, Val Acc: 66.43%\n",
      "Epoch: 4968,     Training Loss: 0.32380786538124084, Training Acc: 74.15%\n",
      "              Val Loss: 0.9542086720466614, Val Acc: 66.44%\n",
      "Epoch: 4969,     Training Loss: 0.32336893677711487, Training Acc: 74.15%\n",
      "              Val Loss: 0.9790370464324951, Val Acc: 66.44%\n",
      "Epoch: 4970,     Training Loss: 0.3543216586112976, Training Acc: 74.15%\n",
      "              Val Loss: 0.9706052541732788, Val Acc: 66.44%\n",
      "Epoch: 4971,     Training Loss: 0.33043113350868225, Training Acc: 74.16%\n",
      "              Val Loss: 0.9541996717453003, Val Acc: 66.44%\n",
      "Epoch: 4972,     Training Loss: 0.31801438331604004, Training Acc: 74.16%\n",
      "              Val Loss: 0.9413150548934937, Val Acc: 66.44%\n",
      "Epoch: 4973,     Training Loss: 0.31656813621520996, Training Acc: 74.16%\n",
      "              Val Loss: 0.9565020799636841, Val Acc: 66.44%\n",
      "Epoch: 4974,     Training Loss: 0.32188594341278076, Training Acc: 74.16%\n",
      "              Val Loss: 0.9788542985916138, Val Acc: 66.44%\n",
      "Epoch: 4975,     Training Loss: 0.33992838859558105, Training Acc: 74.17%\n",
      "              Val Loss: 0.9798756241798401, Val Acc: 66.44%\n",
      "Epoch: 4976,     Training Loss: 0.34517738223075867, Training Acc: 74.17%\n",
      "              Val Loss: 1.0007836818695068, Val Acc: 66.44%\n",
      "Epoch: 4977,     Training Loss: 0.3561915457248688, Training Acc: 74.17%\n",
      "              Val Loss: 0.9726894497871399, Val Acc: 66.45%\n",
      "Epoch: 4978,     Training Loss: 0.32540974020957947, Training Acc: 74.17%\n",
      "              Val Loss: 0.9601663947105408, Val Acc: 66.45%\n",
      "Epoch: 4979,     Training Loss: 0.31440412998199463, Training Acc: 74.18%\n",
      "              Val Loss: 0.970028817653656, Val Acc: 66.45%\n",
      "Epoch: 4980,     Training Loss: 0.3195037543773651, Training Acc: 74.18%\n",
      "              Val Loss: 0.9864051938056946, Val Acc: 66.45%\n",
      "Epoch: 4981,     Training Loss: 0.3337695300579071, Training Acc: 74.18%\n",
      "              Val Loss: 1.0029985904693604, Val Acc: 66.45%\n",
      "Epoch: 4982,     Training Loss: 0.36301395297050476, Training Acc: 74.18%\n",
      "              Val Loss: 0.9788262844085693, Val Acc: 66.45%\n",
      "Epoch: 4983,     Training Loss: 0.3278855085372925, Training Acc: 74.18%\n",
      "              Val Loss: 0.9724373817443848, Val Acc: 66.45%\n",
      "Epoch: 4984,     Training Loss: 0.3157578706741333, Training Acc: 74.19%\n",
      "              Val Loss: 0.9679145812988281, Val Acc: 66.45%\n",
      "Epoch: 4985,     Training Loss: 0.3255655765533447, Training Acc: 74.19%\n",
      "              Val Loss: 0.9931458234786987, Val Acc: 66.45%\n",
      "Epoch: 4986,     Training Loss: 0.3354148864746094, Training Acc: 74.19%\n",
      "              Val Loss: 1.0037955045700073, Val Acc: 66.46%\n",
      "Epoch: 4987,     Training Loss: 0.34865954518318176, Training Acc: 74.19%\n",
      "              Val Loss: 0.9854587316513062, Val Acc: 66.46%\n",
      "Epoch: 4988,     Training Loss: 0.33449774980545044, Training Acc: 74.20%\n",
      "              Val Loss: 0.9753656983375549, Val Acc: 66.46%\n",
      "Epoch: 4989,     Training Loss: 0.31668004393577576, Training Acc: 74.20%\n",
      "              Val Loss: 0.9808387160301208, Val Acc: 66.46%\n",
      "Epoch: 4990,     Training Loss: 0.31328120827674866, Training Acc: 74.20%\n",
      "              Val Loss: 0.9813761711120605, Val Acc: 66.46%\n",
      "Epoch: 4991,     Training Loss: 0.3254074156284332, Training Acc: 74.20%\n",
      "              Val Loss: 0.9969747066497803, Val Acc: 66.46%\n",
      "Epoch: 4992,     Training Loss: 0.3489547669887543, Training Acc: 74.21%\n",
      "              Val Loss: 0.9994149208068848, Val Acc: 66.46%\n",
      "Epoch: 4993,     Training Loss: 0.34562355279922485, Training Acc: 74.21%\n",
      "              Val Loss: 1.0025479793548584, Val Acc: 66.46%\n",
      "Epoch: 4994,     Training Loss: 0.358218789100647, Training Acc: 74.21%\n",
      "              Val Loss: 0.9737917184829712, Val Acc: 66.46%\n",
      "Epoch: 4995,     Training Loss: 0.31916362047195435, Training Acc: 74.21%\n",
      "              Val Loss: 1.012394905090332, Val Acc: 66.46%\n",
      "Epoch: 4996,     Training Loss: 0.3328678011894226, Training Acc: 74.22%\n",
      "              Val Loss: 1.0276284217834473, Val Acc: 66.47%\n",
      "Epoch: 4997,     Training Loss: 0.37450936436653137, Training Acc: 74.22%\n",
      "              Val Loss: 0.9987344145774841, Val Acc: 66.47%\n",
      "Epoch: 4998,     Training Loss: 0.3422219157218933, Training Acc: 74.22%\n",
      "              Val Loss: 0.9809221029281616, Val Acc: 66.47%\n",
      "Epoch: 4999,     Training Loss: 0.32293304800987244, Training Acc: 74.22%\n",
      "              Val Loss: 0.9570434093475342, Val Acc: 66.47%\n",
      "Epoch: 5000,     Training Loss: 0.31536561250686646, Training Acc: 74.23%\n",
      "              Val Loss: 0.9686893224716187, Val Acc: 66.47%\n",
      "Epoch: 5001,     Training Loss: 0.3215619921684265, Training Acc: 74.23%\n",
      "              Val Loss: 1.0019004344940186, Val Acc: 66.47%\n",
      "Epoch: 5002,     Training Loss: 0.3355703353881836, Training Acc: 74.23%\n",
      "              Val Loss: 0.98586106300354, Val Acc: 66.47%\n",
      "Epoch: 5003,     Training Loss: 0.3298085331916809, Training Acc: 74.23%\n",
      "              Val Loss: 0.9849815368652344, Val Acc: 66.47%\n",
      "Epoch: 5004,     Training Loss: 0.3347425162792206, Training Acc: 74.23%\n",
      "              Val Loss: 0.9958553910255432, Val Acc: 66.47%\n",
      "Epoch: 5005,     Training Loss: 0.3254687488079071, Training Acc: 74.24%\n",
      "              Val Loss: 0.9666533470153809, Val Acc: 66.48%\n",
      "Epoch: 5006,     Training Loss: 0.3103535771369934, Training Acc: 74.24%\n",
      "              Val Loss: 0.9722900986671448, Val Acc: 66.48%\n",
      "Epoch: 5007,     Training Loss: 0.3113085925579071, Training Acc: 74.24%\n",
      "              Val Loss: 1.0055124759674072, Val Acc: 66.48%\n",
      "Epoch: 5008,     Training Loss: 0.32481619715690613, Training Acc: 74.25%\n",
      "              Val Loss: 0.9958646893501282, Val Acc: 66.48%\n",
      "Epoch: 5009,     Training Loss: 0.33919161558151245, Training Acc: 74.25%\n",
      "              Val Loss: 1.004463791847229, Val Acc: 66.48%\n",
      "Epoch: 5010,     Training Loss: 0.3373917043209076, Training Acc: 74.25%\n",
      "              Val Loss: 1.0251692533493042, Val Acc: 66.48%\n",
      "Epoch: 5011,     Training Loss: 0.348588228225708, Training Acc: 74.25%\n",
      "              Val Loss: 0.9947704076766968, Val Acc: 66.48%\n",
      "Epoch: 5012,     Training Loss: 0.3372344672679901, Training Acc: 74.25%\n",
      "              Val Loss: 0.9782471656799316, Val Acc: 66.48%\n",
      "Epoch: 5013,     Training Loss: 0.314646452665329, Training Acc: 74.26%\n",
      "              Val Loss: 1.0076489448547363, Val Acc: 66.48%\n",
      "Epoch: 5014,     Training Loss: 0.32192832231521606, Training Acc: 74.26%\n",
      "              Val Loss: 0.9842478036880493, Val Acc: 66.49%\n",
      "Epoch: 5015,     Training Loss: 0.3258916735649109, Training Acc: 74.26%\n",
      "              Val Loss: 0.9884744882583618, Val Acc: 66.49%\n",
      "Epoch: 5016,     Training Loss: 0.32558614015579224, Training Acc: 74.26%\n",
      "              Val Loss: 1.0300804376602173, Val Acc: 66.49%\n",
      "Epoch: 5017,     Training Loss: 0.34127962589263916, Training Acc: 74.27%\n",
      "              Val Loss: 1.002946138381958, Val Acc: 66.49%\n",
      "Epoch: 5018,     Training Loss: 0.3537959158420563, Training Acc: 74.27%\n",
      "              Val Loss: 0.999164342880249, Val Acc: 66.49%\n",
      "Epoch: 5019,     Training Loss: 0.33498045802116394, Training Acc: 74.27%\n",
      "              Val Loss: 1.0252517461776733, Val Acc: 66.49%\n",
      "Epoch: 5020,     Training Loss: 0.3504921793937683, Training Acc: 74.27%\n",
      "              Val Loss: 0.9853420853614807, Val Acc: 66.49%\n",
      "Epoch: 5021,     Training Loss: 0.3287970721721649, Training Acc: 74.28%\n",
      "              Val Loss: 0.9728025197982788, Val Acc: 66.49%\n",
      "Epoch: 5022,     Training Loss: 0.3139001131057739, Training Acc: 74.28%\n",
      "              Val Loss: 1.0102379322052002, Val Acc: 66.49%\n",
      "Epoch: 5023,     Training Loss: 0.3213330805301666, Training Acc: 74.28%\n",
      "              Val Loss: 0.9870670437812805, Val Acc: 66.49%\n",
      "Epoch: 5024,     Training Loss: 0.3143613934516907, Training Acc: 74.28%\n",
      "              Val Loss: 0.9887705445289612, Val Acc: 66.50%\n",
      "Epoch: 5025,     Training Loss: 0.32565173506736755, Training Acc: 74.29%\n",
      "              Val Loss: 1.0239906311035156, Val Acc: 66.50%\n",
      "Epoch: 5026,     Training Loss: 0.3392108976840973, Training Acc: 74.29%\n",
      "              Val Loss: 1.0164589881896973, Val Acc: 66.50%\n",
      "Epoch: 5027,     Training Loss: 0.36811983585357666, Training Acc: 74.29%\n",
      "              Val Loss: 0.986976146697998, Val Acc: 66.50%\n",
      "Epoch: 5028,     Training Loss: 0.3322933614253998, Training Acc: 74.29%\n",
      "              Val Loss: 1.0114524364471436, Val Acc: 66.50%\n",
      "Epoch: 5029,     Training Loss: 0.3251464366912842, Training Acc: 74.29%\n",
      "              Val Loss: 0.9842985272407532, Val Acc: 66.50%\n",
      "Epoch: 5030,     Training Loss: 0.32078105211257935, Training Acc: 74.30%\n",
      "              Val Loss: 1.011214017868042, Val Acc: 66.50%\n",
      "Epoch: 5031,     Training Loss: 0.3331775367259979, Training Acc: 74.30%\n",
      "              Val Loss: 1.052649974822998, Val Acc: 66.50%\n",
      "Epoch: 5032,     Training Loss: 0.3668696880340576, Training Acc: 74.30%\n",
      "              Val Loss: 1.009289264678955, Val Acc: 66.50%\n",
      "Epoch: 5033,     Training Loss: 0.34250420331954956, Training Acc: 74.30%\n",
      "              Val Loss: 0.9756462574005127, Val Acc: 66.50%\n",
      "Epoch: 5034,     Training Loss: 0.31801003217697144, Training Acc: 74.31%\n",
      "              Val Loss: 1.0055711269378662, Val Acc: 66.51%\n",
      "Epoch: 5035,     Training Loss: 0.32110926508903503, Training Acc: 74.31%\n",
      "              Val Loss: 0.9930713772773743, Val Acc: 66.51%\n",
      "Epoch: 5036,     Training Loss: 0.32454654574394226, Training Acc: 74.31%\n",
      "              Val Loss: 1.0041840076446533, Val Acc: 66.51%\n",
      "Epoch: 5037,     Training Loss: 0.34712183475494385, Training Acc: 74.31%\n",
      "              Val Loss: 1.031480073928833, Val Acc: 66.51%\n",
      "Epoch: 5038,     Training Loss: 0.34613746404647827, Training Acc: 74.32%\n",
      "              Val Loss: 1.0308496952056885, Val Acc: 66.51%\n",
      "Epoch: 5039,     Training Loss: 0.36588147282600403, Training Acc: 74.32%\n",
      "              Val Loss: 0.9990525245666504, Val Acc: 66.51%\n",
      "Epoch: 5040,     Training Loss: 0.33027827739715576, Training Acc: 74.32%\n",
      "              Val Loss: 1.0153355598449707, Val Acc: 66.51%\n",
      "Epoch: 5041,     Training Loss: 0.3216736614704132, Training Acc: 74.32%\n",
      "              Val Loss: 1.0093756914138794, Val Acc: 66.51%\n",
      "Epoch: 5042,     Training Loss: 0.34053337574005127, Training Acc: 74.32%\n",
      "              Val Loss: 1.010533332824707, Val Acc: 66.51%\n",
      "Epoch: 5043,     Training Loss: 0.34153926372528076, Training Acc: 74.33%\n",
      "              Val Loss: 1.0031397342681885, Val Acc: 66.51%\n",
      "Epoch: 5044,     Training Loss: 0.32709068059921265, Training Acc: 74.33%\n",
      "              Val Loss: 0.9884841442108154, Val Acc: 66.52%\n",
      "Epoch: 5045,     Training Loss: 0.310218870639801, Training Acc: 74.33%\n",
      "              Val Loss: 0.9909244775772095, Val Acc: 66.52%\n",
      "Epoch: 5046,     Training Loss: 0.31368178129196167, Training Acc: 74.33%\n",
      "              Val Loss: 1.0123172998428345, Val Acc: 66.52%\n",
      "Epoch: 5047,     Training Loss: 0.32181859016418457, Training Acc: 74.34%\n",
      "              Val Loss: 1.0303095579147339, Val Acc: 66.52%\n",
      "Epoch: 5048,     Training Loss: 0.34508511424064636, Training Acc: 74.34%\n",
      "              Val Loss: 1.0832091569900513, Val Acc: 66.52%\n",
      "Epoch: 5049,     Training Loss: 0.42781397700309753, Training Acc: 74.34%\n",
      "              Val Loss: 1.0438318252563477, Val Acc: 66.52%\n",
      "Epoch: 5050,     Training Loss: 0.3585922122001648, Training Acc: 74.34%\n",
      "              Val Loss: 1.0131046772003174, Val Acc: 66.52%\n",
      "Epoch: 5051,     Training Loss: 0.3282802700996399, Training Acc: 74.34%\n",
      "              Val Loss: 1.0376514196395874, Val Acc: 66.52%\n",
      "Epoch: 5052,     Training Loss: 0.3610183000564575, Training Acc: 74.35%\n",
      "              Val Loss: 1.083074688911438, Val Acc: 66.52%\n",
      "Epoch: 5053,     Training Loss: 0.37391021847724915, Training Acc: 74.35%\n",
      "              Val Loss: 1.0087575912475586, Val Acc: 66.52%\n",
      "Epoch: 5054,     Training Loss: 0.35388174653053284, Training Acc: 74.35%\n",
      "              Val Loss: 0.9978285431861877, Val Acc: 66.52%\n",
      "Epoch: 5055,     Training Loss: 0.33669835329055786, Training Acc: 74.35%\n",
      "              Val Loss: 1.0304383039474487, Val Acc: 66.52%\n",
      "Epoch: 5056,     Training Loss: 0.3447018563747406, Training Acc: 74.35%\n",
      "              Val Loss: 1.0033786296844482, Val Acc: 66.53%\n",
      "Epoch: 5057,     Training Loss: 0.34495317935943604, Training Acc: 74.36%\n",
      "              Val Loss: 1.0243375301361084, Val Acc: 66.53%\n",
      "Epoch: 5058,     Training Loss: 0.3418463170528412, Training Acc: 74.36%\n",
      "              Val Loss: 0.9878093004226685, Val Acc: 66.53%\n",
      "Epoch: 5059,     Training Loss: 0.3152428865432739, Training Acc: 74.36%\n",
      "              Val Loss: 0.9747176170349121, Val Acc: 66.53%\n",
      "Epoch: 5060,     Training Loss: 0.3190971612930298, Training Acc: 74.36%\n",
      "              Val Loss: 0.9767687320709229, Val Acc: 66.53%\n",
      "Epoch: 5061,     Training Loss: 0.31740516424179077, Training Acc: 74.37%\n",
      "              Val Loss: 0.9967220425605774, Val Acc: 66.53%\n",
      "Epoch: 5062,     Training Loss: 0.32209938764572144, Training Acc: 74.37%\n",
      "              Val Loss: 1.0037589073181152, Val Acc: 66.53%\n",
      "Epoch: 5063,     Training Loss: 0.31785935163497925, Training Acc: 74.37%\n",
      "              Val Loss: 1.011562466621399, Val Acc: 66.53%\n",
      "Epoch: 5064,     Training Loss: 0.3337400555610657, Training Acc: 74.37%\n",
      "              Val Loss: 1.017500638961792, Val Acc: 66.53%\n",
      "Epoch: 5065,     Training Loss: 0.34243279695510864, Training Acc: 74.38%\n",
      "              Val Loss: 1.032228946685791, Val Acc: 66.54%\n",
      "Epoch: 5066,     Training Loss: 0.3734102249145508, Training Acc: 74.38%\n",
      "              Val Loss: 0.998016893863678, Val Acc: 66.54%\n",
      "Epoch: 5067,     Training Loss: 0.335359126329422, Training Acc: 74.38%\n",
      "              Val Loss: 0.9823331236839294, Val Acc: 66.54%\n",
      "Epoch: 5068,     Training Loss: 0.30945315957069397, Training Acc: 74.38%\n",
      "              Val Loss: 1.0098929405212402, Val Acc: 66.54%\n",
      "Epoch: 5069,     Training Loss: 0.3294254243373871, Training Acc: 74.38%\n",
      "              Val Loss: 1.0347247123718262, Val Acc: 66.54%\n",
      "Epoch: 5070,     Training Loss: 0.3427051603794098, Training Acc: 74.39%\n",
      "              Val Loss: 1.045761227607727, Val Acc: 66.54%\n",
      "Epoch: 5071,     Training Loss: 0.3823011517524719, Training Acc: 74.39%\n",
      "              Val Loss: 1.0119736194610596, Val Acc: 66.54%\n",
      "Epoch: 5072,     Training Loss: 0.3358823359012604, Training Acc: 74.39%\n",
      "              Val Loss: 0.9864782691001892, Val Acc: 66.54%\n",
      "Epoch: 5073,     Training Loss: 0.31323203444480896, Training Acc: 74.39%\n",
      "              Val Loss: 0.9876978397369385, Val Acc: 66.54%\n",
      "Epoch: 5074,     Training Loss: 0.3336353302001953, Training Acc: 74.40%\n",
      "              Val Loss: 1.0355483293533325, Val Acc: 66.54%\n",
      "Epoch: 5075,     Training Loss: 0.34846895933151245, Training Acc: 74.40%\n",
      "              Val Loss: 1.040140151977539, Val Acc: 66.54%\n",
      "Epoch: 5076,     Training Loss: 0.3755537271499634, Training Acc: 74.40%\n",
      "              Val Loss: 1.0210884809494019, Val Acc: 66.55%\n",
      "Epoch: 5077,     Training Loss: 0.34753209352493286, Training Acc: 74.40%\n",
      "              Val Loss: 1.0129047632217407, Val Acc: 66.55%\n",
      "Epoch: 5078,     Training Loss: 0.32105663418769836, Training Acc: 74.40%\n",
      "              Val Loss: 1.0018199682235718, Val Acc: 66.55%\n",
      "Epoch: 5079,     Training Loss: 0.31800365447998047, Training Acc: 74.41%\n",
      "              Val Loss: 1.04087233543396, Val Acc: 66.55%\n",
      "Epoch: 5080,     Training Loss: 0.33618590235710144, Training Acc: 74.41%\n",
      "              Val Loss: 1.0469462871551514, Val Acc: 66.55%\n",
      "Epoch: 5081,     Training Loss: 0.35937267541885376, Training Acc: 74.41%\n",
      "              Val Loss: 1.008670449256897, Val Acc: 66.55%\n",
      "Epoch: 5082,     Training Loss: 0.34080228209495544, Training Acc: 74.41%\n",
      "              Val Loss: 0.9899466037750244, Val Acc: 66.55%\n",
      "Epoch: 5083,     Training Loss: 0.31631582975387573, Training Acc: 74.42%\n",
      "              Val Loss: 1.0219372510910034, Val Acc: 66.55%\n",
      "Epoch: 5084,     Training Loss: 0.32083916664123535, Training Acc: 74.42%\n",
      "              Val Loss: 1.0398354530334473, Val Acc: 66.55%\n",
      "Epoch: 5085,     Training Loss: 0.343199759721756, Training Acc: 74.42%\n",
      "              Val Loss: 1.0526206493377686, Val Acc: 66.55%\n",
      "Epoch: 5086,     Training Loss: 0.3536643087863922, Training Acc: 74.42%\n",
      "              Val Loss: 1.0580273866653442, Val Acc: 66.56%\n",
      "Epoch: 5087,     Training Loss: 0.3405223786830902, Training Acc: 74.42%\n",
      "              Val Loss: 1.005629539489746, Val Acc: 66.56%\n",
      "Epoch: 5088,     Training Loss: 0.3470839262008667, Training Acc: 74.43%\n",
      "              Val Loss: 0.9822937250137329, Val Acc: 66.56%\n",
      "Epoch: 5089,     Training Loss: 0.30903083086013794, Training Acc: 74.43%\n",
      "              Val Loss: 1.0523149967193604, Val Acc: 66.56%\n",
      "Epoch: 5090,     Training Loss: 0.3437170088291168, Training Acc: 74.43%\n",
      "              Val Loss: 1.0323078632354736, Val Acc: 66.56%\n",
      "Epoch: 5091,     Training Loss: 0.37891674041748047, Training Acc: 74.43%\n",
      "              Val Loss: 1.0295251607894897, Val Acc: 66.56%\n",
      "Epoch: 5092,     Training Loss: 0.33156582713127136, Training Acc: 74.43%\n",
      "              Val Loss: 1.04293692111969, Val Acc: 66.56%\n",
      "Epoch: 5093,     Training Loss: 0.3336232900619507, Training Acc: 74.44%\n",
      "              Val Loss: 0.9982050061225891, Val Acc: 66.56%\n",
      "Epoch: 5094,     Training Loss: 0.33375072479248047, Training Acc: 74.44%\n",
      "              Val Loss: 1.0093395709991455, Val Acc: 66.56%\n",
      "Epoch: 5095,     Training Loss: 0.31652531027793884, Training Acc: 74.44%\n",
      "              Val Loss: 1.0603021383285522, Val Acc: 66.56%\n",
      "Epoch: 5096,     Training Loss: 0.35107889771461487, Training Acc: 74.44%\n",
      "              Val Loss: 1.0553852319717407, Val Acc: 66.56%\n",
      "Epoch: 5097,     Training Loss: 0.37758633494377136, Training Acc: 74.45%\n",
      "              Val Loss: 1.0195339918136597, Val Acc: 66.57%\n",
      "Epoch: 5098,     Training Loss: 0.3736018240451813, Training Acc: 74.45%\n",
      "              Val Loss: 1.1153230667114258, Val Acc: 66.57%\n",
      "Epoch: 5099,     Training Loss: 0.39522433280944824, Training Acc: 74.45%\n",
      "              Val Loss: 0.978023886680603, Val Acc: 66.57%\n",
      "Epoch: 5100,     Training Loss: 0.31478503346443176, Training Acc: 74.45%\n",
      "              Val Loss: 1.0174784660339355, Val Acc: 66.57%\n",
      "Epoch: 5101,     Training Loss: 0.35554322600364685, Training Acc: 74.45%\n",
      "              Val Loss: 1.0330089330673218, Val Acc: 66.57%\n",
      "Epoch: 5102,     Training Loss: 0.34097832441329956, Training Acc: 74.46%\n",
      "              Val Loss: 1.1273598670959473, Val Acc: 66.57%\n",
      "Epoch: 5103,     Training Loss: 0.43857038021087646, Training Acc: 74.46%\n",
      "              Val Loss: 1.0682110786437988, Val Acc: 66.57%\n",
      "Epoch: 5104,     Training Loss: 0.4101141095161438, Training Acc: 74.46%\n",
      "              Val Loss: 1.0405173301696777, Val Acc: 66.57%\n",
      "Epoch: 5105,     Training Loss: 0.39572998881340027, Training Acc: 74.46%\n",
      "              Val Loss: 0.9973940253257751, Val Acc: 66.57%\n",
      "Epoch: 5106,     Training Loss: 0.325165718793869, Training Acc: 74.46%\n",
      "              Val Loss: 1.1339627504348755, Val Acc: 66.57%\n",
      "Epoch: 5107,     Training Loss: 0.4290026128292084, Training Acc: 74.46%\n",
      "              Val Loss: 1.1678266525268555, Val Acc: 66.57%\n",
      "Epoch: 5108,     Training Loss: 0.5181488394737244, Training Acc: 74.46%\n",
      "              Val Loss: 1.073926568031311, Val Acc: 66.57%\n",
      "Epoch: 5109,     Training Loss: 0.3918759226799011, Training Acc: 74.47%\n",
      "              Val Loss: 1.030617594718933, Val Acc: 66.57%\n",
      "Epoch: 5110,     Training Loss: 0.38563773036003113, Training Acc: 74.47%\n",
      "              Val Loss: 1.0914256572723389, Val Acc: 66.57%\n",
      "Epoch: 5111,     Training Loss: 0.4442879557609558, Training Acc: 74.47%\n",
      "              Val Loss: 1.0423979759216309, Val Acc: 66.58%\n",
      "Epoch: 5112,     Training Loss: 0.38248732686042786, Training Acc: 74.47%\n",
      "              Val Loss: 0.9822608232498169, Val Acc: 66.58%\n",
      "Epoch: 5113,     Training Loss: 0.3436008393764496, Training Acc: 74.47%\n",
      "              Val Loss: 1.0099862813949585, Val Acc: 66.58%\n",
      "Epoch: 5114,     Training Loss: 0.35253533720970154, Training Acc: 74.47%\n",
      "              Val Loss: 1.0409722328186035, Val Acc: 66.58%\n",
      "Epoch: 5115,     Training Loss: 0.35311684012413025, Training Acc: 74.48%\n",
      "              Val Loss: 0.991271436214447, Val Acc: 66.58%\n",
      "Epoch: 5116,     Training Loss: 0.33421608805656433, Training Acc: 74.48%\n",
      "              Val Loss: 1.0013808012008667, Val Acc: 66.58%\n",
      "Epoch: 5117,     Training Loss: 0.34458789229393005, Training Acc: 74.48%\n",
      "              Val Loss: 0.9871190786361694, Val Acc: 66.58%\n",
      "Epoch: 5118,     Training Loss: 0.3145996332168579, Training Acc: 74.48%\n",
      "              Val Loss: 1.0422557592391968, Val Acc: 66.58%\n",
      "Epoch: 5119,     Training Loss: 0.35814815759658813, Training Acc: 74.49%\n",
      "              Val Loss: 1.002345085144043, Val Acc: 66.58%\n",
      "Epoch: 5120,     Training Loss: 0.3553635776042938, Training Acc: 74.49%\n",
      "              Val Loss: 1.0926483869552612, Val Acc: 66.58%\n",
      "Epoch: 5121,     Training Loss: 0.4609178900718689, Training Acc: 74.49%\n",
      "              Val Loss: 1.0558701753616333, Val Acc: 66.58%\n",
      "Epoch: 5122,     Training Loss: 0.3676072359085083, Training Acc: 74.49%\n",
      "              Val Loss: 1.0468363761901855, Val Acc: 66.58%\n",
      "Epoch: 5123,     Training Loss: 0.35539501905441284, Training Acc: 74.49%\n",
      "              Val Loss: 1.0004912614822388, Val Acc: 66.59%\n",
      "Epoch: 5124,     Training Loss: 0.3309963345527649, Training Acc: 74.49%\n",
      "              Val Loss: 1.094413161277771, Val Acc: 66.59%\n",
      "Epoch: 5125,     Training Loss: 0.3872228264808655, Training Acc: 74.50%\n",
      "              Val Loss: 1.0490044355392456, Val Acc: 66.59%\n",
      "Epoch: 5126,     Training Loss: 0.3935083746910095, Training Acc: 74.50%\n",
      "              Val Loss: 1.0197994709014893, Val Acc: 66.59%\n",
      "Epoch: 5127,     Training Loss: 0.3482234477996826, Training Acc: 74.50%\n",
      "              Val Loss: 1.0188701152801514, Val Acc: 66.59%\n",
      "Epoch: 5128,     Training Loss: 0.34354791045188904, Training Acc: 74.50%\n",
      "              Val Loss: 1.0333291292190552, Val Acc: 66.59%\n",
      "Epoch: 5129,     Training Loss: 0.3928943872451782, Training Acc: 74.50%\n",
      "              Val Loss: 1.030139684677124, Val Acc: 66.59%\n",
      "Epoch: 5130,     Training Loss: 0.3468325734138489, Training Acc: 74.51%\n",
      "              Val Loss: 1.022209882736206, Val Acc: 66.59%\n",
      "Epoch: 5131,     Training Loss: 0.32410842180252075, Training Acc: 74.51%\n",
      "              Val Loss: 1.0000908374786377, Val Acc: 66.59%\n",
      "Epoch: 5132,     Training Loss: 0.3284837305545807, Training Acc: 74.51%\n",
      "              Val Loss: 0.9915021657943726, Val Acc: 66.59%\n",
      "Epoch: 5133,     Training Loss: 0.32301589846611023, Training Acc: 74.51%\n",
      "              Val Loss: 1.0150995254516602, Val Acc: 66.59%\n",
      "Epoch: 5134,     Training Loss: 0.3330908715724945, Training Acc: 74.52%\n",
      "              Val Loss: 1.0042344331741333, Val Acc: 66.60%\n",
      "Epoch: 5135,     Training Loss: 0.32342395186424255, Training Acc: 74.52%\n",
      "              Val Loss: 0.9973970651626587, Val Acc: 66.60%\n",
      "Epoch: 5136,     Training Loss: 0.3319184184074402, Training Acc: 74.52%\n",
      "              Val Loss: 1.0119986534118652, Val Acc: 66.60%\n",
      "Epoch: 5137,     Training Loss: 0.32252824306488037, Training Acc: 74.52%\n",
      "              Val Loss: 1.0310534238815308, Val Acc: 66.60%\n",
      "Epoch: 5138,     Training Loss: 0.3328720033168793, Training Acc: 74.52%\n",
      "              Val Loss: 1.0032058954238892, Val Acc: 66.60%\n",
      "Epoch: 5139,     Training Loss: 0.31451281905174255, Training Acc: 74.53%\n",
      "              Val Loss: 0.9972904920578003, Val Acc: 66.60%\n",
      "Epoch: 5140,     Training Loss: 0.31092560291290283, Training Acc: 74.53%\n",
      "              Val Loss: 1.0020742416381836, Val Acc: 66.60%\n",
      "Epoch: 5141,     Training Loss: 0.30331048369407654, Training Acc: 74.53%\n",
      "              Val Loss: 0.9997822046279907, Val Acc: 66.60%\n",
      "Epoch: 5142,     Training Loss: 0.3080059885978699, Training Acc: 74.53%\n",
      "              Val Loss: 0.992371678352356, Val Acc: 66.60%\n",
      "Epoch: 5143,     Training Loss: 0.2990192174911499, Training Acc: 74.54%\n",
      "              Val Loss: 1.0162543058395386, Val Acc: 66.61%\n",
      "Epoch: 5144,     Training Loss: 0.30798667669296265, Training Acc: 74.54%\n",
      "              Val Loss: 0.9972888231277466, Val Acc: 66.61%\n",
      "Epoch: 5145,     Training Loss: 0.3010084629058838, Training Acc: 74.54%\n",
      "              Val Loss: 0.9991911053657532, Val Acc: 66.61%\n",
      "Epoch: 5146,     Training Loss: 0.30138808488845825, Training Acc: 74.54%\n",
      "              Val Loss: 0.9978103637695312, Val Acc: 66.61%\n",
      "Epoch: 5147,     Training Loss: 0.30405303835868835, Training Acc: 74.55%\n",
      "              Val Loss: 0.9869594573974609, Val Acc: 66.61%\n",
      "Epoch: 5148,     Training Loss: 0.2998182773590088, Training Acc: 74.55%\n",
      "              Val Loss: 0.9909906983375549, Val Acc: 66.61%\n",
      "Epoch: 5149,     Training Loss: 0.30364716053009033, Training Acc: 74.55%\n",
      "              Val Loss: 1.00617253780365, Val Acc: 66.61%\n",
      "Epoch: 5150,     Training Loss: 0.30021587014198303, Training Acc: 74.55%\n",
      "              Val Loss: 1.0022399425506592, Val Acc: 66.61%\n",
      "Epoch: 5151,     Training Loss: 0.30579495429992676, Training Acc: 74.56%\n",
      "              Val Loss: 1.0114216804504395, Val Acc: 66.61%\n",
      "Epoch: 5152,     Training Loss: 0.3027927875518799, Training Acc: 74.56%\n",
      "              Val Loss: 1.021416425704956, Val Acc: 66.62%\n",
      "Epoch: 5153,     Training Loss: 0.31566452980041504, Training Acc: 74.56%\n",
      "              Val Loss: 1.0280252695083618, Val Acc: 66.62%\n",
      "Epoch: 5154,     Training Loss: 0.3289368748664856, Training Acc: 74.56%\n",
      "              Val Loss: 1.058259129524231, Val Acc: 66.62%\n",
      "Epoch: 5155,     Training Loss: 0.38443028926849365, Training Acc: 74.57%\n",
      "              Val Loss: 1.0546603202819824, Val Acc: 66.62%\n",
      "Epoch: 5156,     Training Loss: 0.3441586196422577, Training Acc: 74.57%\n",
      "              Val Loss: 1.0085186958312988, Val Acc: 66.62%\n",
      "Epoch: 5157,     Training Loss: 0.3232203423976898, Training Acc: 74.57%\n",
      "              Val Loss: 1.0101110935211182, Val Acc: 66.62%\n",
      "Epoch: 5158,     Training Loss: 0.300020694732666, Training Acc: 74.57%\n",
      "              Val Loss: 1.062239408493042, Val Acc: 66.62%\n",
      "Epoch: 5159,     Training Loss: 0.3374793231487274, Training Acc: 74.58%\n",
      "              Val Loss: 1.1052141189575195, Val Acc: 66.62%\n",
      "Epoch: 5160,     Training Loss: 0.43628838658332825, Training Acc: 74.58%\n",
      "              Val Loss: 1.0383470058441162, Val Acc: 66.62%\n",
      "Epoch: 5161,     Training Loss: 0.34531357884407043, Training Acc: 74.58%\n",
      "              Val Loss: 1.013495922088623, Val Acc: 66.62%\n",
      "Epoch: 5162,     Training Loss: 0.3115786612033844, Training Acc: 74.58%\n",
      "              Val Loss: 1.0169737339019775, Val Acc: 66.62%\n",
      "Epoch: 5163,     Training Loss: 0.33377787470817566, Training Acc: 74.58%\n",
      "              Val Loss: 1.0415581464767456, Val Acc: 66.62%\n",
      "Epoch: 5164,     Training Loss: 0.3333806097507477, Training Acc: 74.59%\n",
      "              Val Loss: 1.0390079021453857, Val Acc: 66.63%\n",
      "Epoch: 5165,     Training Loss: 0.32975485920906067, Training Acc: 74.59%\n",
      "              Val Loss: 1.004388689994812, Val Acc: 66.63%\n",
      "Epoch: 5166,     Training Loss: 0.2973806858062744, Training Acc: 74.59%\n",
      "              Val Loss: 1.027960181236267, Val Acc: 66.63%\n",
      "Epoch: 5167,     Training Loss: 0.3141014575958252, Training Acc: 74.59%\n",
      "              Val Loss: 1.0421596765518188, Val Acc: 66.63%\n",
      "Epoch: 5168,     Training Loss: 0.3397253453731537, Training Acc: 74.59%\n",
      "              Val Loss: 1.0446233749389648, Val Acc: 66.63%\n",
      "Epoch: 5169,     Training Loss: 0.3290899693965912, Training Acc: 74.60%\n",
      "              Val Loss: 1.011352300643921, Val Acc: 66.63%\n",
      "Epoch: 5170,     Training Loss: 0.3202284574508667, Training Acc: 74.60%\n",
      "              Val Loss: 1.0124328136444092, Val Acc: 66.63%\n",
      "Epoch: 5171,     Training Loss: 0.299874484539032, Training Acc: 74.60%\n",
      "              Val Loss: 1.0150173902511597, Val Acc: 66.63%\n",
      "Epoch: 5172,     Training Loss: 0.3101256191730499, Training Acc: 74.60%\n",
      "              Val Loss: 1.0121121406555176, Val Acc: 66.63%\n",
      "Epoch: 5173,     Training Loss: 0.32361942529678345, Training Acc: 74.61%\n",
      "              Val Loss: 1.0574078559875488, Val Acc: 66.63%\n",
      "Epoch: 5174,     Training Loss: 0.3321477174758911, Training Acc: 74.61%\n",
      "              Val Loss: 1.0197629928588867, Val Acc: 66.63%\n",
      "Epoch: 5175,     Training Loss: 0.3387126624584198, Training Acc: 74.61%\n",
      "              Val Loss: 1.015421986579895, Val Acc: 66.64%\n",
      "Epoch: 5176,     Training Loss: 0.3076886236667633, Training Acc: 74.61%\n",
      "              Val Loss: 1.0271854400634766, Val Acc: 66.64%\n",
      "Epoch: 5177,     Training Loss: 0.3106028437614441, Training Acc: 74.61%\n",
      "              Val Loss: 0.9920194745063782, Val Acc: 66.64%\n",
      "Epoch: 5178,     Training Loss: 0.30579107999801636, Training Acc: 74.62%\n",
      "              Val Loss: 1.0263540744781494, Val Acc: 66.64%\n",
      "Epoch: 5179,     Training Loss: 0.31721606850624084, Training Acc: 74.62%\n",
      "              Val Loss: 1.04155695438385, Val Acc: 66.64%\n",
      "Epoch: 5180,     Training Loss: 0.3429415225982666, Training Acc: 74.62%\n",
      "              Val Loss: 1.0430995225906372, Val Acc: 66.64%\n",
      "Epoch: 5181,     Training Loss: 0.35531899333000183, Training Acc: 74.62%\n",
      "              Val Loss: 1.110581874847412, Val Acc: 66.64%\n",
      "Epoch: 5182,     Training Loss: 0.4190429747104645, Training Acc: 74.62%\n",
      "              Val Loss: 1.0315790176391602, Val Acc: 66.64%\n",
      "Epoch: 5183,     Training Loss: 0.3177269697189331, Training Acc: 74.63%\n",
      "              Val Loss: 1.053022861480713, Val Acc: 66.64%\n",
      "Epoch: 5184,     Training Loss: 0.3411528766155243, Training Acc: 74.63%\n",
      "              Val Loss: 1.0944151878356934, Val Acc: 66.64%\n",
      "Epoch: 5185,     Training Loss: 0.3942868411540985, Training Acc: 74.63%\n",
      "              Val Loss: 1.1025142669677734, Val Acc: 66.64%\n",
      "Epoch: 5186,     Training Loss: 0.3737861216068268, Training Acc: 74.63%\n",
      "              Val Loss: 1.0531868934631348, Val Acc: 66.64%\n",
      "Epoch: 5187,     Training Loss: 0.4037942886352539, Training Acc: 74.63%\n",
      "              Val Loss: 1.0865294933319092, Val Acc: 66.64%\n",
      "Epoch: 5188,     Training Loss: 0.36852872371673584, Training Acc: 74.64%\n",
      "              Val Loss: 1.1371431350708008, Val Acc: 66.64%\n",
      "Epoch: 5189,     Training Loss: 0.43556031584739685, Training Acc: 74.64%\n",
      "              Val Loss: 1.1328613758087158, Val Acc: 66.64%\n",
      "Epoch: 5190,     Training Loss: 0.5024875402450562, Training Acc: 74.64%\n",
      "              Val Loss: 1.1515891551971436, Val Acc: 66.65%\n",
      "Epoch: 5191,     Training Loss: 0.43283557891845703, Training Acc: 74.64%\n",
      "              Val Loss: 1.064726710319519, Val Acc: 66.65%\n",
      "Epoch: 5192,     Training Loss: 0.3675011694431305, Training Acc: 74.64%\n",
      "              Val Loss: 1.038152813911438, Val Acc: 66.65%\n",
      "Epoch: 5193,     Training Loss: 0.38334736227989197, Training Acc: 74.64%\n",
      "              Val Loss: 1.064786434173584, Val Acc: 66.65%\n",
      "Epoch: 5194,     Training Loss: 0.37717205286026, Training Acc: 74.64%\n",
      "              Val Loss: 1.0976324081420898, Val Acc: 66.65%\n",
      "Epoch: 5195,     Training Loss: 0.3869192600250244, Training Acc: 74.65%\n",
      "              Val Loss: 1.0711796283721924, Val Acc: 66.65%\n",
      "Epoch: 5196,     Training Loss: 0.3493043780326843, Training Acc: 74.65%\n",
      "              Val Loss: 1.0033029317855835, Val Acc: 66.65%\n",
      "Epoch: 5197,     Training Loss: 0.33022770285606384, Training Acc: 74.65%\n",
      "              Val Loss: 1.0327461957931519, Val Acc: 66.65%\n",
      "Epoch: 5198,     Training Loss: 0.35523372888565063, Training Acc: 74.65%\n",
      "              Val Loss: 1.0430138111114502, Val Acc: 66.65%\n",
      "Epoch: 5199,     Training Loss: 0.3475029766559601, Training Acc: 74.65%\n",
      "              Val Loss: 1.090903878211975, Val Acc: 66.65%\n",
      "Epoch: 5200,     Training Loss: 0.42572659254074097, Training Acc: 74.65%\n",
      "              Val Loss: 1.004411220550537, Val Acc: 66.65%\n",
      "Epoch: 5201,     Training Loss: 0.3276747465133667, Training Acc: 74.66%\n",
      "              Val Loss: 1.0867615938186646, Val Acc: 66.65%\n",
      "Epoch: 5202,     Training Loss: 0.3778097927570343, Training Acc: 74.66%\n",
      "              Val Loss: 1.048280119895935, Val Acc: 66.66%\n",
      "Epoch: 5203,     Training Loss: 0.3837527930736542, Training Acc: 74.66%\n",
      "              Val Loss: 1.0900365114212036, Val Acc: 66.66%\n",
      "Epoch: 5204,     Training Loss: 0.37450534105300903, Training Acc: 74.66%\n",
      "              Val Loss: 1.0484908819198608, Val Acc: 66.66%\n",
      "Epoch: 5205,     Training Loss: 0.34551918506622314, Training Acc: 74.66%\n",
      "              Val Loss: 1.0216124057769775, Val Acc: 66.66%\n",
      "Epoch: 5206,     Training Loss: 0.3330448567867279, Training Acc: 74.67%\n",
      "              Val Loss: 1.0163074731826782, Val Acc: 66.66%\n",
      "Epoch: 5207,     Training Loss: 0.33696800470352173, Training Acc: 74.67%\n",
      "              Val Loss: 1.0848904848098755, Val Acc: 66.66%\n",
      "Epoch: 5208,     Training Loss: 0.37040945887565613, Training Acc: 74.67%\n",
      "              Val Loss: 1.0602434873580933, Val Acc: 66.66%\n",
      "Epoch: 5209,     Training Loss: 0.35864531993865967, Training Acc: 74.67%\n",
      "              Val Loss: 1.1050418615341187, Val Acc: 66.66%\n",
      "Epoch: 5210,     Training Loss: 0.46695196628570557, Training Acc: 74.67%\n",
      "              Val Loss: 1.0229681730270386, Val Acc: 66.66%\n",
      "Epoch: 5211,     Training Loss: 0.3400719165802002, Training Acc: 74.68%\n",
      "              Val Loss: 1.0886716842651367, Val Acc: 66.66%\n",
      "Epoch: 5212,     Training Loss: 0.3685961961746216, Training Acc: 74.68%\n",
      "              Val Loss: 1.0775291919708252, Val Acc: 66.66%\n",
      "Epoch: 5213,     Training Loss: 0.4240909814834595, Training Acc: 74.68%\n",
      "              Val Loss: 1.0368351936340332, Val Acc: 66.66%\n",
      "Epoch: 5214,     Training Loss: 0.34995773434638977, Training Acc: 74.68%\n",
      "              Val Loss: 1.081036925315857, Val Acc: 66.66%\n",
      "Epoch: 5215,     Training Loss: 0.35838860273361206, Training Acc: 74.68%\n",
      "              Val Loss: 1.1139287948608398, Val Acc: 66.66%\n",
      "Epoch: 5216,     Training Loss: 0.4448856711387634, Training Acc: 74.68%\n",
      "              Val Loss: 1.0617456436157227, Val Acc: 66.67%\n",
      "Epoch: 5217,     Training Loss: 0.40414193272590637, Training Acc: 74.68%\n",
      "              Val Loss: 1.0952174663543701, Val Acc: 66.67%\n",
      "Epoch: 5218,     Training Loss: 0.37950652837753296, Training Acc: 74.69%\n",
      "              Val Loss: 1.0991809368133545, Val Acc: 66.67%\n",
      "Epoch: 5219,     Training Loss: 0.3960545063018799, Training Acc: 74.69%\n",
      "              Val Loss: 1.1408854722976685, Val Acc: 66.67%\n",
      "Epoch: 5220,     Training Loss: 0.42636799812316895, Training Acc: 74.69%\n",
      "              Val Loss: 1.0373876094818115, Val Acc: 66.67%\n",
      "Epoch: 5221,     Training Loss: 0.3550683259963989, Training Acc: 74.69%\n",
      "              Val Loss: 1.0554863214492798, Val Acc: 66.67%\n",
      "Epoch: 5222,     Training Loss: 0.36988362669944763, Training Acc: 74.69%\n",
      "              Val Loss: 1.0347871780395508, Val Acc: 66.67%\n",
      "Epoch: 5223,     Training Loss: 0.3529893755912781, Training Acc: 74.70%\n",
      "              Val Loss: 1.0117216110229492, Val Acc: 66.67%\n",
      "Epoch: 5224,     Training Loss: 0.3469330072402954, Training Acc: 74.70%\n",
      "              Val Loss: 1.0559532642364502, Val Acc: 66.67%\n",
      "Epoch: 5225,     Training Loss: 0.36047878861427307, Training Acc: 74.70%\n",
      "              Val Loss: 1.0366084575653076, Val Acc: 66.67%\n",
      "Epoch: 5226,     Training Loss: 0.36640140414237976, Training Acc: 74.70%\n",
      "              Val Loss: 1.0708867311477661, Val Acc: 66.67%\n",
      "Epoch: 5227,     Training Loss: 0.3837467133998871, Training Acc: 74.70%\n",
      "              Val Loss: 1.028846025466919, Val Acc: 66.67%\n",
      "Epoch: 5228,     Training Loss: 0.33942708373069763, Training Acc: 74.70%\n",
      "              Val Loss: 1.0340484380722046, Val Acc: 66.67%\n",
      "Epoch: 5229,     Training Loss: 0.3226292133331299, Training Acc: 74.71%\n",
      "              Val Loss: 1.0741798877716064, Val Acc: 66.68%\n",
      "Epoch: 5230,     Training Loss: 0.3442921042442322, Training Acc: 74.71%\n",
      "              Val Loss: 1.0493369102478027, Val Acc: 66.68%\n",
      "Epoch: 5231,     Training Loss: 0.35182124376296997, Training Acc: 74.71%\n",
      "              Val Loss: 1.006938099861145, Val Acc: 66.68%\n",
      "Epoch: 5232,     Training Loss: 0.3043033480644226, Training Acc: 74.71%\n",
      "              Val Loss: 1.0237900018692017, Val Acc: 66.68%\n",
      "Epoch: 5233,     Training Loss: 0.3343784213066101, Training Acc: 74.72%\n",
      "              Val Loss: 1.038417100906372, Val Acc: 66.68%\n",
      "Epoch: 5234,     Training Loss: 0.37446269392967224, Training Acc: 74.72%\n",
      "              Val Loss: 1.0310742855072021, Val Acc: 66.68%\n",
      "Epoch: 5235,     Training Loss: 0.31850671768188477, Training Acc: 74.72%\n",
      "              Val Loss: 1.0400876998901367, Val Acc: 66.68%\n",
      "Epoch: 5236,     Training Loss: 0.3052077889442444, Training Acc: 74.72%\n",
      "              Val Loss: 1.0641309022903442, Val Acc: 66.68%\n",
      "Epoch: 5237,     Training Loss: 0.33960041403770447, Training Acc: 74.72%\n",
      "              Val Loss: 1.061202049255371, Val Acc: 66.68%\n",
      "Epoch: 5238,     Training Loss: 0.3307015597820282, Training Acc: 74.73%\n",
      "              Val Loss: 1.0290863513946533, Val Acc: 66.68%\n",
      "Epoch: 5239,     Training Loss: 0.318645715713501, Training Acc: 74.73%\n",
      "              Val Loss: 1.0051606893539429, Val Acc: 66.68%\n",
      "Epoch: 5240,     Training Loss: 0.2982707917690277, Training Acc: 74.73%\n",
      "              Val Loss: 1.016047477722168, Val Acc: 66.68%\n",
      "Epoch: 5241,     Training Loss: 0.30248889327049255, Training Acc: 74.73%\n",
      "              Val Loss: 1.0464142560958862, Val Acc: 66.69%\n",
      "Epoch: 5242,     Training Loss: 0.33310404419898987, Training Acc: 74.74%\n",
      "              Val Loss: 1.046960711479187, Val Acc: 66.69%\n",
      "Epoch: 5243,     Training Loss: 0.32308754324913025, Training Acc: 74.74%\n",
      "              Val Loss: 1.0314831733703613, Val Acc: 66.69%\n",
      "Epoch: 5244,     Training Loss: 0.31250759959220886, Training Acc: 74.74%\n",
      "              Val Loss: 1.0337051153182983, Val Acc: 66.69%\n",
      "Epoch: 5245,     Training Loss: 0.2969287931919098, Training Acc: 74.74%\n",
      "              Val Loss: 1.0258793830871582, Val Acc: 66.69%\n",
      "Epoch: 5246,     Training Loss: 0.30300644040107727, Training Acc: 74.74%\n",
      "              Val Loss: 1.0264623165130615, Val Acc: 66.69%\n",
      "Epoch: 5247,     Training Loss: 0.3133833408355713, Training Acc: 74.75%\n",
      "              Val Loss: 1.0459933280944824, Val Acc: 66.69%\n",
      "Epoch: 5248,     Training Loss: 0.31734976172447205, Training Acc: 74.75%\n",
      "              Val Loss: 1.0399811267852783, Val Acc: 66.69%\n",
      "Epoch: 5249,     Training Loss: 0.3553227186203003, Training Acc: 74.75%\n",
      "              Val Loss: 1.0238159894943237, Val Acc: 66.69%\n",
      "Epoch: 5250,     Training Loss: 0.3095666468143463, Training Acc: 74.75%\n",
      "              Val Loss: 1.047666072845459, Val Acc: 66.69%\n",
      "Epoch: 5251,     Training Loss: 0.31361377239227295, Training Acc: 74.76%\n",
      "              Val Loss: 1.0191558599472046, Val Acc: 66.69%\n",
      "Epoch: 5252,     Training Loss: 0.32594597339630127, Training Acc: 74.76%\n",
      "              Val Loss: 1.0520049333572388, Val Acc: 66.70%\n",
      "Epoch: 5253,     Training Loss: 0.3313513994216919, Training Acc: 74.76%\n",
      "              Val Loss: 1.0742725133895874, Val Acc: 66.70%\n",
      "Epoch: 5254,     Training Loss: 0.3588062524795532, Training Acc: 74.76%\n",
      "              Val Loss: 1.0350251197814941, Val Acc: 66.70%\n",
      "Epoch: 5255,     Training Loss: 0.3225213289260864, Training Acc: 74.76%\n",
      "              Val Loss: 1.0147192478179932, Val Acc: 66.70%\n",
      "Epoch: 5256,     Training Loss: 0.30615296959877014, Training Acc: 74.77%\n",
      "              Val Loss: 1.078321933746338, Val Acc: 66.70%\n",
      "Epoch: 5257,     Training Loss: 0.33324217796325684, Training Acc: 74.77%\n",
      "              Val Loss: 1.0893867015838623, Val Acc: 66.70%\n",
      "Epoch: 5258,     Training Loss: 0.3607044517993927, Training Acc: 74.77%\n",
      "              Val Loss: 1.0489355325698853, Val Acc: 66.70%\n",
      "Epoch: 5259,     Training Loss: 0.3749634623527527, Training Acc: 74.77%\n",
      "              Val Loss: 1.1162471771240234, Val Acc: 66.70%\n",
      "Epoch: 5260,     Training Loss: 0.37025901675224304, Training Acc: 74.77%\n",
      "              Val Loss: 0.9947119951248169, Val Acc: 66.70%\n",
      "Epoch: 5261,     Training Loss: 0.303424596786499, Training Acc: 74.78%\n",
      "              Val Loss: 1.0313342809677124, Val Acc: 66.70%\n",
      "Epoch: 5262,     Training Loss: 0.3514227569103241, Training Acc: 74.78%\n",
      "              Val Loss: 1.0465753078460693, Val Acc: 66.70%\n",
      "Epoch: 5263,     Training Loss: 0.32671135663986206, Training Acc: 74.78%\n",
      "              Val Loss: 1.110774040222168, Val Acc: 66.70%\n",
      "Epoch: 5264,     Training Loss: 0.37921983003616333, Training Acc: 74.78%\n",
      "              Val Loss: 1.0308642387390137, Val Acc: 66.71%\n",
      "Epoch: 5265,     Training Loss: 0.3317507207393646, Training Acc: 74.78%\n",
      "              Val Loss: 1.0296416282653809, Val Acc: 66.71%\n",
      "Epoch: 5266,     Training Loss: 0.3281710743904114, Training Acc: 74.79%\n",
      "              Val Loss: 1.0150041580200195, Val Acc: 66.71%\n",
      "Epoch: 5267,     Training Loss: 0.3067905306816101, Training Acc: 74.79%\n",
      "              Val Loss: 1.0821882486343384, Val Acc: 66.71%\n",
      "Epoch: 5268,     Training Loss: 0.3505876660346985, Training Acc: 74.79%\n",
      "              Val Loss: 1.0592540502548218, Val Acc: 66.71%\n",
      "Epoch: 5269,     Training Loss: 0.3705507218837738, Training Acc: 74.79%\n",
      "              Val Loss: 1.0780125856399536, Val Acc: 66.71%\n",
      "Epoch: 5270,     Training Loss: 0.36067700386047363, Training Acc: 74.79%\n",
      "              Val Loss: 1.024604082107544, Val Acc: 66.71%\n",
      "Epoch: 5271,     Training Loss: 0.34336262941360474, Training Acc: 74.80%\n",
      "              Val Loss: 1.0124366283416748, Val Acc: 66.71%\n",
      "Epoch: 5272,     Training Loss: 0.3161619305610657, Training Acc: 74.80%\n",
      "              Val Loss: 1.057550072669983, Val Acc: 66.71%\n",
      "Epoch: 5273,     Training Loss: 0.34430640935897827, Training Acc: 74.80%\n",
      "              Val Loss: 1.0625709295272827, Val Acc: 66.71%\n",
      "Epoch: 5274,     Training Loss: 0.37788286805152893, Training Acc: 74.80%\n",
      "              Val Loss: 1.0615339279174805, Val Acc: 66.71%\n",
      "Epoch: 5275,     Training Loss: 0.3382270932197571, Training Acc: 74.80%\n",
      "              Val Loss: 1.023769736289978, Val Acc: 66.71%\n",
      "Epoch: 5276,     Training Loss: 0.30127543210983276, Training Acc: 74.81%\n",
      "              Val Loss: 1.0213035345077515, Val Acc: 66.72%\n",
      "Epoch: 5277,     Training Loss: 0.31522414088249207, Training Acc: 74.81%\n",
      "              Val Loss: 1.0257575511932373, Val Acc: 66.72%\n",
      "Epoch: 5278,     Training Loss: 0.3048928380012512, Training Acc: 74.81%\n",
      "              Val Loss: 1.072767972946167, Val Acc: 66.72%\n",
      "Epoch: 5279,     Training Loss: 0.3329038918018341, Training Acc: 74.81%\n",
      "              Val Loss: 1.0198615789413452, Val Acc: 66.72%\n",
      "Epoch: 5280,     Training Loss: 0.314508318901062, Training Acc: 74.81%\n",
      "              Val Loss: 1.0101451873779297, Val Acc: 66.72%\n",
      "Epoch: 5281,     Training Loss: 0.3259364664554596, Training Acc: 74.82%\n",
      "              Val Loss: 1.0208704471588135, Val Acc: 66.72%\n",
      "Epoch: 5282,     Training Loss: 0.313150018453598, Training Acc: 74.82%\n",
      "              Val Loss: 1.0237481594085693, Val Acc: 66.72%\n",
      "Epoch: 5283,     Training Loss: 0.3131515383720398, Training Acc: 74.82%\n",
      "              Val Loss: 1.0085673332214355, Val Acc: 66.72%\n",
      "Epoch: 5284,     Training Loss: 0.30278709530830383, Training Acc: 74.82%\n",
      "              Val Loss: 1.0289171934127808, Val Acc: 66.72%\n",
      "Epoch: 5285,     Training Loss: 0.3050391376018524, Training Acc: 74.83%\n",
      "              Val Loss: 1.0226417779922485, Val Acc: 66.72%\n",
      "Epoch: 5286,     Training Loss: 0.30144640803337097, Training Acc: 74.83%\n",
      "              Val Loss: 1.0267691612243652, Val Acc: 66.72%\n",
      "Epoch: 5287,     Training Loss: 0.31241828203201294, Training Acc: 74.83%\n",
      "              Val Loss: 1.034990668296814, Val Acc: 66.73%\n",
      "Epoch: 5288,     Training Loss: 0.3355921804904938, Training Acc: 74.83%\n",
      "              Val Loss: 1.0546009540557861, Val Acc: 66.73%\n",
      "Epoch: 5289,     Training Loss: 0.32742077112197876, Training Acc: 74.83%\n",
      "              Val Loss: 1.0784796476364136, Val Acc: 66.73%\n",
      "Epoch: 5290,     Training Loss: 0.39392685890197754, Training Acc: 74.84%\n",
      "              Val Loss: 1.037185788154602, Val Acc: 66.73%\n",
      "Epoch: 5291,     Training Loss: 0.30964934825897217, Training Acc: 74.84%\n",
      "              Val Loss: 1.071221947669983, Val Acc: 66.73%\n",
      "Epoch: 5292,     Training Loss: 0.3383508622646332, Training Acc: 74.84%\n",
      "              Val Loss: 1.0435974597930908, Val Acc: 66.73%\n",
      "Epoch: 5293,     Training Loss: 0.3694441318511963, Training Acc: 74.84%\n",
      "              Val Loss: 1.0637602806091309, Val Acc: 66.73%\n",
      "Epoch: 5294,     Training Loss: 0.35046276450157166, Training Acc: 74.84%\n",
      "              Val Loss: 1.0672399997711182, Val Acc: 66.73%\n",
      "Epoch: 5295,     Training Loss: 0.35717788338661194, Training Acc: 74.85%\n",
      "              Val Loss: 1.0122703313827515, Val Acc: 66.73%\n",
      "Epoch: 5296,     Training Loss: 0.3099479079246521, Training Acc: 74.85%\n",
      "              Val Loss: 1.0549336671829224, Val Acc: 66.73%\n",
      "Epoch: 5297,     Training Loss: 0.33074337244033813, Training Acc: 74.85%\n",
      "              Val Loss: 1.1290957927703857, Val Acc: 66.73%\n",
      "Epoch: 5298,     Training Loss: 0.38678479194641113, Training Acc: 74.85%\n",
      "              Val Loss: 1.1042238473892212, Val Acc: 66.73%\n",
      "Epoch: 5299,     Training Loss: 0.3769911229610443, Training Acc: 74.85%\n",
      "              Val Loss: 1.0892220735549927, Val Acc: 66.73%\n",
      "Epoch: 5300,     Training Loss: 0.4519086182117462, Training Acc: 74.85%\n",
      "              Val Loss: 1.0839215517044067, Val Acc: 66.73%\n",
      "Epoch: 5301,     Training Loss: 0.3694330155849457, Training Acc: 74.86%\n",
      "              Val Loss: 1.0530458688735962, Val Acc: 66.74%\n",
      "Epoch: 5302,     Training Loss: 0.3527121841907501, Training Acc: 74.86%\n",
      "              Val Loss: 1.1065868139266968, Val Acc: 66.74%\n",
      "Epoch: 5303,     Training Loss: 0.4463597536087036, Training Acc: 74.86%\n",
      "              Val Loss: 1.0388116836547852, Val Acc: 66.74%\n",
      "Epoch: 5304,     Training Loss: 0.339822918176651, Training Acc: 74.86%\n",
      "              Val Loss: 1.1389492750167847, Val Acc: 66.74%\n",
      "Epoch: 5305,     Training Loss: 0.3837675154209137, Training Acc: 74.86%\n",
      "              Val Loss: 1.0080395936965942, Val Acc: 66.74%\n",
      "Epoch: 5306,     Training Loss: 0.32856932282447815, Training Acc: 74.86%\n",
      "              Val Loss: 1.0555789470672607, Val Acc: 66.74%\n",
      "Epoch: 5307,     Training Loss: 0.36318543553352356, Training Acc: 74.87%\n",
      "              Val Loss: 1.0476666688919067, Val Acc: 66.74%\n",
      "Epoch: 5308,     Training Loss: 0.3261216878890991, Training Acc: 74.87%\n",
      "              Val Loss: 1.1015398502349854, Val Acc: 66.74%\n",
      "Epoch: 5309,     Training Loss: 0.3475995659828186, Training Acc: 74.87%\n",
      "              Val Loss: 1.032989740371704, Val Acc: 66.74%\n",
      "Epoch: 5310,     Training Loss: 0.3293669521808624, Training Acc: 74.87%\n",
      "              Val Loss: 1.0284370183944702, Val Acc: 66.74%\n",
      "Epoch: 5311,     Training Loss: 0.3363839089870453, Training Acc: 74.87%\n",
      "              Val Loss: 1.0463078022003174, Val Acc: 66.74%\n",
      "Epoch: 5312,     Training Loss: 0.3414151668548584, Training Acc: 74.88%\n",
      "              Val Loss: 1.0732431411743164, Val Acc: 66.74%\n",
      "Epoch: 5313,     Training Loss: 0.391951322555542, Training Acc: 74.88%\n",
      "              Val Loss: 1.0308504104614258, Val Acc: 66.75%\n",
      "Epoch: 5314,     Training Loss: 0.36312541365623474, Training Acc: 74.88%\n",
      "              Val Loss: 1.1157896518707275, Val Acc: 66.75%\n",
      "Epoch: 5315,     Training Loss: 0.444315642118454, Training Acc: 74.88%\n",
      "              Val Loss: 1.0475221872329712, Val Acc: 66.75%\n",
      "Epoch: 5316,     Training Loss: 0.3334948718547821, Training Acc: 74.88%\n",
      "              Val Loss: 1.0829079151153564, Val Acc: 66.75%\n",
      "Epoch: 5317,     Training Loss: 0.37592774629592896, Training Acc: 74.88%\n",
      "              Val Loss: 1.054309368133545, Val Acc: 66.75%\n",
      "Epoch: 5318,     Training Loss: 0.35071972012519836, Training Acc: 74.89%\n",
      "              Val Loss: 1.130743145942688, Val Acc: 66.75%\n",
      "Epoch: 5319,     Training Loss: 0.4016018211841583, Training Acc: 74.89%\n",
      "              Val Loss: 1.0259572267532349, Val Acc: 66.75%\n",
      "Epoch: 5320,     Training Loss: 0.38885775208473206, Training Acc: 74.89%\n",
      "              Val Loss: 1.0257196426391602, Val Acc: 66.75%\n",
      "Epoch: 5321,     Training Loss: 0.35105571150779724, Training Acc: 74.89%\n",
      "              Val Loss: 1.0697565078735352, Val Acc: 66.75%\n",
      "Epoch: 5322,     Training Loss: 0.36529019474983215, Training Acc: 74.89%\n",
      "              Val Loss: 1.0576173067092896, Val Acc: 66.75%\n",
      "Epoch: 5323,     Training Loss: 0.3892245888710022, Training Acc: 74.89%\n",
      "              Val Loss: 1.0806621313095093, Val Acc: 66.75%\n",
      "Epoch: 5324,     Training Loss: 0.36908575892448425, Training Acc: 74.90%\n",
      "              Val Loss: 1.1257739067077637, Val Acc: 66.75%\n",
      "Epoch: 5325,     Training Loss: 0.34688496589660645, Training Acc: 74.90%\n",
      "              Val Loss: 1.0672178268432617, Val Acc: 66.75%\n",
      "Epoch: 5326,     Training Loss: 0.3244689702987671, Training Acc: 74.90%\n",
      "              Val Loss: 1.032192349433899, Val Acc: 66.75%\n",
      "Epoch: 5327,     Training Loss: 0.33737805485725403, Training Acc: 74.90%\n",
      "              Val Loss: 0.9989357590675354, Val Acc: 66.76%\n",
      "Epoch: 5328,     Training Loss: 0.31001728773117065, Training Acc: 74.90%\n",
      "              Val Loss: 1.0506889820098877, Val Acc: 66.76%\n",
      "Epoch: 5329,     Training Loss: 0.3367709219455719, Training Acc: 74.91%\n",
      "              Val Loss: 1.0035098791122437, Val Acc: 66.76%\n",
      "Epoch: 5330,     Training Loss: 0.2960491478443146, Training Acc: 74.91%\n",
      "              Val Loss: 1.0347394943237305, Val Acc: 66.76%\n",
      "Epoch: 5331,     Training Loss: 0.3235677480697632, Training Acc: 74.91%\n",
      "              Val Loss: 1.0570001602172852, Val Acc: 66.76%\n",
      "Epoch: 5332,     Training Loss: 0.3026013672351837, Training Acc: 74.91%\n",
      "              Val Loss: 1.0699188709259033, Val Acc: 66.76%\n",
      "Epoch: 5333,     Training Loss: 0.31078505516052246, Training Acc: 74.92%\n",
      "              Val Loss: 1.0136545896530151, Val Acc: 66.76%\n",
      "Epoch: 5334,     Training Loss: 0.31285473704338074, Training Acc: 74.92%\n",
      "              Val Loss: 1.0141308307647705, Val Acc: 66.76%\n",
      "Epoch: 5335,     Training Loss: 0.3081291913986206, Training Acc: 74.92%\n",
      "              Val Loss: 1.041377067565918, Val Acc: 66.76%\n",
      "Epoch: 5336,     Training Loss: 0.32357653975486755, Training Acc: 74.92%\n",
      "              Val Loss: 1.0311932563781738, Val Acc: 66.76%\n",
      "Epoch: 5337,     Training Loss: 0.3081626892089844, Training Acc: 74.92%\n",
      "              Val Loss: 1.0394575595855713, Val Acc: 66.76%\n",
      "Epoch: 5338,     Training Loss: 0.33431366086006165, Training Acc: 74.93%\n",
      "              Val Loss: 1.074560523033142, Val Acc: 66.77%\n",
      "Epoch: 5339,     Training Loss: 0.31666091084480286, Training Acc: 74.93%\n",
      "              Val Loss: 1.0690867900848389, Val Acc: 66.77%\n",
      "Epoch: 5340,     Training Loss: 0.32659459114074707, Training Acc: 74.93%\n",
      "              Val Loss: 1.0400269031524658, Val Acc: 66.77%\n",
      "Epoch: 5341,     Training Loss: 0.31039026379585266, Training Acc: 74.93%\n",
      "              Val Loss: 1.0111017227172852, Val Acc: 66.77%\n",
      "Epoch: 5342,     Training Loss: 0.2888369858264923, Training Acc: 74.94%\n",
      "              Val Loss: 1.04097580909729, Val Acc: 66.77%\n",
      "Epoch: 5343,     Training Loss: 0.3046922981739044, Training Acc: 74.94%\n",
      "              Val Loss: 1.0265936851501465, Val Acc: 66.77%\n",
      "Epoch: 5344,     Training Loss: 0.30180302262306213, Training Acc: 74.94%\n",
      "              Val Loss: 1.0432957410812378, Val Acc: 66.77%\n",
      "Epoch: 5345,     Training Loss: 0.33111003041267395, Training Acc: 74.94%\n",
      "              Val Loss: 1.0881251096725464, Val Acc: 66.77%\n",
      "Epoch: 5346,     Training Loss: 0.3287960886955261, Training Acc: 74.94%\n",
      "              Val Loss: 1.0877074003219604, Val Acc: 66.77%\n",
      "Epoch: 5347,     Training Loss: 0.36467796564102173, Training Acc: 74.95%\n",
      "              Val Loss: 1.0415637493133545, Val Acc: 66.77%\n",
      "Epoch: 5348,     Training Loss: 0.3136639893054962, Training Acc: 74.95%\n",
      "              Val Loss: 1.0382637977600098, Val Acc: 66.77%\n",
      "Epoch: 5349,     Training Loss: 0.29904285073280334, Training Acc: 74.95%\n",
      "              Val Loss: 1.052175760269165, Val Acc: 66.78%\n",
      "Epoch: 5350,     Training Loss: 0.33061087131500244, Training Acc: 74.95%\n",
      "              Val Loss: 1.0760009288787842, Val Acc: 66.78%\n",
      "Epoch: 5351,     Training Loss: 0.3350786566734314, Training Acc: 74.95%\n",
      "              Val Loss: 1.0644450187683105, Val Acc: 66.78%\n",
      "Epoch: 5352,     Training Loss: 0.3448949456214905, Training Acc: 74.96%\n",
      "              Val Loss: 1.0660144090652466, Val Acc: 66.78%\n",
      "Epoch: 5353,     Training Loss: 0.30523091554641724, Training Acc: 74.96%\n",
      "              Val Loss: 1.052302360534668, Val Acc: 66.78%\n",
      "Epoch: 5354,     Training Loss: 0.3050697445869446, Training Acc: 74.96%\n",
      "              Val Loss: 1.046095371246338, Val Acc: 66.78%\n",
      "Epoch: 5355,     Training Loss: 0.3275611400604248, Training Acc: 74.96%\n",
      "              Val Loss: 1.0750513076782227, Val Acc: 66.78%\n",
      "Epoch: 5356,     Training Loss: 0.3240785598754883, Training Acc: 74.96%\n",
      "              Val Loss: 1.0344133377075195, Val Acc: 66.78%\n",
      "Epoch: 5357,     Training Loss: 0.3175688087940216, Training Acc: 74.97%\n",
      "              Val Loss: 1.0362533330917358, Val Acc: 66.78%\n",
      "Epoch: 5358,     Training Loss: 0.3040739893913269, Training Acc: 74.97%\n",
      "              Val Loss: 1.0406006574630737, Val Acc: 66.78%\n",
      "Epoch: 5359,     Training Loss: 0.28999564051628113, Training Acc: 74.97%\n",
      "              Val Loss: 1.0425691604614258, Val Acc: 66.78%\n",
      "Epoch: 5360,     Training Loss: 0.29723650217056274, Training Acc: 74.97%\n",
      "              Val Loss: 1.072444200515747, Val Acc: 66.79%\n",
      "Epoch: 5361,     Training Loss: 0.3183058202266693, Training Acc: 74.98%\n",
      "              Val Loss: 1.0807499885559082, Val Acc: 66.79%\n",
      "Epoch: 5362,     Training Loss: 0.3487838804721832, Training Acc: 74.98%\n",
      "              Val Loss: 1.0639241933822632, Val Acc: 66.79%\n",
      "Epoch: 5363,     Training Loss: 0.3159436285495758, Training Acc: 74.98%\n",
      "              Val Loss: 1.0116063356399536, Val Acc: 66.79%\n",
      "Epoch: 5364,     Training Loss: 0.2917409837245941, Training Acc: 74.98%\n",
      "              Val Loss: 1.0297002792358398, Val Acc: 66.79%\n",
      "Epoch: 5365,     Training Loss: 0.29361891746520996, Training Acc: 74.99%\n",
      "              Val Loss: 1.0663995742797852, Val Acc: 66.79%\n",
      "Epoch: 5366,     Training Loss: 0.31202995777130127, Training Acc: 74.99%\n",
      "              Val Loss: 1.0688368082046509, Val Acc: 66.79%\n",
      "Epoch: 5367,     Training Loss: 0.35345354676246643, Training Acc: 74.99%\n",
      "              Val Loss: 1.090085506439209, Val Acc: 66.79%\n",
      "Epoch: 5368,     Training Loss: 0.3253568410873413, Training Acc: 74.99%\n",
      "              Val Loss: 1.032617449760437, Val Acc: 66.79%\n",
      "Epoch: 5369,     Training Loss: 0.2959001064300537, Training Acc: 74.99%\n",
      "              Val Loss: 1.0208929777145386, Val Acc: 66.79%\n",
      "Epoch: 5370,     Training Loss: 0.29050183296203613, Training Acc: 75.00%\n",
      "              Val Loss: 1.0666990280151367, Val Acc: 66.79%\n",
      "Epoch: 5371,     Training Loss: 0.3096470534801483, Training Acc: 75.00%\n",
      "              Val Loss: 1.083804965019226, Val Acc: 66.79%\n",
      "Epoch: 5372,     Training Loss: 0.347860187292099, Training Acc: 75.00%\n",
      "              Val Loss: 1.0828289985656738, Val Acc: 66.79%\n",
      "Epoch: 5373,     Training Loss: 0.33682841062545776, Training Acc: 75.00%\n",
      "              Val Loss: 1.0419470071792603, Val Acc: 66.80%\n",
      "Epoch: 5374,     Training Loss: 0.3237667381763458, Training Acc: 75.00%\n",
      "              Val Loss: 1.0535037517547607, Val Acc: 66.80%\n",
      "Epoch: 5375,     Training Loss: 0.2935107350349426, Training Acc: 75.01%\n",
      "              Val Loss: 1.0740686655044556, Val Acc: 66.80%\n",
      "Epoch: 5376,     Training Loss: 0.32029208540916443, Training Acc: 75.01%\n",
      "              Val Loss: 1.1193642616271973, Val Acc: 66.80%\n",
      "Epoch: 5377,     Training Loss: 0.4049132466316223, Training Acc: 75.01%\n",
      "              Val Loss: 1.0985511541366577, Val Acc: 66.80%\n",
      "Epoch: 5378,     Training Loss: 0.3342169225215912, Training Acc: 75.01%\n",
      "              Val Loss: 1.0162756443023682, Val Acc: 66.80%\n",
      "Epoch: 5379,     Training Loss: 0.29410412907600403, Training Acc: 75.01%\n",
      "              Val Loss: 1.016375184059143, Val Acc: 66.80%\n",
      "Epoch: 5380,     Training Loss: 0.30571281909942627, Training Acc: 75.02%\n",
      "              Val Loss: 1.0693475008010864, Val Acc: 66.80%\n",
      "Epoch: 5381,     Training Loss: 0.31294429302215576, Training Acc: 75.02%\n",
      "              Val Loss: 1.0576764345169067, Val Acc: 66.80%\n",
      "Epoch: 5382,     Training Loss: 0.31684598326683044, Training Acc: 75.02%\n",
      "              Val Loss: 1.034379243850708, Val Acc: 66.80%\n",
      "Epoch: 5383,     Training Loss: 0.2929416000843048, Training Acc: 75.02%\n",
      "              Val Loss: 1.0597020387649536, Val Acc: 66.80%\n",
      "Epoch: 5384,     Training Loss: 0.3000045120716095, Training Acc: 75.03%\n",
      "              Val Loss: 1.081586241722107, Val Acc: 66.80%\n",
      "Epoch: 5385,     Training Loss: 0.3427492082118988, Training Acc: 75.03%\n",
      "              Val Loss: 1.0572134256362915, Val Acc: 66.81%\n",
      "Epoch: 5386,     Training Loss: 0.32240498065948486, Training Acc: 75.03%\n",
      "              Val Loss: 1.0446550846099854, Val Acc: 66.81%\n",
      "Epoch: 5387,     Training Loss: 0.2985469698905945, Training Acc: 75.03%\n",
      "              Val Loss: 1.0467369556427002, Val Acc: 66.81%\n",
      "Epoch: 5388,     Training Loss: 0.28787684440612793, Training Acc: 75.03%\n",
      "              Val Loss: 1.0600084066390991, Val Acc: 66.81%\n",
      "Epoch: 5389,     Training Loss: 0.3124050199985504, Training Acc: 75.04%\n",
      "              Val Loss: 1.0564813613891602, Val Acc: 66.81%\n",
      "Epoch: 5390,     Training Loss: 0.32010605931282043, Training Acc: 75.04%\n",
      "              Val Loss: 1.0911253690719604, Val Acc: 66.81%\n",
      "Epoch: 5391,     Training Loss: 0.3177075684070587, Training Acc: 75.04%\n",
      "              Val Loss: 1.038791537284851, Val Acc: 66.81%\n",
      "Epoch: 5392,     Training Loss: 0.32968807220458984, Training Acc: 75.04%\n",
      "              Val Loss: 1.0198813676834106, Val Acc: 66.81%\n",
      "Epoch: 5393,     Training Loss: 0.28613245487213135, Training Acc: 75.04%\n",
      "              Val Loss: 1.0713629722595215, Val Acc: 66.81%\n",
      "Epoch: 5394,     Training Loss: 0.3149089217185974, Training Acc: 75.05%\n",
      "              Val Loss: 1.0375210046768188, Val Acc: 66.81%\n",
      "Epoch: 5395,     Training Loss: 0.3149067163467407, Training Acc: 75.05%\n",
      "              Val Loss: 1.0975489616394043, Val Acc: 66.81%\n",
      "Epoch: 5396,     Training Loss: 0.33315715193748474, Training Acc: 75.05%\n",
      "              Val Loss: 1.1203233003616333, Val Acc: 66.81%\n",
      "Epoch: 5397,     Training Loss: 0.375213086605072, Training Acc: 75.05%\n",
      "              Val Loss: 1.0894676446914673, Val Acc: 66.81%\n",
      "Epoch: 5398,     Training Loss: 0.3310909569263458, Training Acc: 75.05%\n",
      "              Val Loss: 1.0628342628479004, Val Acc: 66.82%\n",
      "Epoch: 5399,     Training Loss: 0.34719982743263245, Training Acc: 75.06%\n",
      "              Val Loss: 1.053187370300293, Val Acc: 66.82%\n",
      "Epoch: 5400,     Training Loss: 0.305856317281723, Training Acc: 75.06%\n",
      "              Val Loss: 1.103532075881958, Val Acc: 66.82%\n",
      "Epoch: 5401,     Training Loss: 0.3615303337574005, Training Acc: 75.06%\n",
      "              Val Loss: 1.1249134540557861, Val Acc: 66.82%\n",
      "Epoch: 5402,     Training Loss: 0.4396779239177704, Training Acc: 75.06%\n",
      "              Val Loss: 1.1645293235778809, Val Acc: 66.82%\n",
      "Epoch: 5403,     Training Loss: 0.390446275472641, Training Acc: 75.06%\n",
      "              Val Loss: 1.0693638324737549, Val Acc: 66.82%\n",
      "Epoch: 5404,     Training Loss: 0.33359092473983765, Training Acc: 75.06%\n",
      "              Val Loss: 1.0597718954086304, Val Acc: 66.82%\n",
      "Epoch: 5405,     Training Loss: 0.33292824029922485, Training Acc: 75.07%\n",
      "              Val Loss: 1.0912171602249146, Val Acc: 66.82%\n",
      "Epoch: 5406,     Training Loss: 0.3464031219482422, Training Acc: 75.07%\n",
      "              Val Loss: 1.1981183290481567, Val Acc: 66.82%\n",
      "Epoch: 5407,     Training Loss: 0.44622352719306946, Training Acc: 75.07%\n",
      "              Val Loss: 1.1056212186813354, Val Acc: 66.82%\n",
      "Epoch: 5408,     Training Loss: 0.36853650212287903, Training Acc: 75.07%\n",
      "              Val Loss: 1.0482608079910278, Val Acc: 66.82%\n",
      "Epoch: 5409,     Training Loss: 0.36892232298851013, Training Acc: 75.07%\n",
      "              Val Loss: 1.0125172138214111, Val Acc: 66.82%\n",
      "Epoch: 5410,     Training Loss: 0.318129301071167, Training Acc: 75.07%\n",
      "              Val Loss: 1.0929837226867676, Val Acc: 66.82%\n",
      "Epoch: 5411,     Training Loss: 0.3592413365840912, Training Acc: 75.08%\n",
      "              Val Loss: 1.027828335762024, Val Acc: 66.83%\n",
      "Epoch: 5412,     Training Loss: 0.32800862193107605, Training Acc: 75.08%\n",
      "              Val Loss: 1.0546590089797974, Val Acc: 66.83%\n",
      "Epoch: 5413,     Training Loss: 0.35070183873176575, Training Acc: 75.08%\n",
      "              Val Loss: 1.0748878717422485, Val Acc: 66.83%\n",
      "Epoch: 5414,     Training Loss: 0.3396393954753876, Training Acc: 75.08%\n",
      "              Val Loss: 1.0640254020690918, Val Acc: 66.83%\n",
      "Epoch: 5415,     Training Loss: 0.312094122171402, Training Acc: 75.08%\n",
      "              Val Loss: 1.0500324964523315, Val Acc: 66.83%\n",
      "Epoch: 5416,     Training Loss: 0.3234333097934723, Training Acc: 75.09%\n",
      "              Val Loss: 1.0554081201553345, Val Acc: 66.83%\n",
      "Epoch: 5417,     Training Loss: 0.3084026575088501, Training Acc: 75.09%\n",
      "              Val Loss: 1.097764253616333, Val Acc: 66.83%\n",
      "Epoch: 5418,     Training Loss: 0.32957351207733154, Training Acc: 75.09%\n",
      "              Val Loss: 1.04652738571167, Val Acc: 66.83%\n",
      "Epoch: 5419,     Training Loss: 0.33066630363464355, Training Acc: 75.09%\n",
      "              Val Loss: 1.0566890239715576, Val Acc: 66.83%\n",
      "Epoch: 5420,     Training Loss: 0.327957421541214, Training Acc: 75.09%\n",
      "              Val Loss: 1.1036051511764526, Val Acc: 66.83%\n",
      "Epoch: 5421,     Training Loss: 0.3491130471229553, Training Acc: 75.10%\n",
      "              Val Loss: 1.0741441249847412, Val Acc: 66.83%\n",
      "Epoch: 5422,     Training Loss: 0.30139991641044617, Training Acc: 75.10%\n",
      "              Val Loss: 1.0519986152648926, Val Acc: 66.83%\n",
      "Epoch: 5423,     Training Loss: 0.31240013241767883, Training Acc: 75.10%\n",
      "              Val Loss: 1.0610193014144897, Val Acc: 66.83%\n",
      "Epoch: 5424,     Training Loss: 0.29521840810775757, Training Acc: 75.10%\n",
      "              Val Loss: 1.0919474363327026, Val Acc: 66.84%\n",
      "Epoch: 5425,     Training Loss: 0.32371291518211365, Training Acc: 75.10%\n",
      "              Val Loss: 1.108739972114563, Val Acc: 66.84%\n",
      "Epoch: 5426,     Training Loss: 0.39848899841308594, Training Acc: 75.11%\n",
      "              Val Loss: 1.070797085762024, Val Acc: 66.84%\n",
      "Epoch: 5427,     Training Loss: 0.33455491065979004, Training Acc: 75.11%\n",
      "              Val Loss: 1.0925493240356445, Val Acc: 66.84%\n",
      "Epoch: 5428,     Training Loss: 0.3308630883693695, Training Acc: 75.11%\n",
      "              Val Loss: 1.0510563850402832, Val Acc: 66.84%\n",
      "Epoch: 5429,     Training Loss: 0.3066176772117615, Training Acc: 75.11%\n",
      "              Val Loss: 1.1370948553085327, Val Acc: 66.84%\n",
      "Epoch: 5430,     Training Loss: 0.36047467589378357, Training Acc: 75.11%\n",
      "              Val Loss: 1.1352696418762207, Val Acc: 66.84%\n",
      "Epoch: 5431,     Training Loss: 0.38185009360313416, Training Acc: 75.12%\n",
      "              Val Loss: 1.124190330505371, Val Acc: 66.84%\n",
      "Epoch: 5432,     Training Loss: 0.3432299792766571, Training Acc: 75.12%\n",
      "              Val Loss: 1.0417007207870483, Val Acc: 66.84%\n",
      "Epoch: 5433,     Training Loss: 0.32271358370780945, Training Acc: 75.12%\n",
      "              Val Loss: 1.029258370399475, Val Acc: 66.84%\n",
      "Epoch: 5434,     Training Loss: 0.30169597268104553, Training Acc: 75.12%\n",
      "              Val Loss: 1.0840367078781128, Val Acc: 66.84%\n",
      "Epoch: 5435,     Training Loss: 0.35218605399131775, Training Acc: 75.12%\n",
      "              Val Loss: 1.107692003250122, Val Acc: 66.84%\n",
      "Epoch: 5436,     Training Loss: 0.40845853090286255, Training Acc: 75.12%\n",
      "              Val Loss: 1.1674267053604126, Val Acc: 66.84%\n",
      "Epoch: 5437,     Training Loss: 0.39426785707473755, Training Acc: 75.13%\n",
      "              Val Loss: 1.1047645807266235, Val Acc: 66.84%\n",
      "Epoch: 5438,     Training Loss: 0.34079229831695557, Training Acc: 75.13%\n",
      "              Val Loss: 1.0897594690322876, Val Acc: 66.84%\n",
      "Epoch: 5439,     Training Loss: 0.31757837533950806, Training Acc: 75.13%\n",
      "              Val Loss: 1.1333736181259155, Val Acc: 66.85%\n",
      "Epoch: 5440,     Training Loss: 0.35473090410232544, Training Acc: 75.13%\n",
      "              Val Loss: 1.0732531547546387, Val Acc: 66.85%\n",
      "Epoch: 5441,     Training Loss: 0.3394091725349426, Training Acc: 75.13%\n",
      "              Val Loss: 1.0634313821792603, Val Acc: 66.85%\n",
      "Epoch: 5442,     Training Loss: 0.3211826682090759, Training Acc: 75.14%\n",
      "              Val Loss: 1.0522867441177368, Val Acc: 66.85%\n",
      "Epoch: 5443,     Training Loss: 0.31172263622283936, Training Acc: 75.14%\n",
      "              Val Loss: 1.1187140941619873, Val Acc: 66.85%\n",
      "Epoch: 5444,     Training Loss: 0.3630482852458954, Training Acc: 75.14%\n",
      "              Val Loss: 1.0631300210952759, Val Acc: 66.85%\n",
      "Epoch: 5445,     Training Loss: 0.29896262288093567, Training Acc: 75.14%\n",
      "              Val Loss: 1.0676933526992798, Val Acc: 66.85%\n",
      "Epoch: 5446,     Training Loss: 0.30605611205101013, Training Acc: 75.14%\n",
      "              Val Loss: 1.0421470403671265, Val Acc: 66.85%\n",
      "Epoch: 5447,     Training Loss: 0.2939937710762024, Training Acc: 75.15%\n",
      "              Val Loss: 1.0880465507507324, Val Acc: 66.85%\n",
      "Epoch: 5448,     Training Loss: 0.3323259651660919, Training Acc: 75.15%\n",
      "              Val Loss: 1.074520468711853, Val Acc: 66.85%\n",
      "Epoch: 5449,     Training Loss: 0.3601550757884979, Training Acc: 75.15%\n",
      "              Val Loss: 1.0670455694198608, Val Acc: 66.85%\n",
      "Epoch: 5450,     Training Loss: 0.3104037046432495, Training Acc: 75.15%\n",
      "              Val Loss: 1.0499181747436523, Val Acc: 66.85%\n",
      "Epoch: 5451,     Training Loss: 0.29531237483024597, Training Acc: 75.15%\n",
      "              Val Loss: 1.0663987398147583, Val Acc: 66.86%\n",
      "Epoch: 5452,     Training Loss: 0.3135018050670624, Training Acc: 75.16%\n",
      "              Val Loss: 1.1024044752120972, Val Acc: 66.86%\n",
      "Epoch: 5453,     Training Loss: 0.3184175491333008, Training Acc: 75.16%\n",
      "              Val Loss: 1.0540509223937988, Val Acc: 66.86%\n",
      "Epoch: 5454,     Training Loss: 0.3012179136276245, Training Acc: 75.16%\n",
      "              Val Loss: 1.060044288635254, Val Acc: 66.86%\n",
      "Epoch: 5455,     Training Loss: 0.29183173179626465, Training Acc: 75.16%\n",
      "              Val Loss: 1.0529416799545288, Val Acc: 66.86%\n",
      "Epoch: 5456,     Training Loss: 0.2833493947982788, Training Acc: 75.16%\n",
      "              Val Loss: 1.072716236114502, Val Acc: 66.86%\n",
      "Epoch: 5457,     Training Loss: 0.30682092905044556, Training Acc: 75.17%\n",
      "              Val Loss: 1.089461326599121, Val Acc: 66.86%\n",
      "Epoch: 5458,     Training Loss: 0.30570167303085327, Training Acc: 75.17%\n",
      "              Val Loss: 1.100826621055603, Val Acc: 66.86%\n",
      "Epoch: 5459,     Training Loss: 0.3454030752182007, Training Acc: 75.17%\n",
      "              Val Loss: 1.0722914934158325, Val Acc: 66.86%\n",
      "Epoch: 5460,     Training Loss: 0.3028024137020111, Training Acc: 75.17%\n",
      "              Val Loss: 1.060776710510254, Val Acc: 66.86%\n",
      "Epoch: 5461,     Training Loss: 0.2864436209201813, Training Acc: 75.18%\n",
      "              Val Loss: 1.0647227764129639, Val Acc: 66.86%\n",
      "Epoch: 5462,     Training Loss: 0.30644693970680237, Training Acc: 75.18%\n",
      "              Val Loss: 1.0831236839294434, Val Acc: 66.86%\n",
      "Epoch: 5463,     Training Loss: 0.31677860021591187, Training Acc: 75.18%\n",
      "              Val Loss: 1.0737693309783936, Val Acc: 66.87%\n",
      "Epoch: 5464,     Training Loss: 0.3211292624473572, Training Acc: 75.18%\n",
      "              Val Loss: 1.0642428398132324, Val Acc: 66.87%\n",
      "Epoch: 5465,     Training Loss: 0.2941872477531433, Training Acc: 75.18%\n",
      "              Val Loss: 1.0477794408798218, Val Acc: 66.87%\n",
      "Epoch: 5466,     Training Loss: 0.2883008122444153, Training Acc: 75.19%\n",
      "              Val Loss: 1.0597243309020996, Val Acc: 66.87%\n",
      "Epoch: 5467,     Training Loss: 0.28207579255104065, Training Acc: 75.19%\n",
      "              Val Loss: 1.0953116416931152, Val Acc: 66.87%\n",
      "Epoch: 5468,     Training Loss: 0.30910080671310425, Training Acc: 75.19%\n",
      "              Val Loss: 1.0994678735733032, Val Acc: 66.87%\n",
      "Epoch: 5469,     Training Loss: 0.359684556722641, Training Acc: 75.19%\n",
      "              Val Loss: 1.112457513809204, Val Acc: 66.87%\n",
      "Epoch: 5470,     Training Loss: 0.3303195834159851, Training Acc: 75.19%\n",
      "              Val Loss: 1.0453660488128662, Val Acc: 66.87%\n",
      "Epoch: 5471,     Training Loss: 0.30070871114730835, Training Acc: 75.20%\n",
      "              Val Loss: 1.0437926054000854, Val Acc: 66.87%\n",
      "Epoch: 5472,     Training Loss: 0.29136550426483154, Training Acc: 75.20%\n",
      "              Val Loss: 1.1329851150512695, Val Acc: 66.87%\n",
      "Epoch: 5473,     Training Loss: 0.34155720472335815, Training Acc: 75.20%\n",
      "              Val Loss: 1.1525222063064575, Val Acc: 66.87%\n",
      "Epoch: 5474,     Training Loss: 0.412173867225647, Training Acc: 75.20%\n",
      "              Val Loss: 1.1161130666732788, Val Acc: 66.87%\n",
      "Epoch: 5475,     Training Loss: 0.34630322456359863, Training Acc: 75.20%\n",
      "              Val Loss: 1.0546460151672363, Val Acc: 66.87%\n",
      "Epoch: 5476,     Training Loss: 0.306922048330307, Training Acc: 75.21%\n",
      "              Val Loss: 1.0448917150497437, Val Acc: 66.88%\n",
      "Epoch: 5477,     Training Loss: 0.303384006023407, Training Acc: 75.21%\n",
      "              Val Loss: 1.1054677963256836, Val Acc: 66.88%\n",
      "Epoch: 5478,     Training Loss: 0.33689311146736145, Training Acc: 75.21%\n",
      "              Val Loss: 1.085383653640747, Val Acc: 66.88%\n",
      "Epoch: 5479,     Training Loss: 0.3378206193447113, Training Acc: 75.21%\n",
      "              Val Loss: 1.0927835702896118, Val Acc: 66.88%\n",
      "Epoch: 5480,     Training Loss: 0.3059349060058594, Training Acc: 75.21%\n",
      "              Val Loss: 1.0697380304336548, Val Acc: 66.88%\n",
      "Epoch: 5481,     Training Loss: 0.30564072728157043, Training Acc: 75.22%\n",
      "              Val Loss: 1.0733376741409302, Val Acc: 66.88%\n",
      "Epoch: 5482,     Training Loss: 0.33898788690567017, Training Acc: 75.22%\n",
      "              Val Loss: 1.1047091484069824, Val Acc: 66.88%\n",
      "Epoch: 5483,     Training Loss: 0.31265267729759216, Training Acc: 75.22%\n",
      "              Val Loss: 1.0390180349349976, Val Acc: 66.88%\n",
      "Epoch: 5484,     Training Loss: 0.28533315658569336, Training Acc: 75.22%\n",
      "              Val Loss: 1.0512497425079346, Val Acc: 66.88%\n",
      "Epoch: 5485,     Training Loss: 0.2944217324256897, Training Acc: 75.22%\n",
      "              Val Loss: 1.0889073610305786, Val Acc: 66.88%\n",
      "Epoch: 5486,     Training Loss: 0.30466488003730774, Training Acc: 75.23%\n",
      "              Val Loss: 1.0703461170196533, Val Acc: 66.88%\n",
      "Epoch: 5487,     Training Loss: 0.32025155425071716, Training Acc: 75.23%\n",
      "              Val Loss: 1.0598223209381104, Val Acc: 66.88%\n",
      "Epoch: 5488,     Training Loss: 0.2957233190536499, Training Acc: 75.23%\n",
      "              Val Loss: 1.053844928741455, Val Acc: 66.88%\n",
      "Epoch: 5489,     Training Loss: 0.2935340404510498, Training Acc: 75.23%\n",
      "              Val Loss: 1.0328541994094849, Val Acc: 66.89%\n",
      "Epoch: 5490,     Training Loss: 0.27851080894470215, Training Acc: 75.23%\n",
      "              Val Loss: 1.0391263961791992, Val Acc: 66.89%\n",
      "Epoch: 5491,     Training Loss: 0.27949967980384827, Training Acc: 75.24%\n",
      "              Val Loss: 1.0609769821166992, Val Acc: 66.89%\n",
      "Epoch: 5492,     Training Loss: 0.29185548424720764, Training Acc: 75.24%\n",
      "              Val Loss: 1.071384072303772, Val Acc: 66.89%\n",
      "Epoch: 5493,     Training Loss: 0.29986822605133057, Training Acc: 75.24%\n",
      "              Val Loss: 1.070776104927063, Val Acc: 66.89%\n",
      "Epoch: 5494,     Training Loss: 0.31825000047683716, Training Acc: 75.24%\n",
      "              Val Loss: 1.0903699398040771, Val Acc: 66.89%\n",
      "Epoch: 5495,     Training Loss: 0.29668062925338745, Training Acc: 75.25%\n",
      "              Val Loss: 1.0513300895690918, Val Acc: 66.89%\n",
      "Epoch: 5496,     Training Loss: 0.286266565322876, Training Acc: 75.25%\n",
      "              Val Loss: 1.0488276481628418, Val Acc: 66.89%\n",
      "Epoch: 5497,     Training Loss: 0.27375853061676025, Training Acc: 75.25%\n",
      "              Val Loss: 1.074496865272522, Val Acc: 66.89%\n",
      "Epoch: 5498,     Training Loss: 0.2861208915710449, Training Acc: 75.25%\n",
      "              Val Loss: 1.0503742694854736, Val Acc: 66.89%\n",
      "Epoch: 5499,     Training Loss: 0.2973717749118805, Training Acc: 75.26%\n",
      "              Val Loss: 1.0798476934432983, Val Acc: 66.89%\n",
      "Epoch: 5500,     Training Loss: 0.2976858615875244, Training Acc: 75.26%\n",
      "              Val Loss: 1.095177412033081, Val Acc: 66.90%\n",
      "Epoch: 5501,     Training Loss: 0.3365207612514496, Training Acc: 75.26%\n",
      "              Val Loss: 1.0834590196609497, Val Acc: 66.90%\n",
      "Epoch: 5502,     Training Loss: 0.32500022649765015, Training Acc: 75.26%\n",
      "              Val Loss: 1.0954643487930298, Val Acc: 66.90%\n",
      "Epoch: 5503,     Training Loss: 0.3174341022968292, Training Acc: 75.26%\n",
      "              Val Loss: 1.0632473230361938, Val Acc: 66.90%\n",
      "Epoch: 5504,     Training Loss: 0.2779322564601898, Training Acc: 75.27%\n",
      "              Val Loss: 1.0892084836959839, Val Acc: 66.90%\n",
      "Epoch: 5505,     Training Loss: 0.31374356150627136, Training Acc: 75.27%\n",
      "              Val Loss: 1.1057863235473633, Val Acc: 66.90%\n",
      "Epoch: 5506,     Training Loss: 0.3392096757888794, Training Acc: 75.27%\n",
      "              Val Loss: 1.120995044708252, Val Acc: 66.90%\n",
      "Epoch: 5507,     Training Loss: 0.3341914117336273, Training Acc: 75.27%\n",
      "              Val Loss: 1.1250784397125244, Val Acc: 66.90%\n",
      "Epoch: 5508,     Training Loss: 0.41873466968536377, Training Acc: 75.27%\n",
      "              Val Loss: 1.0664572715759277, Val Acc: 66.90%\n",
      "Epoch: 5509,     Training Loss: 0.30845093727111816, Training Acc: 75.27%\n",
      "              Val Loss: 1.1623607873916626, Val Acc: 66.90%\n",
      "Epoch: 5510,     Training Loss: 0.39298027753829956, Training Acc: 75.28%\n",
      "              Val Loss: 1.163294792175293, Val Acc: 66.90%\n",
      "Epoch: 5511,     Training Loss: 0.45481574535369873, Training Acc: 75.28%\n",
      "              Val Loss: 1.2392200231552124, Val Acc: 66.90%\n",
      "Epoch: 5512,     Training Loss: 0.4360155761241913, Training Acc: 75.28%\n",
      "              Val Loss: 1.1287164688110352, Val Acc: 66.90%\n",
      "Epoch: 5513,     Training Loss: 0.39518752694129944, Training Acc: 75.28%\n",
      "              Val Loss: 1.0973799228668213, Val Acc: 66.90%\n",
      "Epoch: 5514,     Training Loss: 0.37120264768600464, Training Acc: 75.28%\n",
      "              Val Loss: 1.115479826927185, Val Acc: 66.90%\n",
      "Epoch: 5515,     Training Loss: 0.3887981176376343, Training Acc: 75.28%\n",
      "              Val Loss: 1.2322025299072266, Val Acc: 66.90%\n",
      "Epoch: 5516,     Training Loss: 0.46699169278144836, Training Acc: 75.28%\n",
      "              Val Loss: 1.0819823741912842, Val Acc: 66.90%\n",
      "Epoch: 5517,     Training Loss: 0.33970537781715393, Training Acc: 75.28%\n",
      "              Val Loss: 1.0916954278945923, Val Acc: 66.91%\n",
      "Epoch: 5518,     Training Loss: 0.38077598810195923, Training Acc: 75.29%\n",
      "              Val Loss: 1.0000271797180176, Val Acc: 66.91%\n",
      "Epoch: 5519,     Training Loss: 0.3192536234855652, Training Acc: 75.29%\n",
      "              Val Loss: 1.101407527923584, Val Acc: 66.91%\n",
      "Epoch: 5520,     Training Loss: 0.38606297969818115, Training Acc: 75.29%\n",
      "              Val Loss: 1.0554295778274536, Val Acc: 66.91%\n",
      "Epoch: 5521,     Training Loss: 0.3540108799934387, Training Acc: 75.29%\n",
      "              Val Loss: 1.1053305864334106, Val Acc: 66.91%\n",
      "Epoch: 5522,     Training Loss: 0.36714741587638855, Training Acc: 75.29%\n",
      "              Val Loss: 1.059874176979065, Val Acc: 66.91%\n",
      "Epoch: 5523,     Training Loss: 0.3196321427822113, Training Acc: 75.29%\n",
      "              Val Loss: 1.0831180810928345, Val Acc: 66.91%\n",
      "Epoch: 5524,     Training Loss: 0.3293643593788147, Training Acc: 75.30%\n",
      "              Val Loss: 1.048843264579773, Val Acc: 66.91%\n",
      "Epoch: 5525,     Training Loss: 0.32511529326438904, Training Acc: 75.30%\n",
      "              Val Loss: 1.0500811338424683, Val Acc: 66.91%\n",
      "Epoch: 5526,     Training Loss: 0.3281841278076172, Training Acc: 75.30%\n",
      "              Val Loss: 1.0778429508209229, Val Acc: 66.91%\n",
      "Epoch: 5527,     Training Loss: 0.3102966248989105, Training Acc: 75.30%\n",
      "              Val Loss: 1.0629726648330688, Val Acc: 66.91%\n",
      "Epoch: 5528,     Training Loss: 0.31327301263809204, Training Acc: 75.30%\n",
      "              Val Loss: 1.043472409248352, Val Acc: 66.92%\n",
      "Epoch: 5529,     Training Loss: 0.31148165464401245, Training Acc: 75.31%\n",
      "              Val Loss: 1.1185600757598877, Val Acc: 66.92%\n",
      "Epoch: 5530,     Training Loss: 0.3318254053592682, Training Acc: 75.31%\n",
      "              Val Loss: 1.0766613483428955, Val Acc: 66.92%\n",
      "Epoch: 5531,     Training Loss: 0.3085792064666748, Training Acc: 75.31%\n",
      "              Val Loss: 1.0850752592086792, Val Acc: 66.92%\n",
      "Epoch: 5532,     Training Loss: 0.30603697896003723, Training Acc: 75.31%\n",
      "              Val Loss: 1.0929803848266602, Val Acc: 66.92%\n",
      "Epoch: 5533,     Training Loss: 0.2913920283317566, Training Acc: 75.32%\n",
      "              Val Loss: 1.0749205350875854, Val Acc: 66.92%\n",
      "Epoch: 5534,     Training Loss: 0.288550466299057, Training Acc: 75.32%\n",
      "              Val Loss: 1.078286051750183, Val Acc: 66.92%\n",
      "Epoch: 5535,     Training Loss: 0.303493857383728, Training Acc: 75.32%\n",
      "              Val Loss: 1.0873080492019653, Val Acc: 66.92%\n",
      "Epoch: 5536,     Training Loss: 0.31160908937454224, Training Acc: 75.32%\n",
      "              Val Loss: 1.1058533191680908, Val Acc: 66.92%\n",
      "Epoch: 5537,     Training Loss: 0.3158234655857086, Training Acc: 75.32%\n",
      "              Val Loss: 1.096448540687561, Val Acc: 66.92%\n",
      "Epoch: 5538,     Training Loss: 0.3540729284286499, Training Acc: 75.33%\n",
      "              Val Loss: 1.1064354181289673, Val Acc: 66.92%\n",
      "Epoch: 5539,     Training Loss: 0.3041897416114807, Training Acc: 75.33%\n",
      "              Val Loss: 1.077242136001587, Val Acc: 66.92%\n",
      "Epoch: 5540,     Training Loss: 0.29067155718803406, Training Acc: 75.33%\n",
      "              Val Loss: 1.0868045091629028, Val Acc: 66.92%\n",
      "Epoch: 5541,     Training Loss: 0.3326346278190613, Training Acc: 75.33%\n",
      "              Val Loss: 1.1133625507354736, Val Acc: 66.92%\n",
      "Epoch: 5542,     Training Loss: 0.32783639430999756, Training Acc: 75.33%\n",
      "              Val Loss: 1.0967354774475098, Val Acc: 66.93%\n",
      "Epoch: 5543,     Training Loss: 0.33634620904922485, Training Acc: 75.34%\n",
      "              Val Loss: 1.070488691329956, Val Acc: 66.93%\n",
      "Epoch: 5544,     Training Loss: 0.3008635640144348, Training Acc: 75.34%\n",
      "              Val Loss: 1.065595269203186, Val Acc: 66.93%\n",
      "Epoch: 5545,     Training Loss: 0.286589115858078, Training Acc: 75.34%\n",
      "              Val Loss: 1.1098179817199707, Val Acc: 66.93%\n",
      "Epoch: 5546,     Training Loss: 0.32305508852005005, Training Acc: 75.34%\n",
      "              Val Loss: 1.1099708080291748, Val Acc: 66.93%\n",
      "Epoch: 5547,     Training Loss: 0.34024688601493835, Training Acc: 75.34%\n",
      "              Val Loss: 1.110440969467163, Val Acc: 66.93%\n",
      "Epoch: 5548,     Training Loss: 0.37129437923431396, Training Acc: 75.34%\n",
      "              Val Loss: 1.114498496055603, Val Acc: 66.93%\n",
      "Epoch: 5549,     Training Loss: 0.3268950581550598, Training Acc: 75.35%\n",
      "              Val Loss: 1.0610202550888062, Val Acc: 66.93%\n",
      "Epoch: 5550,     Training Loss: 0.2909790277481079, Training Acc: 75.35%\n",
      "              Val Loss: 1.0873676538467407, Val Acc: 66.93%\n",
      "Epoch: 5551,     Training Loss: 0.3119087815284729, Training Acc: 75.35%\n",
      "              Val Loss: 1.1409286260604858, Val Acc: 66.93%\n",
      "Epoch: 5552,     Training Loss: 0.31284230947494507, Training Acc: 75.35%\n",
      "              Val Loss: 1.0756034851074219, Val Acc: 66.93%\n",
      "Epoch: 5553,     Training Loss: 0.30050867795944214, Training Acc: 75.36%\n",
      "              Val Loss: 1.047622799873352, Val Acc: 66.93%\n",
      "Epoch: 5554,     Training Loss: 0.2838139832019806, Training Acc: 75.36%\n",
      "              Val Loss: 1.0790107250213623, Val Acc: 66.93%\n",
      "Epoch: 5555,     Training Loss: 0.29929471015930176, Training Acc: 75.36%\n",
      "              Val Loss: 1.0461986064910889, Val Acc: 66.93%\n",
      "Epoch: 5556,     Training Loss: 0.28815627098083496, Training Acc: 75.36%\n",
      "              Val Loss: 1.0921626091003418, Val Acc: 66.94%\n",
      "Epoch: 5557,     Training Loss: 0.3059636056423187, Training Acc: 75.36%\n",
      "              Val Loss: 1.1310510635375977, Val Acc: 66.94%\n",
      "Epoch: 5558,     Training Loss: 0.3302783966064453, Training Acc: 75.37%\n",
      "              Val Loss: 1.1430473327636719, Val Acc: 66.94%\n",
      "Epoch: 5559,     Training Loss: 0.3376878798007965, Training Acc: 75.37%\n",
      "              Val Loss: 1.0852583646774292, Val Acc: 66.94%\n",
      "Epoch: 5560,     Training Loss: 0.3376004099845886, Training Acc: 75.37%\n",
      "              Val Loss: 1.0958539247512817, Val Acc: 66.94%\n",
      "Epoch: 5561,     Training Loss: 0.3063991665840149, Training Acc: 75.37%\n",
      "              Val Loss: 1.1121431589126587, Val Acc: 66.94%\n",
      "Epoch: 5562,     Training Loss: 0.3422899544239044, Training Acc: 75.37%\n",
      "              Val Loss: 1.1501461267471313, Val Acc: 66.94%\n",
      "Epoch: 5563,     Training Loss: 0.4156046211719513, Training Acc: 75.37%\n",
      "              Val Loss: 1.1638939380645752, Val Acc: 66.94%\n",
      "Epoch: 5564,     Training Loss: 0.36043626070022583, Training Acc: 75.38%\n",
      "              Val Loss: 1.057487964630127, Val Acc: 66.94%\n",
      "Epoch: 5565,     Training Loss: 0.2855129837989807, Training Acc: 75.38%\n",
      "              Val Loss: 1.0948625802993774, Val Acc: 66.94%\n",
      "Epoch: 5566,     Training Loss: 0.3171704411506653, Training Acc: 75.38%\n",
      "              Val Loss: 1.1306661367416382, Val Acc: 66.94%\n",
      "Epoch: 5567,     Training Loss: 0.3085663616657257, Training Acc: 75.38%\n",
      "              Val Loss: 1.185014247894287, Val Acc: 66.94%\n",
      "Epoch: 5568,     Training Loss: 0.37441182136535645, Training Acc: 75.38%\n",
      "              Val Loss: 1.085675835609436, Val Acc: 66.94%\n",
      "Epoch: 5569,     Training Loss: 0.3290674090385437, Training Acc: 75.39%\n",
      "              Val Loss: 1.0769680738449097, Val Acc: 66.94%\n",
      "Epoch: 5570,     Training Loss: 0.3252144753932953, Training Acc: 75.39%\n",
      "              Val Loss: 1.0338770151138306, Val Acc: 66.94%\n",
      "Epoch: 5571,     Training Loss: 0.2930484414100647, Training Acc: 75.39%\n",
      "              Val Loss: 1.103061318397522, Val Acc: 66.95%\n",
      "Epoch: 5572,     Training Loss: 0.34031668305397034, Training Acc: 75.39%\n",
      "              Val Loss: 1.1157511472702026, Val Acc: 66.95%\n",
      "Epoch: 5573,     Training Loss: 0.3558267652988434, Training Acc: 75.39%\n",
      "              Val Loss: 1.1562999486923218, Val Acc: 66.95%\n",
      "Epoch: 5574,     Training Loss: 0.3484983742237091, Training Acc: 75.39%\n",
      "              Val Loss: 1.0902833938598633, Val Acc: 66.95%\n",
      "Epoch: 5575,     Training Loss: 0.3427603244781494, Training Acc: 75.40%\n",
      "              Val Loss: 1.09170663356781, Val Acc: 66.95%\n",
      "Epoch: 5576,     Training Loss: 0.3127845823764801, Training Acc: 75.40%\n",
      "              Val Loss: 1.157009482383728, Val Acc: 66.95%\n",
      "Epoch: 5577,     Training Loss: 0.3730013966560364, Training Acc: 75.40%\n",
      "              Val Loss: 1.157688856124878, Val Acc: 66.95%\n",
      "Epoch: 5578,     Training Loss: 0.4279962480068207, Training Acc: 75.40%\n",
      "              Val Loss: 1.1532214879989624, Val Acc: 66.95%\n",
      "Epoch: 5579,     Training Loss: 0.38104093074798584, Training Acc: 75.40%\n",
      "              Val Loss: 1.0737388134002686, Val Acc: 66.95%\n",
      "Epoch: 5580,     Training Loss: 0.3098726272583008, Training Acc: 75.40%\n",
      "              Val Loss: 1.0873727798461914, Val Acc: 66.95%\n",
      "Epoch: 5581,     Training Loss: 0.32838666439056396, Training Acc: 75.41%\n",
      "              Val Loss: 1.1355561017990112, Val Acc: 66.95%\n",
      "Epoch: 5582,     Training Loss: 0.331645131111145, Training Acc: 75.41%\n",
      "              Val Loss: 1.2265753746032715, Val Acc: 66.95%\n",
      "Epoch: 5583,     Training Loss: 0.4150274991989136, Training Acc: 75.41%\n",
      "              Val Loss: 1.0799506902694702, Val Acc: 66.95%\n",
      "Epoch: 5584,     Training Loss: 0.3250453472137451, Training Acc: 75.41%\n",
      "              Val Loss: 1.0792210102081299, Val Acc: 66.95%\n",
      "Epoch: 5585,     Training Loss: 0.3224789798259735, Training Acc: 75.41%\n",
      "              Val Loss: 1.0586777925491333, Val Acc: 66.95%\n",
      "Epoch: 5586,     Training Loss: 0.3308519423007965, Training Acc: 75.42%\n",
      "              Val Loss: 1.1072583198547363, Val Acc: 66.95%\n",
      "Epoch: 5587,     Training Loss: 0.3565536439418793, Training Acc: 75.42%\n",
      "              Val Loss: 1.0937473773956299, Val Acc: 66.96%\n",
      "Epoch: 5588,     Training Loss: 0.3334381580352783, Training Acc: 75.42%\n",
      "              Val Loss: 1.1276859045028687, Val Acc: 66.96%\n",
      "Epoch: 5589,     Training Loss: 0.32187530398368835, Training Acc: 75.42%\n",
      "              Val Loss: 1.0921978950500488, Val Acc: 66.96%\n",
      "Epoch: 5590,     Training Loss: 0.30620041489601135, Training Acc: 75.42%\n",
      "              Val Loss: 1.1155601739883423, Val Acc: 66.96%\n",
      "Epoch: 5591,     Training Loss: 0.33397233486175537, Training Acc: 75.42%\n",
      "              Val Loss: 1.0952256917953491, Val Acc: 66.96%\n",
      "Epoch: 5592,     Training Loss: 0.32329219579696655, Training Acc: 75.43%\n",
      "              Val Loss: 1.073385238647461, Val Acc: 66.96%\n",
      "Epoch: 5593,     Training Loss: 0.3277416527271271, Training Acc: 75.43%\n",
      "              Val Loss: 1.069932460784912, Val Acc: 66.96%\n",
      "Epoch: 5594,     Training Loss: 0.30322015285491943, Training Acc: 75.43%\n",
      "              Val Loss: 1.0637820959091187, Val Acc: 66.96%\n",
      "Epoch: 5595,     Training Loss: 0.28943005204200745, Training Acc: 75.43%\n",
      "              Val Loss: 1.0760979652404785, Val Acc: 66.96%\n",
      "Epoch: 5596,     Training Loss: 0.2923860549926758, Training Acc: 75.43%\n",
      "              Val Loss: 1.09128999710083, Val Acc: 66.96%\n",
      "Epoch: 5597,     Training Loss: 0.2956005930900574, Training Acc: 75.44%\n",
      "              Val Loss: 1.0827398300170898, Val Acc: 66.96%\n",
      "Epoch: 5598,     Training Loss: 0.2953397035598755, Training Acc: 75.44%\n",
      "              Val Loss: 1.0818654298782349, Val Acc: 66.96%\n",
      "Epoch: 5599,     Training Loss: 0.29028284549713135, Training Acc: 75.44%\n",
      "              Val Loss: 1.0587619543075562, Val Acc: 66.97%\n",
      "Epoch: 5600,     Training Loss: 0.2856121063232422, Training Acc: 75.44%\n",
      "              Val Loss: 1.0541861057281494, Val Acc: 66.97%\n",
      "Epoch: 5601,     Training Loss: 0.2782585024833679, Training Acc: 75.45%\n",
      "              Val Loss: 1.0765981674194336, Val Acc: 66.97%\n",
      "Epoch: 5602,     Training Loss: 0.27970653772354126, Training Acc: 75.45%\n",
      "              Val Loss: 1.0816115140914917, Val Acc: 66.97%\n",
      "Epoch: 5603,     Training Loss: 0.2823048233985901, Training Acc: 75.45%\n",
      "              Val Loss: 1.094473123550415, Val Acc: 66.97%\n",
      "Epoch: 5604,     Training Loss: 0.28630945086479187, Training Acc: 75.45%\n",
      "              Val Loss: 1.076841950416565, Val Acc: 66.97%\n",
      "Epoch: 5605,     Training Loss: 0.2815844714641571, Training Acc: 75.45%\n",
      "              Val Loss: 1.0953094959259033, Val Acc: 66.97%\n",
      "Epoch: 5606,     Training Loss: 0.28063470125198364, Training Acc: 75.46%\n",
      "              Val Loss: 1.0631810426712036, Val Acc: 66.97%\n",
      "Epoch: 5607,     Training Loss: 0.27130305767059326, Training Acc: 75.46%\n",
      "              Val Loss: 1.0693727731704712, Val Acc: 66.97%\n",
      "Epoch: 5608,     Training Loss: 0.2714183032512665, Training Acc: 75.46%\n",
      "              Val Loss: 1.0823460817337036, Val Acc: 66.97%\n",
      "Epoch: 5609,     Training Loss: 0.2705366611480713, Training Acc: 75.46%\n",
      "              Val Loss: 1.0677281618118286, Val Acc: 66.97%\n",
      "Epoch: 5610,     Training Loss: 0.27286192774772644, Training Acc: 75.47%\n",
      "              Val Loss: 1.0732476711273193, Val Acc: 66.97%\n",
      "Epoch: 5611,     Training Loss: 0.27060574293136597, Training Acc: 75.47%\n",
      "              Val Loss: 1.076077938079834, Val Acc: 66.98%\n",
      "Epoch: 5612,     Training Loss: 0.27576062083244324, Training Acc: 75.47%\n",
      "              Val Loss: 1.0779706239700317, Val Acc: 66.98%\n",
      "Epoch: 5613,     Training Loss: 0.2807139754295349, Training Acc: 75.47%\n",
      "              Val Loss: 1.0909606218338013, Val Acc: 66.98%\n",
      "Epoch: 5614,     Training Loss: 0.2952064573764801, Training Acc: 75.48%\n",
      "              Val Loss: 1.120827078819275, Val Acc: 66.98%\n",
      "Epoch: 5615,     Training Loss: 0.30073082447052, Training Acc: 75.48%\n",
      "              Val Loss: 1.1180999279022217, Val Acc: 66.98%\n",
      "Epoch: 5616,     Training Loss: 0.3512941002845764, Training Acc: 75.48%\n",
      "              Val Loss: 1.0933117866516113, Val Acc: 66.98%\n",
      "Epoch: 5617,     Training Loss: 0.29652896523475647, Training Acc: 75.48%\n",
      "              Val Loss: 1.0750129222869873, Val Acc: 66.98%\n",
      "Epoch: 5618,     Training Loss: 0.2803913950920105, Training Acc: 75.48%\n",
      "              Val Loss: 1.0562870502471924, Val Acc: 66.98%\n",
      "Epoch: 5619,     Training Loss: 0.28307044506073, Training Acc: 75.49%\n",
      "              Val Loss: 1.1036616563796997, Val Acc: 66.98%\n",
      "Epoch: 5620,     Training Loss: 0.29063260555267334, Training Acc: 75.49%\n",
      "              Val Loss: 1.1279433965682983, Val Acc: 66.98%\n",
      "Epoch: 5621,     Training Loss: 0.32396942377090454, Training Acc: 75.49%\n",
      "              Val Loss: 1.136003017425537, Val Acc: 66.98%\n",
      "Epoch: 5622,     Training Loss: 0.3324681520462036, Training Acc: 75.49%\n",
      "              Val Loss: 1.137392282485962, Val Acc: 66.98%\n",
      "Epoch: 5623,     Training Loss: 0.35909175872802734, Training Acc: 75.49%\n",
      "              Val Loss: 1.135119915008545, Val Acc: 66.98%\n",
      "Epoch: 5624,     Training Loss: 0.3096488118171692, Training Acc: 75.50%\n",
      "              Val Loss: 1.1021887063980103, Val Acc: 66.98%\n",
      "Epoch: 5625,     Training Loss: 0.3015027940273285, Training Acc: 75.50%\n",
      "              Val Loss: 1.1222636699676514, Val Acc: 66.98%\n",
      "Epoch: 5626,     Training Loss: 0.3346262276172638, Training Acc: 75.50%\n",
      "              Val Loss: 1.1658958196640015, Val Acc: 66.98%\n",
      "Epoch: 5627,     Training Loss: 0.32627391815185547, Training Acc: 75.50%\n",
      "              Val Loss: 1.0733668804168701, Val Acc: 66.99%\n",
      "Epoch: 5628,     Training Loss: 0.2938244342803955, Training Acc: 75.50%\n",
      "              Val Loss: 1.0774019956588745, Val Acc: 66.99%\n",
      "Epoch: 5629,     Training Loss: 0.2846551835536957, Training Acc: 75.50%\n",
      "              Val Loss: 1.1161750555038452, Val Acc: 66.99%\n",
      "Epoch: 5630,     Training Loss: 0.28892990946769714, Training Acc: 75.51%\n",
      "              Val Loss: 1.1139321327209473, Val Acc: 66.99%\n",
      "Epoch: 5631,     Training Loss: 0.31629717350006104, Training Acc: 75.51%\n",
      "              Val Loss: 1.0960164070129395, Val Acc: 66.99%\n",
      "Epoch: 5632,     Training Loss: 0.3023061454296112, Training Acc: 75.51%\n",
      "              Val Loss: 1.1283668279647827, Val Acc: 66.99%\n",
      "Epoch: 5633,     Training Loss: 0.3261348009109497, Training Acc: 75.51%\n",
      "              Val Loss: 1.0847458839416504, Val Acc: 66.99%\n",
      "Epoch: 5634,     Training Loss: 0.2800891697406769, Training Acc: 75.51%\n",
      "              Val Loss: 1.0919092893600464, Val Acc: 66.99%\n",
      "Epoch: 5635,     Training Loss: 0.2893476188182831, Training Acc: 75.52%\n",
      "              Val Loss: 1.1098827123641968, Val Acc: 66.99%\n",
      "Epoch: 5636,     Training Loss: 0.2858697175979614, Training Acc: 75.52%\n",
      "              Val Loss: 1.1425424814224243, Val Acc: 66.99%\n",
      "Epoch: 5637,     Training Loss: 0.31809210777282715, Training Acc: 75.52%\n",
      "              Val Loss: 1.1517661809921265, Val Acc: 66.99%\n",
      "Epoch: 5638,     Training Loss: 0.3955105245113373, Training Acc: 75.52%\n",
      "              Val Loss: 1.1513018608093262, Val Acc: 66.99%\n",
      "Epoch: 5639,     Training Loss: 0.3479520380496979, Training Acc: 75.52%\n",
      "              Val Loss: 1.0947115421295166, Val Acc: 66.99%\n",
      "Epoch: 5640,     Training Loss: 0.3123242259025574, Training Acc: 75.53%\n",
      "              Val Loss: 1.0927069187164307, Val Acc: 66.99%\n",
      "Epoch: 5641,     Training Loss: 0.3221226930618286, Training Acc: 75.53%\n",
      "              Val Loss: 1.1905760765075684, Val Acc: 66.99%\n",
      "Epoch: 5642,     Training Loss: 0.35625335574150085, Training Acc: 75.53%\n",
      "              Val Loss: 1.15329909324646, Val Acc: 66.99%\n",
      "Epoch: 5643,     Training Loss: 0.36432307958602905, Training Acc: 75.53%\n",
      "              Val Loss: 1.1163898706436157, Val Acc: 67.00%\n",
      "Epoch: 5644,     Training Loss: 0.33216312527656555, Training Acc: 75.53%\n",
      "              Val Loss: 1.0506327152252197, Val Acc: 67.00%\n",
      "Epoch: 5645,     Training Loss: 0.28571000695228577, Training Acc: 75.54%\n",
      "              Val Loss: 1.154603123664856, Val Acc: 67.00%\n",
      "Epoch: 5646,     Training Loss: 0.34695136547088623, Training Acc: 75.54%\n",
      "              Val Loss: 1.1191445589065552, Val Acc: 67.00%\n",
      "Epoch: 5647,     Training Loss: 0.3540164828300476, Training Acc: 75.54%\n",
      "              Val Loss: 1.1487915515899658, Val Acc: 67.00%\n",
      "Epoch: 5648,     Training Loss: 0.42088213562965393, Training Acc: 75.54%\n",
      "              Val Loss: 1.1607961654663086, Val Acc: 67.00%\n",
      "Epoch: 5649,     Training Loss: 0.3703940510749817, Training Acc: 75.54%\n",
      "              Val Loss: 1.1066875457763672, Val Acc: 67.00%\n",
      "Epoch: 5650,     Training Loss: 0.329377144575119, Training Acc: 75.54%\n",
      "              Val Loss: 1.1092746257781982, Val Acc: 67.00%\n",
      "Epoch: 5651,     Training Loss: 0.3149716854095459, Training Acc: 75.54%\n",
      "              Val Loss: 1.1925815343856812, Val Acc: 67.00%\n",
      "Epoch: 5652,     Training Loss: 0.36088302731513977, Training Acc: 75.55%\n",
      "              Val Loss: 1.0878087282180786, Val Acc: 67.00%\n",
      "Epoch: 5653,     Training Loss: 0.33370885252952576, Training Acc: 75.55%\n",
      "              Val Loss: 1.086443305015564, Val Acc: 67.00%\n",
      "Epoch: 5654,     Training Loss: 0.3176112771034241, Training Acc: 75.55%\n",
      "              Val Loss: 1.1350865364074707, Val Acc: 67.00%\n",
      "Epoch: 5655,     Training Loss: 0.32822704315185547, Training Acc: 75.55%\n",
      "              Val Loss: 1.122361183166504, Val Acc: 67.00%\n",
      "Epoch: 5656,     Training Loss: 0.35154005885124207, Training Acc: 75.55%\n",
      "              Val Loss: 1.1371359825134277, Val Acc: 67.00%\n",
      "Epoch: 5657,     Training Loss: 0.3324357569217682, Training Acc: 75.56%\n",
      "              Val Loss: 1.0933517217636108, Val Acc: 67.00%\n",
      "Epoch: 5658,     Training Loss: 0.3042014539241791, Training Acc: 75.56%\n",
      "              Val Loss: 1.063768744468689, Val Acc: 67.01%\n",
      "Epoch: 5659,     Training Loss: 0.2950303554534912, Training Acc: 75.56%\n",
      "              Val Loss: 1.1017930507659912, Val Acc: 67.01%\n",
      "Epoch: 5660,     Training Loss: 0.31523701548576355, Training Acc: 75.56%\n",
      "              Val Loss: 1.1208618879318237, Val Acc: 67.01%\n",
      "Epoch: 5661,     Training Loss: 0.3395412862300873, Training Acc: 75.56%\n",
      "              Val Loss: 1.0808401107788086, Val Acc: 67.01%\n",
      "Epoch: 5662,     Training Loss: 0.2874258756637573, Training Acc: 75.57%\n",
      "              Val Loss: 1.066545009613037, Val Acc: 67.01%\n",
      "Epoch: 5663,     Training Loss: 0.28078532218933105, Training Acc: 75.57%\n",
      "              Val Loss: 1.0768691301345825, Val Acc: 67.01%\n",
      "Epoch: 5664,     Training Loss: 0.2889626622200012, Training Acc: 75.57%\n",
      "              Val Loss: 1.1218749284744263, Val Acc: 67.01%\n",
      "Epoch: 5665,     Training Loss: 0.3078603446483612, Training Acc: 75.57%\n",
      "              Val Loss: 1.089443564414978, Val Acc: 67.01%\n",
      "Epoch: 5666,     Training Loss: 0.3158308267593384, Training Acc: 75.57%\n",
      "              Val Loss: 1.078848958015442, Val Acc: 67.01%\n",
      "Epoch: 5667,     Training Loss: 0.27670302987098694, Training Acc: 75.58%\n",
      "              Val Loss: 1.0965973138809204, Val Acc: 67.01%\n",
      "Epoch: 5668,     Training Loss: 0.2821822464466095, Training Acc: 75.58%\n",
      "              Val Loss: 1.0863258838653564, Val Acc: 67.01%\n",
      "Epoch: 5669,     Training Loss: 0.31474441289901733, Training Acc: 75.58%\n",
      "              Val Loss: 1.0782617330551147, Val Acc: 67.01%\n",
      "Epoch: 5670,     Training Loss: 0.2825852334499359, Training Acc: 75.58%\n",
      "              Val Loss: 1.0773392915725708, Val Acc: 67.01%\n",
      "Epoch: 5671,     Training Loss: 0.27459055185317993, Training Acc: 75.58%\n",
      "              Val Loss: 1.0671865940093994, Val Acc: 67.01%\n",
      "Epoch: 5672,     Training Loss: 0.28155356645584106, Training Acc: 75.59%\n",
      "              Val Loss: 1.1100797653198242, Val Acc: 67.02%\n",
      "Epoch: 5673,     Training Loss: 0.2965826690196991, Training Acc: 75.59%\n",
      "              Val Loss: 1.1526503562927246, Val Acc: 67.02%\n",
      "Epoch: 5674,     Training Loss: 0.3437950015068054, Training Acc: 75.59%\n",
      "              Val Loss: 1.1355565786361694, Val Acc: 67.02%\n",
      "Epoch: 5675,     Training Loss: 0.3231751620769501, Training Acc: 75.59%\n",
      "              Val Loss: 1.101487636566162, Val Acc: 67.02%\n",
      "Epoch: 5676,     Training Loss: 0.3076871931552887, Training Acc: 75.59%\n",
      "              Val Loss: 1.1147040128707886, Val Acc: 67.02%\n",
      "Epoch: 5677,     Training Loss: 0.2857128381729126, Training Acc: 75.60%\n",
      "              Val Loss: 1.1168562173843384, Val Acc: 67.02%\n",
      "Epoch: 5678,     Training Loss: 0.3010571300983429, Training Acc: 75.60%\n",
      "              Val Loss: 1.1136473417282104, Val Acc: 67.02%\n",
      "Epoch: 5679,     Training Loss: 0.33358487486839294, Training Acc: 75.60%\n",
      "              Val Loss: 1.1463333368301392, Val Acc: 67.02%\n",
      "Epoch: 5680,     Training Loss: 0.3072766065597534, Training Acc: 75.60%\n",
      "              Val Loss: 1.054274082183838, Val Acc: 67.02%\n",
      "Epoch: 5681,     Training Loss: 0.28338682651519775, Training Acc: 75.60%\n",
      "              Val Loss: 1.067774772644043, Val Acc: 67.02%\n",
      "Epoch: 5682,     Training Loss: 0.2990037202835083, Training Acc: 75.61%\n",
      "              Val Loss: 1.1426005363464355, Val Acc: 67.02%\n",
      "Epoch: 5683,     Training Loss: 0.31019657850265503, Training Acc: 75.61%\n",
      "              Val Loss: 1.1305570602416992, Val Acc: 67.02%\n",
      "Epoch: 5684,     Training Loss: 0.34538406133651733, Training Acc: 75.61%\n",
      "              Val Loss: 1.09308660030365, Val Acc: 67.02%\n",
      "Epoch: 5685,     Training Loss: 0.2872345447540283, Training Acc: 75.61%\n",
      "              Val Loss: 1.1260322332382202, Val Acc: 67.02%\n",
      "Epoch: 5686,     Training Loss: 0.3009243309497833, Training Acc: 75.61%\n",
      "              Val Loss: 1.1109743118286133, Val Acc: 67.02%\n",
      "Epoch: 5687,     Training Loss: 0.3339891731739044, Training Acc: 75.62%\n",
      "              Val Loss: 1.1201434135437012, Val Acc: 67.03%\n",
      "Epoch: 5688,     Training Loss: 0.3190973699092865, Training Acc: 75.62%\n",
      "              Val Loss: 1.1691614389419556, Val Acc: 67.03%\n",
      "Epoch: 5689,     Training Loss: 0.36130771040916443, Training Acc: 75.62%\n",
      "              Val Loss: 1.0966867208480835, Val Acc: 67.03%\n",
      "Epoch: 5690,     Training Loss: 0.2957535982131958, Training Acc: 75.62%\n",
      "              Val Loss: 1.1042426824569702, Val Acc: 67.03%\n",
      "Epoch: 5691,     Training Loss: 0.29307496547698975, Training Acc: 75.62%\n",
      "              Val Loss: 1.1587705612182617, Val Acc: 67.03%\n",
      "Epoch: 5692,     Training Loss: 0.3167591094970703, Training Acc: 75.62%\n",
      "              Val Loss: 1.169216275215149, Val Acc: 67.03%\n",
      "Epoch: 5693,     Training Loss: 0.35100680589675903, Training Acc: 75.63%\n",
      "              Val Loss: 1.1411051750183105, Val Acc: 67.03%\n",
      "Epoch: 5694,     Training Loss: 0.4163801670074463, Training Acc: 75.63%\n",
      "              Val Loss: 1.1810529232025146, Val Acc: 67.03%\n",
      "Epoch: 5695,     Training Loss: 0.38660427927970886, Training Acc: 75.63%\n",
      "              Val Loss: 1.0744534730911255, Val Acc: 67.03%\n",
      "Epoch: 5696,     Training Loss: 0.29302966594696045, Training Acc: 75.63%\n",
      "              Val Loss: 1.1551021337509155, Val Acc: 67.03%\n",
      "Epoch: 5697,     Training Loss: 0.3586529791355133, Training Acc: 75.63%\n",
      "              Val Loss: 1.1519287824630737, Val Acc: 67.03%\n",
      "Epoch: 5698,     Training Loss: 0.3245580196380615, Training Acc: 75.63%\n",
      "              Val Loss: 1.3066482543945312, Val Acc: 67.03%\n",
      "Epoch: 5699,     Training Loss: 0.4709482192993164, Training Acc: 75.63%\n",
      "              Val Loss: 1.1773003339767456, Val Acc: 67.03%\n",
      "Epoch: 5700,     Training Loss: 0.39941883087158203, Training Acc: 75.64%\n",
      "              Val Loss: 1.1454055309295654, Val Acc: 67.03%\n",
      "Epoch: 5701,     Training Loss: 0.35667818784713745, Training Acc: 75.64%\n",
      "              Val Loss: 1.1181021928787231, Val Acc: 67.03%\n",
      "Epoch: 5702,     Training Loss: 0.33409759402275085, Training Acc: 75.64%\n",
      "              Val Loss: 1.1834442615509033, Val Acc: 67.03%\n",
      "Epoch: 5703,     Training Loss: 0.3926224112510681, Training Acc: 75.64%\n",
      "              Val Loss: 1.1340985298156738, Val Acc: 67.03%\n",
      "Epoch: 5704,     Training Loss: 0.3850504159927368, Training Acc: 75.64%\n",
      "              Val Loss: 1.204310655593872, Val Acc: 67.03%\n",
      "Epoch: 5705,     Training Loss: 0.4026225805282593, Training Acc: 75.64%\n",
      "              Val Loss: 1.11637544631958, Val Acc: 67.03%\n",
      "Epoch: 5706,     Training Loss: 0.377447247505188, Training Acc: 75.64%\n",
      "              Val Loss: 1.1627596616744995, Val Acc: 67.04%\n",
      "Epoch: 5707,     Training Loss: 0.3506152331829071, Training Acc: 75.65%\n",
      "              Val Loss: 1.1307215690612793, Val Acc: 67.04%\n",
      "Epoch: 5708,     Training Loss: 0.3481493890285492, Training Acc: 75.65%\n",
      "              Val Loss: 1.1132500171661377, Val Acc: 67.04%\n",
      "Epoch: 5709,     Training Loss: 0.39007776975631714, Training Acc: 75.65%\n",
      "              Val Loss: 1.1192055940628052, Val Acc: 67.04%\n",
      "Epoch: 5710,     Training Loss: 0.40284276008605957, Training Acc: 75.65%\n",
      "              Val Loss: 1.2082295417785645, Val Acc: 67.04%\n",
      "Epoch: 5711,     Training Loss: 0.4525657594203949, Training Acc: 75.65%\n",
      "              Val Loss: 1.101942539215088, Val Acc: 67.04%\n",
      "Epoch: 5712,     Training Loss: 0.3089872896671295, Training Acc: 75.65%\n",
      "              Val Loss: 1.2467682361602783, Val Acc: 67.04%\n",
      "Epoch: 5713,     Training Loss: 0.40700092911720276, Training Acc: 75.65%\n",
      "              Val Loss: 1.2359589338302612, Val Acc: 67.04%\n",
      "Epoch: 5714,     Training Loss: 0.4442526698112488, Training Acc: 75.66%\n",
      "              Val Loss: 1.1793538331985474, Val Acc: 67.04%\n",
      "Epoch: 5715,     Training Loss: 0.3496047854423523, Training Acc: 75.66%\n",
      "              Val Loss: 1.2058115005493164, Val Acc: 67.04%\n",
      "Epoch: 5716,     Training Loss: 0.4208131432533264, Training Acc: 75.66%\n",
      "              Val Loss: 1.3777356147766113, Val Acc: 67.04%\n",
      "Epoch: 5717,     Training Loss: 0.6817179918289185, Training Acc: 75.66%\n",
      "              Val Loss: 1.1255208253860474, Val Acc: 67.04%\n",
      "Epoch: 5718,     Training Loss: 0.3415471613407135, Training Acc: 75.66%\n",
      "              Val Loss: 1.4884048700332642, Val Acc: 67.04%\n",
      "Epoch: 5719,     Training Loss: 0.6838275194168091, Training Acc: 75.66%\n",
      "              Val Loss: 2.0722198486328125, Val Acc: 67.03%\n",
      "Epoch: 5720,     Training Loss: 1.446276068687439, Training Acc: 75.66%\n",
      "              Val Loss: 1.4568051099777222, Val Acc: 67.03%\n",
      "Epoch: 5721,     Training Loss: 0.8899399638175964, Training Acc: 75.65%\n",
      "              Val Loss: 1.8458458185195923, Val Acc: 67.03%\n",
      "Epoch: 5722,     Training Loss: 1.1811178922653198, Training Acc: 75.65%\n",
      "              Val Loss: 1.584855556488037, Val Acc: 67.03%\n",
      "Epoch: 5723,     Training Loss: 0.8705981373786926, Training Acc: 75.65%\n",
      "              Val Loss: 1.5717123746871948, Val Acc: 67.03%\n",
      "Epoch: 5724,     Training Loss: 0.9282084107398987, Training Acc: 75.65%\n",
      "              Val Loss: 1.3761428594589233, Val Acc: 67.03%\n",
      "Epoch: 5725,     Training Loss: 0.8218204379081726, Training Acc: 75.65%\n",
      "              Val Loss: 1.2302051782608032, Val Acc: 67.03%\n",
      "Epoch: 5726,     Training Loss: 0.7628443241119385, Training Acc: 75.65%\n",
      "              Val Loss: 1.1390643119812012, Val Acc: 67.03%\n",
      "Epoch: 5727,     Training Loss: 0.7523457407951355, Training Acc: 75.65%\n",
      "              Val Loss: 1.0795432329177856, Val Acc: 67.03%\n",
      "Epoch: 5728,     Training Loss: 0.6643420457839966, Training Acc: 75.65%\n",
      "              Val Loss: 1.135010004043579, Val Acc: 67.03%\n",
      "Epoch: 5729,     Training Loss: 0.6472675800323486, Training Acc: 75.65%\n",
      "              Val Loss: 1.182579517364502, Val Acc: 67.03%\n",
      "Epoch: 5730,     Training Loss: 0.6881530284881592, Training Acc: 75.65%\n",
      "              Val Loss: 0.9780969023704529, Val Acc: 67.03%\n",
      "Epoch: 5731,     Training Loss: 0.563014566898346, Training Acc: 75.65%\n",
      "              Val Loss: 1.181745171546936, Val Acc: 67.03%\n",
      "Epoch: 5732,     Training Loss: 0.7492527961730957, Training Acc: 75.65%\n",
      "              Val Loss: 0.9862411022186279, Val Acc: 67.03%\n",
      "Epoch: 5733,     Training Loss: 0.5964221954345703, Training Acc: 75.65%\n",
      "              Val Loss: 0.9804134368896484, Val Acc: 67.03%\n",
      "Epoch: 5734,     Training Loss: 0.5579980611801147, Training Acc: 75.65%\n",
      "              Val Loss: 1.0084326267242432, Val Acc: 67.03%\n",
      "Epoch: 5735,     Training Loss: 0.57407546043396, Training Acc: 75.65%\n",
      "              Val Loss: 0.9641122221946716, Val Acc: 67.03%\n",
      "Epoch: 5736,     Training Loss: 0.5218325257301331, Training Acc: 75.65%\n",
      "              Val Loss: 0.9828417897224426, Val Acc: 67.03%\n",
      "Epoch: 5737,     Training Loss: 0.5321429371833801, Training Acc: 75.65%\n",
      "              Val Loss: 0.9398312568664551, Val Acc: 67.03%\n",
      "Epoch: 5738,     Training Loss: 0.5048176050186157, Training Acc: 75.65%\n",
      "              Val Loss: 0.8760483264923096, Val Acc: 67.03%\n",
      "Epoch: 5739,     Training Loss: 0.471100777387619, Training Acc: 75.65%\n",
      "              Val Loss: 0.8945753574371338, Val Acc: 67.03%\n",
      "Epoch: 5740,     Training Loss: 0.4795551300048828, Training Acc: 75.65%\n",
      "              Val Loss: 0.8884587287902832, Val Acc: 67.03%\n",
      "Epoch: 5741,     Training Loss: 0.46778368949890137, Training Acc: 75.65%\n",
      "              Val Loss: 0.8623054623603821, Val Acc: 67.03%\n",
      "Epoch: 5742,     Training Loss: 0.4497099220752716, Training Acc: 75.65%\n",
      "              Val Loss: 0.8831740617752075, Val Acc: 67.03%\n",
      "Epoch: 5743,     Training Loss: 0.4401797354221344, Training Acc: 75.65%\n",
      "              Val Loss: 0.8996529579162598, Val Acc: 67.03%\n",
      "Epoch: 5744,     Training Loss: 0.41859257221221924, Training Acc: 75.65%\n",
      "              Val Loss: 0.9182997345924377, Val Acc: 67.04%\n",
      "Epoch: 5745,     Training Loss: 0.4130699634552002, Training Acc: 75.66%\n",
      "              Val Loss: 0.9013462066650391, Val Acc: 67.04%\n",
      "Epoch: 5746,     Training Loss: 0.40351197123527527, Training Acc: 75.66%\n",
      "              Val Loss: 0.8714596629142761, Val Acc: 67.04%\n",
      "Epoch: 5747,     Training Loss: 0.39060840010643005, Training Acc: 75.66%\n",
      "              Val Loss: 0.8670262098312378, Val Acc: 67.04%\n",
      "Epoch: 5748,     Training Loss: 0.3860589563846588, Training Acc: 75.66%\n",
      "              Val Loss: 0.8779842853546143, Val Acc: 67.04%\n",
      "Epoch: 5749,     Training Loss: 0.3768627643585205, Training Acc: 75.66%\n",
      "              Val Loss: 0.8994472622871399, Val Acc: 67.04%\n",
      "Epoch: 5750,     Training Loss: 0.37670838832855225, Training Acc: 75.66%\n",
      "              Val Loss: 0.8954115509986877, Val Acc: 67.04%\n",
      "Epoch: 5751,     Training Loss: 0.3718961477279663, Training Acc: 75.66%\n",
      "              Val Loss: 0.8819863200187683, Val Acc: 67.04%\n",
      "Epoch: 5752,     Training Loss: 0.3622439205646515, Training Acc: 75.67%\n",
      "              Val Loss: 0.8831932544708252, Val Acc: 67.04%\n",
      "Epoch: 5753,     Training Loss: 0.35959580540657043, Training Acc: 75.67%\n",
      "              Val Loss: 0.8848568201065063, Val Acc: 67.04%\n",
      "Epoch: 5754,     Training Loss: 0.35595324635505676, Training Acc: 75.67%\n",
      "              Val Loss: 0.8858672976493835, Val Acc: 67.04%\n",
      "Epoch: 5755,     Training Loss: 0.3509485125541687, Training Acc: 75.67%\n",
      "              Val Loss: 0.9104712009429932, Val Acc: 67.05%\n",
      "Epoch: 5756,     Training Loss: 0.34342488646507263, Training Acc: 75.67%\n",
      "              Val Loss: 0.9467108249664307, Val Acc: 67.05%\n",
      "Epoch: 5757,     Training Loss: 0.3414168953895569, Training Acc: 75.67%\n",
      "              Val Loss: 0.9639900326728821, Val Acc: 67.05%\n",
      "Epoch: 5758,     Training Loss: 0.3372812569141388, Training Acc: 75.68%\n",
      "              Val Loss: 0.9725826382637024, Val Acc: 67.05%\n",
      "Epoch: 5759,     Training Loss: 0.33388209342956543, Training Acc: 75.68%\n",
      "              Val Loss: 0.972160816192627, Val Acc: 67.05%\n",
      "Epoch: 5760,     Training Loss: 0.3311469554901123, Training Acc: 75.68%\n",
      "              Val Loss: 0.9660965800285339, Val Acc: 67.05%\n",
      "Epoch: 5761,     Training Loss: 0.3269892632961273, Training Acc: 75.68%\n",
      "              Val Loss: 0.9664042592048645, Val Acc: 67.05%\n",
      "Epoch: 5762,     Training Loss: 0.3260310888290405, Training Acc: 75.68%\n",
      "              Val Loss: 0.9712756872177124, Val Acc: 67.05%\n",
      "Epoch: 5763,     Training Loss: 0.3233569264411926, Training Acc: 75.69%\n",
      "              Val Loss: 0.9719711542129517, Val Acc: 67.05%\n",
      "Epoch: 5764,     Training Loss: 0.31916043162345886, Training Acc: 75.69%\n",
      "              Val Loss: 0.9801008701324463, Val Acc: 67.05%\n",
      "Epoch: 5765,     Training Loss: 0.3162935972213745, Training Acc: 75.69%\n",
      "              Val Loss: 0.9856104254722595, Val Acc: 67.05%\n",
      "Epoch: 5766,     Training Loss: 0.313764750957489, Training Acc: 75.69%\n",
      "              Val Loss: 0.9874567985534668, Val Acc: 67.05%\n",
      "Epoch: 5767,     Training Loss: 0.3105904459953308, Training Acc: 75.69%\n",
      "              Val Loss: 0.9913312792778015, Val Acc: 67.06%\n",
      "Epoch: 5768,     Training Loss: 0.30746325850486755, Training Acc: 75.70%\n",
      "              Val Loss: 0.99376380443573, Val Acc: 67.06%\n",
      "Epoch: 5769,     Training Loss: 0.3060973584651947, Training Acc: 75.70%\n",
      "              Val Loss: 0.9900458455085754, Val Acc: 67.06%\n",
      "Epoch: 5770,     Training Loss: 0.3044694662094116, Training Acc: 75.70%\n",
      "              Val Loss: 0.99315345287323, Val Acc: 67.06%\n",
      "Epoch: 5771,     Training Loss: 0.30342811346054077, Training Acc: 75.70%\n",
      "              Val Loss: 0.9992116689682007, Val Acc: 67.06%\n",
      "Epoch: 5772,     Training Loss: 0.30190935730934143, Training Acc: 75.70%\n",
      "              Val Loss: 1.011681318283081, Val Acc: 67.06%\n",
      "Epoch: 5773,     Training Loss: 0.30087530612945557, Training Acc: 75.71%\n",
      "              Val Loss: 1.0206577777862549, Val Acc: 67.06%\n",
      "Epoch: 5774,     Training Loss: 0.3005264103412628, Training Acc: 75.71%\n",
      "              Val Loss: 1.0346368551254272, Val Acc: 67.06%\n",
      "Epoch: 5775,     Training Loss: 0.29990819096565247, Training Acc: 75.71%\n",
      "              Val Loss: 1.0378283262252808, Val Acc: 67.06%\n",
      "Epoch: 5776,     Training Loss: 0.3011954724788666, Training Acc: 75.71%\n",
      "              Val Loss: 1.0435608625411987, Val Acc: 67.06%\n",
      "Epoch: 5777,     Training Loss: 0.2993977665901184, Training Acc: 75.71%\n",
      "              Val Loss: 1.0444731712341309, Val Acc: 67.06%\n",
      "Epoch: 5778,     Training Loss: 0.3027327060699463, Training Acc: 75.72%\n",
      "              Val Loss: 1.051914930343628, Val Acc: 67.07%\n",
      "Epoch: 5779,     Training Loss: 0.2989967465400696, Training Acc: 75.72%\n",
      "              Val Loss: 1.0410680770874023, Val Acc: 67.07%\n",
      "Epoch: 5780,     Training Loss: 0.29917311668395996, Training Acc: 75.72%\n",
      "              Val Loss: 1.0449429750442505, Val Acc: 67.07%\n",
      "Epoch: 5781,     Training Loss: 0.29360508918762207, Training Acc: 75.72%\n",
      "              Val Loss: 1.0498812198638916, Val Acc: 67.07%\n",
      "Epoch: 5782,     Training Loss: 0.29049912095069885, Training Acc: 75.72%\n",
      "              Val Loss: 1.0444236993789673, Val Acc: 67.07%\n",
      "Epoch: 5783,     Training Loss: 0.286467969417572, Training Acc: 75.73%\n",
      "              Val Loss: 1.0395746231079102, Val Acc: 67.07%\n",
      "Epoch: 5784,     Training Loss: 0.2858680784702301, Training Acc: 75.73%\n",
      "              Val Loss: 1.0429433584213257, Val Acc: 67.07%\n",
      "Epoch: 5785,     Training Loss: 0.2868881821632385, Training Acc: 75.73%\n",
      "              Val Loss: 1.038896083831787, Val Acc: 67.07%\n",
      "Epoch: 5786,     Training Loss: 0.2892662286758423, Training Acc: 75.73%\n",
      "              Val Loss: 1.0385429859161377, Val Acc: 67.07%\n",
      "Epoch: 5787,     Training Loss: 0.297694593667984, Training Acc: 75.74%\n",
      "              Val Loss: 1.0588456392288208, Val Acc: 67.07%\n",
      "Epoch: 5788,     Training Loss: 0.3001011908054352, Training Acc: 75.74%\n",
      "              Val Loss: 1.046852946281433, Val Acc: 67.07%\n",
      "Epoch: 5789,     Training Loss: 0.30777984857559204, Training Acc: 75.74%\n",
      "              Val Loss: 1.0402697324752808, Val Acc: 67.07%\n",
      "Epoch: 5790,     Training Loss: 0.28980979323387146, Training Acc: 75.74%\n",
      "              Val Loss: 1.038364291191101, Val Acc: 67.07%\n",
      "Epoch: 5791,     Training Loss: 0.28562918305397034, Training Acc: 75.74%\n",
      "              Val Loss: 1.033239722251892, Val Acc: 67.07%\n",
      "Epoch: 5792,     Training Loss: 0.280481219291687, Training Acc: 75.75%\n",
      "              Val Loss: 1.0511051416397095, Val Acc: 67.07%\n",
      "Epoch: 5793,     Training Loss: 0.2857067286968231, Training Acc: 75.75%\n",
      "              Val Loss: 1.0646066665649414, Val Acc: 67.08%\n",
      "Epoch: 5794,     Training Loss: 0.29735681414604187, Training Acc: 75.75%\n",
      "              Val Loss: 1.0617918968200684, Val Acc: 67.08%\n",
      "Epoch: 5795,     Training Loss: 0.29739731550216675, Training Acc: 75.75%\n",
      "              Val Loss: 1.0640883445739746, Val Acc: 67.08%\n",
      "Epoch: 5796,     Training Loss: 0.3059266209602356, Training Acc: 75.75%\n",
      "              Val Loss: 1.0567272901535034, Val Acc: 67.08%\n",
      "Epoch: 5797,     Training Loss: 0.2868848443031311, Training Acc: 75.76%\n",
      "              Val Loss: 1.044600009918213, Val Acc: 67.08%\n",
      "Epoch: 5798,     Training Loss: 0.28226613998413086, Training Acc: 75.76%\n",
      "              Val Loss: 1.0471781492233276, Val Acc: 67.08%\n",
      "Epoch: 5799,     Training Loss: 0.2765456438064575, Training Acc: 75.76%\n",
      "              Val Loss: 1.0712594985961914, Val Acc: 67.08%\n",
      "Epoch: 5800,     Training Loss: 0.28930050134658813, Training Acc: 75.76%\n",
      "              Val Loss: 1.0778026580810547, Val Acc: 67.08%\n",
      "Epoch: 5801,     Training Loss: 0.309935599565506, Training Acc: 75.76%\n",
      "              Val Loss: 1.0789355039596558, Val Acc: 67.08%\n",
      "Epoch: 5802,     Training Loss: 0.3075685203075409, Training Acc: 75.77%\n",
      "              Val Loss: 1.090219259262085, Val Acc: 67.08%\n",
      "Epoch: 5803,     Training Loss: 0.32188957929611206, Training Acc: 75.77%\n",
      "              Val Loss: 1.0643720626831055, Val Acc: 67.08%\n",
      "Epoch: 5804,     Training Loss: 0.28909528255462646, Training Acc: 75.77%\n",
      "              Val Loss: 1.0672836303710938, Val Acc: 67.08%\n",
      "Epoch: 5805,     Training Loss: 0.28964900970458984, Training Acc: 75.77%\n",
      "              Val Loss: 1.0750269889831543, Val Acc: 67.08%\n",
      "Epoch: 5806,     Training Loss: 0.2862136960029602, Training Acc: 75.77%\n",
      "              Val Loss: 1.1344404220581055, Val Acc: 67.08%\n",
      "Epoch: 5807,     Training Loss: 0.3252274990081787, Training Acc: 75.78%\n",
      "              Val Loss: 1.1446670293807983, Val Acc: 67.08%\n",
      "Epoch: 5808,     Training Loss: 0.3799397945404053, Training Acc: 75.78%\n",
      "              Val Loss: 1.1249165534973145, Val Acc: 67.08%\n",
      "Epoch: 5809,     Training Loss: 0.33051440119743347, Training Acc: 75.78%\n",
      "              Val Loss: 1.100551724433899, Val Acc: 67.09%\n",
      "Epoch: 5810,     Training Loss: 0.3317137658596039, Training Acc: 75.78%\n",
      "              Val Loss: 1.060630440711975, Val Acc: 67.09%\n",
      "Epoch: 5811,     Training Loss: 0.2970336675643921, Training Acc: 75.78%\n",
      "              Val Loss: 1.1459596157073975, Val Acc: 67.09%\n",
      "Epoch: 5812,     Training Loss: 0.33759140968322754, Training Acc: 75.78%\n",
      "              Val Loss: 1.1642006635665894, Val Acc: 67.09%\n",
      "Epoch: 5813,     Training Loss: 0.35695570707321167, Training Acc: 75.79%\n",
      "              Val Loss: 1.1659998893737793, Val Acc: 67.09%\n",
      "Epoch: 5814,     Training Loss: 0.36446282267570496, Training Acc: 75.79%\n",
      "              Val Loss: 1.105399250984192, Val Acc: 67.09%\n",
      "Epoch: 5815,     Training Loss: 0.37615856528282166, Training Acc: 75.79%\n",
      "              Val Loss: 1.1184298992156982, Val Acc: 67.09%\n",
      "Epoch: 5816,     Training Loss: 0.3340394198894501, Training Acc: 75.79%\n",
      "              Val Loss: 1.0899097919464111, Val Acc: 67.09%\n",
      "Epoch: 5817,     Training Loss: 0.3284517228603363, Training Acc: 75.79%\n",
      "              Val Loss: 1.1380542516708374, Val Acc: 67.09%\n",
      "Epoch: 5818,     Training Loss: 0.3807072341442108, Training Acc: 75.79%\n",
      "              Val Loss: 1.1134814023971558, Val Acc: 67.09%\n",
      "Epoch: 5819,     Training Loss: 0.3177584707736969, Training Acc: 75.80%\n",
      "              Val Loss: 1.1764968633651733, Val Acc: 67.09%\n",
      "Epoch: 5820,     Training Loss: 0.3241552710533142, Training Acc: 75.80%\n",
      "              Val Loss: 1.0725078582763672, Val Acc: 67.09%\n",
      "Epoch: 5821,     Training Loss: 0.29293957352638245, Training Acc: 75.80%\n",
      "              Val Loss: 1.1029679775238037, Val Acc: 67.09%\n",
      "Epoch: 5822,     Training Loss: 0.33114245533943176, Training Acc: 75.80%\n",
      "              Val Loss: 1.0706393718719482, Val Acc: 67.09%\n",
      "Epoch: 5823,     Training Loss: 0.30552542209625244, Training Acc: 75.80%\n",
      "              Val Loss: 1.1423044204711914, Val Acc: 67.09%\n",
      "Epoch: 5824,     Training Loss: 0.3161960542201996, Training Acc: 75.81%\n",
      "              Val Loss: 1.0734561681747437, Val Acc: 67.09%\n",
      "Epoch: 5825,     Training Loss: 0.28288406133651733, Training Acc: 75.81%\n",
      "              Val Loss: 1.1087568998336792, Val Acc: 67.09%\n",
      "Epoch: 5826,     Training Loss: 0.303815096616745, Training Acc: 75.81%\n",
      "              Val Loss: 1.1594599485397339, Val Acc: 67.10%\n",
      "Epoch: 5827,     Training Loss: 0.3150726854801178, Training Acc: 75.81%\n",
      "              Val Loss: 1.1534863710403442, Val Acc: 67.10%\n",
      "Epoch: 5828,     Training Loss: 0.3446643352508545, Training Acc: 75.81%\n",
      "              Val Loss: 1.1065260171890259, Val Acc: 67.10%\n",
      "Epoch: 5829,     Training Loss: 0.34023991227149963, Training Acc: 75.81%\n",
      "              Val Loss: 1.0849573612213135, Val Acc: 67.10%\n",
      "Epoch: 5830,     Training Loss: 0.3119983971118927, Training Acc: 75.82%\n",
      "              Val Loss: 1.093580961227417, Val Acc: 67.10%\n",
      "Epoch: 5831,     Training Loss: 0.29209423065185547, Training Acc: 75.82%\n",
      "              Val Loss: 1.1158714294433594, Val Acc: 67.10%\n",
      "Epoch: 5832,     Training Loss: 0.31882262229919434, Training Acc: 75.82%\n",
      "              Val Loss: 1.1202350854873657, Val Acc: 67.10%\n",
      "Epoch: 5833,     Training Loss: 0.31973257660865784, Training Acc: 75.82%\n",
      "              Val Loss: 1.17510986328125, Val Acc: 67.10%\n",
      "Epoch: 5834,     Training Loss: 0.3422776162624359, Training Acc: 75.82%\n",
      "              Val Loss: 1.0655730962753296, Val Acc: 67.10%\n",
      "Epoch: 5835,     Training Loss: 0.3003213107585907, Training Acc: 75.83%\n",
      "              Val Loss: 1.0829834938049316, Val Acc: 67.10%\n",
      "Epoch: 5836,     Training Loss: 0.312654048204422, Training Acc: 75.83%\n",
      "              Val Loss: 1.092379093170166, Val Acc: 67.10%\n",
      "Epoch: 5837,     Training Loss: 0.30593228340148926, Training Acc: 75.83%\n",
      "              Val Loss: 1.063179850578308, Val Acc: 67.10%\n",
      "Epoch: 5838,     Training Loss: 0.28897330164909363, Training Acc: 75.83%\n",
      "              Val Loss: 1.111757755279541, Val Acc: 67.10%\n",
      "Epoch: 5839,     Training Loss: 0.30514052510261536, Training Acc: 75.83%\n",
      "              Val Loss: 1.1615291833877563, Val Acc: 67.10%\n",
      "Epoch: 5840,     Training Loss: 0.3097909092903137, Training Acc: 75.84%\n",
      "              Val Loss: 1.1536985635757446, Val Acc: 67.11%\n",
      "Epoch: 5841,     Training Loss: 0.325485497713089, Training Acc: 75.84%\n",
      "              Val Loss: 1.1732494831085205, Val Acc: 67.11%\n",
      "Epoch: 5842,     Training Loss: 0.40241554379463196, Training Acc: 75.84%\n",
      "              Val Loss: 1.1710424423217773, Val Acc: 67.11%\n",
      "Epoch: 5843,     Training Loss: 0.3327207565307617, Training Acc: 75.84%\n",
      "              Val Loss: 1.0906535387039185, Val Acc: 67.11%\n",
      "Epoch: 5844,     Training Loss: 0.28297698497772217, Training Acc: 75.84%\n",
      "              Val Loss: 1.1136211156845093, Val Acc: 67.11%\n",
      "Epoch: 5845,     Training Loss: 0.30449798703193665, Training Acc: 75.84%\n",
      "              Val Loss: 1.1685160398483276, Val Acc: 67.11%\n",
      "Epoch: 5846,     Training Loss: 0.3122998774051666, Training Acc: 75.85%\n",
      "              Val Loss: 1.1918120384216309, Val Acc: 67.11%\n",
      "Epoch: 5847,     Training Loss: 0.3447851538658142, Training Acc: 75.85%\n",
      "              Val Loss: 1.1002821922302246, Val Acc: 67.11%\n",
      "Epoch: 5848,     Training Loss: 0.3101710379123688, Training Acc: 75.85%\n",
      "              Val Loss: 1.0735737085342407, Val Acc: 67.11%\n",
      "Epoch: 5849,     Training Loss: 0.28944146633148193, Training Acc: 75.85%\n",
      "              Val Loss: 1.077020287513733, Val Acc: 67.11%\n",
      "Epoch: 5850,     Training Loss: 0.28186705708503723, Training Acc: 75.85%\n",
      "              Val Loss: 1.106758952140808, Val Acc: 67.11%\n",
      "Epoch: 5851,     Training Loss: 0.3068278431892395, Training Acc: 75.86%\n",
      "              Val Loss: 1.0993125438690186, Val Acc: 67.11%\n",
      "Epoch: 5852,     Training Loss: 0.3052116334438324, Training Acc: 75.86%\n",
      "              Val Loss: 1.130823016166687, Val Acc: 67.11%\n",
      "Epoch: 5853,     Training Loss: 0.29377660155296326, Training Acc: 75.86%\n",
      "              Val Loss: 1.089165449142456, Val Acc: 67.11%\n",
      "Epoch: 5854,     Training Loss: 0.2750706672668457, Training Acc: 75.86%\n",
      "              Val Loss: 1.0854949951171875, Val Acc: 67.11%\n",
      "Epoch: 5855,     Training Loss: 0.27461427450180054, Training Acc: 75.86%\n",
      "              Val Loss: 1.0973998308181763, Val Acc: 67.11%\n",
      "Epoch: 5856,     Training Loss: 0.27787792682647705, Training Acc: 75.87%\n",
      "              Val Loss: 1.0857079029083252, Val Acc: 67.12%\n",
      "Epoch: 5857,     Training Loss: 0.27341485023498535, Training Acc: 75.87%\n",
      "              Val Loss: 1.1109431982040405, Val Acc: 67.12%\n",
      "Epoch: 5858,     Training Loss: 0.2776923179626465, Training Acc: 75.87%\n",
      "              Val Loss: 1.1422967910766602, Val Acc: 67.12%\n",
      "Epoch: 5859,     Training Loss: 0.2881609797477722, Training Acc: 75.87%\n",
      "              Val Loss: 1.1606956720352173, Val Acc: 67.12%\n",
      "Epoch: 5860,     Training Loss: 0.3098147213459015, Training Acc: 75.87%\n",
      "              Val Loss: 1.1691607236862183, Val Acc: 67.12%\n",
      "Epoch: 5861,     Training Loss: 0.3635105788707733, Training Acc: 75.88%\n",
      "              Val Loss: 1.1683486700057983, Val Acc: 67.12%\n",
      "Epoch: 5862,     Training Loss: 0.3109603226184845, Training Acc: 75.88%\n",
      "              Val Loss: 1.0822352170944214, Val Acc: 67.12%\n",
      "Epoch: 5863,     Training Loss: 0.2737126350402832, Training Acc: 75.88%\n",
      "              Val Loss: 1.0794758796691895, Val Acc: 67.12%\n",
      "Epoch: 5864,     Training Loss: 0.2820616662502289, Training Acc: 75.88%\n",
      "              Val Loss: 1.135080099105835, Val Acc: 67.12%\n",
      "Epoch: 5865,     Training Loss: 0.30217936635017395, Training Acc: 75.88%\n",
      "              Val Loss: 1.1767516136169434, Val Acc: 67.12%\n",
      "Epoch: 5866,     Training Loss: 0.3624297082424164, Training Acc: 75.88%\n",
      "              Val Loss: 1.1194454431533813, Val Acc: 67.12%\n",
      "Epoch: 5867,     Training Loss: 0.32220908999443054, Training Acc: 75.89%\n",
      "              Val Loss: 1.1067911386489868, Val Acc: 67.12%\n",
      "Epoch: 5868,     Training Loss: 0.2994660437107086, Training Acc: 75.89%\n",
      "              Val Loss: 1.0938180685043335, Val Acc: 67.12%\n",
      "Epoch: 5869,     Training Loss: 0.2718997001647949, Training Acc: 75.89%\n",
      "              Val Loss: 1.1328734159469604, Val Acc: 67.12%\n",
      "Epoch: 5870,     Training Loss: 0.3044404685497284, Training Acc: 75.89%\n",
      "              Val Loss: 1.1393122673034668, Val Acc: 67.12%\n",
      "Epoch: 5871,     Training Loss: 0.31382179260253906, Training Acc: 75.89%\n",
      "              Val Loss: 1.1610829830169678, Val Acc: 67.12%\n",
      "Epoch: 5872,     Training Loss: 0.29721367359161377, Training Acc: 75.90%\n",
      "              Val Loss: 1.0960428714752197, Val Acc: 67.12%\n",
      "Epoch: 5873,     Training Loss: 0.283718466758728, Training Acc: 75.90%\n",
      "              Val Loss: 1.0875433683395386, Val Acc: 67.13%\n",
      "Epoch: 5874,     Training Loss: 0.274400532245636, Training Acc: 75.90%\n",
      "              Val Loss: 1.1079115867614746, Val Acc: 67.13%\n",
      "Epoch: 5875,     Training Loss: 0.29123276472091675, Training Acc: 75.90%\n",
      "              Val Loss: 1.1007713079452515, Val Acc: 67.13%\n",
      "Epoch: 5876,     Training Loss: 0.29606127738952637, Training Acc: 75.90%\n",
      "              Val Loss: 1.1614059209823608, Val Acc: 67.13%\n",
      "Epoch: 5877,     Training Loss: 0.30580952763557434, Training Acc: 75.91%\n",
      "              Val Loss: 1.1618958711624146, Val Acc: 67.13%\n",
      "Epoch: 5878,     Training Loss: 0.3032302260398865, Training Acc: 75.91%\n",
      "              Val Loss: 1.155015468597412, Val Acc: 67.13%\n",
      "Epoch: 5879,     Training Loss: 0.2956832945346832, Training Acc: 75.91%\n",
      "              Val Loss: 1.1100293397903442, Val Acc: 67.13%\n",
      "Epoch: 5880,     Training Loss: 0.27791327238082886, Training Acc: 75.91%\n",
      "              Val Loss: 1.1495479345321655, Val Acc: 67.13%\n",
      "Epoch: 5881,     Training Loss: 0.2880953848361969, Training Acc: 75.91%\n",
      "              Val Loss: 1.100150465965271, Val Acc: 67.13%\n",
      "Epoch: 5882,     Training Loss: 0.27979570627212524, Training Acc: 75.92%\n",
      "              Val Loss: 1.0989118814468384, Val Acc: 67.13%\n",
      "Epoch: 5883,     Training Loss: 0.2961428761482239, Training Acc: 75.92%\n",
      "              Val Loss: 1.136715292930603, Val Acc: 67.13%\n",
      "Epoch: 5884,     Training Loss: 0.2883826494216919, Training Acc: 75.92%\n",
      "              Val Loss: 1.1512929201126099, Val Acc: 67.13%\n",
      "Epoch: 5885,     Training Loss: 0.307319313287735, Training Acc: 75.92%\n",
      "              Val Loss: 1.1355881690979004, Val Acc: 67.13%\n",
      "Epoch: 5886,     Training Loss: 0.309592604637146, Training Acc: 75.92%\n",
      "              Val Loss: 1.1504127979278564, Val Acc: 67.13%\n",
      "Epoch: 5887,     Training Loss: 0.33085405826568604, Training Acc: 75.93%\n",
      "              Val Loss: 1.1508758068084717, Val Acc: 67.13%\n",
      "Epoch: 5888,     Training Loss: 0.2843218147754669, Training Acc: 75.93%\n",
      "              Val Loss: 1.1293740272521973, Val Acc: 67.13%\n",
      "Epoch: 5889,     Training Loss: 0.28542444109916687, Training Acc: 75.93%\n",
      "              Val Loss: 1.127443790435791, Val Acc: 67.13%\n",
      "Epoch: 5890,     Training Loss: 0.2918533384799957, Training Acc: 75.93%\n",
      "              Val Loss: 1.2025989294052124, Val Acc: 67.14%\n",
      "Epoch: 5891,     Training Loss: 0.32987740635871887, Training Acc: 75.93%\n",
      "              Val Loss: 1.22637140750885, Val Acc: 67.14%\n",
      "Epoch: 5892,     Training Loss: 0.4239349067211151, Training Acc: 75.93%\n",
      "              Val Loss: 1.151535153388977, Val Acc: 67.14%\n",
      "Epoch: 5893,     Training Loss: 0.33229026198387146, Training Acc: 75.94%\n",
      "              Val Loss: 1.1623533964157104, Val Acc: 67.14%\n",
      "Epoch: 5894,     Training Loss: 0.3301290273666382, Training Acc: 75.94%\n",
      "              Val Loss: 1.1110730171203613, Val Acc: 67.14%\n",
      "Epoch: 5895,     Training Loss: 0.3036688566207886, Training Acc: 75.94%\n",
      "              Val Loss: 1.1916027069091797, Val Acc: 67.14%\n",
      "Epoch: 5896,     Training Loss: 0.33866778016090393, Training Acc: 75.94%\n",
      "              Val Loss: 1.2059820890426636, Val Acc: 67.14%\n",
      "Epoch: 5897,     Training Loss: 0.3273673951625824, Training Acc: 75.94%\n",
      "              Val Loss: 1.1890220642089844, Val Acc: 67.14%\n",
      "Epoch: 5898,     Training Loss: 0.3216582238674164, Training Acc: 75.94%\n",
      "              Val Loss: 1.107664942741394, Val Acc: 67.14%\n",
      "Epoch: 5899,     Training Loss: 0.3079048991203308, Training Acc: 75.95%\n",
      "              Val Loss: 1.1510450839996338, Val Acc: 67.14%\n",
      "Epoch: 5900,     Training Loss: 0.3112872838973999, Training Acc: 75.95%\n",
      "              Val Loss: 1.0950042009353638, Val Acc: 67.14%\n",
      "Epoch: 5901,     Training Loss: 0.2897161841392517, Training Acc: 75.95%\n",
      "              Val Loss: 1.0955432653427124, Val Acc: 67.14%\n",
      "Epoch: 5902,     Training Loss: 0.3005269765853882, Training Acc: 75.95%\n",
      "              Val Loss: 1.1422855854034424, Val Acc: 67.14%\n",
      "Epoch: 5903,     Training Loss: 0.28987014293670654, Training Acc: 75.95%\n",
      "              Val Loss: 1.2162588834762573, Val Acc: 67.14%\n",
      "Epoch: 5904,     Training Loss: 0.31850868463516235, Training Acc: 75.96%\n",
      "              Val Loss: 1.1296123266220093, Val Acc: 67.14%\n",
      "Epoch: 5905,     Training Loss: 0.2915371060371399, Training Acc: 75.96%\n",
      "              Val Loss: 1.0915234088897705, Val Acc: 67.14%\n",
      "Epoch: 5906,     Training Loss: 0.29682645201683044, Training Acc: 75.96%\n",
      "              Val Loss: 1.1435613632202148, Val Acc: 67.14%\n",
      "Epoch: 5907,     Training Loss: 0.3043750524520874, Training Acc: 75.96%\n",
      "              Val Loss: 1.1004631519317627, Val Acc: 67.14%\n",
      "Epoch: 5908,     Training Loss: 0.27746033668518066, Training Acc: 75.96%\n",
      "              Val Loss: 1.1267849206924438, Val Acc: 67.15%\n",
      "Epoch: 5909,     Training Loss: 0.27932000160217285, Training Acc: 75.97%\n",
      "              Val Loss: 1.1749292612075806, Val Acc: 67.15%\n",
      "Epoch: 5910,     Training Loss: 0.27729472517967224, Training Acc: 75.97%\n",
      "              Val Loss: 1.1750608682632446, Val Acc: 67.15%\n",
      "Epoch: 5911,     Training Loss: 0.2732982933521271, Training Acc: 75.97%\n",
      "              Val Loss: 1.1247684955596924, Val Acc: 67.15%\n",
      "Epoch: 5912,     Training Loss: 0.29006317257881165, Training Acc: 75.97%\n",
      "              Val Loss: 1.1109020709991455, Val Acc: 67.15%\n",
      "Epoch: 5913,     Training Loss: 0.3031668961048126, Training Acc: 75.97%\n",
      "              Val Loss: 1.1519684791564941, Val Acc: 67.15%\n",
      "Epoch: 5914,     Training Loss: 0.31965699791908264, Training Acc: 75.97%\n",
      "              Val Loss: 1.150630235671997, Val Acc: 67.15%\n",
      "Epoch: 5915,     Training Loss: 0.3510960638523102, Training Acc: 75.98%\n",
      "              Val Loss: 1.1475648880004883, Val Acc: 67.15%\n",
      "Epoch: 5916,     Training Loss: 0.2764926254749298, Training Acc: 75.98%\n",
      "              Val Loss: 1.217057704925537, Val Acc: 67.15%\n",
      "Epoch: 5917,     Training Loss: 0.3082841634750366, Training Acc: 75.98%\n",
      "              Val Loss: 1.2394912242889404, Val Acc: 67.15%\n",
      "Epoch: 5918,     Training Loss: 0.4089711010456085, Training Acc: 75.98%\n",
      "              Val Loss: 1.2205135822296143, Val Acc: 67.15%\n",
      "Epoch: 5919,     Training Loss: 0.3675907254219055, Training Acc: 75.98%\n",
      "              Val Loss: 1.2100106477737427, Val Acc: 67.15%\n",
      "Epoch: 5920,     Training Loss: 0.38454657793045044, Training Acc: 75.98%\n",
      "              Val Loss: 1.1091549396514893, Val Acc: 67.15%\n",
      "Epoch: 5921,     Training Loss: 0.3007557988166809, Training Acc: 75.99%\n",
      "              Val Loss: 1.1944243907928467, Val Acc: 67.15%\n",
      "Epoch: 5922,     Training Loss: 0.34206119179725647, Training Acc: 75.99%\n",
      "              Val Loss: 1.3204630613327026, Val Acc: 67.15%\n",
      "Epoch: 5923,     Training Loss: 0.44864487648010254, Training Acc: 75.99%\n",
      "              Val Loss: 1.1586577892303467, Val Acc: 67.15%\n",
      "Epoch: 5924,     Training Loss: 0.2963904142379761, Training Acc: 75.99%\n",
      "              Val Loss: 1.1312237977981567, Val Acc: 67.15%\n",
      "Epoch: 5925,     Training Loss: 0.3205908238887787, Training Acc: 75.99%\n",
      "              Val Loss: 1.1103880405426025, Val Acc: 67.15%\n",
      "Epoch: 5926,     Training Loss: 0.33906692266464233, Training Acc: 75.99%\n",
      "              Val Loss: 1.1486413478851318, Val Acc: 67.15%\n",
      "Epoch: 5927,     Training Loss: 0.30081576108932495, Training Acc: 75.99%\n",
      "              Val Loss: 1.1427868604660034, Val Acc: 67.15%\n",
      "Epoch: 5928,     Training Loss: 0.31365862488746643, Training Acc: 76.00%\n",
      "              Val Loss: 1.255080223083496, Val Acc: 67.15%\n",
      "Epoch: 5929,     Training Loss: 0.4398106336593628, Training Acc: 76.00%\n",
      "              Val Loss: 1.2498621940612793, Val Acc: 67.15%\n",
      "Epoch: 5930,     Training Loss: 0.34513038396835327, Training Acc: 76.00%\n",
      "              Val Loss: 1.111056923866272, Val Acc: 67.16%\n",
      "Epoch: 5931,     Training Loss: 0.27669012546539307, Training Acc: 76.00%\n",
      "              Val Loss: 1.1326240301132202, Val Acc: 67.16%\n",
      "Epoch: 5932,     Training Loss: 0.3355947434902191, Training Acc: 76.00%\n",
      "              Val Loss: 1.1642181873321533, Val Acc: 67.16%\n",
      "Epoch: 5933,     Training Loss: 0.2956969738006592, Training Acc: 76.00%\n",
      "              Val Loss: 1.1424493789672852, Val Acc: 67.16%\n",
      "Epoch: 5934,     Training Loss: 0.27426716685295105, Training Acc: 76.01%\n",
      "              Val Loss: 1.1283745765686035, Val Acc: 67.16%\n",
      "Epoch: 5935,     Training Loss: 0.2974281311035156, Training Acc: 76.01%\n",
      "              Val Loss: 1.1382532119750977, Val Acc: 67.16%\n",
      "Epoch: 5936,     Training Loss: 0.27801549434661865, Training Acc: 76.01%\n",
      "              Val Loss: 1.163142442703247, Val Acc: 67.16%\n",
      "Epoch: 5937,     Training Loss: 0.2931157052516937, Training Acc: 76.01%\n",
      "              Val Loss: 1.1111416816711426, Val Acc: 67.16%\n",
      "Epoch: 5938,     Training Loss: 0.28149065375328064, Training Acc: 76.01%\n",
      "              Val Loss: 1.1015881299972534, Val Acc: 67.16%\n",
      "Epoch: 5939,     Training Loss: 0.26732611656188965, Training Acc: 76.02%\n",
      "              Val Loss: 1.1672226190567017, Val Acc: 67.16%\n",
      "Epoch: 5940,     Training Loss: 0.27989187836647034, Training Acc: 76.02%\n",
      "              Val Loss: 1.1370165348052979, Val Acc: 67.16%\n",
      "Epoch: 5941,     Training Loss: 0.2626663148403168, Training Acc: 76.02%\n",
      "              Val Loss: 1.1389497518539429, Val Acc: 67.16%\n",
      "Epoch: 5942,     Training Loss: 0.2745961844921112, Training Acc: 76.02%\n",
      "              Val Loss: 1.1510599851608276, Val Acc: 67.16%\n",
      "Epoch: 5943,     Training Loss: 0.26660147309303284, Training Acc: 76.03%\n",
      "              Val Loss: 1.1324445009231567, Val Acc: 67.16%\n",
      "Epoch: 5944,     Training Loss: 0.2686694860458374, Training Acc: 76.03%\n",
      "              Val Loss: 1.1261725425720215, Val Acc: 67.16%\n",
      "Epoch: 5945,     Training Loss: 0.27934131026268005, Training Acc: 76.03%\n",
      "              Val Loss: 1.1225130558013916, Val Acc: 67.16%\n",
      "Epoch: 5946,     Training Loss: 0.27925917506217957, Training Acc: 76.03%\n",
      "              Val Loss: 1.1789844036102295, Val Acc: 67.17%\n",
      "Epoch: 5947,     Training Loss: 0.28829529881477356, Training Acc: 76.03%\n",
      "              Val Loss: 1.1557376384735107, Val Acc: 67.17%\n",
      "Epoch: 5948,     Training Loss: 0.31531113386154175, Training Acc: 76.04%\n",
      "              Val Loss: 1.1633431911468506, Val Acc: 67.17%\n",
      "Epoch: 5949,     Training Loss: 0.2908160388469696, Training Acc: 76.04%\n",
      "              Val Loss: 1.1798222064971924, Val Acc: 67.17%\n",
      "Epoch: 5950,     Training Loss: 0.319730669260025, Training Acc: 76.04%\n",
      "              Val Loss: 1.135374903678894, Val Acc: 67.17%\n",
      "Epoch: 5951,     Training Loss: 0.2868210971355438, Training Acc: 76.04%\n",
      "              Val Loss: 1.1029056310653687, Val Acc: 67.17%\n",
      "Epoch: 5952,     Training Loss: 0.2662030756473541, Training Acc: 76.04%\n",
      "              Val Loss: 1.1454265117645264, Val Acc: 67.17%\n",
      "Epoch: 5953,     Training Loss: 0.2769756615161896, Training Acc: 76.05%\n",
      "              Val Loss: 1.133277416229248, Val Acc: 67.17%\n",
      "Epoch: 5954,     Training Loss: 0.2731669545173645, Training Acc: 76.05%\n",
      "              Val Loss: 1.143088698387146, Val Acc: 67.17%\n",
      "Epoch: 5955,     Training Loss: 0.31224173307418823, Training Acc: 76.05%\n",
      "              Val Loss: 1.1810194253921509, Val Acc: 67.17%\n",
      "Epoch: 5956,     Training Loss: 0.29342055320739746, Training Acc: 76.05%\n",
      "              Val Loss: 1.1321625709533691, Val Acc: 67.17%\n",
      "Epoch: 5957,     Training Loss: 0.2800125777721405, Training Acc: 76.05%\n",
      "              Val Loss: 1.1210075616836548, Val Acc: 67.17%\n",
      "Epoch: 5958,     Training Loss: 0.27989161014556885, Training Acc: 76.05%\n",
      "              Val Loss: 1.1277121305465698, Val Acc: 67.17%\n",
      "Epoch: 5959,     Training Loss: 0.2614884376525879, Training Acc: 76.06%\n",
      "              Val Loss: 1.1714541912078857, Val Acc: 67.17%\n",
      "Epoch: 5960,     Training Loss: 0.274030864238739, Training Acc: 76.06%\n",
      "              Val Loss: 1.1620032787322998, Val Acc: 67.17%\n",
      "Epoch: 5961,     Training Loss: 0.2798033058643341, Training Acc: 76.06%\n",
      "              Val Loss: 1.136620044708252, Val Acc: 67.17%\n",
      "Epoch: 5962,     Training Loss: 0.29030442237854004, Training Acc: 76.06%\n",
      "              Val Loss: 1.189350962638855, Val Acc: 67.18%\n",
      "Epoch: 5963,     Training Loss: 0.29504311084747314, Training Acc: 76.06%\n",
      "              Val Loss: 1.1243892908096313, Val Acc: 67.18%\n",
      "Epoch: 5964,     Training Loss: 0.30295026302337646, Training Acc: 76.07%\n",
      "              Val Loss: 1.1288336515426636, Val Acc: 67.18%\n",
      "Epoch: 5965,     Training Loss: 0.28530293703079224, Training Acc: 76.07%\n",
      "              Val Loss: 1.1412339210510254, Val Acc: 67.18%\n",
      "Epoch: 5966,     Training Loss: 0.26650795340538025, Training Acc: 76.07%\n",
      "              Val Loss: 1.1453378200531006, Val Acc: 67.18%\n",
      "Epoch: 5967,     Training Loss: 0.26457709074020386, Training Acc: 76.07%\n",
      "              Val Loss: 1.160077691078186, Val Acc: 67.18%\n",
      "Epoch: 5968,     Training Loss: 0.2815098762512207, Training Acc: 76.08%\n",
      "              Val Loss: 1.1498517990112305, Val Acc: 67.18%\n",
      "Epoch: 5969,     Training Loss: 0.2969331741333008, Training Acc: 76.08%\n",
      "              Val Loss: 1.1826741695404053, Val Acc: 67.18%\n",
      "Epoch: 5970,     Training Loss: 0.2858506143093109, Training Acc: 76.08%\n",
      "              Val Loss: 1.1054213047027588, Val Acc: 67.18%\n",
      "Epoch: 5971,     Training Loss: 0.27404701709747314, Training Acc: 76.08%\n",
      "              Val Loss: 1.1042882204055786, Val Acc: 67.18%\n",
      "Epoch: 5972,     Training Loss: 0.25781574845314026, Training Acc: 76.08%\n",
      "              Val Loss: 1.1527222394943237, Val Acc: 67.18%\n",
      "Epoch: 5973,     Training Loss: 0.2730835974216461, Training Acc: 76.09%\n",
      "              Val Loss: 1.1413207054138184, Val Acc: 67.18%\n",
      "Epoch: 5974,     Training Loss: 0.2914384603500366, Training Acc: 76.09%\n",
      "              Val Loss: 1.1847683191299438, Val Acc: 67.18%\n",
      "Epoch: 5975,     Training Loss: 0.3015330731868744, Training Acc: 76.09%\n",
      "              Val Loss: 1.2320852279663086, Val Acc: 67.18%\n",
      "Epoch: 5976,     Training Loss: 0.3466211259365082, Training Acc: 76.09%\n",
      "              Val Loss: 1.1704107522964478, Val Acc: 67.18%\n",
      "Epoch: 5977,     Training Loss: 0.2903899550437927, Training Acc: 76.09%\n",
      "              Val Loss: 1.13783860206604, Val Acc: 67.18%\n",
      "Epoch: 5978,     Training Loss: 0.2699553370475769, Training Acc: 76.09%\n",
      "              Val Loss: 1.181270718574524, Val Acc: 67.18%\n",
      "Epoch: 5979,     Training Loss: 0.29117149114608765, Training Acc: 76.10%\n",
      "              Val Loss: 1.1736334562301636, Val Acc: 67.18%\n",
      "Epoch: 5980,     Training Loss: 0.28403395414352417, Training Acc: 76.10%\n",
      "              Val Loss: 1.1595264673233032, Val Acc: 67.19%\n",
      "Epoch: 5981,     Training Loss: 0.32275813817977905, Training Acc: 76.10%\n",
      "              Val Loss: 1.1633288860321045, Val Acc: 67.19%\n",
      "Epoch: 5982,     Training Loss: 0.28213775157928467, Training Acc: 76.10%\n",
      "              Val Loss: 1.1155433654785156, Val Acc: 67.19%\n",
      "Epoch: 5983,     Training Loss: 0.2660537362098694, Training Acc: 76.10%\n",
      "              Val Loss: 1.1031333208084106, Val Acc: 67.19%\n",
      "Epoch: 5984,     Training Loss: 0.2716190218925476, Training Acc: 76.11%\n",
      "              Val Loss: 1.1323037147521973, Val Acc: 67.19%\n",
      "Epoch: 5985,     Training Loss: 0.25844529271125793, Training Acc: 76.11%\n",
      "              Val Loss: 1.1587213277816772, Val Acc: 67.19%\n",
      "Epoch: 5986,     Training Loss: 0.26632100343704224, Training Acc: 76.11%\n",
      "              Val Loss: 1.167098879814148, Val Acc: 67.19%\n",
      "Epoch: 5987,     Training Loss: 0.2751104235649109, Training Acc: 76.11%\n",
      "              Val Loss: 1.148849606513977, Val Acc: 67.19%\n",
      "Epoch: 5988,     Training Loss: 0.2826535701751709, Training Acc: 76.11%\n",
      "              Val Loss: 1.1939674615859985, Val Acc: 67.19%\n",
      "Epoch: 5989,     Training Loss: 0.28871095180511475, Training Acc: 76.12%\n",
      "              Val Loss: 1.1334706544876099, Val Acc: 67.19%\n",
      "Epoch: 5990,     Training Loss: 0.29896998405456543, Training Acc: 76.12%\n",
      "              Val Loss: 1.1353166103363037, Val Acc: 67.19%\n",
      "Epoch: 5991,     Training Loss: 0.2723706364631653, Training Acc: 76.12%\n",
      "              Val Loss: 1.1799511909484863, Val Acc: 67.19%\n",
      "Epoch: 5992,     Training Loss: 0.27127644419670105, Training Acc: 76.12%\n",
      "              Val Loss: 1.1382733583450317, Val Acc: 67.19%\n",
      "Epoch: 5993,     Training Loss: 0.26502230763435364, Training Acc: 76.12%\n",
      "              Val Loss: 1.1655058860778809, Val Acc: 67.19%\n",
      "Epoch: 5994,     Training Loss: 0.28047358989715576, Training Acc: 76.13%\n",
      "              Val Loss: 1.191622257232666, Val Acc: 67.19%\n",
      "Epoch: 5995,     Training Loss: 0.30942240357398987, Training Acc: 76.13%\n",
      "              Val Loss: 1.2057905197143555, Val Acc: 67.19%\n",
      "Epoch: 5996,     Training Loss: 0.2981626093387604, Training Acc: 76.13%\n",
      "              Val Loss: 1.1380867958068848, Val Acc: 67.20%\n",
      "Epoch: 5997,     Training Loss: 0.2948726415634155, Training Acc: 76.13%\n",
      "              Val Loss: 1.1513022184371948, Val Acc: 67.20%\n",
      "Epoch: 5998,     Training Loss: 0.2600950002670288, Training Acc: 76.13%\n",
      "              Val Loss: 1.1933379173278809, Val Acc: 67.20%\n",
      "Epoch: 5999,     Training Loss: 0.2792280316352844, Training Acc: 76.14%\n",
      "              Val Loss: 1.2084195613861084, Val Acc: 67.20%\n",
      "Epoch: 6000,     Training Loss: 0.35024943947792053, Training Acc: 76.14%\n",
      "              Val Loss: 1.2076973915100098, Val Acc: 67.20%\n",
      "Epoch: 6001,     Training Loss: 0.3125837445259094, Training Acc: 76.14%\n",
      "              Val Loss: 1.1723874807357788, Val Acc: 67.20%\n",
      "Epoch: 6002,     Training Loss: 0.2868695557117462, Training Acc: 76.14%\n",
      "              Val Loss: 1.1356658935546875, Val Acc: 67.20%\n",
      "Epoch: 6003,     Training Loss: 0.2679183781147003, Training Acc: 76.14%\n",
      "              Val Loss: 1.1954277753829956, Val Acc: 67.20%\n",
      "Epoch: 6004,     Training Loss: 0.29588183760643005, Training Acc: 76.15%\n",
      "              Val Loss: 1.2374207973480225, Val Acc: 67.20%\n",
      "Epoch: 6005,     Training Loss: 0.3476865291595459, Training Acc: 76.15%\n",
      "              Val Loss: 1.173507571220398, Val Acc: 67.20%\n",
      "Epoch: 6006,     Training Loss: 0.2783931791782379, Training Acc: 76.15%\n",
      "              Val Loss: 1.1454483270645142, Val Acc: 67.20%\n",
      "Epoch: 6007,     Training Loss: 0.2686331570148468, Training Acc: 76.15%\n",
      "              Val Loss: 1.177485704421997, Val Acc: 67.20%\n",
      "Epoch: 6008,     Training Loss: 0.30256009101867676, Training Acc: 76.15%\n",
      "              Val Loss: 1.1786892414093018, Val Acc: 67.20%\n",
      "Epoch: 6009,     Training Loss: 0.3026575744152069, Training Acc: 76.15%\n",
      "              Val Loss: 1.1900701522827148, Val Acc: 67.20%\n",
      "Epoch: 6010,     Training Loss: 0.353176087141037, Training Acc: 76.16%\n",
      "              Val Loss: 1.2162593603134155, Val Acc: 67.20%\n",
      "Epoch: 6011,     Training Loss: 0.30292460322380066, Training Acc: 76.16%\n",
      "              Val Loss: 1.1706442832946777, Val Acc: 67.20%\n",
      "Epoch: 6012,     Training Loss: 0.2872145175933838, Training Acc: 76.16%\n",
      "              Val Loss: 1.1872140169143677, Val Acc: 67.20%\n",
      "Epoch: 6013,     Training Loss: 0.3351510763168335, Training Acc: 76.16%\n",
      "              Val Loss: 1.2381587028503418, Val Acc: 67.20%\n",
      "Epoch: 6014,     Training Loss: 0.31001701951026917, Training Acc: 76.16%\n",
      "              Val Loss: 1.1598179340362549, Val Acc: 67.20%\n",
      "Epoch: 6015,     Training Loss: 0.3004321753978729, Training Acc: 76.16%\n",
      "              Val Loss: 1.1369613409042358, Val Acc: 67.20%\n",
      "Epoch: 6016,     Training Loss: 0.31457823514938354, Training Acc: 76.17%\n",
      "              Val Loss: 1.1974254846572876, Val Acc: 67.21%\n",
      "Epoch: 6017,     Training Loss: 0.3110790550708771, Training Acc: 76.17%\n",
      "              Val Loss: 1.1885625123977661, Val Acc: 67.21%\n",
      "Epoch: 6018,     Training Loss: 0.28196534514427185, Training Acc: 76.17%\n",
      "              Val Loss: 1.1880342960357666, Val Acc: 67.21%\n",
      "Epoch: 6019,     Training Loss: 0.29552245140075684, Training Acc: 76.17%\n",
      "              Val Loss: 1.169036865234375, Val Acc: 67.21%\n",
      "Epoch: 6020,     Training Loss: 0.2796129882335663, Training Acc: 76.17%\n",
      "              Val Loss: 1.2228163480758667, Val Acc: 67.21%\n",
      "Epoch: 6021,     Training Loss: 0.32996219396591187, Training Acc: 76.18%\n",
      "              Val Loss: 1.1838091611862183, Val Acc: 67.21%\n",
      "Epoch: 6022,     Training Loss: 0.3259614109992981, Training Acc: 76.18%\n",
      "              Val Loss: 1.1649737358093262, Val Acc: 67.21%\n",
      "Epoch: 6023,     Training Loss: 0.3435429334640503, Training Acc: 76.18%\n",
      "              Val Loss: 1.1864173412322998, Val Acc: 67.21%\n",
      "Epoch: 6024,     Training Loss: 0.2843519151210785, Training Acc: 76.18%\n",
      "              Val Loss: 1.251914143562317, Val Acc: 67.21%\n",
      "Epoch: 6025,     Training Loss: 0.3111242949962616, Training Acc: 76.18%\n",
      "              Val Loss: 1.2735100984573364, Val Acc: 67.21%\n",
      "Epoch: 6026,     Training Loss: 0.39013850688934326, Training Acc: 76.18%\n",
      "              Val Loss: 1.2224687337875366, Val Acc: 67.21%\n",
      "Epoch: 6027,     Training Loss: 0.31186577677726746, Training Acc: 76.19%\n",
      "              Val Loss: 1.1900657415390015, Val Acc: 67.21%\n",
      "Epoch: 6028,     Training Loss: 0.2995418310165405, Training Acc: 76.19%\n",
      "              Val Loss: 1.1566210985183716, Val Acc: 67.21%\n",
      "Epoch: 6029,     Training Loss: 0.31706711649894714, Training Acc: 76.19%\n",
      "              Val Loss: 1.2296310663223267, Val Acc: 67.21%\n",
      "Epoch: 6030,     Training Loss: 0.3241156041622162, Training Acc: 76.19%\n",
      "              Val Loss: 1.1968352794647217, Val Acc: 67.21%\n",
      "Epoch: 6031,     Training Loss: 0.31402626633644104, Training Acc: 76.19%\n",
      "              Val Loss: 1.1695224046707153, Val Acc: 67.21%\n",
      "Epoch: 6032,     Training Loss: 0.2839794158935547, Training Acc: 76.19%\n",
      "              Val Loss: 1.2231966257095337, Val Acc: 67.21%\n",
      "Epoch: 6033,     Training Loss: 0.31394416093826294, Training Acc: 76.20%\n",
      "              Val Loss: 1.2005200386047363, Val Acc: 67.21%\n",
      "Epoch: 6034,     Training Loss: 0.3227735459804535, Training Acc: 76.20%\n",
      "              Val Loss: 1.229849934577942, Val Acc: 67.21%\n",
      "Epoch: 6035,     Training Loss: 0.2984240651130676, Training Acc: 76.20%\n",
      "              Val Loss: 1.1956911087036133, Val Acc: 67.21%\n",
      "Epoch: 6036,     Training Loss: 0.29783615469932556, Training Acc: 76.20%\n",
      "              Val Loss: 1.1737356185913086, Val Acc: 67.21%\n",
      "Epoch: 6037,     Training Loss: 0.3152713477611542, Training Acc: 76.20%\n",
      "              Val Loss: 1.2416293621063232, Val Acc: 67.21%\n",
      "Epoch: 6038,     Training Loss: 0.32239830493927, Training Acc: 76.20%\n",
      "              Val Loss: 1.1931946277618408, Val Acc: 67.22%\n",
      "Epoch: 6039,     Training Loss: 0.2804509997367859, Training Acc: 76.21%\n",
      "              Val Loss: 1.2099400758743286, Val Acc: 67.22%\n",
      "Epoch: 6040,     Training Loss: 0.2763347625732422, Training Acc: 76.21%\n",
      "              Val Loss: 1.2300564050674438, Val Acc: 67.22%\n",
      "Epoch: 6041,     Training Loss: 0.2914651930332184, Training Acc: 76.21%\n",
      "              Val Loss: 1.2359654903411865, Val Acc: 67.22%\n",
      "Epoch: 6042,     Training Loss: 0.3114527463912964, Training Acc: 76.21%\n",
      "              Val Loss: 1.1777933835983276, Val Acc: 67.22%\n",
      "Epoch: 6043,     Training Loss: 0.29576584696769714, Training Acc: 76.21%\n",
      "              Val Loss: 1.1244853734970093, Val Acc: 67.22%\n",
      "Epoch: 6044,     Training Loss: 0.27677494287490845, Training Acc: 76.22%\n",
      "              Val Loss: 1.1577253341674805, Val Acc: 67.22%\n",
      "Epoch: 6045,     Training Loss: 0.2781040370464325, Training Acc: 76.22%\n",
      "              Val Loss: 1.1781059503555298, Val Acc: 67.22%\n",
      "Epoch: 6046,     Training Loss: 0.2686033546924591, Training Acc: 76.22%\n",
      "              Val Loss: 1.1886167526245117, Val Acc: 67.22%\n",
      "Epoch: 6047,     Training Loss: 0.2927393615245819, Training Acc: 76.22%\n",
      "              Val Loss: 1.2249367237091064, Val Acc: 67.22%\n",
      "Epoch: 6048,     Training Loss: 0.28685641288757324, Training Acc: 76.22%\n",
      "              Val Loss: 1.206265926361084, Val Acc: 67.22%\n",
      "Epoch: 6049,     Training Loss: 0.29262232780456543, Training Acc: 76.23%\n",
      "              Val Loss: 1.1603972911834717, Val Acc: 67.22%\n",
      "Epoch: 6050,     Training Loss: 0.28969553112983704, Training Acc: 76.23%\n",
      "              Val Loss: 1.1474002599716187, Val Acc: 67.22%\n",
      "Epoch: 6051,     Training Loss: 0.28072524070739746, Training Acc: 76.23%\n",
      "              Val Loss: 1.180464267730713, Val Acc: 67.22%\n",
      "Epoch: 6052,     Training Loss: 0.28127995133399963, Training Acc: 76.23%\n",
      "              Val Loss: 1.202736496925354, Val Acc: 67.22%\n",
      "Epoch: 6053,     Training Loss: 0.27449852228164673, Training Acc: 76.23%\n",
      "              Val Loss: 1.2079676389694214, Val Acc: 67.22%\n",
      "Epoch: 6054,     Training Loss: 0.27984505891799927, Training Acc: 76.23%\n",
      "              Val Loss: 1.2122350931167603, Val Acc: 67.22%\n",
      "Epoch: 6055,     Training Loss: 0.26986977458000183, Training Acc: 76.24%\n",
      "              Val Loss: 1.2033379077911377, Val Acc: 67.23%\n",
      "Epoch: 6056,     Training Loss: 0.28531309962272644, Training Acc: 76.24%\n",
      "              Val Loss: 1.1512398719787598, Val Acc: 67.23%\n",
      "Epoch: 6057,     Training Loss: 0.2575760781764984, Training Acc: 76.24%\n",
      "              Val Loss: 1.1767374277114868, Val Acc: 67.23%\n",
      "Epoch: 6058,     Training Loss: 0.27257898449897766, Training Acc: 76.24%\n",
      "              Val Loss: 1.1736631393432617, Val Acc: 67.23%\n",
      "Epoch: 6059,     Training Loss: 0.2680966258049011, Training Acc: 76.24%\n",
      "              Val Loss: 1.1904734373092651, Val Acc: 67.23%\n",
      "Epoch: 6060,     Training Loss: 0.2648336887359619, Training Acc: 76.25%\n",
      "              Val Loss: 1.2019305229187012, Val Acc: 67.23%\n",
      "Epoch: 6061,     Training Loss: 0.27092620730400085, Training Acc: 76.25%\n",
      "              Val Loss: 1.1916346549987793, Val Acc: 67.23%\n",
      "Epoch: 6062,     Training Loss: 0.2639857530593872, Training Acc: 76.25%\n",
      "              Val Loss: 1.1936485767364502, Val Acc: 67.23%\n",
      "Epoch: 6063,     Training Loss: 0.2757140100002289, Training Acc: 76.25%\n",
      "              Val Loss: 1.187780737876892, Val Acc: 67.23%\n",
      "Epoch: 6064,     Training Loss: 0.25634658336639404, Training Acc: 76.26%\n",
      "              Val Loss: 1.1640774011611938, Val Acc: 67.23%\n",
      "Epoch: 6065,     Training Loss: 0.25488579273223877, Training Acc: 76.26%\n",
      "              Val Loss: 1.155772089958191, Val Acc: 67.23%\n",
      "Epoch: 6066,     Training Loss: 0.25996482372283936, Training Acc: 76.26%\n",
      "              Val Loss: 1.1853824853897095, Val Acc: 67.23%\n",
      "Epoch: 6067,     Training Loss: 0.2727225720882416, Training Acc: 76.26%\n",
      "              Val Loss: 1.2157312631607056, Val Acc: 67.23%\n",
      "Epoch: 6068,     Training Loss: 0.3332448899745941, Training Acc: 76.26%\n",
      "              Val Loss: 1.253738522529602, Val Acc: 67.23%\n",
      "Epoch: 6069,     Training Loss: 0.3245525062084198, Training Acc: 76.26%\n",
      "              Val Loss: 1.2333236932754517, Val Acc: 67.23%\n",
      "Epoch: 6070,     Training Loss: 0.3099905550479889, Training Acc: 76.27%\n",
      "              Val Loss: 1.1854894161224365, Val Acc: 67.23%\n",
      "Epoch: 6071,     Training Loss: 0.2679429352283478, Training Acc: 76.27%\n",
      "              Val Loss: 1.2739782333374023, Val Acc: 67.23%\n",
      "Epoch: 6072,     Training Loss: 0.32987841963768005, Training Acc: 76.27%\n",
      "              Val Loss: 1.3947367668151855, Val Acc: 67.23%\n",
      "Epoch: 6073,     Training Loss: 0.5294902920722961, Training Acc: 76.27%\n",
      "              Val Loss: 1.2199492454528809, Val Acc: 67.23%\n",
      "Epoch: 6074,     Training Loss: 0.334445983171463, Training Acc: 76.27%\n",
      "              Val Loss: 1.2257287502288818, Val Acc: 67.23%\n",
      "Epoch: 6075,     Training Loss: 0.3326120674610138, Training Acc: 76.27%\n",
      "              Val Loss: 1.3242251873016357, Val Acc: 67.23%\n",
      "Epoch: 6076,     Training Loss: 0.44669491052627563, Training Acc: 76.27%\n",
      "              Val Loss: 1.3435657024383545, Val Acc: 67.24%\n",
      "Epoch: 6077,     Training Loss: 0.3578142523765564, Training Acc: 76.28%\n",
      "              Val Loss: 1.3025195598602295, Val Acc: 67.24%\n",
      "Epoch: 6078,     Training Loss: 0.38858139514923096, Training Acc: 76.28%\n",
      "              Val Loss: 1.3000737428665161, Val Acc: 67.23%\n",
      "Epoch: 6079,     Training Loss: 0.47497403621673584, Training Acc: 76.28%\n",
      "              Val Loss: 1.325576663017273, Val Acc: 67.24%\n",
      "Epoch: 6080,     Training Loss: 0.4387274980545044, Training Acc: 76.28%\n",
      "              Val Loss: 1.231398582458496, Val Acc: 67.24%\n",
      "Epoch: 6081,     Training Loss: 0.34090039134025574, Training Acc: 76.28%\n",
      "              Val Loss: 1.255509853363037, Val Acc: 67.24%\n",
      "Epoch: 6082,     Training Loss: 0.3997952342033386, Training Acc: 76.28%\n",
      "              Val Loss: 1.2262275218963623, Val Acc: 67.24%\n",
      "Epoch: 6083,     Training Loss: 0.41035759449005127, Training Acc: 76.28%\n",
      "              Val Loss: 1.44011652469635, Val Acc: 67.24%\n",
      "Epoch: 6084,     Training Loss: 0.6308742165565491, Training Acc: 76.28%\n",
      "              Val Loss: 1.1811071634292603, Val Acc: 67.24%\n",
      "Epoch: 6085,     Training Loss: 0.4053283929824829, Training Acc: 76.28%\n",
      "              Val Loss: 1.3870936632156372, Val Acc: 67.24%\n",
      "Epoch: 6086,     Training Loss: 0.5319812297821045, Training Acc: 76.28%\n",
      "              Val Loss: 1.5509697198867798, Val Acc: 67.24%\n",
      "Epoch: 6087,     Training Loss: 0.7137748599052429, Training Acc: 76.28%\n",
      "              Val Loss: 1.186133623123169, Val Acc: 67.24%\n",
      "Epoch: 6088,     Training Loss: 0.43181678652763367, Training Acc: 76.28%\n",
      "              Val Loss: 1.3951297998428345, Val Acc: 67.24%\n",
      "Epoch: 6089,     Training Loss: 0.6603454351425171, Training Acc: 76.28%\n",
      "              Val Loss: 1.4321829080581665, Val Acc: 67.23%\n",
      "Epoch: 6090,     Training Loss: 0.7371324896812439, Training Acc: 76.28%\n",
      "              Val Loss: 1.4161746501922607, Val Acc: 67.23%\n",
      "Epoch: 6091,     Training Loss: 0.568138062953949, Training Acc: 76.28%\n",
      "              Val Loss: 1.7539088726043701, Val Acc: 67.23%\n",
      "Epoch: 6092,     Training Loss: 0.7854864597320557, Training Acc: 76.28%\n",
      "              Val Loss: 1.4670600891113281, Val Acc: 67.23%\n",
      "Epoch: 6093,     Training Loss: 0.6099773645401001, Training Acc: 76.28%\n",
      "              Val Loss: 1.2377004623413086, Val Acc: 67.23%\n",
      "Epoch: 6094,     Training Loss: 0.5499046444892883, Training Acc: 76.28%\n",
      "              Val Loss: 1.2623765468597412, Val Acc: 67.23%\n",
      "Epoch: 6095,     Training Loss: 0.5813893675804138, Training Acc: 76.28%\n",
      "              Val Loss: 1.258049726486206, Val Acc: 67.23%\n",
      "Epoch: 6096,     Training Loss: 0.6094468235969543, Training Acc: 76.28%\n",
      "              Val Loss: 1.1424736976623535, Val Acc: 67.23%\n",
      "Epoch: 6097,     Training Loss: 0.4657541513442993, Training Acc: 76.28%\n",
      "              Val Loss: 1.2694933414459229, Val Acc: 67.23%\n",
      "Epoch: 6098,     Training Loss: 0.5108899474143982, Training Acc: 76.28%\n",
      "              Val Loss: 1.2156926393508911, Val Acc: 67.23%\n",
      "Epoch: 6099,     Training Loss: 0.4579502046108246, Training Acc: 76.28%\n",
      "              Val Loss: 1.2209774255752563, Val Acc: 67.23%\n",
      "Epoch: 6100,     Training Loss: 0.4993414282798767, Training Acc: 76.28%\n",
      "              Val Loss: 1.1053857803344727, Val Acc: 67.23%\n",
      "Epoch: 6101,     Training Loss: 0.4108906686306, Training Acc: 76.29%\n",
      "              Val Loss: 1.1573927402496338, Val Acc: 67.23%\n",
      "Epoch: 6102,     Training Loss: 0.4588344991207123, Training Acc: 76.29%\n",
      "              Val Loss: 1.0697126388549805, Val Acc: 67.23%\n",
      "Epoch: 6103,     Training Loss: 0.41892823576927185, Training Acc: 76.29%\n",
      "              Val Loss: 4.302305221557617, Val Acc: 67.23%\n",
      "Epoch: 6104,     Training Loss: 2.8495004177093506, Training Acc: 76.29%\n",
      "              Val Loss: 2.3442583084106445, Val Acc: 67.23%\n",
      "Epoch: 6105,     Training Loss: 1.5956203937530518, Training Acc: 76.29%\n",
      "              Val Loss: 2.9916629791259766, Val Acc: 67.23%\n",
      "Epoch: 6106,     Training Loss: 2.435750961303711, Training Acc: 76.28%\n",
      "              Val Loss: 3.2544870376586914, Val Acc: 67.22%\n",
      "Epoch: 6107,     Training Loss: 2.6190710067749023, Training Acc: 76.28%\n",
      "              Val Loss: 1.769276738166809, Val Acc: 67.22%\n",
      "Epoch: 6108,     Training Loss: 1.4431941509246826, Training Acc: 76.27%\n",
      "              Val Loss: 1.841086983680725, Val Acc: 67.22%\n",
      "Epoch: 6109,     Training Loss: 1.3933879137039185, Training Acc: 76.27%\n",
      "              Val Loss: 1.8161518573760986, Val Acc: 67.22%\n",
      "Epoch: 6110,     Training Loss: 1.3630262613296509, Training Acc: 76.27%\n",
      "              Val Loss: 1.82988703250885, Val Acc: 67.21%\n",
      "Epoch: 6111,     Training Loss: 1.4181498289108276, Training Acc: 76.26%\n",
      "              Val Loss: 2.274064302444458, Val Acc: 67.21%\n",
      "Epoch: 6112,     Training Loss: 1.7720173597335815, Training Acc: 76.26%\n",
      "              Val Loss: 2.6838600635528564, Val Acc: 67.21%\n",
      "Epoch: 6113,     Training Loss: 2.2169716358184814, Training Acc: 76.25%\n",
      "              Val Loss: 2.1531312465667725, Val Acc: 67.20%\n",
      "Epoch: 6114,     Training Loss: 1.7425442934036255, Training Acc: 76.25%\n",
      "              Val Loss: 1.7393690347671509, Val Acc: 67.20%\n",
      "Epoch: 6115,     Training Loss: 1.3419612646102905, Training Acc: 76.25%\n",
      "              Val Loss: 1.3908836841583252, Val Acc: 67.20%\n",
      "Epoch: 6116,     Training Loss: 1.1298863887786865, Training Acc: 76.25%\n",
      "              Val Loss: 1.349155306816101, Val Acc: 67.20%\n",
      "Epoch: 6117,     Training Loss: 1.1546767950057983, Training Acc: 76.24%\n",
      "              Val Loss: 1.4053421020507812, Val Acc: 67.20%\n",
      "Epoch: 6118,     Training Loss: 1.1586740016937256, Training Acc: 76.24%\n",
      "              Val Loss: 2.0637009143829346, Val Acc: 67.19%\n",
      "Epoch: 6119,     Training Loss: 1.7706445455551147, Training Acc: 76.24%\n",
      "              Val Loss: 1.1559559106826782, Val Acc: 67.19%\n",
      "Epoch: 6120,     Training Loss: 0.9691181182861328, Training Acc: 76.23%\n",
      "              Val Loss: 2.0412585735321045, Val Acc: 67.19%\n",
      "Epoch: 6121,     Training Loss: 1.7206063270568848, Training Acc: 76.23%\n",
      "              Val Loss: 1.801112413406372, Val Acc: 67.19%\n",
      "Epoch: 6122,     Training Loss: 1.4190924167633057, Training Acc: 76.23%\n",
      "              Val Loss: 1.4099620580673218, Val Acc: 67.18%\n",
      "Epoch: 6123,     Training Loss: 1.1872122287750244, Training Acc: 76.22%\n",
      "              Val Loss: 1.4234939813613892, Val Acc: 67.18%\n",
      "Epoch: 6124,     Training Loss: 1.226997971534729, Training Acc: 76.22%\n",
      "              Val Loss: 1.3105010986328125, Val Acc: 67.18%\n",
      "Epoch: 6125,     Training Loss: 1.1571567058563232, Training Acc: 76.22%\n",
      "              Val Loss: 1.2050206661224365, Val Acc: 67.18%\n",
      "Epoch: 6126,     Training Loss: 0.9858500957489014, Training Acc: 76.22%\n",
      "              Val Loss: 1.2223222255706787, Val Acc: 67.18%\n",
      "Epoch: 6127,     Training Loss: 1.0068793296813965, Training Acc: 76.21%\n",
      "              Val Loss: 1.243379831314087, Val Acc: 67.18%\n",
      "Epoch: 6128,     Training Loss: 1.0224738121032715, Training Acc: 76.21%\n",
      "              Val Loss: 1.086737871170044, Val Acc: 67.17%\n",
      "Epoch: 6129,     Training Loss: 0.8644258975982666, Training Acc: 76.21%\n",
      "              Val Loss: 1.1321933269500732, Val Acc: 67.17%\n",
      "Epoch: 6130,     Training Loss: 0.9272812604904175, Training Acc: 76.21%\n",
      "              Val Loss: 1.0182278156280518, Val Acc: 67.17%\n",
      "Epoch: 6131,     Training Loss: 0.8008407354354858, Training Acc: 76.20%\n",
      "              Val Loss: 1.0393489599227905, Val Acc: 67.17%\n",
      "Epoch: 6132,     Training Loss: 0.7940101623535156, Training Acc: 76.20%\n",
      "              Val Loss: 1.1137140989303589, Val Acc: 67.17%\n",
      "Epoch: 6133,     Training Loss: 0.8596591949462891, Training Acc: 76.20%\n",
      "              Val Loss: 0.9633271098136902, Val Acc: 67.17%\n",
      "Epoch: 6134,     Training Loss: 0.7388400435447693, Training Acc: 76.20%\n",
      "              Val Loss: 1.0874903202056885, Val Acc: 67.17%\n",
      "Epoch: 6135,     Training Loss: 0.8519058227539062, Training Acc: 76.20%\n",
      "              Val Loss: 0.9974310994148254, Val Acc: 67.17%\n",
      "Epoch: 6136,     Training Loss: 0.7842642068862915, Training Acc: 76.20%\n",
      "              Val Loss: 0.9498400688171387, Val Acc: 67.17%\n",
      "Epoch: 6137,     Training Loss: 0.7168047428131104, Training Acc: 76.19%\n",
      "              Val Loss: 1.0884342193603516, Val Acc: 67.17%\n",
      "Epoch: 6138,     Training Loss: 0.8111318945884705, Training Acc: 76.19%\n",
      "              Val Loss: 0.9171038269996643, Val Acc: 67.17%\n",
      "Epoch: 6139,     Training Loss: 0.6862924098968506, Training Acc: 76.19%\n",
      "              Val Loss: 0.9651802182197571, Val Acc: 67.17%\n",
      "Epoch: 6140,     Training Loss: 0.738798201084137, Training Acc: 76.19%\n",
      "              Val Loss: 0.9540020823478699, Val Acc: 67.16%\n",
      "Epoch: 6141,     Training Loss: 0.7119197845458984, Training Acc: 76.19%\n",
      "              Val Loss: 0.9122898578643799, Val Acc: 67.16%\n",
      "Epoch: 6142,     Training Loss: 0.6647502779960632, Training Acc: 76.19%\n",
      "              Val Loss: 0.9869391918182373, Val Acc: 67.16%\n",
      "Epoch: 6143,     Training Loss: 0.7201244235038757, Training Acc: 76.19%\n",
      "              Val Loss: 0.9016985297203064, Val Acc: 67.16%\n",
      "Epoch: 6144,     Training Loss: 0.6601060628890991, Training Acc: 76.19%\n",
      "              Val Loss: 0.8945866227149963, Val Acc: 67.16%\n",
      "Epoch: 6145,     Training Loss: 0.6881954669952393, Training Acc: 76.19%\n",
      "              Val Loss: 0.8752532005310059, Val Acc: 67.16%\n",
      "Epoch: 6146,     Training Loss: 0.6750972270965576, Training Acc: 76.18%\n",
      "              Val Loss: 0.8516697883605957, Val Acc: 67.16%\n",
      "Epoch: 6147,     Training Loss: 0.6413291692733765, Training Acc: 76.18%\n",
      "              Val Loss: 0.8955238461494446, Val Acc: 67.16%\n",
      "Epoch: 6148,     Training Loss: 0.6727733016014099, Training Acc: 76.18%\n",
      "              Val Loss: 0.8486107587814331, Val Acc: 67.16%\n",
      "Epoch: 6149,     Training Loss: 0.6371139883995056, Training Acc: 76.18%\n",
      "              Val Loss: 0.8420857191085815, Val Acc: 67.16%\n",
      "Epoch: 6150,     Training Loss: 0.6410636901855469, Training Acc: 76.18%\n",
      "              Val Loss: 0.8506289124488831, Val Acc: 67.16%\n",
      "Epoch: 6151,     Training Loss: 0.6491451263427734, Training Acc: 76.18%\n",
      "              Val Loss: 0.839171290397644, Val Acc: 67.16%\n",
      "Epoch: 6152,     Training Loss: 0.621553361415863, Training Acc: 76.18%\n",
      "              Val Loss: 0.8704818487167358, Val Acc: 67.16%\n",
      "Epoch: 6153,     Training Loss: 0.6349027156829834, Training Acc: 76.18%\n",
      "              Val Loss: 0.8549558520317078, Val Acc: 67.16%\n",
      "Epoch: 6154,     Training Loss: 0.6243537664413452, Training Acc: 76.18%\n",
      "              Val Loss: 0.8415939211845398, Val Acc: 67.16%\n",
      "Epoch: 6155,     Training Loss: 0.6175351738929749, Training Acc: 76.18%\n",
      "              Val Loss: 0.8466357588768005, Val Acc: 67.16%\n",
      "Epoch: 6156,     Training Loss: 0.6230443716049194, Training Acc: 76.18%\n",
      "              Val Loss: 0.8429036736488342, Val Acc: 67.16%\n",
      "Epoch: 6157,     Training Loss: 0.6088883876800537, Training Acc: 76.18%\n",
      "              Val Loss: 0.8649027347564697, Val Acc: 67.16%\n",
      "Epoch: 6158,     Training Loss: 0.6126097440719604, Training Acc: 76.18%\n",
      "              Val Loss: 0.861409604549408, Val Acc: 67.16%\n",
      "Epoch: 6159,     Training Loss: 0.6075842976570129, Training Acc: 76.18%\n",
      "              Val Loss: 0.8466510772705078, Val Acc: 67.16%\n",
      "Epoch: 6160,     Training Loss: 0.6029193997383118, Training Acc: 76.18%\n",
      "              Val Loss: 0.8437443375587463, Val Acc: 67.17%\n",
      "Epoch: 6161,     Training Loss: 0.6054701805114746, Training Acc: 76.18%\n",
      "              Val Loss: 0.8317988514900208, Val Acc: 67.17%\n",
      "Epoch: 6162,     Training Loss: 0.594296395778656, Training Acc: 76.18%\n",
      "              Val Loss: 0.8395951986312866, Val Acc: 67.17%\n",
      "Epoch: 6163,     Training Loss: 0.598314106464386, Training Acc: 76.18%\n",
      "              Val Loss: 0.8322088122367859, Val Acc: 67.17%\n",
      "Epoch: 6164,     Training Loss: 0.5935401916503906, Training Acc: 76.18%\n",
      "              Val Loss: 0.8169065117835999, Val Acc: 67.17%\n",
      "Epoch: 6165,     Training Loss: 0.5876513123512268, Training Acc: 76.18%\n",
      "              Val Loss: 0.8161978721618652, Val Acc: 67.17%\n",
      "Epoch: 6166,     Training Loss: 0.590140700340271, Training Acc: 76.18%\n",
      "              Val Loss: 0.8160603046417236, Val Acc: 67.17%\n",
      "Epoch: 6167,     Training Loss: 0.5824155211448669, Training Acc: 76.18%\n",
      "              Val Loss: 0.8293870687484741, Val Acc: 67.17%\n",
      "Epoch: 6168,     Training Loss: 0.5844499468803406, Training Acc: 76.18%\n",
      "              Val Loss: 0.8267865777015686, Val Acc: 67.17%\n",
      "Epoch: 6169,     Training Loss: 0.582580029964447, Training Acc: 76.18%\n",
      "              Val Loss: 0.8165178894996643, Val Acc: 67.17%\n",
      "Epoch: 6170,     Training Loss: 0.5756914615631104, Training Acc: 76.18%\n",
      "              Val Loss: 0.8171471357345581, Val Acc: 67.17%\n",
      "Epoch: 6171,     Training Loss: 0.5765994191169739, Training Acc: 76.18%\n",
      "              Val Loss: 0.8154364824295044, Val Acc: 67.17%\n",
      "Epoch: 6172,     Training Loss: 0.5721907019615173, Training Acc: 76.18%\n",
      "              Val Loss: 0.826246976852417, Val Acc: 67.17%\n",
      "Epoch: 6173,     Training Loss: 0.5743045210838318, Training Acc: 76.18%\n",
      "              Val Loss: 0.8207107782363892, Val Acc: 67.17%\n",
      "Epoch: 6174,     Training Loss: 0.5697317719459534, Training Acc: 76.18%\n",
      "              Val Loss: 0.8143059015274048, Val Acc: 67.17%\n",
      "Epoch: 6175,     Training Loss: 0.565517246723175, Training Acc: 76.18%\n",
      "              Val Loss: 0.8113391399383545, Val Acc: 67.17%\n",
      "Epoch: 6176,     Training Loss: 0.5656300187110901, Training Acc: 76.18%\n",
      "              Val Loss: 0.8107049465179443, Val Acc: 67.17%\n",
      "Epoch: 6177,     Training Loss: 0.5625227689743042, Training Acc: 76.18%\n",
      "              Val Loss: 0.8139698505401611, Val Acc: 67.17%\n",
      "Epoch: 6178,     Training Loss: 0.5625295639038086, Training Acc: 76.18%\n",
      "              Val Loss: 0.8069487810134888, Val Acc: 67.17%\n",
      "Epoch: 6179,     Training Loss: 0.5608580708503723, Training Acc: 76.18%\n",
      "              Val Loss: 0.7999608516693115, Val Acc: 67.18%\n",
      "Epoch: 6180,     Training Loss: 0.5556871891021729, Training Acc: 76.18%\n",
      "              Val Loss: 0.8105078339576721, Val Acc: 67.18%\n",
      "Epoch: 6181,     Training Loss: 0.5595070123672485, Training Acc: 76.18%\n",
      "              Val Loss: 0.8103302121162415, Val Acc: 67.18%\n",
      "Epoch: 6182,     Training Loss: 0.5602405071258545, Training Acc: 76.18%\n",
      "              Val Loss: 0.8052175641059875, Val Acc: 67.18%\n",
      "Epoch: 6183,     Training Loss: 0.5513166189193726, Training Acc: 76.18%\n",
      "              Val Loss: 0.8206577897071838, Val Acc: 67.18%\n",
      "Epoch: 6184,     Training Loss: 0.5602924227714539, Training Acc: 76.18%\n",
      "              Val Loss: 0.8116007447242737, Val Acc: 67.18%\n",
      "Epoch: 6185,     Training Loss: 0.5583255887031555, Training Acc: 76.19%\n",
      "              Val Loss: 0.8219571113586426, Val Acc: 67.18%\n",
      "Epoch: 6186,     Training Loss: 0.5645452737808228, Training Acc: 76.19%\n",
      "              Val Loss: 0.8128381967544556, Val Acc: 67.18%\n",
      "Epoch: 6187,     Training Loss: 0.5537172555923462, Training Acc: 76.19%\n",
      "              Val Loss: 0.8194620013237, Val Acc: 67.18%\n",
      "Epoch: 6188,     Training Loss: 0.5614797472953796, Training Acc: 76.19%\n",
      "              Val Loss: 0.8137316703796387, Val Acc: 67.18%\n",
      "Epoch: 6189,     Training Loss: 0.5557864904403687, Training Acc: 76.19%\n",
      "              Val Loss: 0.7951070666313171, Val Acc: 67.18%\n",
      "Epoch: 6190,     Training Loss: 0.5404760241508484, Training Acc: 76.19%\n",
      "              Val Loss: 0.8140684366226196, Val Acc: 67.18%\n",
      "Epoch: 6191,     Training Loss: 0.5566560626029968, Training Acc: 76.19%\n",
      "              Val Loss: 0.7952933311462402, Val Acc: 67.18%\n",
      "Epoch: 6192,     Training Loss: 0.5368440747261047, Training Acc: 76.19%\n",
      "              Val Loss: 0.7978723645210266, Val Acc: 67.18%\n",
      "Epoch: 6193,     Training Loss: 0.5392890572547913, Training Acc: 76.19%\n",
      "              Val Loss: 0.8042717576026917, Val Acc: 67.19%\n",
      "Epoch: 6194,     Training Loss: 0.5439921617507935, Training Acc: 76.19%\n",
      "              Val Loss: 0.7911325693130493, Val Acc: 67.19%\n",
      "Epoch: 6195,     Training Loss: 0.5310091972351074, Training Acc: 76.19%\n",
      "              Val Loss: 0.7987578511238098, Val Acc: 67.19%\n",
      "Epoch: 6196,     Training Loss: 0.5391954183578491, Training Acc: 76.19%\n",
      "              Val Loss: 0.7984607815742493, Val Acc: 67.19%\n",
      "Epoch: 6197,     Training Loss: 0.5343434810638428, Training Acc: 76.19%\n",
      "              Val Loss: 0.7950149774551392, Val Acc: 67.19%\n",
      "Epoch: 6198,     Training Loss: 0.5301771759986877, Training Acc: 76.19%\n",
      "              Val Loss: 0.7938191294670105, Val Acc: 67.19%\n",
      "Epoch: 6199,     Training Loss: 0.5336482524871826, Training Acc: 76.19%\n",
      "              Val Loss: 0.7928757667541504, Val Acc: 67.19%\n",
      "Epoch: 6200,     Training Loss: 0.5280855894088745, Training Acc: 76.19%\n",
      "              Val Loss: 0.8012518286705017, Val Acc: 67.19%\n",
      "Epoch: 6201,     Training Loss: 0.5302618145942688, Training Acc: 76.19%\n",
      "              Val Loss: 0.7920305132865906, Val Acc: 67.19%\n",
      "Epoch: 6202,     Training Loss: 0.5249824523925781, Training Acc: 76.19%\n",
      "              Val Loss: 0.797756016254425, Val Acc: 67.19%\n",
      "Epoch: 6203,     Training Loss: 0.528109073638916, Training Acc: 76.19%\n",
      "              Val Loss: 0.801135241985321, Val Acc: 67.19%\n",
      "Epoch: 6204,     Training Loss: 0.5278164148330688, Training Acc: 76.19%\n",
      "              Val Loss: 0.7863975763320923, Val Acc: 67.19%\n",
      "Epoch: 6205,     Training Loss: 0.5172344446182251, Training Acc: 76.19%\n",
      "              Val Loss: 0.8059287071228027, Val Acc: 67.19%\n",
      "Epoch: 6206,     Training Loss: 0.5318918824195862, Training Acc: 76.20%\n",
      "              Val Loss: 0.8009420037269592, Val Acc: 67.20%\n",
      "Epoch: 6207,     Training Loss: 0.5246684551239014, Training Acc: 76.20%\n",
      "              Val Loss: 0.7867672443389893, Val Acc: 67.20%\n",
      "Epoch: 6208,     Training Loss: 0.5140378475189209, Training Acc: 76.20%\n",
      "              Val Loss: 0.8071547150611877, Val Acc: 67.20%\n",
      "Epoch: 6209,     Training Loss: 0.5320074558258057, Training Acc: 76.20%\n",
      "              Val Loss: 0.7953671813011169, Val Acc: 67.20%\n",
      "Epoch: 6210,     Training Loss: 0.5203403234481812, Training Acc: 76.20%\n",
      "              Val Loss: 0.7978278398513794, Val Acc: 67.20%\n",
      "Epoch: 6211,     Training Loss: 0.5178297162055969, Training Acc: 76.20%\n",
      "              Val Loss: 0.7992912530899048, Val Acc: 67.20%\n",
      "Epoch: 6212,     Training Loss: 0.5226845145225525, Training Acc: 76.20%\n",
      "              Val Loss: 0.7953314185142517, Val Acc: 67.20%\n",
      "Epoch: 6213,     Training Loss: 0.520390510559082, Training Acc: 76.20%\n",
      "              Val Loss: 0.794569194316864, Val Acc: 67.20%\n",
      "Epoch: 6214,     Training Loss: 0.5150002837181091, Training Acc: 76.20%\n",
      "              Val Loss: 0.7891091704368591, Val Acc: 67.20%\n",
      "Epoch: 6215,     Training Loss: 0.5113745331764221, Training Acc: 76.20%\n",
      "              Val Loss: 0.7946561574935913, Val Acc: 67.20%\n",
      "Epoch: 6216,     Training Loss: 0.51772141456604, Training Acc: 76.20%\n",
      "              Val Loss: 0.7803654670715332, Val Acc: 67.20%\n",
      "Epoch: 6217,     Training Loss: 0.502733051776886, Training Acc: 76.20%\n",
      "              Val Loss: 0.7843210697174072, Val Acc: 67.21%\n",
      "Epoch: 6218,     Training Loss: 0.5053722262382507, Training Acc: 76.20%\n",
      "              Val Loss: 0.7894928455352783, Val Acc: 67.21%\n",
      "Epoch: 6219,     Training Loss: 0.5099321603775024, Training Acc: 76.20%\n",
      "              Val Loss: 0.7774305939674377, Val Acc: 67.21%\n",
      "Epoch: 6220,     Training Loss: 0.49695178866386414, Training Acc: 76.20%\n",
      "              Val Loss: 0.7798945903778076, Val Acc: 67.21%\n",
      "Epoch: 6221,     Training Loss: 0.5002115368843079, Training Acc: 76.20%\n",
      "              Val Loss: 0.7829443216323853, Val Acc: 67.21%\n",
      "Epoch: 6222,     Training Loss: 0.5048859715461731, Training Acc: 76.21%\n",
      "              Val Loss: 0.774550199508667, Val Acc: 67.21%\n",
      "Epoch: 6223,     Training Loss: 0.49418145418167114, Training Acc: 76.21%\n",
      "              Val Loss: 0.7758629322052002, Val Acc: 67.21%\n",
      "Epoch: 6224,     Training Loss: 0.495222806930542, Training Acc: 76.21%\n",
      "              Val Loss: 0.7830638289451599, Val Acc: 67.21%\n",
      "Epoch: 6225,     Training Loss: 0.5023029446601868, Training Acc: 76.21%\n",
      "              Val Loss: 0.7771420478820801, Val Acc: 67.21%\n",
      "Epoch: 6226,     Training Loss: 0.49405917525291443, Training Acc: 76.21%\n",
      "              Val Loss: 0.7774001359939575, Val Acc: 67.21%\n",
      "Epoch: 6227,     Training Loss: 0.4927109479904175, Training Acc: 76.21%\n",
      "              Val Loss: 0.7966291904449463, Val Acc: 67.22%\n",
      "Epoch: 6228,     Training Loss: 0.5061634182929993, Training Acc: 76.21%\n",
      "              Val Loss: 0.7883519530296326, Val Acc: 67.22%\n",
      "Epoch: 6229,     Training Loss: 0.49589648842811584, Training Acc: 76.21%\n",
      "              Val Loss: 0.7883601188659668, Val Acc: 67.22%\n",
      "Epoch: 6230,     Training Loss: 0.4944021701812744, Training Acc: 76.21%\n",
      "              Val Loss: 0.8217803239822388, Val Acc: 67.22%\n",
      "Epoch: 6231,     Training Loss: 0.5173200964927673, Training Acc: 76.21%\n",
      "              Val Loss: 0.7879717350006104, Val Acc: 67.22%\n",
      "Epoch: 6232,     Training Loss: 0.4953063726425171, Training Acc: 76.21%\n",
      "              Val Loss: 0.7869210839271545, Val Acc: 67.22%\n",
      "Epoch: 6233,     Training Loss: 0.49683234095573425, Training Acc: 76.21%\n",
      "              Val Loss: 0.8330050110816956, Val Acc: 67.22%\n",
      "Epoch: 6234,     Training Loss: 0.5267483592033386, Training Acc: 76.21%\n",
      "              Val Loss: 0.7791681885719299, Val Acc: 67.22%\n",
      "Epoch: 6235,     Training Loss: 0.4904533624649048, Training Acc: 76.21%\n",
      "              Val Loss: 0.7901239991188049, Val Acc: 67.22%\n",
      "Epoch: 6236,     Training Loss: 0.4996682405471802, Training Acc: 76.22%\n",
      "              Val Loss: 0.8282871842384338, Val Acc: 67.22%\n",
      "Epoch: 6237,     Training Loss: 0.5177236795425415, Training Acc: 76.22%\n",
      "              Val Loss: 0.7797886729240417, Val Acc: 67.22%\n",
      "Epoch: 6238,     Training Loss: 0.48097777366638184, Training Acc: 76.22%\n",
      "              Val Loss: 0.798431932926178, Val Acc: 67.23%\n",
      "Epoch: 6239,     Training Loss: 0.49781444668769836, Training Acc: 76.22%\n",
      "              Val Loss: 0.829760730266571, Val Acc: 67.23%\n",
      "Epoch: 6240,     Training Loss: 0.5116335153579712, Training Acc: 76.22%\n",
      "              Val Loss: 0.7880499958992004, Val Acc: 67.23%\n",
      "Epoch: 6241,     Training Loss: 0.4839346706867218, Training Acc: 76.22%\n",
      "              Val Loss: 0.7939676642417908, Val Acc: 67.23%\n",
      "Epoch: 6242,     Training Loss: 0.49510085582733154, Training Acc: 76.22%\n",
      "              Val Loss: 0.8274366855621338, Val Acc: 67.23%\n",
      "Epoch: 6243,     Training Loss: 0.5130665302276611, Training Acc: 76.22%\n",
      "              Val Loss: 0.7755236625671387, Val Acc: 67.23%\n",
      "Epoch: 6244,     Training Loss: 0.48008033633232117, Training Acc: 76.22%\n",
      "              Val Loss: 0.7849498987197876, Val Acc: 67.23%\n",
      "Epoch: 6245,     Training Loss: 0.488811731338501, Training Acc: 76.22%\n",
      "              Val Loss: 0.8259332180023193, Val Acc: 67.23%\n",
      "Epoch: 6246,     Training Loss: 0.507455050945282, Training Acc: 76.22%\n",
      "              Val Loss: 0.7718724012374878, Val Acc: 67.23%\n",
      "Epoch: 6247,     Training Loss: 0.47241249680519104, Training Acc: 76.22%\n",
      "              Val Loss: 0.7812974452972412, Val Acc: 67.23%\n",
      "Epoch: 6248,     Training Loss: 0.48176613450050354, Training Acc: 76.22%\n",
      "              Val Loss: 0.820772111415863, Val Acc: 67.23%\n",
      "Epoch: 6249,     Training Loss: 0.5012288689613342, Training Acc: 76.22%\n",
      "              Val Loss: 0.7779775261878967, Val Acc: 67.23%\n",
      "Epoch: 6250,     Training Loss: 0.4729171395301819, Training Acc: 76.23%\n",
      "              Val Loss: 0.7794216871261597, Val Acc: 67.24%\n",
      "Epoch: 6251,     Training Loss: 0.47728851437568665, Training Acc: 76.23%\n",
      "              Val Loss: 0.8250961899757385, Val Acc: 67.24%\n",
      "Epoch: 6252,     Training Loss: 0.5035262703895569, Training Acc: 76.23%\n",
      "              Val Loss: 0.7757564783096313, Val Acc: 67.24%\n",
      "Epoch: 6253,     Training Loss: 0.47162413597106934, Training Acc: 76.23%\n",
      "              Val Loss: 0.7824783325195312, Val Acc: 67.24%\n",
      "Epoch: 6254,     Training Loss: 0.47468826174736023, Training Acc: 76.23%\n",
      "              Val Loss: 0.8319010138511658, Val Acc: 67.24%\n",
      "Epoch: 6255,     Training Loss: 0.500950038433075, Training Acc: 76.23%\n",
      "              Val Loss: 0.7810106873512268, Val Acc: 67.24%\n",
      "Epoch: 6256,     Training Loss: 0.46930885314941406, Training Acc: 76.23%\n",
      "              Val Loss: 0.7814701795578003, Val Acc: 67.24%\n",
      "Epoch: 6257,     Training Loss: 0.469941109418869, Training Acc: 76.23%\n",
      "              Val Loss: 0.8375442028045654, Val Acc: 67.24%\n",
      "Epoch: 6258,     Training Loss: 0.5021094679832458, Training Acc: 76.23%\n",
      "              Val Loss: 0.7839483022689819, Val Acc: 67.24%\n",
      "Epoch: 6259,     Training Loss: 0.4706617295742035, Training Acc: 76.23%\n",
      "              Val Loss: 0.7832745313644409, Val Acc: 67.24%\n",
      "Epoch: 6260,     Training Loss: 0.46982476115226746, Training Acc: 76.23%\n",
      "              Val Loss: 0.842424213886261, Val Acc: 67.24%\n",
      "Epoch: 6261,     Training Loss: 0.5026661157608032, Training Acc: 76.23%\n",
      "              Val Loss: 0.7844284772872925, Val Acc: 67.25%\n",
      "Epoch: 6262,     Training Loss: 0.4668259024620056, Training Acc: 76.24%\n",
      "              Val Loss: 0.7833074927330017, Val Acc: 67.25%\n",
      "Epoch: 6263,     Training Loss: 0.46320271492004395, Training Acc: 76.24%\n",
      "              Val Loss: 0.8393937945365906, Val Acc: 67.25%\n",
      "Epoch: 6264,     Training Loss: 0.49561893939971924, Training Acc: 76.24%\n",
      "              Val Loss: 0.7866725325584412, Val Acc: 67.25%\n",
      "Epoch: 6265,     Training Loss: 0.46544861793518066, Training Acc: 76.24%\n",
      "              Val Loss: 0.7812397480010986, Val Acc: 67.25%\n",
      "Epoch: 6266,     Training Loss: 0.4590364098548889, Training Acc: 76.24%\n",
      "              Val Loss: 0.8239814043045044, Val Acc: 67.25%\n",
      "Epoch: 6267,     Training Loss: 0.48521193861961365, Training Acc: 76.24%\n",
      "              Val Loss: 0.7835701704025269, Val Acc: 67.25%\n",
      "Epoch: 6268,     Training Loss: 0.4626361131668091, Training Acc: 76.24%\n",
      "              Val Loss: 0.7781755328178406, Val Acc: 67.25%\n",
      "Epoch: 6269,     Training Loss: 0.4533289074897766, Training Acc: 76.24%\n",
      "              Val Loss: 0.8066406846046448, Val Acc: 67.25%\n",
      "Epoch: 6270,     Training Loss: 0.47191229462623596, Training Acc: 76.24%\n",
      "              Val Loss: 0.7932109236717224, Val Acc: 67.25%\n",
      "Epoch: 6271,     Training Loss: 0.4680265784263611, Training Acc: 76.24%\n",
      "              Val Loss: 0.7834620475769043, Val Acc: 67.25%\n",
      "Epoch: 6272,     Training Loss: 0.45236673951148987, Training Acc: 76.24%\n",
      "              Val Loss: 0.7924429178237915, Val Acc: 67.26%\n",
      "Epoch: 6273,     Training Loss: 0.4613766074180603, Training Acc: 76.24%\n",
      "              Val Loss: 0.8010818958282471, Val Acc: 67.26%\n",
      "Epoch: 6274,     Training Loss: 0.47772473096847534, Training Acc: 76.25%\n",
      "              Val Loss: 0.785206139087677, Val Acc: 67.26%\n",
      "Epoch: 6275,     Training Loss: 0.45219725370407104, Training Acc: 76.25%\n",
      "              Val Loss: 0.7843911051750183, Val Acc: 67.26%\n",
      "Epoch: 6276,     Training Loss: 0.4509829580783844, Training Acc: 76.25%\n",
      "              Val Loss: 0.8033084273338318, Val Acc: 67.26%\n",
      "Epoch: 6277,     Training Loss: 0.4748876094818115, Training Acc: 76.25%\n",
      "              Val Loss: 0.7901193499565125, Val Acc: 67.26%\n",
      "Epoch: 6278,     Training Loss: 0.45319506525993347, Training Acc: 76.25%\n",
      "              Val Loss: 0.7816011905670166, Val Acc: 67.26%\n",
      "Epoch: 6279,     Training Loss: 0.44394493103027344, Training Acc: 76.25%\n",
      "              Val Loss: 0.7897475957870483, Val Acc: 67.26%\n",
      "Epoch: 6280,     Training Loss: 0.4546052813529968, Training Acc: 76.25%\n",
      "              Val Loss: 0.7988908290863037, Val Acc: 67.26%\n",
      "Epoch: 6281,     Training Loss: 0.45895206928253174, Training Acc: 76.25%\n",
      "              Val Loss: 0.7894765734672546, Val Acc: 67.26%\n",
      "Epoch: 6282,     Training Loss: 0.4533342719078064, Training Acc: 76.25%\n",
      "              Val Loss: 0.7800214886665344, Val Acc: 67.26%\n",
      "Epoch: 6283,     Training Loss: 0.4405340850353241, Training Acc: 76.25%\n",
      "              Val Loss: 0.813586950302124, Val Acc: 67.27%\n",
      "Epoch: 6284,     Training Loss: 0.46862831711769104, Training Acc: 76.26%\n",
      "              Val Loss: 0.8112650513648987, Val Acc: 67.27%\n",
      "Epoch: 6285,     Training Loss: 0.4756196141242981, Training Acc: 76.26%\n",
      "              Val Loss: 0.7976641058921814, Val Acc: 67.27%\n",
      "Epoch: 6286,     Training Loss: 0.44924086332321167, Training Acc: 76.26%\n",
      "              Val Loss: 0.830190896987915, Val Acc: 67.27%\n",
      "Epoch: 6287,     Training Loss: 0.47352495789527893, Training Acc: 76.26%\n",
      "              Val Loss: 0.8564801216125488, Val Acc: 67.27%\n",
      "Epoch: 6288,     Training Loss: 0.5156175494194031, Training Acc: 76.26%\n",
      "              Val Loss: 0.8093343377113342, Val Acc: 67.27%\n",
      "Epoch: 6289,     Training Loss: 0.45310142636299133, Training Acc: 76.26%\n",
      "              Val Loss: 0.8405076861381531, Val Acc: 67.27%\n",
      "Epoch: 6290,     Training Loss: 0.4739818572998047, Training Acc: 76.26%\n",
      "              Val Loss: 0.865572988986969, Val Acc: 67.27%\n",
      "Epoch: 6291,     Training Loss: 0.5253970623016357, Training Acc: 76.26%\n",
      "              Val Loss: 0.7863779664039612, Val Acc: 67.27%\n",
      "Epoch: 6292,     Training Loss: 0.43697550892829895, Training Acc: 76.26%\n",
      "              Val Loss: 0.8616419434547424, Val Acc: 67.27%\n",
      "Epoch: 6293,     Training Loss: 0.49366146326065063, Training Acc: 76.26%\n",
      "              Val Loss: 0.8604956269264221, Val Acc: 67.27%\n",
      "Epoch: 6294,     Training Loss: 0.5220836997032166, Training Acc: 76.26%\n",
      "              Val Loss: 0.7972530126571655, Val Acc: 67.27%\n",
      "Epoch: 6295,     Training Loss: 0.44672635197639465, Training Acc: 76.26%\n",
      "              Val Loss: 0.9278590679168701, Val Acc: 67.28%\n",
      "Epoch: 6296,     Training Loss: 0.5388352274894714, Training Acc: 76.26%\n",
      "              Val Loss: 0.8554178476333618, Val Acc: 67.28%\n",
      "Epoch: 6297,     Training Loss: 0.5212724208831787, Training Acc: 76.26%\n",
      "              Val Loss: 0.8005412220954895, Val Acc: 67.28%\n",
      "Epoch: 6298,     Training Loss: 0.45511066913604736, Training Acc: 76.26%\n",
      "              Val Loss: 0.9557334780693054, Val Acc: 67.28%\n",
      "Epoch: 6299,     Training Loss: 0.5528822541236877, Training Acc: 76.26%\n",
      "              Val Loss: 0.8285689353942871, Val Acc: 67.28%\n",
      "Epoch: 6300,     Training Loss: 0.48610296845436096, Training Acc: 76.26%\n",
      "              Val Loss: 0.810657799243927, Val Acc: 67.28%\n",
      "Epoch: 6301,     Training Loss: 0.46397319436073303, Training Acc: 76.27%\n",
      "              Val Loss: 0.9139012098312378, Val Acc: 67.28%\n",
      "Epoch: 6302,     Training Loss: 0.5175713300704956, Training Acc: 76.27%\n",
      "              Val Loss: 0.8060021996498108, Val Acc: 67.28%\n",
      "Epoch: 6303,     Training Loss: 0.4518193304538727, Training Acc: 76.27%\n",
      "              Val Loss: 0.800352931022644, Val Acc: 67.28%\n",
      "Epoch: 6304,     Training Loss: 0.45022809505462646, Training Acc: 76.27%\n",
      "              Val Loss: 0.8797118663787842, Val Acc: 67.28%\n",
      "Epoch: 6305,     Training Loss: 0.497050940990448, Training Acc: 76.27%\n",
      "              Val Loss: 0.8082916736602783, Val Acc: 67.28%\n",
      "Epoch: 6306,     Training Loss: 0.4536961019039154, Training Acc: 76.27%\n",
      "              Val Loss: 0.7992095947265625, Val Acc: 67.28%\n",
      "Epoch: 6307,     Training Loss: 0.44403815269470215, Training Acc: 76.27%\n",
      "              Val Loss: 0.86163729429245, Val Acc: 67.28%\n",
      "Epoch: 6308,     Training Loss: 0.481816828250885, Training Acc: 76.27%\n",
      "              Val Loss: 0.8040473461151123, Val Acc: 67.29%\n",
      "Epoch: 6309,     Training Loss: 0.4493403732776642, Training Acc: 76.27%\n",
      "              Val Loss: 0.795166552066803, Val Acc: 67.29%\n",
      "Epoch: 6310,     Training Loss: 0.4321018159389496, Training Acc: 76.27%\n",
      "              Val Loss: 0.8498090505599976, Val Acc: 67.29%\n",
      "Epoch: 6311,     Training Loss: 0.46591436862945557, Training Acc: 76.27%\n",
      "              Val Loss: 0.8096597194671631, Val Acc: 67.29%\n",
      "Epoch: 6312,     Training Loss: 0.4493474066257477, Training Acc: 76.27%\n",
      "              Val Loss: 0.7942545413970947, Val Acc: 67.29%\n",
      "Epoch: 6313,     Training Loss: 0.42913123965263367, Training Acc: 76.28%\n",
      "              Val Loss: 0.8416396379470825, Val Acc: 67.29%\n",
      "Epoch: 6314,     Training Loss: 0.46153339743614197, Training Acc: 76.28%\n",
      "              Val Loss: 0.8183438181877136, Val Acc: 67.29%\n",
      "Epoch: 6315,     Training Loss: 0.45705994963645935, Training Acc: 76.28%\n",
      "              Val Loss: 0.7967197895050049, Val Acc: 67.29%\n",
      "Epoch: 6316,     Training Loss: 0.4294029474258423, Training Acc: 76.28%\n",
      "              Val Loss: 0.8347660303115845, Val Acc: 67.29%\n",
      "Epoch: 6317,     Training Loss: 0.45557984709739685, Training Acc: 76.28%\n",
      "              Val Loss: 0.8495669364929199, Val Acc: 67.29%\n",
      "Epoch: 6318,     Training Loss: 0.4810139834880829, Training Acc: 76.28%\n",
      "              Val Loss: 0.8074796795845032, Val Acc: 67.30%\n",
      "Epoch: 6319,     Training Loss: 0.4298403561115265, Training Acc: 76.28%\n",
      "              Val Loss: 0.8459928631782532, Val Acc: 67.30%\n",
      "Epoch: 6320,     Training Loss: 0.46186837553977966, Training Acc: 76.28%\n",
      "              Val Loss: 0.8572101593017578, Val Acc: 67.30%\n",
      "Epoch: 6321,     Training Loss: 0.4971904754638672, Training Acc: 76.28%\n",
      "              Val Loss: 0.7934804558753967, Val Acc: 67.30%\n",
      "Epoch: 6322,     Training Loss: 0.42313143610954285, Training Acc: 76.28%\n",
      "              Val Loss: 0.8618285655975342, Val Acc: 67.30%\n",
      "Epoch: 6323,     Training Loss: 0.4747963845729828, Training Acc: 76.28%\n",
      "              Val Loss: 0.8532813191413879, Val Acc: 67.30%\n",
      "Epoch: 6324,     Training Loss: 0.49151837825775146, Training Acc: 76.28%\n",
      "              Val Loss: 0.8070307970046997, Val Acc: 67.30%\n",
      "Epoch: 6325,     Training Loss: 0.42989999055862427, Training Acc: 76.29%\n",
      "              Val Loss: 0.9216164350509644, Val Acc: 67.30%\n",
      "Epoch: 6326,     Training Loss: 0.5125704407691956, Training Acc: 76.29%\n",
      "              Val Loss: 0.8486839532852173, Val Acc: 67.30%\n",
      "Epoch: 6327,     Training Loss: 0.4867638349533081, Training Acc: 76.29%\n",
      "              Val Loss: 0.8073455691337585, Val Acc: 67.30%\n",
      "Epoch: 6328,     Training Loss: 0.43593674898147583, Training Acc: 76.29%\n",
      "              Val Loss: 0.9571066498756409, Val Acc: 67.30%\n",
      "Epoch: 6329,     Training Loss: 0.5309007167816162, Training Acc: 76.29%\n",
      "              Val Loss: 0.8356977701187134, Val Acc: 67.30%\n",
      "Epoch: 6330,     Training Loss: 0.4707263112068176, Training Acc: 76.29%\n",
      "              Val Loss: 0.8201342821121216, Val Acc: 67.30%\n",
      "Epoch: 6331,     Training Loss: 0.45064041018486023, Training Acc: 76.29%\n",
      "              Val Loss: 0.9155575633049011, Val Acc: 67.31%\n",
      "Epoch: 6332,     Training Loss: 0.5002060532569885, Training Acc: 76.29%\n",
      "              Val Loss: 0.8139029145240784, Val Acc: 67.31%\n",
      "Epoch: 6333,     Training Loss: 0.4373071789741516, Training Acc: 76.29%\n",
      "              Val Loss: 0.8092473745346069, Val Acc: 67.31%\n",
      "Epoch: 6334,     Training Loss: 0.43530723452568054, Training Acc: 76.29%\n",
      "              Val Loss: 0.8810479640960693, Val Acc: 67.31%\n",
      "Epoch: 6335,     Training Loss: 0.4708642065525055, Training Acc: 76.29%\n",
      "              Val Loss: 0.8179964423179626, Val Acc: 67.31%\n",
      "Epoch: 6336,     Training Loss: 0.43412426114082336, Training Acc: 76.29%\n",
      "              Val Loss: 0.8088444471359253, Val Acc: 67.31%\n",
      "Epoch: 6337,     Training Loss: 0.42494744062423706, Training Acc: 76.29%\n",
      "              Val Loss: 0.8583870530128479, Val Acc: 67.31%\n",
      "Epoch: 6338,     Training Loss: 0.4621739983558655, Training Acc: 76.30%\n",
      "              Val Loss: 0.8233135342597961, Val Acc: 67.31%\n",
      "Epoch: 6339,     Training Loss: 0.442138671875, Training Acc: 76.30%\n",
      "              Val Loss: 0.8041315674781799, Val Acc: 67.31%\n",
      "Epoch: 6340,     Training Loss: 0.4166732430458069, Training Acc: 76.30%\n",
      "              Val Loss: 0.8483284711837769, Val Acc: 67.31%\n",
      "Epoch: 6341,     Training Loss: 0.44906383752822876, Training Acc: 76.30%\n",
      "              Val Loss: 0.8316036462783813, Val Acc: 67.31%\n",
      "Epoch: 6342,     Training Loss: 0.44738996028900146, Training Acc: 76.30%\n",
      "              Val Loss: 0.8108938336372375, Val Acc: 67.32%\n",
      "Epoch: 6343,     Training Loss: 0.41371604800224304, Training Acc: 76.30%\n",
      "              Val Loss: 0.8584702014923096, Val Acc: 67.32%\n",
      "Epoch: 6344,     Training Loss: 0.44969022274017334, Training Acc: 76.30%\n",
      "              Val Loss: 0.8391457200050354, Val Acc: 67.32%\n",
      "Epoch: 6345,     Training Loss: 0.45402052998542786, Training Acc: 76.30%\n",
      "              Val Loss: 0.8077588081359863, Val Acc: 67.32%\n",
      "Epoch: 6346,     Training Loss: 0.41211915016174316, Training Acc: 76.30%\n",
      "              Val Loss: 0.871524453163147, Val Acc: 67.32%\n",
      "Epoch: 6347,     Training Loss: 0.4557243287563324, Training Acc: 76.30%\n",
      "              Val Loss: 0.8616763949394226, Val Acc: 67.32%\n",
      "Epoch: 6348,     Training Loss: 0.4645903408527374, Training Acc: 76.31%\n",
      "              Val Loss: 0.8293424248695374, Val Acc: 67.32%\n",
      "Epoch: 6349,     Training Loss: 0.42041805386543274, Training Acc: 76.31%\n",
      "              Val Loss: 0.8955250382423401, Val Acc: 67.32%\n",
      "Epoch: 6350,     Training Loss: 0.4677982032299042, Training Acc: 76.31%\n",
      "              Val Loss: 0.8757253289222717, Val Acc: 67.32%\n",
      "Epoch: 6351,     Training Loss: 0.48005223274230957, Training Acc: 76.31%\n",
      "              Val Loss: 0.813877284526825, Val Acc: 67.32%\n",
      "Epoch: 6352,     Training Loss: 0.41476571559906006, Training Acc: 76.31%\n",
      "              Val Loss: 0.9093672037124634, Val Acc: 67.32%\n",
      "Epoch: 6353,     Training Loss: 0.4833484888076782, Training Acc: 76.31%\n",
      "              Val Loss: 0.8737512826919556, Val Acc: 67.32%\n",
      "Epoch: 6354,     Training Loss: 0.48554855585098267, Training Acc: 76.31%\n",
      "              Val Loss: 0.8212648034095764, Val Acc: 67.32%\n",
      "Epoch: 6355,     Training Loss: 0.4208827316761017, Training Acc: 76.31%\n",
      "              Val Loss: 0.950366735458374, Val Acc: 67.32%\n",
      "Epoch: 6356,     Training Loss: 0.5108233094215393, Training Acc: 76.31%\n",
      "              Val Loss: 0.8599205017089844, Val Acc: 67.33%\n",
      "Epoch: 6357,     Training Loss: 0.4697501063346863, Training Acc: 76.31%\n",
      "              Val Loss: 0.8268716335296631, Val Acc: 67.33%\n",
      "Epoch: 6358,     Training Loss: 0.42765313386917114, Training Acc: 76.31%\n",
      "              Val Loss: 0.9660240411758423, Val Acc: 67.33%\n",
      "Epoch: 6359,     Training Loss: 0.5131446719169617, Training Acc: 76.31%\n",
      "              Val Loss: 0.8345396518707275, Val Acc: 67.33%\n",
      "Epoch: 6360,     Training Loss: 0.4453316628932953, Training Acc: 76.31%\n",
      "              Val Loss: 0.8319190144538879, Val Acc: 67.33%\n",
      "Epoch: 6361,     Training Loss: 0.43792733550071716, Training Acc: 76.32%\n",
      "              Val Loss: 0.9337087869644165, Val Acc: 67.33%\n",
      "Epoch: 6362,     Training Loss: 0.48883190751075745, Training Acc: 76.32%\n",
      "              Val Loss: 0.8186506628990173, Val Acc: 67.33%\n",
      "Epoch: 6363,     Training Loss: 0.42046284675598145, Training Acc: 76.32%\n",
      "              Val Loss: 0.8333029747009277, Val Acc: 67.33%\n",
      "Epoch: 6364,     Training Loss: 0.43684902787208557, Training Acc: 76.32%\n",
      "              Val Loss: 0.9053833484649658, Val Acc: 67.33%\n",
      "Epoch: 6365,     Training Loss: 0.4659193456172943, Training Acc: 76.32%\n",
      "              Val Loss: 0.8308500051498413, Val Acc: 67.33%\n",
      "Epoch: 6366,     Training Loss: 0.417266309261322, Training Acc: 76.32%\n",
      "              Val Loss: 0.8361371755599976, Val Acc: 67.33%\n",
      "Epoch: 6367,     Training Loss: 0.42555245757102966, Training Acc: 76.32%\n",
      "              Val Loss: 0.8720864653587341, Val Acc: 67.33%\n",
      "Epoch: 6368,     Training Loss: 0.4456552267074585, Training Acc: 76.32%\n",
      "              Val Loss: 0.8380487561225891, Val Acc: 67.34%\n",
      "Epoch: 6369,     Training Loss: 0.4198223948478699, Training Acc: 76.32%\n",
      "              Val Loss: 0.8282092809677124, Val Acc: 67.34%\n",
      "Epoch: 6370,     Training Loss: 0.4091171622276306, Training Acc: 76.32%\n",
      "              Val Loss: 0.8616847395896912, Val Acc: 67.34%\n",
      "Epoch: 6371,     Training Loss: 0.43115124106407166, Training Acc: 76.33%\n",
      "              Val Loss: 0.8460511565208435, Val Acc: 67.34%\n",
      "Epoch: 6372,     Training Loss: 0.42424941062927246, Training Acc: 76.33%\n",
      "              Val Loss: 0.8308529853820801, Val Acc: 67.34%\n",
      "Epoch: 6373,     Training Loss: 0.4024801254272461, Training Acc: 76.33%\n",
      "              Val Loss: 0.8505585193634033, Val Acc: 67.34%\n",
      "Epoch: 6374,     Training Loss: 0.42064669728279114, Training Acc: 76.33%\n",
      "              Val Loss: 0.8380881547927856, Val Acc: 67.34%\n",
      "Epoch: 6375,     Training Loss: 0.42534247040748596, Training Acc: 76.33%\n",
      "              Val Loss: 0.8206700682640076, Val Acc: 67.34%\n",
      "Epoch: 6376,     Training Loss: 0.40044766664505005, Training Acc: 76.33%\n",
      "              Val Loss: 0.8388345241546631, Val Acc: 67.34%\n",
      "Epoch: 6377,     Training Loss: 0.4110552668571472, Training Acc: 76.33%\n",
      "              Val Loss: 0.8445234894752502, Val Acc: 67.34%\n",
      "Epoch: 6378,     Training Loss: 0.42455247044563293, Training Acc: 76.33%\n",
      "              Val Loss: 0.8348436951637268, Val Acc: 67.34%\n",
      "Epoch: 6379,     Training Loss: 0.4008159637451172, Training Acc: 76.34%\n",
      "              Val Loss: 0.8500056266784668, Val Acc: 67.34%\n",
      "Epoch: 6380,     Training Loss: 0.4134916663169861, Training Acc: 76.34%\n",
      "              Val Loss: 0.8519033193588257, Val Acc: 67.34%\n",
      "Epoch: 6381,     Training Loss: 0.43266910314559937, Training Acc: 76.34%\n",
      "              Val Loss: 0.8360090851783752, Val Acc: 67.35%\n",
      "Epoch: 6382,     Training Loss: 0.40429896116256714, Training Acc: 76.34%\n",
      "              Val Loss: 0.8440628051757812, Val Acc: 67.35%\n",
      "Epoch: 6383,     Training Loss: 0.4042365252971649, Training Acc: 76.34%\n",
      "              Val Loss: 0.8574300408363342, Val Acc: 67.35%\n",
      "Epoch: 6384,     Training Loss: 0.4301563501358032, Training Acc: 76.34%\n",
      "              Val Loss: 0.8445181250572205, Val Acc: 67.35%\n",
      "Epoch: 6385,     Training Loss: 0.4053276479244232, Training Acc: 76.34%\n",
      "              Val Loss: 0.8363543152809143, Val Acc: 67.35%\n",
      "Epoch: 6386,     Training Loss: 0.3977820575237274, Training Acc: 76.34%\n",
      "              Val Loss: 0.8472104072570801, Val Acc: 67.35%\n",
      "Epoch: 6387,     Training Loss: 0.4172317087650299, Training Acc: 76.34%\n",
      "              Val Loss: 0.8504012823104858, Val Acc: 67.35%\n",
      "Epoch: 6388,     Training Loss: 0.4087616801261902, Training Acc: 76.35%\n",
      "              Val Loss: 0.8314926028251648, Val Acc: 67.35%\n",
      "Epoch: 6389,     Training Loss: 0.39558276534080505, Training Acc: 76.35%\n",
      "              Val Loss: 0.8365511298179626, Val Acc: 67.35%\n",
      "Epoch: 6390,     Training Loss: 0.3992918133735657, Training Acc: 76.35%\n",
      "              Val Loss: 0.8491606712341309, Val Acc: 67.35%\n",
      "Epoch: 6391,     Training Loss: 0.4063606262207031, Training Acc: 76.35%\n",
      "              Val Loss: 0.8376557230949402, Val Acc: 67.35%\n",
      "Epoch: 6392,     Training Loss: 0.4067302942276001, Training Acc: 76.35%\n",
      "              Val Loss: 0.8393897414207458, Val Acc: 67.35%\n",
      "Epoch: 6393,     Training Loss: 0.3930613398551941, Training Acc: 76.35%\n",
      "              Val Loss: 0.8487401604652405, Val Acc: 67.36%\n",
      "Epoch: 6394,     Training Loss: 0.39812907576560974, Training Acc: 76.35%\n",
      "              Val Loss: 0.8448212146759033, Val Acc: 67.36%\n",
      "Epoch: 6395,     Training Loss: 0.413196325302124, Training Acc: 76.35%\n",
      "              Val Loss: 0.8446627259254456, Val Acc: 67.36%\n",
      "Epoch: 6396,     Training Loss: 0.3965543806552887, Training Acc: 76.36%\n",
      "              Val Loss: 0.8360604643821716, Val Acc: 67.36%\n",
      "Epoch: 6397,     Training Loss: 0.3909643888473511, Training Acc: 76.36%\n",
      "              Val Loss: 0.8345175385475159, Val Acc: 67.36%\n",
      "Epoch: 6398,     Training Loss: 0.397068053483963, Training Acc: 76.36%\n",
      "              Val Loss: 0.8522687554359436, Val Acc: 67.36%\n",
      "Epoch: 6399,     Training Loss: 0.4002853333950043, Training Acc: 76.36%\n",
      "              Val Loss: 0.8474098443984985, Val Acc: 67.36%\n",
      "Epoch: 6400,     Training Loss: 0.39748522639274597, Training Acc: 76.36%\n",
      "              Val Loss: 0.8431609272956848, Val Acc: 67.36%\n",
      "Epoch: 6401,     Training Loss: 0.388162225484848, Training Acc: 76.36%\n",
      "              Val Loss: 0.8455553650856018, Val Acc: 67.36%\n",
      "Epoch: 6402,     Training Loss: 0.3919564187526703, Training Acc: 76.36%\n",
      "              Val Loss: 0.8473936319351196, Val Acc: 67.36%\n",
      "Epoch: 6403,     Training Loss: 0.4005235731601715, Training Acc: 76.36%\n",
      "              Val Loss: 0.864437460899353, Val Acc: 67.36%\n",
      "Epoch: 6404,     Training Loss: 0.39922696352005005, Training Acc: 76.37%\n",
      "              Val Loss: 0.8430518507957458, Val Acc: 67.37%\n",
      "Epoch: 6405,     Training Loss: 0.39187777042388916, Training Acc: 76.37%\n",
      "              Val Loss: 0.8460981249809265, Val Acc: 67.37%\n",
      "Epoch: 6406,     Training Loss: 0.38721397519111633, Training Acc: 76.37%\n",
      "              Val Loss: 0.8523033261299133, Val Acc: 67.37%\n",
      "Epoch: 6407,     Training Loss: 0.39049163460731506, Training Acc: 76.37%\n",
      "              Val Loss: 0.8505815267562866, Val Acc: 67.37%\n",
      "Epoch: 6408,     Training Loss: 0.40616700053215027, Training Acc: 76.37%\n",
      "              Val Loss: 0.8644724488258362, Val Acc: 67.37%\n",
      "Epoch: 6409,     Training Loss: 0.39584115147590637, Training Acc: 76.37%\n",
      "              Val Loss: 0.8480666875839233, Val Acc: 67.37%\n",
      "Epoch: 6410,     Training Loss: 0.3912885785102844, Training Acc: 76.37%\n",
      "              Val Loss: 0.8451421856880188, Val Acc: 67.37%\n",
      "Epoch: 6411,     Training Loss: 0.38554903864860535, Training Acc: 76.37%\n",
      "              Val Loss: 0.8466600775718689, Val Acc: 67.37%\n",
      "Epoch: 6412,     Training Loss: 0.3842383921146393, Training Acc: 76.38%\n",
      "              Val Loss: 0.8478066325187683, Val Acc: 67.37%\n",
      "Epoch: 6413,     Training Loss: 0.38785117864608765, Training Acc: 76.38%\n",
      "              Val Loss: 0.8632422089576721, Val Acc: 67.37%\n",
      "Epoch: 6414,     Training Loss: 0.3925997018814087, Training Acc: 76.38%\n",
      "              Val Loss: 0.8522341251373291, Val Acc: 67.37%\n",
      "Epoch: 6415,     Training Loss: 0.3952699899673462, Training Acc: 76.38%\n",
      "              Val Loss: 0.8584069609642029, Val Acc: 67.37%\n",
      "Epoch: 6416,     Training Loss: 0.38894984126091003, Training Acc: 76.38%\n",
      "              Val Loss: 0.8405908942222595, Val Acc: 67.38%\n",
      "Epoch: 6417,     Training Loss: 0.3844536244869232, Training Acc: 76.38%\n",
      "              Val Loss: 0.8456894159317017, Val Acc: 67.38%\n",
      "Epoch: 6418,     Training Loss: 0.3804490268230438, Training Acc: 76.38%\n",
      "              Val Loss: 0.8542041778564453, Val Acc: 67.38%\n",
      "Epoch: 6419,     Training Loss: 0.38163089752197266, Training Acc: 76.39%\n",
      "              Val Loss: 0.8465856313705444, Val Acc: 67.38%\n",
      "Epoch: 6420,     Training Loss: 0.38463228940963745, Training Acc: 76.39%\n",
      "              Val Loss: 0.8627367615699768, Val Acc: 67.38%\n",
      "Epoch: 6421,     Training Loss: 0.38858354091644287, Training Acc: 76.39%\n",
      "              Val Loss: 0.8607734441757202, Val Acc: 67.38%\n",
      "Epoch: 6422,     Training Loss: 0.39545711874961853, Training Acc: 76.39%\n",
      "              Val Loss: 0.8793594837188721, Val Acc: 67.38%\n",
      "Epoch: 6423,     Training Loss: 0.3950081765651703, Training Acc: 76.39%\n",
      "              Val Loss: 0.8575182557106018, Val Acc: 67.38%\n",
      "Epoch: 6424,     Training Loss: 0.3943083882331848, Training Acc: 76.39%\n",
      "              Val Loss: 0.8649123907089233, Val Acc: 67.38%\n",
      "Epoch: 6425,     Training Loss: 0.38521435856819153, Training Acc: 76.39%\n",
      "              Val Loss: 0.8494035601615906, Val Acc: 67.38%\n",
      "Epoch: 6426,     Training Loss: 0.3796443045139313, Training Acc: 76.39%\n",
      "              Val Loss: 0.8545575737953186, Val Acc: 67.38%\n",
      "Epoch: 6427,     Training Loss: 0.3804033398628235, Training Acc: 76.40%\n",
      "              Val Loss: 0.8522486090660095, Val Acc: 67.38%\n",
      "Epoch: 6428,     Training Loss: 0.3769584000110626, Training Acc: 76.40%\n",
      "              Val Loss: 0.8521159291267395, Val Acc: 67.39%\n",
      "Epoch: 6429,     Training Loss: 0.37841078639030457, Training Acc: 76.40%\n",
      "              Val Loss: 0.8669015765190125, Val Acc: 67.39%\n",
      "Epoch: 6430,     Training Loss: 0.38119232654571533, Training Acc: 76.40%\n",
      "              Val Loss: 0.8664485812187195, Val Acc: 67.39%\n",
      "Epoch: 6431,     Training Loss: 0.3870771527290344, Training Acc: 76.40%\n",
      "              Val Loss: 0.8811599016189575, Val Acc: 67.39%\n",
      "Epoch: 6432,     Training Loss: 0.3879522383213043, Training Acc: 76.40%\n",
      "              Val Loss: 0.8673539161682129, Val Acc: 67.39%\n",
      "Epoch: 6433,     Training Loss: 0.3986189365386963, Training Acc: 76.40%\n",
      "              Val Loss: 0.8954698443412781, Val Acc: 67.39%\n",
      "Epoch: 6434,     Training Loss: 0.40269747376441956, Training Acc: 76.41%\n",
      "              Val Loss: 0.8837097883224487, Val Acc: 67.39%\n",
      "Epoch: 6435,     Training Loss: 0.41031140089035034, Training Acc: 76.41%\n",
      "              Val Loss: 0.8895097374916077, Val Acc: 67.39%\n",
      "Epoch: 6436,     Training Loss: 0.38717424869537354, Training Acc: 76.41%\n",
      "              Val Loss: 0.862059473991394, Val Acc: 67.39%\n",
      "Epoch: 6437,     Training Loss: 0.3783552050590515, Training Acc: 76.41%\n",
      "              Val Loss: 0.8645321130752563, Val Acc: 67.39%\n",
      "Epoch: 6438,     Training Loss: 0.37487831711769104, Training Acc: 76.41%\n",
      "              Val Loss: 0.8619348406791687, Val Acc: 67.39%\n",
      "Epoch: 6439,     Training Loss: 0.3736502528190613, Training Acc: 76.41%\n",
      "              Val Loss: 0.8616782426834106, Val Acc: 67.39%\n",
      "Epoch: 6440,     Training Loss: 0.37560832500457764, Training Acc: 76.41%\n",
      "              Val Loss: 0.8798186779022217, Val Acc: 67.40%\n",
      "Epoch: 6441,     Training Loss: 0.37777072191238403, Training Acc: 76.41%\n",
      "              Val Loss: 0.8733457326889038, Val Acc: 67.40%\n",
      "Epoch: 6442,     Training Loss: 0.3860645294189453, Training Acc: 76.42%\n",
      "              Val Loss: 0.8929879069328308, Val Acc: 67.40%\n",
      "Epoch: 6443,     Training Loss: 0.39089107513427734, Training Acc: 76.42%\n",
      "              Val Loss: 0.8918983936309814, Val Acc: 67.40%\n",
      "Epoch: 6444,     Training Loss: 0.4175954759120941, Training Acc: 76.42%\n",
      "              Val Loss: 0.9276107549667358, Val Acc: 67.40%\n",
      "Epoch: 6445,     Training Loss: 0.41233375668525696, Training Acc: 76.42%\n",
      "              Val Loss: 0.887471616268158, Val Acc: 67.40%\n",
      "Epoch: 6446,     Training Loss: 0.40444472432136536, Training Acc: 76.42%\n",
      "              Val Loss: 0.884838879108429, Val Acc: 67.40%\n",
      "Epoch: 6447,     Training Loss: 0.3774312734603882, Training Acc: 76.42%\n",
      "              Val Loss: 0.8753132820129395, Val Acc: 67.40%\n",
      "Epoch: 6448,     Training Loss: 0.3723873496055603, Training Acc: 76.42%\n",
      "              Val Loss: 0.8710477948188782, Val Acc: 67.40%\n",
      "Epoch: 6449,     Training Loss: 0.3841254711151123, Training Acc: 76.42%\n",
      "              Val Loss: 0.9020582437515259, Val Acc: 67.40%\n",
      "Epoch: 6450,     Training Loss: 0.3942078649997711, Training Acc: 76.43%\n",
      "              Val Loss: 0.8925149440765381, Val Acc: 67.40%\n",
      "Epoch: 6451,     Training Loss: 0.4080583155155182, Training Acc: 76.43%\n",
      "              Val Loss: 0.9067366719245911, Val Acc: 67.40%\n",
      "Epoch: 6452,     Training Loss: 0.3891817033290863, Training Acc: 76.43%\n",
      "              Val Loss: 0.8747842907905579, Val Acc: 67.41%\n",
      "Epoch: 6453,     Training Loss: 0.37637031078338623, Training Acc: 76.43%\n",
      "              Val Loss: 0.8790116310119629, Val Acc: 67.41%\n",
      "Epoch: 6454,     Training Loss: 0.371918648481369, Training Acc: 76.43%\n",
      "              Val Loss: 0.8775981068611145, Val Acc: 67.41%\n",
      "Epoch: 6455,     Training Loss: 0.36872777342796326, Training Acc: 76.43%\n",
      "              Val Loss: 0.8827247023582458, Val Acc: 67.41%\n",
      "Epoch: 6456,     Training Loss: 0.3729199171066284, Training Acc: 76.43%\n",
      "              Val Loss: 0.8940277695655823, Val Acc: 67.41%\n",
      "Epoch: 6457,     Training Loss: 0.37167027592658997, Training Acc: 76.43%\n",
      "              Val Loss: 0.8827288746833801, Val Acc: 67.41%\n",
      "Epoch: 6458,     Training Loss: 0.3799898624420166, Training Acc: 76.44%\n",
      "              Val Loss: 0.917259931564331, Val Acc: 67.41%\n",
      "Epoch: 6459,     Training Loss: 0.3903135061264038, Training Acc: 76.44%\n",
      "              Val Loss: 0.9114559292793274, Val Acc: 67.41%\n",
      "Epoch: 6460,     Training Loss: 0.4140166938304901, Training Acc: 76.44%\n",
      "              Val Loss: 0.9122725129127502, Val Acc: 67.41%\n",
      "Epoch: 6461,     Training Loss: 0.3850337564945221, Training Acc: 76.44%\n",
      "              Val Loss: 0.8775402307510376, Val Acc: 67.41%\n",
      "Epoch: 6462,     Training Loss: 0.37789738178253174, Training Acc: 76.44%\n",
      "              Val Loss: 0.8791078329086304, Val Acc: 67.41%\n",
      "Epoch: 6463,     Training Loss: 0.3713858723640442, Training Acc: 76.44%\n",
      "              Val Loss: 0.878476619720459, Val Acc: 67.41%\n",
      "Epoch: 6464,     Training Loss: 0.36870452761650085, Training Acc: 76.44%\n",
      "              Val Loss: 0.893717348575592, Val Acc: 67.41%\n",
      "Epoch: 6465,     Training Loss: 0.3691520392894745, Training Acc: 76.44%\n",
      "              Val Loss: 0.8841730356216431, Val Acc: 67.42%\n",
      "Epoch: 6466,     Training Loss: 0.3651255667209625, Training Acc: 76.45%\n",
      "              Val Loss: 0.8857728838920593, Val Acc: 67.42%\n",
      "Epoch: 6467,     Training Loss: 0.3671915829181671, Training Acc: 76.45%\n",
      "              Val Loss: 0.881093442440033, Val Acc: 67.42%\n",
      "Epoch: 6468,     Training Loss: 0.36549049615859985, Training Acc: 76.45%\n",
      "              Val Loss: 0.8974802494049072, Val Acc: 67.42%\n",
      "Epoch: 6469,     Training Loss: 0.36832600831985474, Training Acc: 76.45%\n",
      "              Val Loss: 0.8920375108718872, Val Acc: 67.42%\n",
      "Epoch: 6470,     Training Loss: 0.3787041902542114, Training Acc: 76.45%\n",
      "              Val Loss: 0.9210874438285828, Val Acc: 67.42%\n",
      "Epoch: 6471,     Training Loss: 0.3877084255218506, Training Acc: 76.45%\n",
      "              Val Loss: 0.9138326048851013, Val Acc: 67.42%\n",
      "Epoch: 6472,     Training Loss: 0.414907306432724, Training Acc: 76.45%\n",
      "              Val Loss: 0.9492217302322388, Val Acc: 67.42%\n",
      "Epoch: 6473,     Training Loss: 0.4112947881221771, Training Acc: 76.46%\n",
      "              Val Loss: 0.9139208793640137, Val Acc: 67.42%\n",
      "Epoch: 6474,     Training Loss: 0.41511207818984985, Training Acc: 76.46%\n",
      "              Val Loss: 0.8965134620666504, Val Acc: 67.42%\n",
      "Epoch: 6475,     Training Loss: 0.37305977940559387, Training Acc: 76.46%\n",
      "              Val Loss: 0.8819037079811096, Val Acc: 67.42%\n",
      "Epoch: 6476,     Training Loss: 0.36865684390068054, Training Acc: 76.46%\n",
      "              Val Loss: 0.8779342770576477, Val Acc: 67.42%\n",
      "Epoch: 6477,     Training Loss: 0.3816123604774475, Training Acc: 76.46%\n",
      "              Val Loss: 0.93794846534729, Val Acc: 67.42%\n",
      "Epoch: 6478,     Training Loss: 0.40149471163749695, Training Acc: 76.46%\n",
      "              Val Loss: 0.9109012484550476, Val Acc: 67.42%\n",
      "Epoch: 6479,     Training Loss: 0.4127109944820404, Training Acc: 76.46%\n",
      "              Val Loss: 0.9386809468269348, Val Acc: 67.43%\n",
      "Epoch: 6480,     Training Loss: 0.3878808319568634, Training Acc: 76.46%\n",
      "              Val Loss: 0.8887119293212891, Val Acc: 67.43%\n",
      "Epoch: 6481,     Training Loss: 0.37751656770706177, Training Acc: 76.47%\n",
      "              Val Loss: 0.887355625629425, Val Acc: 67.43%\n",
      "Epoch: 6482,     Training Loss: 0.3763772249221802, Training Acc: 76.47%\n",
      "              Val Loss: 0.8784990906715393, Val Acc: 67.43%\n",
      "Epoch: 6483,     Training Loss: 0.3684237003326416, Training Acc: 76.47%\n",
      "              Val Loss: 0.9111945629119873, Val Acc: 67.43%\n",
      "Epoch: 6484,     Training Loss: 0.368200421333313, Training Acc: 76.47%\n",
      "              Val Loss: 0.8931208252906799, Val Acc: 67.43%\n",
      "Epoch: 6485,     Training Loss: 0.3680969178676605, Training Acc: 76.47%\n",
      "              Val Loss: 0.8959807753562927, Val Acc: 67.43%\n",
      "Epoch: 6486,     Training Loss: 0.36552441120147705, Training Acc: 76.47%\n",
      "              Val Loss: 0.8866218328475952, Val Acc: 67.43%\n",
      "Epoch: 6487,     Training Loss: 0.3662779629230499, Training Acc: 76.47%\n",
      "              Val Loss: 0.9126144647598267, Val Acc: 67.43%\n",
      "Epoch: 6488,     Training Loss: 0.37299779057502747, Training Acc: 76.47%\n",
      "              Val Loss: 0.9059510231018066, Val Acc: 67.43%\n",
      "Epoch: 6489,     Training Loss: 0.3911621868610382, Training Acc: 76.48%\n",
      "              Val Loss: 0.9591638445854187, Val Acc: 67.43%\n",
      "Epoch: 6490,     Training Loss: 0.4035947322845459, Training Acc: 76.48%\n",
      "              Val Loss: 0.969269335269928, Val Acc: 67.43%\n",
      "Epoch: 6491,     Training Loss: 0.4780648350715637, Training Acc: 76.48%\n",
      "              Val Loss: 0.9519199132919312, Val Acc: 67.43%\n",
      "Epoch: 6492,     Training Loss: 0.40792155265808105, Training Acc: 76.48%\n",
      "              Val Loss: 0.888996422290802, Val Acc: 67.43%\n",
      "Epoch: 6493,     Training Loss: 0.37379637360572815, Training Acc: 76.48%\n",
      "              Val Loss: 0.8791905045509338, Val Acc: 67.44%\n",
      "Epoch: 6494,     Training Loss: 0.36949649453163147, Training Acc: 76.48%\n",
      "              Val Loss: 0.9375272393226624, Val Acc: 67.44%\n",
      "Epoch: 6495,     Training Loss: 0.3985658586025238, Training Acc: 76.48%\n",
      "              Val Loss: 0.9186488389968872, Val Acc: 67.44%\n",
      "Epoch: 6496,     Training Loss: 0.4108463525772095, Training Acc: 76.48%\n",
      "              Val Loss: 0.9255038499832153, Val Acc: 67.44%\n",
      "Epoch: 6497,     Training Loss: 0.3814085125923157, Training Acc: 76.48%\n",
      "              Val Loss: 0.895632803440094, Val Acc: 67.44%\n",
      "Epoch: 6498,     Training Loss: 0.36513087153434753, Training Acc: 76.49%\n",
      "              Val Loss: 0.9053347706794739, Val Acc: 67.44%\n",
      "Epoch: 6499,     Training Loss: 0.40099474787712097, Training Acc: 76.49%\n",
      "              Val Loss: 0.9637552499771118, Val Acc: 67.44%\n",
      "Epoch: 6500,     Training Loss: 0.41336414217948914, Training Acc: 76.49%\n",
      "              Val Loss: 0.9399199485778809, Val Acc: 67.44%\n",
      "Epoch: 6501,     Training Loss: 0.4230883717536926, Training Acc: 76.49%\n",
      "              Val Loss: 0.9593866467475891, Val Acc: 67.44%\n",
      "Epoch: 6502,     Training Loss: 0.40032362937927246, Training Acc: 76.49%\n",
      "              Val Loss: 0.9064401388168335, Val Acc: 67.44%\n",
      "Epoch: 6503,     Training Loss: 0.37305861711502075, Training Acc: 76.49%\n",
      "              Val Loss: 0.8849460482597351, Val Acc: 67.44%\n",
      "Epoch: 6504,     Training Loss: 0.37526944279670715, Training Acc: 76.49%\n",
      "              Val Loss: 0.8953825235366821, Val Acc: 67.44%\n",
      "Epoch: 6505,     Training Loss: 0.3750208914279938, Training Acc: 76.49%\n",
      "              Val Loss: 0.929893970489502, Val Acc: 67.44%\n",
      "Epoch: 6506,     Training Loss: 0.3953287601470947, Training Acc: 76.50%\n",
      "              Val Loss: 0.9357603192329407, Val Acc: 67.44%\n",
      "Epoch: 6507,     Training Loss: 0.3856992721557617, Training Acc: 76.50%\n",
      "              Val Loss: 0.888542652130127, Val Acc: 67.44%\n",
      "Epoch: 6508,     Training Loss: 0.36809486150741577, Training Acc: 76.50%\n",
      "              Val Loss: 0.8945814371109009, Val Acc: 67.45%\n",
      "Epoch: 6509,     Training Loss: 0.38777774572372437, Training Acc: 76.50%\n",
      "              Val Loss: 0.9366106390953064, Val Acc: 67.45%\n",
      "Epoch: 6510,     Training Loss: 0.39235007762908936, Training Acc: 76.50%\n",
      "              Val Loss: 0.9441476464271545, Val Acc: 67.45%\n",
      "Epoch: 6511,     Training Loss: 0.43492549657821655, Training Acc: 76.50%\n",
      "              Val Loss: 0.9656262993812561, Val Acc: 67.45%\n",
      "Epoch: 6512,     Training Loss: 0.39021071791648865, Training Acc: 76.50%\n",
      "              Val Loss: 0.9203131794929504, Val Acc: 67.45%\n",
      "Epoch: 6513,     Training Loss: 0.3620600402355194, Training Acc: 76.50%\n",
      "              Val Loss: 0.9206773638725281, Val Acc: 67.45%\n",
      "Epoch: 6514,     Training Loss: 0.4062684178352356, Training Acc: 76.51%\n",
      "              Val Loss: 0.967972993850708, Val Acc: 67.45%\n",
      "Epoch: 6515,     Training Loss: 0.4064401388168335, Training Acc: 76.51%\n",
      "              Val Loss: 0.9519339799880981, Val Acc: 67.45%\n",
      "Epoch: 6516,     Training Loss: 0.4228115975856781, Training Acc: 76.51%\n",
      "              Val Loss: 0.9757853150367737, Val Acc: 67.45%\n",
      "Epoch: 6517,     Training Loss: 0.40981656312942505, Training Acc: 76.51%\n",
      "              Val Loss: 0.9021467566490173, Val Acc: 67.45%\n",
      "Epoch: 6518,     Training Loss: 0.35901764035224915, Training Acc: 76.51%\n",
      "              Val Loss: 0.9282739758491516, Val Acc: 67.45%\n",
      "Epoch: 6519,     Training Loss: 0.39876866340637207, Training Acc: 76.51%\n",
      "              Val Loss: 0.8966955542564392, Val Acc: 67.45%\n",
      "Epoch: 6520,     Training Loss: 0.3677016794681549, Training Acc: 76.51%\n",
      "              Val Loss: 0.9292804598808289, Val Acc: 67.45%\n",
      "Epoch: 6521,     Training Loss: 0.37531498074531555, Training Acc: 76.51%\n",
      "              Val Loss: 0.959048867225647, Val Acc: 67.45%\n",
      "Epoch: 6522,     Training Loss: 0.3931187093257904, Training Acc: 76.51%\n",
      "              Val Loss: 0.8992635607719421, Val Acc: 67.46%\n",
      "Epoch: 6523,     Training Loss: 0.3557244539260864, Training Acc: 76.52%\n",
      "              Val Loss: 0.9545474052429199, Val Acc: 67.46%\n",
      "Epoch: 6524,     Training Loss: 0.39880356192588806, Training Acc: 76.52%\n",
      "              Val Loss: 0.9485927820205688, Val Acc: 67.46%\n",
      "Epoch: 6525,     Training Loss: 0.43577203154563904, Training Acc: 76.52%\n",
      "              Val Loss: 1.020238995552063, Val Acc: 67.46%\n",
      "Epoch: 6526,     Training Loss: 0.43951570987701416, Training Acc: 76.52%\n",
      "              Val Loss: 0.9985746145248413, Val Acc: 67.46%\n",
      "Epoch: 6527,     Training Loss: 0.4826187491416931, Training Acc: 76.52%\n",
      "              Val Loss: 0.937175452709198, Val Acc: 67.46%\n",
      "Epoch: 6528,     Training Loss: 0.380635529756546, Training Acc: 76.52%\n",
      "              Val Loss: 0.9655606746673584, Val Acc: 67.46%\n",
      "Epoch: 6529,     Training Loss: 0.40697070956230164, Training Acc: 76.52%\n",
      "              Val Loss: 1.0477266311645508, Val Acc: 67.46%\n",
      "Epoch: 6530,     Training Loss: 0.5463854670524597, Training Acc: 76.52%\n",
      "              Val Loss: 0.9903014898300171, Val Acc: 67.46%\n",
      "Epoch: 6531,     Training Loss: 0.4276602864265442, Training Acc: 76.52%\n",
      "              Val Loss: 0.9222908020019531, Val Acc: 67.46%\n",
      "Epoch: 6532,     Training Loss: 0.3805498480796814, Training Acc: 76.52%\n",
      "              Val Loss: 0.9537684917449951, Val Acc: 67.46%\n",
      "Epoch: 6533,     Training Loss: 0.4280027449131012, Training Acc: 76.52%\n",
      "              Val Loss: 0.9714208841323853, Val Acc: 67.46%\n",
      "Epoch: 6534,     Training Loss: 0.4117150902748108, Training Acc: 76.53%\n",
      "              Val Loss: 0.9126608967781067, Val Acc: 67.46%\n",
      "Epoch: 6535,     Training Loss: 0.39028194546699524, Training Acc: 76.53%\n",
      "              Val Loss: 0.9181222319602966, Val Acc: 67.46%\n",
      "Epoch: 6536,     Training Loss: 0.36817020177841187, Training Acc: 76.53%\n",
      "              Val Loss: 0.9447559118270874, Val Acc: 67.46%\n",
      "Epoch: 6537,     Training Loss: 0.3838927447795868, Training Acc: 76.53%\n",
      "              Val Loss: 0.9479167461395264, Val Acc: 67.46%\n",
      "Epoch: 6538,     Training Loss: 0.41768425703048706, Training Acc: 76.53%\n",
      "              Val Loss: 0.9503790140151978, Val Acc: 67.46%\n",
      "Epoch: 6539,     Training Loss: 0.3789472281932831, Training Acc: 76.53%\n",
      "              Val Loss: 0.9182148575782776, Val Acc: 67.47%\n",
      "Epoch: 6540,     Training Loss: 0.3691086173057556, Training Acc: 76.53%\n",
      "              Val Loss: 0.9386526346206665, Val Acc: 67.47%\n",
      "Epoch: 6541,     Training Loss: 0.42840129137039185, Training Acc: 76.53%\n",
      "              Val Loss: 0.9585118889808655, Val Acc: 67.47%\n",
      "Epoch: 6542,     Training Loss: 0.39633724093437195, Training Acc: 76.54%\n",
      "              Val Loss: 0.9280171990394592, Val Acc: 67.47%\n",
      "Epoch: 6543,     Training Loss: 0.38452035188674927, Training Acc: 76.54%\n",
      "              Val Loss: 0.9216436743736267, Val Acc: 67.47%\n",
      "Epoch: 6544,     Training Loss: 0.36686041951179504, Training Acc: 76.54%\n",
      "              Val Loss: 0.9605239033699036, Val Acc: 67.47%\n",
      "Epoch: 6545,     Training Loss: 0.3838587701320648, Training Acc: 76.54%\n",
      "              Val Loss: 0.9733771681785583, Val Acc: 67.47%\n",
      "Epoch: 6546,     Training Loss: 0.4472736716270447, Training Acc: 76.54%\n",
      "              Val Loss: 0.9528986215591431, Val Acc: 67.47%\n",
      "Epoch: 6547,     Training Loss: 0.3884226977825165, Training Acc: 76.54%\n",
      "              Val Loss: 0.9155951142311096, Val Acc: 67.47%\n",
      "Epoch: 6548,     Training Loss: 0.36202529072761536, Training Acc: 76.54%\n",
      "              Val Loss: 0.946519136428833, Val Acc: 67.47%\n",
      "Epoch: 6549,     Training Loss: 0.38611263036727905, Training Acc: 76.54%\n",
      "              Val Loss: 0.9394141435623169, Val Acc: 67.47%\n",
      "Epoch: 6550,     Training Loss: 0.3662082254886627, Training Acc: 76.54%\n",
      "              Val Loss: 0.9047576189041138, Val Acc: 67.47%\n",
      "Epoch: 6551,     Training Loss: 0.3687039315700531, Training Acc: 76.55%\n",
      "              Val Loss: 0.9037593007087708, Val Acc: 67.47%\n",
      "Epoch: 6552,     Training Loss: 0.36508285999298096, Training Acc: 76.55%\n",
      "              Val Loss: 0.9390733242034912, Val Acc: 67.47%\n",
      "Epoch: 6553,     Training Loss: 0.3652190864086151, Training Acc: 76.55%\n",
      "              Val Loss: 0.9237863421440125, Val Acc: 67.47%\n",
      "Epoch: 6554,     Training Loss: 0.3751421868801117, Training Acc: 76.55%\n",
      "              Val Loss: 0.9324119687080383, Val Acc: 67.48%\n",
      "Epoch: 6555,     Training Loss: 0.354186475276947, Training Acc: 76.55%\n",
      "              Val Loss: 0.9278424978256226, Val Acc: 67.48%\n",
      "Epoch: 6556,     Training Loss: 0.3571981191635132, Training Acc: 76.55%\n",
      "              Val Loss: 0.9116611480712891, Val Acc: 67.48%\n",
      "Epoch: 6557,     Training Loss: 0.3610599935054779, Training Acc: 76.55%\n",
      "              Val Loss: 0.9367144703865051, Val Acc: 67.48%\n",
      "Epoch: 6558,     Training Loss: 0.35302820801734924, Training Acc: 76.56%\n",
      "              Val Loss: 0.9555327892303467, Val Acc: 67.48%\n",
      "Epoch: 6559,     Training Loss: 0.36765938997268677, Training Acc: 76.56%\n",
      "              Val Loss: 0.9531064629554749, Val Acc: 67.48%\n",
      "Epoch: 6560,     Training Loss: 0.3580540716648102, Training Acc: 76.56%\n",
      "              Val Loss: 0.9220305681228638, Val Acc: 67.48%\n",
      "Epoch: 6561,     Training Loss: 0.3577934503555298, Training Acc: 76.56%\n",
      "              Val Loss: 0.9509484767913818, Val Acc: 67.48%\n",
      "Epoch: 6562,     Training Loss: 0.3662470877170563, Training Acc: 76.56%\n",
      "              Val Loss: 0.928636372089386, Val Acc: 67.48%\n",
      "Epoch: 6563,     Training Loss: 0.36694326996803284, Training Acc: 76.56%\n",
      "              Val Loss: 0.9776098728179932, Val Acc: 67.48%\n",
      "Epoch: 6564,     Training Loss: 0.37603434920310974, Training Acc: 76.56%\n",
      "              Val Loss: 0.946420431137085, Val Acc: 67.48%\n",
      "Epoch: 6565,     Training Loss: 0.38903194665908813, Training Acc: 76.56%\n",
      "              Val Loss: 0.9680423140525818, Val Acc: 67.48%\n",
      "Epoch: 6566,     Training Loss: 0.379906564950943, Training Acc: 76.57%\n",
      "              Val Loss: 0.9095937609672546, Val Acc: 67.48%\n",
      "Epoch: 6567,     Training Loss: 0.36131927371025085, Training Acc: 76.57%\n",
      "              Val Loss: 0.9414457678794861, Val Acc: 67.49%\n",
      "Epoch: 6568,     Training Loss: 0.35386526584625244, Training Acc: 76.57%\n",
      "              Val Loss: 0.9244928956031799, Val Acc: 67.49%\n",
      "Epoch: 6569,     Training Loss: 0.34457045793533325, Training Acc: 76.57%\n",
      "              Val Loss: 0.9158104062080383, Val Acc: 67.49%\n",
      "Epoch: 6570,     Training Loss: 0.34601983428001404, Training Acc: 76.57%\n",
      "              Val Loss: 0.9367868304252625, Val Acc: 67.49%\n",
      "Epoch: 6571,     Training Loss: 0.3508587181568146, Training Acc: 76.57%\n",
      "              Val Loss: 0.9317063093185425, Val Acc: 67.49%\n",
      "Epoch: 6572,     Training Loss: 0.35413262248039246, Training Acc: 76.57%\n",
      "              Val Loss: 0.9816074967384338, Val Acc: 67.49%\n",
      "Epoch: 6573,     Training Loss: 0.37502896785736084, Training Acc: 76.58%\n",
      "              Val Loss: 0.9918795228004456, Val Acc: 67.49%\n",
      "Epoch: 6574,     Training Loss: 0.446396142244339, Training Acc: 76.58%\n",
      "              Val Loss: 1.029913067817688, Val Acc: 67.49%\n",
      "Epoch: 6575,     Training Loss: 0.4151972532272339, Training Acc: 76.58%\n",
      "              Val Loss: 0.9422838091850281, Val Acc: 67.49%\n",
      "Epoch: 6576,     Training Loss: 0.39354681968688965, Training Acc: 76.58%\n",
      "              Val Loss: 0.9355636835098267, Val Acc: 67.49%\n",
      "Epoch: 6577,     Training Loss: 0.354827880859375, Training Acc: 76.58%\n",
      "              Val Loss: 0.9280149936676025, Val Acc: 67.49%\n",
      "Epoch: 6578,     Training Loss: 0.35338401794433594, Training Acc: 76.58%\n",
      "              Val Loss: 0.9080090522766113, Val Acc: 67.49%\n",
      "Epoch: 6579,     Training Loss: 0.3622492849826813, Training Acc: 76.58%\n",
      "              Val Loss: 0.9363604187965393, Val Acc: 67.49%\n",
      "Epoch: 6580,     Training Loss: 0.367361456155777, Training Acc: 76.58%\n",
      "              Val Loss: 0.9279173016548157, Val Acc: 67.49%\n",
      "Epoch: 6581,     Training Loss: 0.37544891238212585, Training Acc: 76.58%\n",
      "              Val Loss: 0.9547247290611267, Val Acc: 67.49%\n",
      "Epoch: 6582,     Training Loss: 0.36277303099632263, Training Acc: 76.59%\n",
      "              Val Loss: 0.9211006760597229, Val Acc: 67.50%\n",
      "Epoch: 6583,     Training Loss: 0.345096617937088, Training Acc: 76.59%\n",
      "              Val Loss: 0.9287567138671875, Val Acc: 67.50%\n",
      "Epoch: 6584,     Training Loss: 0.34877368807792664, Training Acc: 76.59%\n",
      "              Val Loss: 0.9491459727287292, Val Acc: 67.50%\n",
      "Epoch: 6585,     Training Loss: 0.35691654682159424, Training Acc: 76.59%\n",
      "              Val Loss: 0.952252984046936, Val Acc: 67.50%\n",
      "Epoch: 6586,     Training Loss: 0.3911856710910797, Training Acc: 76.59%\n",
      "              Val Loss: 1.0121984481811523, Val Acc: 67.50%\n",
      "Epoch: 6587,     Training Loss: 0.39202120900154114, Training Acc: 76.59%\n",
      "              Val Loss: 0.9742797613143921, Val Acc: 67.50%\n",
      "Epoch: 6588,     Training Loss: 0.4297756552696228, Training Acc: 76.59%\n",
      "              Val Loss: 0.9914251565933228, Val Acc: 67.50%\n",
      "Epoch: 6589,     Training Loss: 0.3911668062210083, Training Acc: 76.59%\n",
      "              Val Loss: 0.9142389893531799, Val Acc: 67.50%\n",
      "Epoch: 6590,     Training Loss: 0.35488930344581604, Training Acc: 76.60%\n",
      "              Val Loss: 0.9186460971832275, Val Acc: 67.50%\n",
      "Epoch: 6591,     Training Loss: 0.34477221965789795, Training Acc: 76.60%\n",
      "              Val Loss: 0.946327805519104, Val Acc: 67.50%\n",
      "Epoch: 6592,     Training Loss: 0.3596426844596863, Training Acc: 76.60%\n",
      "              Val Loss: 0.9450858235359192, Val Acc: 67.50%\n",
      "Epoch: 6593,     Training Loss: 0.39268845319747925, Training Acc: 76.60%\n",
      "              Val Loss: 0.9639619588851929, Val Acc: 67.50%\n",
      "Epoch: 6594,     Training Loss: 0.3705565631389618, Training Acc: 76.60%\n",
      "              Val Loss: 0.921836256980896, Val Acc: 67.50%\n",
      "Epoch: 6595,     Training Loss: 0.35733070969581604, Training Acc: 76.60%\n",
      "              Val Loss: 0.9302401542663574, Val Acc: 67.50%\n",
      "Epoch: 6596,     Training Loss: 0.34052109718322754, Training Acc: 76.60%\n",
      "              Val Loss: 0.9401695728302002, Val Acc: 67.51%\n",
      "Epoch: 6597,     Training Loss: 0.3444885015487671, Training Acc: 76.60%\n",
      "              Val Loss: 0.9346463084220886, Val Acc: 67.51%\n",
      "Epoch: 6598,     Training Loss: 0.37456828355789185, Training Acc: 76.61%\n",
      "              Val Loss: 1.0071253776550293, Val Acc: 67.51%\n",
      "Epoch: 6599,     Training Loss: 0.39380013942718506, Training Acc: 76.61%\n",
      "              Val Loss: 1.0363975763320923, Val Acc: 67.51%\n",
      "Epoch: 6600,     Training Loss: 0.4791301488876343, Training Acc: 76.61%\n",
      "              Val Loss: 0.9821235537528992, Val Acc: 67.51%\n",
      "Epoch: 6601,     Training Loss: 0.3729758560657501, Training Acc: 76.61%\n",
      "              Val Loss: 0.9392403364181519, Val Acc: 67.51%\n",
      "Epoch: 6602,     Training Loss: 0.3496633768081665, Training Acc: 76.61%\n",
      "              Val Loss: 0.9642763733863831, Val Acc: 67.51%\n",
      "Epoch: 6603,     Training Loss: 0.4095495939254761, Training Acc: 76.61%\n",
      "              Val Loss: 1.0455985069274902, Val Acc: 67.51%\n",
      "Epoch: 6604,     Training Loss: 0.4214431643486023, Training Acc: 76.61%\n",
      "              Val Loss: 0.9465775489807129, Val Acc: 67.51%\n",
      "Epoch: 6605,     Training Loss: 0.38415849208831787, Training Acc: 76.61%\n",
      "              Val Loss: 0.9796558618545532, Val Acc: 67.51%\n",
      "Epoch: 6606,     Training Loss: 0.3826311230659485, Training Acc: 76.61%\n",
      "              Val Loss: 0.9637936949729919, Val Acc: 67.51%\n",
      "Epoch: 6607,     Training Loss: 0.3711625635623932, Training Acc: 76.62%\n",
      "              Val Loss: 0.9622889161109924, Val Acc: 67.51%\n",
      "Epoch: 6608,     Training Loss: 0.4268381595611572, Training Acc: 76.62%\n",
      "              Val Loss: 0.9502780437469482, Val Acc: 67.51%\n",
      "Epoch: 6609,     Training Loss: 0.3645743429660797, Training Acc: 76.62%\n",
      "              Val Loss: 0.9685094952583313, Val Acc: 67.51%\n",
      "Epoch: 6610,     Training Loss: 0.3649182915687561, Training Acc: 76.62%\n",
      "              Val Loss: 0.9613405466079712, Val Acc: 67.51%\n",
      "Epoch: 6611,     Training Loss: 0.3973504602909088, Training Acc: 76.62%\n",
      "              Val Loss: 0.9716952443122864, Val Acc: 67.52%\n",
      "Epoch: 6612,     Training Loss: 0.3601946234703064, Training Acc: 76.62%\n",
      "              Val Loss: 0.9393693804740906, Val Acc: 67.52%\n",
      "Epoch: 6613,     Training Loss: 0.35196688771247864, Training Acc: 76.62%\n",
      "              Val Loss: 0.9286638498306274, Val Acc: 67.52%\n",
      "Epoch: 6614,     Training Loss: 0.36944976449012756, Training Acc: 76.62%\n",
      "              Val Loss: 0.9969139099121094, Val Acc: 67.52%\n",
      "Epoch: 6615,     Training Loss: 0.3840027153491974, Training Acc: 76.63%\n",
      "              Val Loss: 0.980105459690094, Val Acc: 67.52%\n",
      "Epoch: 6616,     Training Loss: 0.3931058943271637, Training Acc: 76.63%\n",
      "              Val Loss: 0.9819210171699524, Val Acc: 67.52%\n",
      "Epoch: 6617,     Training Loss: 0.3717464208602905, Training Acc: 76.63%\n",
      "              Val Loss: 0.9348664879798889, Val Acc: 67.52%\n",
      "Epoch: 6618,     Training Loss: 0.3468838930130005, Training Acc: 76.63%\n",
      "              Val Loss: 0.9360110759735107, Val Acc: 67.52%\n",
      "Epoch: 6619,     Training Loss: 0.3702918291091919, Training Acc: 76.63%\n",
      "              Val Loss: 0.9382953643798828, Val Acc: 67.52%\n",
      "Epoch: 6620,     Training Loss: 0.34850504994392395, Training Acc: 76.63%\n",
      "              Val Loss: 0.9474283456802368, Val Acc: 67.52%\n",
      "Epoch: 6621,     Training Loss: 0.3524419665336609, Training Acc: 76.63%\n",
      "              Val Loss: 0.9672968983650208, Val Acc: 67.52%\n",
      "Epoch: 6622,     Training Loss: 0.3572511672973633, Training Acc: 76.63%\n",
      "              Val Loss: 0.9199067950248718, Val Acc: 67.52%\n",
      "Epoch: 6623,     Training Loss: 0.3403809666633606, Training Acc: 76.64%\n",
      "              Val Loss: 0.918033242225647, Val Acc: 67.52%\n",
      "Epoch: 6624,     Training Loss: 0.3472610414028168, Training Acc: 76.64%\n",
      "              Val Loss: 0.9380424618721008, Val Acc: 67.52%\n",
      "Epoch: 6625,     Training Loss: 0.34144166111946106, Training Acc: 76.64%\n",
      "              Val Loss: 0.9541255235671997, Val Acc: 67.53%\n",
      "Epoch: 6626,     Training Loss: 0.34522849321365356, Training Acc: 76.64%\n",
      "              Val Loss: 0.9580599069595337, Val Acc: 67.53%\n",
      "Epoch: 6627,     Training Loss: 0.33919966220855713, Training Acc: 76.64%\n",
      "              Val Loss: 0.9692407846450806, Val Acc: 67.53%\n",
      "Epoch: 6628,     Training Loss: 0.3454219102859497, Training Acc: 76.64%\n",
      "              Val Loss: 0.9500304460525513, Val Acc: 67.53%\n",
      "Epoch: 6629,     Training Loss: 0.36294320225715637, Training Acc: 76.64%\n",
      "              Val Loss: 1.0051569938659668, Val Acc: 67.53%\n",
      "Epoch: 6630,     Training Loss: 0.3773496150970459, Training Acc: 76.65%\n",
      "              Val Loss: 1.0276873111724854, Val Acc: 67.53%\n",
      "Epoch: 6631,     Training Loss: 0.444077730178833, Training Acc: 76.65%\n",
      "              Val Loss: 1.0178278684616089, Val Acc: 67.53%\n",
      "Epoch: 6632,     Training Loss: 0.3817700445652008, Training Acc: 76.65%\n",
      "              Val Loss: 0.9490877389907837, Val Acc: 67.53%\n",
      "Epoch: 6633,     Training Loss: 0.3594018220901489, Training Acc: 76.65%\n",
      "              Val Loss: 0.9413869976997375, Val Acc: 67.53%\n",
      "Epoch: 6634,     Training Loss: 0.3505411446094513, Training Acc: 76.65%\n",
      "              Val Loss: 0.946892261505127, Val Acc: 67.53%\n",
      "Epoch: 6635,     Training Loss: 0.3537376821041107, Training Acc: 76.65%\n",
      "              Val Loss: 0.9384590983390808, Val Acc: 67.53%\n",
      "Epoch: 6636,     Training Loss: 0.3659306466579437, Training Acc: 76.65%\n",
      "              Val Loss: 0.9796878695487976, Val Acc: 67.53%\n",
      "Epoch: 6637,     Training Loss: 0.36132267117500305, Training Acc: 76.65%\n",
      "              Val Loss: 0.9614349603652954, Val Acc: 67.53%\n",
      "Epoch: 6638,     Training Loss: 0.35125839710235596, Training Acc: 76.66%\n",
      "              Val Loss: 0.9495291709899902, Val Acc: 67.54%\n",
      "Epoch: 6639,     Training Loss: 0.3571995496749878, Training Acc: 76.66%\n",
      "              Val Loss: 1.002935767173767, Val Acc: 67.54%\n",
      "Epoch: 6640,     Training Loss: 0.3784151077270508, Training Acc: 76.66%\n",
      "              Val Loss: 0.9754438996315002, Val Acc: 67.54%\n",
      "Epoch: 6641,     Training Loss: 0.403364360332489, Training Acc: 76.66%\n",
      "              Val Loss: 1.0149158239364624, Val Acc: 67.54%\n",
      "Epoch: 6642,     Training Loss: 0.38447806239128113, Training Acc: 76.66%\n",
      "              Val Loss: 0.9465166330337524, Val Acc: 67.54%\n",
      "Epoch: 6643,     Training Loss: 0.3671030104160309, Training Acc: 76.66%\n",
      "              Val Loss: 0.9614870548248291, Val Acc: 67.54%\n",
      "Epoch: 6644,     Training Loss: 0.37420254945755005, Training Acc: 76.66%\n",
      "              Val Loss: 0.9263103008270264, Val Acc: 67.54%\n",
      "Epoch: 6645,     Training Loss: 0.3478764593601227, Training Acc: 76.66%\n",
      "              Val Loss: 0.9684807062149048, Val Acc: 67.54%\n",
      "Epoch: 6646,     Training Loss: 0.351645827293396, Training Acc: 76.66%\n",
      "              Val Loss: 0.948811411857605, Val Acc: 67.54%\n",
      "Epoch: 6647,     Training Loss: 0.3591221272945404, Training Acc: 76.67%\n",
      "              Val Loss: 0.928995668888092, Val Acc: 67.54%\n",
      "Epoch: 6648,     Training Loss: 0.33111894130706787, Training Acc: 76.67%\n",
      "              Val Loss: 0.9587404131889343, Val Acc: 67.54%\n",
      "Epoch: 6649,     Training Loss: 0.35106536746025085, Training Acc: 76.67%\n",
      "              Val Loss: 0.9366874098777771, Val Acc: 67.54%\n",
      "Epoch: 6650,     Training Loss: 0.3549948036670685, Training Acc: 76.67%\n",
      "              Val Loss: 1.0297911167144775, Val Acc: 67.54%\n",
      "Epoch: 6651,     Training Loss: 0.391670823097229, Training Acc: 76.67%\n",
      "              Val Loss: 0.994533360004425, Val Acc: 67.54%\n",
      "Epoch: 6652,     Training Loss: 0.41173848509788513, Training Acc: 76.67%\n",
      "              Val Loss: 1.0071314573287964, Val Acc: 67.54%\n",
      "Epoch: 6653,     Training Loss: 0.3813720941543579, Training Acc: 76.67%\n",
      "              Val Loss: 0.9618919491767883, Val Acc: 67.55%\n",
      "Epoch: 6654,     Training Loss: 0.39837920665740967, Training Acc: 76.67%\n",
      "              Val Loss: 0.9388282895088196, Val Acc: 67.55%\n",
      "Epoch: 6655,     Training Loss: 0.34980225563049316, Training Acc: 76.68%\n",
      "              Val Loss: 0.9652230143547058, Val Acc: 67.55%\n",
      "Epoch: 6656,     Training Loss: 0.3655884563922882, Training Acc: 76.68%\n",
      "              Val Loss: 0.9343119263648987, Val Acc: 67.55%\n",
      "Epoch: 6657,     Training Loss: 0.3414608836174011, Training Acc: 76.68%\n",
      "              Val Loss: 1.0023865699768066, Val Acc: 67.55%\n",
      "Epoch: 6658,     Training Loss: 0.37523353099823, Training Acc: 76.68%\n",
      "              Val Loss: 0.9340100884437561, Val Acc: 67.55%\n",
      "Epoch: 6659,     Training Loss: 0.34973740577697754, Training Acc: 76.68%\n",
      "              Val Loss: 0.9551547765731812, Val Acc: 67.55%\n",
      "Epoch: 6660,     Training Loss: 0.3558199405670166, Training Acc: 76.68%\n",
      "              Val Loss: 0.9370437860488892, Val Acc: 67.55%\n",
      "Epoch: 6661,     Training Loss: 0.3446671664714813, Training Acc: 76.68%\n",
      "              Val Loss: 0.9401586651802063, Val Acc: 67.55%\n",
      "Epoch: 6662,     Training Loss: 0.35492804646492004, Training Acc: 76.68%\n",
      "              Val Loss: 0.9553925395011902, Val Acc: 67.55%\n",
      "Epoch: 6663,     Training Loss: 0.3345658779144287, Training Acc: 76.69%\n",
      "              Val Loss: 0.9862850308418274, Val Acc: 67.55%\n",
      "Epoch: 6664,     Training Loss: 0.35375890135765076, Training Acc: 76.69%\n",
      "              Val Loss: 0.9528971910476685, Val Acc: 67.55%\n",
      "Epoch: 6665,     Training Loss: 0.33527234196662903, Training Acc: 76.69%\n",
      "              Val Loss: 0.9588289856910706, Val Acc: 67.55%\n",
      "Epoch: 6666,     Training Loss: 0.3418112099170685, Training Acc: 76.69%\n",
      "              Val Loss: 0.9517574906349182, Val Acc: 67.56%\n",
      "Epoch: 6667,     Training Loss: 0.3685634136199951, Training Acc: 76.69%\n",
      "              Val Loss: 1.0132406949996948, Val Acc: 67.56%\n",
      "Epoch: 6668,     Training Loss: 0.38568902015686035, Training Acc: 76.69%\n",
      "              Val Loss: 1.0577179193496704, Val Acc: 67.56%\n",
      "Epoch: 6669,     Training Loss: 0.4901517927646637, Training Acc: 76.69%\n",
      "              Val Loss: 0.9938049912452698, Val Acc: 67.56%\n",
      "Epoch: 6670,     Training Loss: 0.3648819327354431, Training Acc: 76.69%\n",
      "              Val Loss: 0.990090012550354, Val Acc: 67.56%\n",
      "Epoch: 6671,     Training Loss: 0.37660112977027893, Training Acc: 76.70%\n",
      "              Val Loss: 0.9825686812400818, Val Acc: 67.56%\n",
      "Epoch: 6672,     Training Loss: 0.42299070954322815, Training Acc: 76.70%\n",
      "              Val Loss: 1.104085087776184, Val Acc: 67.56%\n",
      "Epoch: 6673,     Training Loss: 0.45896053314208984, Training Acc: 76.70%\n",
      "              Val Loss: 0.970710813999176, Val Acc: 67.56%\n",
      "Epoch: 6674,     Training Loss: 0.4053211212158203, Training Acc: 76.70%\n",
      "              Val Loss: 1.0485743284225464, Val Acc: 67.56%\n",
      "Epoch: 6675,     Training Loss: 0.4184134304523468, Training Acc: 76.70%\n",
      "              Val Loss: 0.9635674953460693, Val Acc: 67.56%\n",
      "Epoch: 6676,     Training Loss: 0.3544042110443115, Training Acc: 76.70%\n",
      "              Val Loss: 0.9830306172370911, Val Acc: 67.56%\n",
      "Epoch: 6677,     Training Loss: 0.4248688519001007, Training Acc: 76.70%\n",
      "              Val Loss: 0.947100043296814, Val Acc: 67.56%\n",
      "Epoch: 6678,     Training Loss: 0.37022149562835693, Training Acc: 76.70%\n",
      "              Val Loss: 0.9536223411560059, Val Acc: 67.56%\n",
      "Epoch: 6679,     Training Loss: 0.3682447373867035, Training Acc: 76.70%\n",
      "              Val Loss: 0.9546206593513489, Val Acc: 67.56%\n",
      "Epoch: 6680,     Training Loss: 0.3665982782840729, Training Acc: 76.70%\n",
      "              Val Loss: 0.9833574891090393, Val Acc: 67.56%\n",
      "Epoch: 6681,     Training Loss: 0.36086899042129517, Training Acc: 76.71%\n",
      "              Val Loss: 0.9993846416473389, Val Acc: 67.56%\n",
      "Epoch: 6682,     Training Loss: 0.35904842615127563, Training Acc: 76.71%\n",
      "              Val Loss: 0.9851464629173279, Val Acc: 67.57%\n",
      "Epoch: 6683,     Training Loss: 0.3722763955593109, Training Acc: 76.71%\n",
      "              Val Loss: 0.9805071949958801, Val Acc: 67.57%\n",
      "Epoch: 6684,     Training Loss: 0.34506645798683167, Training Acc: 76.71%\n",
      "              Val Loss: 0.9908809661865234, Val Acc: 67.57%\n",
      "Epoch: 6685,     Training Loss: 0.3649767339229584, Training Acc: 76.71%\n",
      "              Val Loss: 0.9877662658691406, Val Acc: 67.57%\n",
      "Epoch: 6686,     Training Loss: 0.35631805658340454, Training Acc: 76.71%\n",
      "              Val Loss: 0.9805123209953308, Val Acc: 67.57%\n",
      "Epoch: 6687,     Training Loss: 0.34791305661201477, Training Acc: 76.71%\n",
      "              Val Loss: 0.9558494687080383, Val Acc: 67.57%\n",
      "Epoch: 6688,     Training Loss: 0.33701056241989136, Training Acc: 76.72%\n",
      "              Val Loss: 0.9822322726249695, Val Acc: 67.57%\n",
      "Epoch: 6689,     Training Loss: 0.35724398493766785, Training Acc: 76.72%\n",
      "              Val Loss: 0.9887070655822754, Val Acc: 67.57%\n",
      "Epoch: 6690,     Training Loss: 0.3607551157474518, Training Acc: 76.72%\n",
      "              Val Loss: 0.9984173774719238, Val Acc: 67.57%\n",
      "Epoch: 6691,     Training Loss: 0.3509848415851593, Training Acc: 76.72%\n",
      "              Val Loss: 0.9953649044036865, Val Acc: 67.57%\n",
      "Epoch: 6692,     Training Loss: 0.39751356840133667, Training Acc: 76.72%\n",
      "              Val Loss: 1.0564972162246704, Val Acc: 67.57%\n",
      "Epoch: 6693,     Training Loss: 0.3872891366481781, Training Acc: 76.72%\n",
      "              Val Loss: 1.026342511177063, Val Acc: 67.57%\n",
      "Epoch: 6694,     Training Loss: 0.41960570216178894, Training Acc: 76.72%\n",
      "              Val Loss: 1.0330032110214233, Val Acc: 67.57%\n",
      "Epoch: 6695,     Training Loss: 0.3731876015663147, Training Acc: 76.72%\n",
      "              Val Loss: 0.9835828542709351, Val Acc: 67.57%\n",
      "Epoch: 6696,     Training Loss: 0.3511119782924652, Training Acc: 76.72%\n",
      "              Val Loss: 0.9702683091163635, Val Acc: 67.57%\n",
      "Epoch: 6697,     Training Loss: 0.3394533097743988, Training Acc: 76.73%\n",
      "              Val Loss: 1.0026353597640991, Val Acc: 67.58%\n",
      "Epoch: 6698,     Training Loss: 0.36014068126678467, Training Acc: 76.73%\n",
      "              Val Loss: 1.0115896463394165, Val Acc: 67.58%\n",
      "Epoch: 6699,     Training Loss: 0.38754236698150635, Training Acc: 76.73%\n",
      "              Val Loss: 1.0391727685928345, Val Acc: 67.58%\n",
      "Epoch: 6700,     Training Loss: 0.37055638432502747, Training Acc: 76.73%\n",
      "              Val Loss: 1.0008348226547241, Val Acc: 67.58%\n",
      "Epoch: 6701,     Training Loss: 0.3575056195259094, Training Acc: 76.73%\n",
      "              Val Loss: 0.9961730241775513, Val Acc: 67.58%\n",
      "Epoch: 6702,     Training Loss: 0.3593319356441498, Training Acc: 76.73%\n",
      "              Val Loss: 1.0001810789108276, Val Acc: 67.58%\n",
      "Epoch: 6703,     Training Loss: 0.348359078168869, Training Acc: 76.73%\n",
      "              Val Loss: 0.9935994148254395, Val Acc: 67.58%\n",
      "Epoch: 6704,     Training Loss: 0.36780548095703125, Training Acc: 76.73%\n",
      "              Val Loss: 1.031057357788086, Val Acc: 67.58%\n",
      "Epoch: 6705,     Training Loss: 0.36365804076194763, Training Acc: 76.74%\n",
      "              Val Loss: 0.9884201884269714, Val Acc: 67.58%\n",
      "Epoch: 6706,     Training Loss: 0.33550313115119934, Training Acc: 76.74%\n",
      "              Val Loss: 1.0184897184371948, Val Acc: 67.58%\n",
      "Epoch: 6707,     Training Loss: 0.3763452470302582, Training Acc: 76.74%\n",
      "              Val Loss: 1.0017318725585938, Val Acc: 67.58%\n",
      "Epoch: 6708,     Training Loss: 0.3718520402908325, Training Acc: 76.74%\n",
      "              Val Loss: 1.0920836925506592, Val Acc: 67.58%\n",
      "Epoch: 6709,     Training Loss: 0.4068562388420105, Training Acc: 76.74%\n",
      "              Val Loss: 1.092259407043457, Val Acc: 67.58%\n",
      "Epoch: 6710,     Training Loss: 0.5096459984779358, Training Acc: 76.74%\n",
      "              Val Loss: 1.0096330642700195, Val Acc: 67.58%\n",
      "Epoch: 6711,     Training Loss: 0.36803901195526123, Training Acc: 76.74%\n",
      "              Val Loss: 1.0575135946273804, Val Acc: 67.58%\n",
      "Epoch: 6712,     Training Loss: 0.39659351110458374, Training Acc: 76.74%\n",
      "              Val Loss: 1.1333234310150146, Val Acc: 67.58%\n",
      "Epoch: 6713,     Training Loss: 0.5422343015670776, Training Acc: 76.74%\n",
      "              Val Loss: 1.0320326089859009, Val Acc: 67.58%\n",
      "Epoch: 6714,     Training Loss: 0.39403343200683594, Training Acc: 76.74%\n",
      "              Val Loss: 1.0617616176605225, Val Acc: 67.59%\n",
      "Epoch: 6715,     Training Loss: 0.4160376489162445, Training Acc: 76.74%\n",
      "              Val Loss: 1.039684534072876, Val Acc: 67.59%\n",
      "Epoch: 6716,     Training Loss: 0.44861823320388794, Training Acc: 76.75%\n",
      "              Val Loss: 1.0681337118148804, Val Acc: 67.59%\n",
      "Epoch: 6717,     Training Loss: 0.42340657114982605, Training Acc: 76.75%\n",
      "              Val Loss: 1.051357388496399, Val Acc: 67.59%\n",
      "Epoch: 6718,     Training Loss: 0.4051229953765869, Training Acc: 76.75%\n",
      "              Val Loss: 1.0144190788269043, Val Acc: 67.59%\n",
      "Epoch: 6719,     Training Loss: 0.37620311975479126, Training Acc: 76.75%\n",
      "              Val Loss: 1.0655516386032104, Val Acc: 67.59%\n",
      "Epoch: 6720,     Training Loss: 0.4103315472602844, Training Acc: 76.75%\n",
      "              Val Loss: 1.0373648405075073, Val Acc: 67.59%\n",
      "Epoch: 6721,     Training Loss: 0.38677743077278137, Training Acc: 76.75%\n",
      "              Val Loss: 1.0020949840545654, Val Acc: 67.59%\n",
      "Epoch: 6722,     Training Loss: 0.3552417457103729, Training Acc: 76.75%\n",
      "              Val Loss: 1.0432689189910889, Val Acc: 67.59%\n",
      "Epoch: 6723,     Training Loss: 0.3971346318721771, Training Acc: 76.75%\n",
      "              Val Loss: 0.9774585962295532, Val Acc: 67.59%\n",
      "Epoch: 6724,     Training Loss: 0.3374493718147278, Training Acc: 76.75%\n",
      "              Val Loss: 1.0454338788986206, Val Acc: 67.59%\n",
      "Epoch: 6725,     Training Loss: 0.3822683095932007, Training Acc: 76.75%\n",
      "              Val Loss: 0.9766242504119873, Val Acc: 67.59%\n",
      "Epoch: 6726,     Training Loss: 0.33954447507858276, Training Acc: 76.76%\n",
      "              Val Loss: 0.9932981729507446, Val Acc: 67.59%\n",
      "Epoch: 6727,     Training Loss: 0.3569881021976471, Training Acc: 76.76%\n",
      "              Val Loss: 0.9921518564224243, Val Acc: 67.59%\n",
      "Epoch: 6728,     Training Loss: 0.35712626576423645, Training Acc: 76.76%\n",
      "              Val Loss: 0.9745398759841919, Val Acc: 67.59%\n",
      "Epoch: 6729,     Training Loss: 0.34218883514404297, Training Acc: 76.76%\n",
      "              Val Loss: 0.9712113738059998, Val Acc: 67.59%\n",
      "Epoch: 6730,     Training Loss: 0.3497959077358246, Training Acc: 76.76%\n",
      "              Val Loss: 0.9619802236557007, Val Acc: 67.60%\n",
      "Epoch: 6731,     Training Loss: 0.33848893642425537, Training Acc: 76.76%\n",
      "              Val Loss: 0.9570340514183044, Val Acc: 67.60%\n",
      "Epoch: 6732,     Training Loss: 0.3351879417896271, Training Acc: 76.76%\n",
      "              Val Loss: 0.9558385610580444, Val Acc: 67.60%\n",
      "Epoch: 6733,     Training Loss: 0.3408362567424774, Training Acc: 76.77%\n",
      "              Val Loss: 0.9512473940849304, Val Acc: 67.60%\n",
      "Epoch: 6734,     Training Loss: 0.3345094323158264, Training Acc: 76.77%\n",
      "              Val Loss: 0.9777546525001526, Val Acc: 67.60%\n",
      "Epoch: 6735,     Training Loss: 0.33854472637176514, Training Acc: 76.77%\n",
      "              Val Loss: 0.9637371897697449, Val Acc: 67.60%\n",
      "Epoch: 6736,     Training Loss: 0.3522416949272156, Training Acc: 76.77%\n",
      "              Val Loss: 0.9704647660255432, Val Acc: 67.60%\n",
      "Epoch: 6737,     Training Loss: 0.3321094214916229, Training Acc: 76.77%\n",
      "              Val Loss: 0.9857008457183838, Val Acc: 67.60%\n",
      "Epoch: 6738,     Training Loss: 0.34790143370628357, Training Acc: 76.77%\n",
      "              Val Loss: 0.9734025001525879, Val Acc: 67.60%\n",
      "Epoch: 6739,     Training Loss: 0.3227359652519226, Training Acc: 76.77%\n",
      "              Val Loss: 0.9941058158874512, Val Acc: 67.60%\n",
      "Epoch: 6740,     Training Loss: 0.3328510522842407, Training Acc: 76.78%\n",
      "              Val Loss: 1.0018774271011353, Val Acc: 67.60%\n",
      "Epoch: 6741,     Training Loss: 0.34926551580429077, Training Acc: 76.78%\n",
      "              Val Loss: 1.0159586668014526, Val Acc: 67.60%\n",
      "Epoch: 6742,     Training Loss: 0.3397270441055298, Training Acc: 76.78%\n",
      "              Val Loss: 0.992275595664978, Val Acc: 67.60%\n",
      "Epoch: 6743,     Training Loss: 0.3581548035144806, Training Acc: 76.78%\n",
      "              Val Loss: 1.011225700378418, Val Acc: 67.61%\n",
      "Epoch: 6744,     Training Loss: 0.3360050320625305, Training Acc: 76.78%\n",
      "              Val Loss: 0.974744975566864, Val Acc: 67.61%\n",
      "Epoch: 6745,     Training Loss: 0.3305003345012665, Training Acc: 76.78%\n",
      "              Val Loss: 0.9759102463722229, Val Acc: 67.61%\n",
      "Epoch: 6746,     Training Loss: 0.3267959952354431, Training Acc: 76.78%\n",
      "              Val Loss: 0.9771826267242432, Val Acc: 67.61%\n",
      "Epoch: 6747,     Training Loss: 0.3224855661392212, Training Acc: 76.79%\n",
      "              Val Loss: 0.9758470058441162, Val Acc: 67.61%\n",
      "Epoch: 6748,     Training Loss: 0.32182177901268005, Training Acc: 76.79%\n",
      "              Val Loss: 0.9914194345474243, Val Acc: 67.61%\n",
      "Epoch: 6749,     Training Loss: 0.3273753821849823, Training Acc: 76.79%\n",
      "              Val Loss: 0.9765755534172058, Val Acc: 67.61%\n",
      "Epoch: 6750,     Training Loss: 0.32394832372665405, Training Acc: 76.79%\n",
      "              Val Loss: 1.007584810256958, Val Acc: 67.61%\n",
      "Epoch: 6751,     Training Loss: 0.3295130431652069, Training Acc: 76.79%\n",
      "              Val Loss: 0.9898976683616638, Val Acc: 67.61%\n",
      "Epoch: 6752,     Training Loss: 0.3443220853805542, Training Acc: 76.79%\n",
      "              Val Loss: 1.0400497913360596, Val Acc: 67.61%\n",
      "Epoch: 6753,     Training Loss: 0.3470742106437683, Training Acc: 76.79%\n",
      "              Val Loss: 1.0204918384552002, Val Acc: 67.61%\n",
      "Epoch: 6754,     Training Loss: 0.37294554710388184, Training Acc: 76.80%\n",
      "              Val Loss: 1.030350923538208, Val Acc: 67.61%\n",
      "Epoch: 6755,     Training Loss: 0.3424173593521118, Training Acc: 76.80%\n",
      "              Val Loss: 0.9832099676132202, Val Acc: 67.61%\n",
      "Epoch: 6756,     Training Loss: 0.3336556553840637, Training Acc: 76.80%\n",
      "              Val Loss: 0.9840829968452454, Val Acc: 67.62%\n",
      "Epoch: 6757,     Training Loss: 0.32002779841423035, Training Acc: 76.80%\n",
      "              Val Loss: 0.9883305430412292, Val Acc: 67.62%\n",
      "Epoch: 6758,     Training Loss: 0.3230191469192505, Training Acc: 76.80%\n",
      "              Val Loss: 0.9835736155509949, Val Acc: 67.62%\n",
      "Epoch: 6759,     Training Loss: 0.33935412764549255, Training Acc: 76.80%\n",
      "              Val Loss: 1.0284206867218018, Val Acc: 67.62%\n",
      "Epoch: 6760,     Training Loss: 0.3410733938217163, Training Acc: 76.80%\n",
      "              Val Loss: 0.9955540299415588, Val Acc: 67.62%\n",
      "Epoch: 6761,     Training Loss: 0.350708931684494, Training Acc: 76.81%\n",
      "              Val Loss: 1.0099464654922485, Val Acc: 67.62%\n",
      "Epoch: 6762,     Training Loss: 0.33114874362945557, Training Acc: 76.81%\n",
      "              Val Loss: 0.984313428401947, Val Acc: 67.62%\n",
      "Epoch: 6763,     Training Loss: 0.32786834239959717, Training Acc: 76.81%\n",
      "              Val Loss: 0.988094687461853, Val Acc: 67.62%\n",
      "Epoch: 6764,     Training Loss: 0.31605198979377747, Training Acc: 76.81%\n",
      "              Val Loss: 0.9970462322235107, Val Acc: 67.62%\n",
      "Epoch: 6765,     Training Loss: 0.31723910570144653, Training Acc: 76.81%\n",
      "              Val Loss: 0.9978141784667969, Val Acc: 67.62%\n",
      "Epoch: 6766,     Training Loss: 0.3264503479003906, Training Acc: 76.81%\n",
      "              Val Loss: 1.0277920961380005, Val Acc: 67.62%\n",
      "Epoch: 6767,     Training Loss: 0.3316335380077362, Training Acc: 76.81%\n",
      "              Val Loss: 1.0100750923156738, Val Acc: 67.62%\n",
      "Epoch: 6768,     Training Loss: 0.35639554262161255, Training Acc: 76.82%\n",
      "              Val Loss: 1.0489487648010254, Val Acc: 67.62%\n",
      "Epoch: 6769,     Training Loss: 0.3474005162715912, Training Acc: 76.82%\n",
      "              Val Loss: 1.0029298067092896, Val Acc: 67.63%\n",
      "Epoch: 6770,     Training Loss: 0.356460303068161, Training Acc: 76.82%\n",
      "              Val Loss: 1.0109171867370605, Val Acc: 67.63%\n",
      "Epoch: 6771,     Training Loss: 0.3296010494232178, Training Acc: 76.82%\n",
      "              Val Loss: 0.983562707901001, Val Acc: 67.63%\n",
      "Epoch: 6772,     Training Loss: 0.3219837546348572, Training Acc: 76.82%\n",
      "              Val Loss: 0.9855636358261108, Val Acc: 67.63%\n",
      "Epoch: 6773,     Training Loss: 0.3153650760650635, Training Acc: 76.82%\n",
      "              Val Loss: 0.999457836151123, Val Acc: 67.63%\n",
      "Epoch: 6774,     Training Loss: 0.31805145740509033, Training Acc: 76.82%\n",
      "              Val Loss: 0.997240424156189, Val Acc: 67.63%\n",
      "Epoch: 6775,     Training Loss: 0.333825945854187, Training Acc: 76.83%\n",
      "              Val Loss: 1.041511058807373, Val Acc: 67.63%\n",
      "Epoch: 6776,     Training Loss: 0.3417041003704071, Training Acc: 76.83%\n",
      "              Val Loss: 1.0260616540908813, Val Acc: 67.63%\n",
      "Epoch: 6777,     Training Loss: 0.3753466308116913, Training Acc: 76.83%\n",
      "              Val Loss: 1.0529601573944092, Val Acc: 67.63%\n",
      "Epoch: 6778,     Training Loss: 0.3467961251735687, Training Acc: 76.83%\n",
      "              Val Loss: 0.9959496855735779, Val Acc: 67.63%\n",
      "Epoch: 6779,     Training Loss: 0.3388326168060303, Training Acc: 76.83%\n",
      "              Val Loss: 0.9969218373298645, Val Acc: 67.63%\n",
      "Epoch: 6780,     Training Loss: 0.3197256922721863, Training Acc: 76.83%\n",
      "              Val Loss: 0.9905389547348022, Val Acc: 67.63%\n",
      "Epoch: 6781,     Training Loss: 0.3150477111339569, Training Acc: 76.83%\n",
      "              Val Loss: 0.9834801554679871, Val Acc: 67.63%\n",
      "Epoch: 6782,     Training Loss: 0.3200472593307495, Training Acc: 76.84%\n",
      "              Val Loss: 1.0129040479660034, Val Acc: 67.64%\n",
      "Epoch: 6783,     Training Loss: 0.32708224654197693, Training Acc: 76.84%\n",
      "              Val Loss: 0.999458372592926, Val Acc: 67.64%\n",
      "Epoch: 6784,     Training Loss: 0.3415290117263794, Training Acc: 76.84%\n",
      "              Val Loss: 1.0274326801300049, Val Acc: 67.64%\n",
      "Epoch: 6785,     Training Loss: 0.3328982889652252, Training Acc: 76.84%\n",
      "              Val Loss: 1.0008983612060547, Val Acc: 67.64%\n",
      "Epoch: 6786,     Training Loss: 0.3399050533771515, Training Acc: 76.84%\n",
      "              Val Loss: 1.0328863859176636, Val Acc: 67.64%\n",
      "Epoch: 6787,     Training Loss: 0.3298732042312622, Training Acc: 76.84%\n",
      "              Val Loss: 0.9958362579345703, Val Acc: 67.64%\n",
      "Epoch: 6788,     Training Loss: 0.3288635015487671, Training Acc: 76.84%\n",
      "              Val Loss: 1.0109537839889526, Val Acc: 67.64%\n",
      "Epoch: 6789,     Training Loss: 0.3186313509941101, Training Acc: 76.85%\n",
      "              Val Loss: 0.9923927187919617, Val Acc: 67.64%\n",
      "Epoch: 6790,     Training Loss: 0.3169609010219574, Training Acc: 76.85%\n",
      "              Val Loss: 1.002606987953186, Val Acc: 67.64%\n",
      "Epoch: 6791,     Training Loss: 0.31378355622291565, Training Acc: 76.85%\n",
      "              Val Loss: 0.9934223890304565, Val Acc: 67.64%\n",
      "Epoch: 6792,     Training Loss: 0.31179821491241455, Training Acc: 76.85%\n",
      "              Val Loss: 1.0073915719985962, Val Acc: 67.64%\n",
      "Epoch: 6793,     Training Loss: 0.31181544065475464, Training Acc: 76.85%\n",
      "              Val Loss: 1.0000168085098267, Val Acc: 67.64%\n",
      "Epoch: 6794,     Training Loss: 0.3113114833831787, Training Acc: 76.85%\n",
      "              Val Loss: 1.0103954076766968, Val Acc: 67.65%\n",
      "Epoch: 6795,     Training Loss: 0.311224102973938, Training Acc: 76.85%\n",
      "              Val Loss: 1.001032829284668, Val Acc: 67.65%\n",
      "Epoch: 6796,     Training Loss: 0.31509336829185486, Training Acc: 76.86%\n",
      "              Val Loss: 1.0250877141952515, Val Acc: 67.65%\n",
      "Epoch: 6797,     Training Loss: 0.32203036546707153, Training Acc: 76.86%\n",
      "              Val Loss: 1.0200190544128418, Val Acc: 67.65%\n",
      "Epoch: 6798,     Training Loss: 0.35115817189216614, Training Acc: 76.86%\n",
      "              Val Loss: 1.0881283283233643, Val Acc: 67.65%\n",
      "Epoch: 6799,     Training Loss: 0.3677029013633728, Training Acc: 76.86%\n",
      "              Val Loss: 1.0777992010116577, Val Acc: 67.65%\n",
      "Epoch: 6800,     Training Loss: 0.4343227744102478, Training Acc: 76.86%\n",
      "              Val Loss: 1.0452868938446045, Val Acc: 67.65%\n",
      "Epoch: 6801,     Training Loss: 0.34229937195777893, Training Acc: 76.86%\n",
      "              Val Loss: 0.9829801917076111, Val Acc: 67.65%\n",
      "Epoch: 6802,     Training Loss: 0.3140158951282501, Training Acc: 76.86%\n",
      "              Val Loss: 0.980568528175354, Val Acc: 67.65%\n",
      "Epoch: 6803,     Training Loss: 0.32672905921936035, Training Acc: 76.86%\n",
      "              Val Loss: 1.035750389099121, Val Acc: 67.65%\n",
      "Epoch: 6804,     Training Loss: 0.34416019916534424, Training Acc: 76.87%\n",
      "              Val Loss: 1.0153827667236328, Val Acc: 67.65%\n",
      "Epoch: 6805,     Training Loss: 0.3615075945854187, Training Acc: 76.87%\n",
      "              Val Loss: 1.011978268623352, Val Acc: 67.65%\n",
      "Epoch: 6806,     Training Loss: 0.32210981845855713, Training Acc: 76.87%\n",
      "              Val Loss: 1.0059376955032349, Val Acc: 67.65%\n",
      "Epoch: 6807,     Training Loss: 0.3157993257045746, Training Acc: 76.87%\n",
      "              Val Loss: 1.0065932273864746, Val Acc: 67.65%\n",
      "Epoch: 6808,     Training Loss: 0.3428637981414795, Training Acc: 76.87%\n",
      "              Val Loss: 1.0652555227279663, Val Acc: 67.66%\n",
      "Epoch: 6809,     Training Loss: 0.34856241941452026, Training Acc: 76.87%\n",
      "              Val Loss: 1.0307221412658691, Val Acc: 67.66%\n",
      "Epoch: 6810,     Training Loss: 0.36208686232566833, Training Acc: 76.87%\n",
      "              Val Loss: 1.0382676124572754, Val Acc: 67.66%\n",
      "Epoch: 6811,     Training Loss: 0.32725563645362854, Training Acc: 76.88%\n",
      "              Val Loss: 0.9983782172203064, Val Acc: 67.66%\n",
      "Epoch: 6812,     Training Loss: 0.31450411677360535, Training Acc: 76.88%\n",
      "              Val Loss: 1.0036922693252563, Val Acc: 67.66%\n",
      "Epoch: 6813,     Training Loss: 0.32546406984329224, Training Acc: 76.88%\n",
      "              Val Loss: 1.0523163080215454, Val Acc: 67.66%\n",
      "Epoch: 6814,     Training Loss: 0.33603087067604065, Training Acc: 76.88%\n",
      "              Val Loss: 1.0309598445892334, Val Acc: 67.66%\n",
      "Epoch: 6815,     Training Loss: 0.35942554473876953, Training Acc: 76.88%\n",
      "              Val Loss: 1.047663927078247, Val Acc: 67.66%\n",
      "Epoch: 6816,     Training Loss: 0.33654242753982544, Training Acc: 76.88%\n",
      "              Val Loss: 0.9916273355484009, Val Acc: 67.66%\n",
      "Epoch: 6817,     Training Loss: 0.32238444685935974, Training Acc: 76.88%\n",
      "              Val Loss: 1.0029845237731934, Val Acc: 67.66%\n",
      "Epoch: 6818,     Training Loss: 0.3250840902328491, Training Acc: 76.89%\n",
      "              Val Loss: 1.008609414100647, Val Acc: 67.66%\n",
      "Epoch: 6819,     Training Loss: 0.313208669424057, Training Acc: 76.89%\n",
      "              Val Loss: 1.028387188911438, Val Acc: 67.66%\n",
      "Epoch: 6820,     Training Loss: 0.31834566593170166, Training Acc: 76.89%\n",
      "              Val Loss: 1.0061793327331543, Val Acc: 67.66%\n",
      "Epoch: 6821,     Training Loss: 0.31547561287879944, Training Acc: 76.89%\n",
      "              Val Loss: 1.004693627357483, Val Acc: 67.67%\n",
      "Epoch: 6822,     Training Loss: 0.31227147579193115, Training Acc: 76.89%\n",
      "              Val Loss: 1.010300874710083, Val Acc: 67.67%\n",
      "Epoch: 6823,     Training Loss: 0.3124724328517914, Training Acc: 76.89%\n",
      "              Val Loss: 1.0152981281280518, Val Acc: 67.67%\n",
      "Epoch: 6824,     Training Loss: 0.31280022859573364, Training Acc: 76.89%\n",
      "              Val Loss: 1.0274702310562134, Val Acc: 67.67%\n",
      "Epoch: 6825,     Training Loss: 0.31297123432159424, Training Acc: 76.90%\n",
      "              Val Loss: 1.001283049583435, Val Acc: 67.67%\n",
      "Epoch: 6826,     Training Loss: 0.31668975949287415, Training Acc: 76.90%\n",
      "              Val Loss: 1.0382031202316284, Val Acc: 67.67%\n",
      "Epoch: 6827,     Training Loss: 0.3347890377044678, Training Acc: 76.90%\n",
      "              Val Loss: 1.0511926412582397, Val Acc: 67.67%\n",
      "Epoch: 6828,     Training Loss: 0.37816596031188965, Training Acc: 76.90%\n",
      "              Val Loss: 1.0948833227157593, Val Acc: 67.67%\n",
      "Epoch: 6829,     Training Loss: 0.36502426862716675, Training Acc: 76.90%\n",
      "              Val Loss: 1.0429027080535889, Val Acc: 67.67%\n",
      "Epoch: 6830,     Training Loss: 0.38703304529190063, Training Acc: 76.90%\n",
      "              Val Loss: 1.0277628898620605, Val Acc: 67.67%\n",
      "Epoch: 6831,     Training Loss: 0.32921767234802246, Training Acc: 76.90%\n",
      "              Val Loss: 1.000430703163147, Val Acc: 67.67%\n",
      "Epoch: 6832,     Training Loss: 0.31413203477859497, Training Acc: 76.91%\n",
      "              Val Loss: 0.9994776248931885, Val Acc: 67.67%\n",
      "Epoch: 6833,     Training Loss: 0.3253397047519684, Training Acc: 76.91%\n",
      "              Val Loss: 1.0548349618911743, Val Acc: 67.67%\n",
      "Epoch: 6834,     Training Loss: 0.3360649049282074, Training Acc: 76.91%\n",
      "              Val Loss: 1.0232677459716797, Val Acc: 67.67%\n",
      "Epoch: 6835,     Training Loss: 0.3454244136810303, Training Acc: 76.91%\n",
      "              Val Loss: 1.0427935123443604, Val Acc: 67.68%\n",
      "Epoch: 6836,     Training Loss: 0.33427292108535767, Training Acc: 76.91%\n",
      "              Val Loss: 1.0241494178771973, Val Acc: 67.68%\n",
      "Epoch: 6837,     Training Loss: 0.34363070130348206, Training Acc: 76.91%\n",
      "              Val Loss: 1.0248239040374756, Val Acc: 67.68%\n",
      "Epoch: 6838,     Training Loss: 0.3117996156215668, Training Acc: 76.91%\n",
      "              Val Loss: 1.0399922132492065, Val Acc: 67.68%\n",
      "Epoch: 6839,     Training Loss: 0.3190189003944397, Training Acc: 76.92%\n",
      "              Val Loss: 1.0286803245544434, Val Acc: 67.68%\n",
      "Epoch: 6840,     Training Loss: 0.3312877416610718, Training Acc: 76.92%\n",
      "              Val Loss: 1.0581494569778442, Val Acc: 67.68%\n",
      "Epoch: 6841,     Training Loss: 0.33687740564346313, Training Acc: 76.92%\n",
      "              Val Loss: 1.0386682748794556, Val Acc: 67.68%\n",
      "Epoch: 6842,     Training Loss: 0.35295018553733826, Training Acc: 76.92%\n",
      "              Val Loss: 1.0528159141540527, Val Acc: 67.68%\n",
      "Epoch: 6843,     Training Loss: 0.32887592911720276, Training Acc: 76.92%\n",
      "              Val Loss: 1.008771538734436, Val Acc: 67.68%\n",
      "Epoch: 6844,     Training Loss: 0.332691490650177, Training Acc: 76.92%\n",
      "              Val Loss: 1.0259006023406982, Val Acc: 67.68%\n",
      "Epoch: 6845,     Training Loss: 0.32228460907936096, Training Acc: 76.92%\n",
      "              Val Loss: 1.0213111639022827, Val Acc: 67.68%\n",
      "Epoch: 6846,     Training Loss: 0.3245566189289093, Training Acc: 76.92%\n",
      "              Val Loss: 1.0506113767623901, Val Acc: 67.68%\n",
      "Epoch: 6847,     Training Loss: 0.33004191517829895, Training Acc: 76.93%\n",
      "              Val Loss: 1.018056035041809, Val Acc: 67.68%\n",
      "Epoch: 6848,     Training Loss: 0.3229737877845764, Training Acc: 76.93%\n",
      "              Val Loss: 1.0509979724884033, Val Acc: 67.68%\n",
      "Epoch: 6849,     Training Loss: 0.32571831345558167, Training Acc: 76.93%\n",
      "              Val Loss: 1.0102037191390991, Val Acc: 67.69%\n",
      "Epoch: 6850,     Training Loss: 0.32910922169685364, Training Acc: 76.93%\n",
      "              Val Loss: 1.0483397245407104, Val Acc: 67.69%\n",
      "Epoch: 6851,     Training Loss: 0.3230556547641754, Training Acc: 76.93%\n",
      "              Val Loss: 1.0390405654907227, Val Acc: 67.69%\n",
      "Epoch: 6852,     Training Loss: 0.33443641662597656, Training Acc: 76.93%\n",
      "              Val Loss: 1.0429610013961792, Val Acc: 67.69%\n",
      "Epoch: 6853,     Training Loss: 0.31822818517684937, Training Acc: 76.93%\n",
      "              Val Loss: 1.0076961517333984, Val Acc: 67.69%\n",
      "Epoch: 6854,     Training Loss: 0.32220613956451416, Training Acc: 76.94%\n",
      "              Val Loss: 1.023410439491272, Val Acc: 67.69%\n",
      "Epoch: 6855,     Training Loss: 0.31680426001548767, Training Acc: 76.94%\n",
      "              Val Loss: 1.010727047920227, Val Acc: 67.69%\n",
      "Epoch: 6856,     Training Loss: 0.3157350420951843, Training Acc: 76.94%\n",
      "              Val Loss: 1.0612637996673584, Val Acc: 67.69%\n",
      "Epoch: 6857,     Training Loss: 0.32735252380371094, Training Acc: 76.94%\n",
      "              Val Loss: 1.0364611148834229, Val Acc: 67.69%\n",
      "Epoch: 6858,     Training Loss: 0.3312542736530304, Training Acc: 76.94%\n",
      "              Val Loss: 1.0684515237808228, Val Acc: 67.69%\n",
      "Epoch: 6859,     Training Loss: 0.33338528871536255, Training Acc: 76.94%\n",
      "              Val Loss: 1.0213022232055664, Val Acc: 67.69%\n",
      "Epoch: 6860,     Training Loss: 0.3429487347602844, Training Acc: 76.94%\n",
      "              Val Loss: 1.061713457107544, Val Acc: 67.69%\n",
      "Epoch: 6861,     Training Loss: 0.33473914861679077, Training Acc: 76.95%\n",
      "              Val Loss: 1.043603777885437, Val Acc: 67.69%\n",
      "Epoch: 6862,     Training Loss: 0.33482781052589417, Training Acc: 76.95%\n",
      "              Val Loss: 1.0420960187911987, Val Acc: 67.69%\n",
      "Epoch: 6863,     Training Loss: 0.31266602873802185, Training Acc: 76.95%\n",
      "              Val Loss: 1.0286855697631836, Val Acc: 67.70%\n",
      "Epoch: 6864,     Training Loss: 0.3249683678150177, Training Acc: 76.95%\n",
      "              Val Loss: 1.034071922302246, Val Acc: 67.70%\n",
      "Epoch: 6865,     Training Loss: 0.3139553666114807, Training Acc: 76.95%\n",
      "              Val Loss: 1.029913067817688, Val Acc: 67.70%\n",
      "Epoch: 6866,     Training Loss: 0.3190980553627014, Training Acc: 76.95%\n",
      "              Val Loss: 1.0688663721084595, Val Acc: 67.70%\n",
      "Epoch: 6867,     Training Loss: 0.3279553949832916, Training Acc: 76.95%\n",
      "              Val Loss: 1.0394264459609985, Val Acc: 67.70%\n",
      "Epoch: 6868,     Training Loss: 0.333609938621521, Training Acc: 76.96%\n",
      "              Val Loss: 1.0912504196166992, Val Acc: 67.70%\n",
      "Epoch: 6869,     Training Loss: 0.3455512523651123, Training Acc: 76.96%\n",
      "              Val Loss: 1.0343941450119019, Val Acc: 67.70%\n",
      "Epoch: 6870,     Training Loss: 0.36266669631004333, Training Acc: 76.96%\n",
      "              Val Loss: 1.078007698059082, Val Acc: 67.70%\n",
      "Epoch: 6871,     Training Loss: 0.35545429587364197, Training Acc: 76.96%\n",
      "              Val Loss: 1.0717780590057373, Val Acc: 67.70%\n",
      "Epoch: 6872,     Training Loss: 0.352001428604126, Training Acc: 76.96%\n",
      "              Val Loss: 1.0538594722747803, Val Acc: 67.70%\n",
      "Epoch: 6873,     Training Loss: 0.31640055775642395, Training Acc: 76.96%\n",
      "              Val Loss: 1.051164984703064, Val Acc: 67.70%\n",
      "Epoch: 6874,     Training Loss: 0.33945462107658386, Training Acc: 76.96%\n",
      "              Val Loss: 1.018072485923767, Val Acc: 67.70%\n",
      "Epoch: 6875,     Training Loss: 0.3097972273826599, Training Acc: 76.96%\n",
      "              Val Loss: 1.0715513229370117, Val Acc: 67.70%\n",
      "Epoch: 6876,     Training Loss: 0.34320273995399475, Training Acc: 76.97%\n",
      "              Val Loss: 1.0369199514389038, Val Acc: 67.70%\n",
      "Epoch: 6877,     Training Loss: 0.3373914957046509, Training Acc: 76.97%\n",
      "              Val Loss: 1.075849175453186, Val Acc: 67.70%\n",
      "Epoch: 6878,     Training Loss: 0.3379008173942566, Training Acc: 76.97%\n",
      "              Val Loss: 1.066025733947754, Val Acc: 67.70%\n",
      "Epoch: 6879,     Training Loss: 0.34688064455986023, Training Acc: 76.97%\n",
      "              Val Loss: 1.0422307252883911, Val Acc: 67.71%\n",
      "Epoch: 6880,     Training Loss: 0.31628644466400146, Training Acc: 76.97%\n",
      "              Val Loss: 1.0220614671707153, Val Acc: 67.71%\n",
      "Epoch: 6881,     Training Loss: 0.3302725553512573, Training Acc: 76.97%\n",
      "              Val Loss: 1.0149418115615845, Val Acc: 67.71%\n",
      "Epoch: 6882,     Training Loss: 0.305110901594162, Training Acc: 76.97%\n",
      "              Val Loss: 1.0725995302200317, Val Acc: 67.71%\n",
      "Epoch: 6883,     Training Loss: 0.3306768536567688, Training Acc: 76.98%\n",
      "              Val Loss: 1.0667915344238281, Val Acc: 67.71%\n",
      "Epoch: 6884,     Training Loss: 0.36752575635910034, Training Acc: 76.98%\n",
      "              Val Loss: 1.1343799829483032, Val Acc: 67.71%\n",
      "Epoch: 6885,     Training Loss: 0.3795660734176636, Training Acc: 76.98%\n",
      "              Val Loss: 1.1326112747192383, Val Acc: 67.71%\n",
      "Epoch: 6886,     Training Loss: 0.4383378326892853, Training Acc: 76.98%\n",
      "              Val Loss: 1.0960719585418701, Val Acc: 67.71%\n",
      "Epoch: 6887,     Training Loss: 0.34858980774879456, Training Acc: 76.98%\n",
      "              Val Loss: 1.0494818687438965, Val Acc: 67.71%\n",
      "Epoch: 6888,     Training Loss: 0.3503356873989105, Training Acc: 76.98%\n",
      "              Val Loss: 1.021978735923767, Val Acc: 67.71%\n",
      "Epoch: 6889,     Training Loss: 0.33626529574394226, Training Acc: 76.98%\n",
      "              Val Loss: 1.0687774419784546, Val Acc: 67.71%\n",
      "Epoch: 6890,     Training Loss: 0.3508128225803375, Training Acc: 76.98%\n",
      "              Val Loss: 1.0370320081710815, Val Acc: 67.71%\n",
      "Epoch: 6891,     Training Loss: 0.3464735746383667, Training Acc: 76.98%\n",
      "              Val Loss: 1.1115549802780151, Val Acc: 67.71%\n",
      "Epoch: 6892,     Training Loss: 0.38427871465682983, Training Acc: 76.99%\n",
      "              Val Loss: 1.0364372730255127, Val Acc: 67.71%\n",
      "Epoch: 6893,     Training Loss: 0.3281412124633789, Training Acc: 76.99%\n",
      "              Val Loss: 1.0763578414916992, Val Acc: 67.71%\n",
      "Epoch: 6894,     Training Loss: 0.34955790638923645, Training Acc: 76.99%\n",
      "              Val Loss: 1.0013768672943115, Val Acc: 67.71%\n",
      "Epoch: 6895,     Training Loss: 0.32480257749557495, Training Acc: 76.99%\n",
      "              Val Loss: 1.0163688659667969, Val Acc: 67.72%\n",
      "Epoch: 6896,     Training Loss: 0.32918021082878113, Training Acc: 76.99%\n",
      "              Val Loss: 1.0930895805358887, Val Acc: 67.72%\n",
      "Epoch: 6897,     Training Loss: 0.34806355834007263, Training Acc: 76.99%\n",
      "              Val Loss: 1.0367634296417236, Val Acc: 67.72%\n",
      "Epoch: 6898,     Training Loss: 0.3341955840587616, Training Acc: 76.99%\n",
      "              Val Loss: 1.1362628936767578, Val Acc: 67.72%\n",
      "Epoch: 6899,     Training Loss: 0.3807024359703064, Training Acc: 76.99%\n",
      "              Val Loss: 1.096419334411621, Val Acc: 67.72%\n",
      "Epoch: 6900,     Training Loss: 0.40073922276496887, Training Acc: 77.00%\n",
      "              Val Loss: 1.100624918937683, Val Acc: 67.72%\n",
      "Epoch: 6901,     Training Loss: 0.3728273808956146, Training Acc: 77.00%\n",
      "              Val Loss: 1.015295386314392, Val Acc: 67.72%\n",
      "Epoch: 6902,     Training Loss: 0.3510667681694031, Training Acc: 77.00%\n",
      "              Val Loss: 1.0295050144195557, Val Acc: 67.72%\n",
      "Epoch: 6903,     Training Loss: 0.336810827255249, Training Acc: 77.00%\n",
      "              Val Loss: 1.0431263446807861, Val Acc: 67.72%\n",
      "Epoch: 6904,     Training Loss: 0.32706713676452637, Training Acc: 77.00%\n",
      "              Val Loss: 1.0707345008850098, Val Acc: 67.72%\n",
      "Epoch: 6905,     Training Loss: 0.3282116949558258, Training Acc: 77.00%\n",
      "              Val Loss: 1.099225401878357, Val Acc: 67.72%\n",
      "Epoch: 6906,     Training Loss: 0.34928470849990845, Training Acc: 77.00%\n",
      "              Val Loss: 1.0355215072631836, Val Acc: 67.72%\n",
      "Epoch: 6907,     Training Loss: 0.33753398060798645, Training Acc: 77.00%\n",
      "              Val Loss: 1.0948413610458374, Val Acc: 67.72%\n",
      "Epoch: 6908,     Training Loss: 0.3511413335800171, Training Acc: 77.01%\n",
      "              Val Loss: 1.0358455181121826, Val Acc: 67.72%\n",
      "Epoch: 6909,     Training Loss: 0.3424372971057892, Training Acc: 77.01%\n",
      "              Val Loss: 1.0730715990066528, Val Acc: 67.72%\n",
      "Epoch: 6910,     Training Loss: 0.3412487506866455, Training Acc: 77.01%\n",
      "              Val Loss: 1.070400357246399, Val Acc: 67.72%\n",
      "Epoch: 6911,     Training Loss: 0.3202701807022095, Training Acc: 77.01%\n",
      "              Val Loss: 1.0650485754013062, Val Acc: 67.73%\n",
      "Epoch: 6912,     Training Loss: 0.31682032346725464, Training Acc: 77.01%\n",
      "              Val Loss: 1.055194616317749, Val Acc: 67.73%\n",
      "Epoch: 6913,     Training Loss: 0.32559651136398315, Training Acc: 77.01%\n",
      "              Val Loss: 1.0480459928512573, Val Acc: 67.73%\n",
      "Epoch: 6914,     Training Loss: 0.3437008261680603, Training Acc: 77.01%\n",
      "              Val Loss: 1.0929272174835205, Val Acc: 67.73%\n",
      "Epoch: 6915,     Training Loss: 0.33733975887298584, Training Acc: 77.01%\n",
      "              Val Loss: 1.0622793436050415, Val Acc: 67.73%\n",
      "Epoch: 6916,     Training Loss: 0.35464248061180115, Training Acc: 77.02%\n",
      "              Val Loss: 1.100124716758728, Val Acc: 67.73%\n",
      "Epoch: 6917,     Training Loss: 0.3381907641887665, Training Acc: 77.02%\n",
      "              Val Loss: 1.0349960327148438, Val Acc: 67.73%\n",
      "Epoch: 6918,     Training Loss: 0.32062289118766785, Training Acc: 77.02%\n",
      "              Val Loss: 1.0405678749084473, Val Acc: 67.73%\n",
      "Epoch: 6919,     Training Loss: 0.3072250485420227, Training Acc: 77.02%\n",
      "              Val Loss: 1.0371135473251343, Val Acc: 67.73%\n",
      "Epoch: 6920,     Training Loss: 0.30789878964424133, Training Acc: 77.02%\n",
      "              Val Loss: 1.0446515083312988, Val Acc: 67.73%\n",
      "Epoch: 6921,     Training Loss: 0.30703601241111755, Training Acc: 77.02%\n",
      "              Val Loss: 1.0600179433822632, Val Acc: 67.73%\n",
      "Epoch: 6922,     Training Loss: 0.30277833342552185, Training Acc: 77.03%\n",
      "              Val Loss: 1.0499836206436157, Val Acc: 67.73%\n",
      "Epoch: 6923,     Training Loss: 0.3065101206302643, Training Acc: 77.03%\n",
      "              Val Loss: 1.081183910369873, Val Acc: 67.73%\n",
      "Epoch: 6924,     Training Loss: 0.3204444944858551, Training Acc: 77.03%\n",
      "              Val Loss: 1.0809589624404907, Val Acc: 67.73%\n",
      "Epoch: 6925,     Training Loss: 0.345191091299057, Training Acc: 77.03%\n",
      "              Val Loss: 1.1318901777267456, Val Acc: 67.73%\n",
      "Epoch: 6926,     Training Loss: 0.34664443135261536, Training Acc: 77.03%\n",
      "              Val Loss: 1.0868525505065918, Val Acc: 67.74%\n",
      "Epoch: 6927,     Training Loss: 0.38739439845085144, Training Acc: 77.03%\n",
      "              Val Loss: 1.1100903749465942, Val Acc: 67.74%\n",
      "Epoch: 6928,     Training Loss: 0.34515923261642456, Training Acc: 77.03%\n",
      "              Val Loss: 1.0351872444152832, Val Acc: 67.74%\n",
      "Epoch: 6929,     Training Loss: 0.3229005038738251, Training Acc: 77.03%\n",
      "              Val Loss: 1.0447784662246704, Val Acc: 67.74%\n",
      "Epoch: 6930,     Training Loss: 0.30916059017181396, Training Acc: 77.04%\n",
      "              Val Loss: 1.0473885536193848, Val Acc: 67.74%\n",
      "Epoch: 6931,     Training Loss: 0.3037305176258087, Training Acc: 77.04%\n",
      "              Val Loss: 1.0357413291931152, Val Acc: 67.74%\n",
      "Epoch: 6932,     Training Loss: 0.31040894985198975, Training Acc: 77.04%\n",
      "              Val Loss: 1.0719584226608276, Val Acc: 67.74%\n",
      "Epoch: 6933,     Training Loss: 0.32274964451789856, Training Acc: 77.04%\n",
      "              Val Loss: 1.079193115234375, Val Acc: 67.74%\n",
      "Epoch: 6934,     Training Loss: 0.36037272214889526, Training Acc: 77.04%\n",
      "              Val Loss: 1.1026885509490967, Val Acc: 67.74%\n",
      "Epoch: 6935,     Training Loss: 0.3332173824310303, Training Acc: 77.04%\n",
      "              Val Loss: 1.0407795906066895, Val Acc: 67.74%\n",
      "Epoch: 6936,     Training Loss: 0.31707602739334106, Training Acc: 77.04%\n",
      "              Val Loss: 1.0725480318069458, Val Acc: 67.74%\n",
      "Epoch: 6937,     Training Loss: 0.31436029076576233, Training Acc: 77.05%\n",
      "              Val Loss: 1.0406402349472046, Val Acc: 67.74%\n",
      "Epoch: 6938,     Training Loss: 0.3082025647163391, Training Acc: 77.05%\n",
      "              Val Loss: 1.0539305210113525, Val Acc: 67.74%\n",
      "Epoch: 6939,     Training Loss: 0.30029696226119995, Training Acc: 77.05%\n",
      "              Val Loss: 1.0324879884719849, Val Acc: 67.74%\n",
      "Epoch: 6940,     Training Loss: 0.2992612421512604, Training Acc: 77.05%\n",
      "              Val Loss: 1.0351948738098145, Val Acc: 67.75%\n",
      "Epoch: 6941,     Training Loss: 0.30081337690353394, Training Acc: 77.05%\n",
      "              Val Loss: 1.0345070362091064, Val Acc: 67.75%\n",
      "Epoch: 6942,     Training Loss: 0.3022152781486511, Training Acc: 77.05%\n",
      "              Val Loss: 1.0502204895019531, Val Acc: 67.75%\n",
      "Epoch: 6943,     Training Loss: 0.3005741536617279, Training Acc: 77.05%\n",
      "              Val Loss: 1.042762279510498, Val Acc: 67.75%\n",
      "Epoch: 6944,     Training Loss: 0.3090183734893799, Training Acc: 77.06%\n",
      "              Val Loss: 1.0822159051895142, Val Acc: 67.75%\n",
      "Epoch: 6945,     Training Loss: 0.3152572512626648, Training Acc: 77.06%\n",
      "              Val Loss: 1.049015760421753, Val Acc: 67.75%\n",
      "Epoch: 6946,     Training Loss: 0.3410937488079071, Training Acc: 77.06%\n",
      "              Val Loss: 1.1118627786636353, Val Acc: 67.75%\n",
      "Epoch: 6947,     Training Loss: 0.3437078893184662, Training Acc: 77.06%\n",
      "              Val Loss: 1.0901323556900024, Val Acc: 67.75%\n",
      "Epoch: 6948,     Training Loss: 0.38023361563682556, Training Acc: 77.06%\n",
      "              Val Loss: 1.0959352254867554, Val Acc: 67.75%\n",
      "Epoch: 6949,     Training Loss: 0.3300139307975769, Training Acc: 77.06%\n",
      "              Val Loss: 1.026146411895752, Val Acc: 67.75%\n",
      "Epoch: 6950,     Training Loss: 0.3058162033557892, Training Acc: 77.06%\n",
      "              Val Loss: 1.0356096029281616, Val Acc: 67.75%\n",
      "Epoch: 6951,     Training Loss: 0.30313530564308167, Training Acc: 77.07%\n",
      "              Val Loss: 1.0670976638793945, Val Acc: 67.75%\n",
      "Epoch: 6952,     Training Loss: 0.3139660656452179, Training Acc: 77.07%\n",
      "              Val Loss: 1.0664371252059937, Val Acc: 67.75%\n",
      "Epoch: 6953,     Training Loss: 0.3476901948451996, Training Acc: 77.07%\n",
      "              Val Loss: 1.1278502941131592, Val Acc: 67.75%\n",
      "Epoch: 6954,     Training Loss: 0.3440338969230652, Training Acc: 77.07%\n",
      "              Val Loss: 1.0583312511444092, Val Acc: 67.75%\n",
      "Epoch: 6955,     Training Loss: 0.33822718262672424, Training Acc: 77.07%\n",
      "              Val Loss: 1.0928322076797485, Val Acc: 67.75%\n",
      "Epoch: 6956,     Training Loss: 0.33024880290031433, Training Acc: 77.07%\n",
      "              Val Loss: 1.0420881509780884, Val Acc: 67.76%\n",
      "Epoch: 6957,     Training Loss: 0.3204297125339508, Training Acc: 77.07%\n",
      "              Val Loss: 1.0696368217468262, Val Acc: 67.76%\n",
      "Epoch: 6958,     Training Loss: 0.3121345639228821, Training Acc: 77.07%\n",
      "              Val Loss: 1.0532739162445068, Val Acc: 67.76%\n",
      "Epoch: 6959,     Training Loss: 0.301344096660614, Training Acc: 77.08%\n",
      "              Val Loss: 1.0406272411346436, Val Acc: 67.76%\n",
      "Epoch: 6960,     Training Loss: 0.2967214584350586, Training Acc: 77.08%\n",
      "              Val Loss: 1.0523123741149902, Val Acc: 67.76%\n",
      "Epoch: 6961,     Training Loss: 0.3007945418357849, Training Acc: 77.08%\n",
      "              Val Loss: 1.065940022468567, Val Acc: 67.76%\n",
      "Epoch: 6962,     Training Loss: 0.3068441152572632, Training Acc: 77.08%\n",
      "              Val Loss: 1.0878888368606567, Val Acc: 67.76%\n",
      "Epoch: 6963,     Training Loss: 0.3107089698314667, Training Acc: 77.08%\n",
      "              Val Loss: 1.0602083206176758, Val Acc: 67.76%\n",
      "Epoch: 6964,     Training Loss: 0.324894517660141, Training Acc: 77.08%\n",
      "              Val Loss: 1.1358914375305176, Val Acc: 67.76%\n",
      "Epoch: 6965,     Training Loss: 0.346437007188797, Training Acc: 77.09%\n",
      "              Val Loss: 1.1059656143188477, Val Acc: 67.76%\n",
      "Epoch: 6966,     Training Loss: 0.3939843773841858, Training Acc: 77.09%\n",
      "              Val Loss: 1.1416290998458862, Val Acc: 67.76%\n",
      "Epoch: 6967,     Training Loss: 0.3513645827770233, Training Acc: 77.09%\n",
      "              Val Loss: 1.0801621675491333, Val Acc: 67.76%\n",
      "Epoch: 6968,     Training Loss: 0.3301752507686615, Training Acc: 77.09%\n",
      "              Val Loss: 1.0442944765090942, Val Acc: 67.76%\n",
      "Epoch: 6969,     Training Loss: 0.2996208667755127, Training Acc: 77.09%\n",
      "              Val Loss: 1.0681941509246826, Val Acc: 67.76%\n",
      "Epoch: 6970,     Training Loss: 0.31733453273773193, Training Acc: 77.09%\n",
      "              Val Loss: 1.0772265195846558, Val Acc: 67.76%\n",
      "Epoch: 6971,     Training Loss: 0.34508803486824036, Training Acc: 77.09%\n",
      "              Val Loss: 1.106407642364502, Val Acc: 67.77%\n",
      "Epoch: 6972,     Training Loss: 0.3317781388759613, Training Acc: 77.09%\n",
      "              Val Loss: 1.0497217178344727, Val Acc: 67.77%\n",
      "Epoch: 6973,     Training Loss: 0.32014352083206177, Training Acc: 77.10%\n",
      "              Val Loss: 1.0559296607971191, Val Acc: 67.77%\n",
      "Epoch: 6974,     Training Loss: 0.30341702699661255, Training Acc: 77.10%\n",
      "              Val Loss: 1.074052095413208, Val Acc: 67.77%\n",
      "Epoch: 6975,     Training Loss: 0.30509817600250244, Training Acc: 77.10%\n",
      "              Val Loss: 1.0748264789581299, Val Acc: 67.77%\n",
      "Epoch: 6976,     Training Loss: 0.31340229511260986, Training Acc: 77.10%\n",
      "              Val Loss: 1.1172897815704346, Val Acc: 67.77%\n",
      "Epoch: 6977,     Training Loss: 0.31782829761505127, Training Acc: 77.10%\n",
      "              Val Loss: 1.0799168348312378, Val Acc: 67.77%\n",
      "Epoch: 6978,     Training Loss: 0.3222423195838928, Training Acc: 77.10%\n",
      "              Val Loss: 1.1176825761795044, Val Acc: 67.77%\n",
      "Epoch: 6979,     Training Loss: 0.32449984550476074, Training Acc: 77.10%\n",
      "              Val Loss: 1.0620020627975464, Val Acc: 67.77%\n",
      "Epoch: 6980,     Training Loss: 0.3245151937007904, Training Acc: 77.11%\n",
      "              Val Loss: 1.0996568202972412, Val Acc: 67.77%\n",
      "Epoch: 6981,     Training Loss: 0.3150482475757599, Training Acc: 77.11%\n",
      "              Val Loss: 1.059205412864685, Val Acc: 67.77%\n",
      "Epoch: 6982,     Training Loss: 0.3113914728164673, Training Acc: 77.11%\n",
      "              Val Loss: 1.0625311136245728, Val Acc: 67.77%\n",
      "Epoch: 6983,     Training Loss: 0.30408617854118347, Training Acc: 77.11%\n",
      "              Val Loss: 1.0564688444137573, Val Acc: 67.77%\n",
      "Epoch: 6984,     Training Loss: 0.29595956206321716, Training Acc: 77.11%\n",
      "              Val Loss: 1.0643788576126099, Val Acc: 67.77%\n",
      "Epoch: 6985,     Training Loss: 0.2907860279083252, Training Acc: 77.11%\n",
      "              Val Loss: 1.0676764249801636, Val Acc: 67.78%\n",
      "Epoch: 6986,     Training Loss: 0.29473623633384705, Training Acc: 77.11%\n",
      "              Val Loss: 1.0769211053848267, Val Acc: 67.78%\n",
      "Epoch: 6987,     Training Loss: 0.2938762903213501, Training Acc: 77.12%\n",
      "              Val Loss: 1.085363745689392, Val Acc: 67.78%\n",
      "Epoch: 6988,     Training Loss: 0.29411137104034424, Training Acc: 77.12%\n",
      "              Val Loss: 1.0797303915023804, Val Acc: 67.78%\n",
      "Epoch: 6989,     Training Loss: 0.2989901304244995, Training Acc: 77.12%\n",
      "              Val Loss: 1.1138567924499512, Val Acc: 67.78%\n",
      "Epoch: 6990,     Training Loss: 0.3069489002227783, Training Acc: 77.12%\n",
      "              Val Loss: 1.0877453088760376, Val Acc: 67.78%\n",
      "Epoch: 6991,     Training Loss: 0.33899345993995667, Training Acc: 77.12%\n",
      "              Val Loss: 1.1424235105514526, Val Acc: 67.78%\n",
      "Epoch: 6992,     Training Loss: 0.3450980484485626, Training Acc: 77.12%\n",
      "              Val Loss: 1.1101272106170654, Val Acc: 67.78%\n",
      "Epoch: 6993,     Training Loss: 0.38460490107536316, Training Acc: 77.12%\n",
      "              Val Loss: 1.1062148809432983, Val Acc: 67.78%\n",
      "Epoch: 6994,     Training Loss: 0.3275570273399353, Training Acc: 77.13%\n",
      "              Val Loss: 1.0443110466003418, Val Acc: 67.78%\n",
      "Epoch: 6995,     Training Loss: 0.30724430084228516, Training Acc: 77.13%\n",
      "              Val Loss: 1.0471590757369995, Val Acc: 67.78%\n",
      "Epoch: 6996,     Training Loss: 0.2957574725151062, Training Acc: 77.13%\n",
      "              Val Loss: 1.094078779220581, Val Acc: 67.78%\n",
      "Epoch: 6997,     Training Loss: 0.3119751513004303, Training Acc: 77.13%\n",
      "              Val Loss: 1.1047176122665405, Val Acc: 67.78%\n",
      "Epoch: 6998,     Training Loss: 0.3602580726146698, Training Acc: 77.13%\n",
      "              Val Loss: 1.150844693183899, Val Acc: 67.78%\n",
      "Epoch: 6999,     Training Loss: 0.33844050765037537, Training Acc: 77.13%\n",
      "              Val Loss: 1.0863076448440552, Val Acc: 67.78%\n",
      "Epoch: 7000,     Training Loss: 0.33149537444114685, Training Acc: 77.13%\n",
      "              Val Loss: 1.0987327098846436, Val Acc: 67.79%\n",
      "Epoch: 7001,     Training Loss: 0.31181544065475464, Training Acc: 77.13%\n",
      "              Val Loss: 1.059097409248352, Val Acc: 67.79%\n",
      "Epoch: 7002,     Training Loss: 0.2970356047153473, Training Acc: 77.14%\n",
      "              Val Loss: 1.0871880054473877, Val Acc: 67.79%\n",
      "Epoch: 7003,     Training Loss: 0.29445794224739075, Training Acc: 77.14%\n",
      "              Val Loss: 1.0806756019592285, Val Acc: 67.79%\n",
      "Epoch: 7004,     Training Loss: 0.2896744906902313, Training Acc: 77.14%\n",
      "              Val Loss: 1.0674313306808472, Val Acc: 67.79%\n",
      "Epoch: 7005,     Training Loss: 0.29367491602897644, Training Acc: 77.14%\n",
      "              Val Loss: 1.090641975402832, Val Acc: 67.79%\n",
      "Epoch: 7006,     Training Loss: 0.2964516282081604, Training Acc: 77.14%\n",
      "              Val Loss: 1.076436996459961, Val Acc: 67.79%\n",
      "Epoch: 7007,     Training Loss: 0.2985321581363678, Training Acc: 77.14%\n",
      "              Val Loss: 1.120185136795044, Val Acc: 67.79%\n",
      "Epoch: 7008,     Training Loss: 0.3120897710323334, Training Acc: 77.15%\n",
      "              Val Loss: 1.095859169960022, Val Acc: 67.79%\n",
      "Epoch: 7009,     Training Loss: 0.33685874938964844, Training Acc: 77.15%\n",
      "              Val Loss: 1.1404314041137695, Val Acc: 67.79%\n",
      "Epoch: 7010,     Training Loss: 0.3317362666130066, Training Acc: 77.15%\n",
      "              Val Loss: 1.100358486175537, Val Acc: 67.79%\n",
      "Epoch: 7011,     Training Loss: 0.3610205054283142, Training Acc: 77.15%\n",
      "              Val Loss: 1.1347196102142334, Val Acc: 67.79%\n",
      "Epoch: 7012,     Training Loss: 0.32533371448516846, Training Acc: 77.15%\n",
      "              Val Loss: 1.0751726627349854, Val Acc: 67.79%\n",
      "Epoch: 7013,     Training Loss: 0.31652265787124634, Training Acc: 77.15%\n",
      "              Val Loss: 1.0733588933944702, Val Acc: 67.79%\n",
      "Epoch: 7014,     Training Loss: 0.294620543718338, Training Acc: 77.15%\n",
      "              Val Loss: 1.0714774131774902, Val Acc: 67.80%\n",
      "Epoch: 7015,     Training Loss: 0.29021939635276794, Training Acc: 77.15%\n",
      "              Val Loss: 1.0752302408218384, Val Acc: 67.80%\n",
      "Epoch: 7016,     Training Loss: 0.30404114723205566, Training Acc: 77.16%\n",
      "              Val Loss: 1.1158920526504517, Val Acc: 67.80%\n",
      "Epoch: 7017,     Training Loss: 0.31052327156066895, Training Acc: 77.16%\n",
      "              Val Loss: 1.0781166553497314, Val Acc: 67.80%\n",
      "Epoch: 7018,     Training Loss: 0.32178592681884766, Training Acc: 77.16%\n",
      "              Val Loss: 1.126895546913147, Val Acc: 67.80%\n",
      "Epoch: 7019,     Training Loss: 0.3240077495574951, Training Acc: 77.16%\n",
      "              Val Loss: 1.1138206720352173, Val Acc: 67.80%\n",
      "Epoch: 7020,     Training Loss: 0.35949552059173584, Training Acc: 77.16%\n",
      "              Val Loss: 1.1167415380477905, Val Acc: 67.80%\n",
      "Epoch: 7021,     Training Loss: 0.3134719729423523, Training Acc: 77.16%\n",
      "              Val Loss: 1.0877578258514404, Val Acc: 67.80%\n",
      "Epoch: 7022,     Training Loss: 0.29832762479782104, Training Acc: 77.16%\n",
      "              Val Loss: 1.0780577659606934, Val Acc: 67.80%\n",
      "Epoch: 7023,     Training Loss: 0.30131155252456665, Training Acc: 77.17%\n",
      "              Val Loss: 1.090527057647705, Val Acc: 67.80%\n",
      "Epoch: 7024,     Training Loss: 0.30643248558044434, Training Acc: 77.17%\n",
      "              Val Loss: 1.1103607416152954, Val Acc: 67.80%\n",
      "Epoch: 7025,     Training Loss: 0.3148561716079712, Training Acc: 77.17%\n",
      "              Val Loss: 1.101317286491394, Val Acc: 67.80%\n",
      "Epoch: 7026,     Training Loss: 0.29687756299972534, Training Acc: 77.17%\n",
      "              Val Loss: 1.0741326808929443, Val Acc: 67.80%\n",
      "Epoch: 7027,     Training Loss: 0.30915382504463196, Training Acc: 77.17%\n",
      "              Val Loss: 1.1211330890655518, Val Acc: 67.80%\n",
      "Epoch: 7028,     Training Loss: 0.31560376286506653, Training Acc: 77.17%\n",
      "              Val Loss: 1.083607792854309, Val Acc: 67.80%\n",
      "Epoch: 7029,     Training Loss: 0.30505865812301636, Training Acc: 77.17%\n",
      "              Val Loss: 1.127439260482788, Val Acc: 67.81%\n",
      "Epoch: 7030,     Training Loss: 0.3124629855155945, Training Acc: 77.18%\n",
      "              Val Loss: 1.1081223487854004, Val Acc: 67.81%\n",
      "Epoch: 7031,     Training Loss: 0.3128547966480255, Training Acc: 77.18%\n",
      "              Val Loss: 1.1155657768249512, Val Acc: 67.81%\n",
      "Epoch: 7032,     Training Loss: 0.3163396120071411, Training Acc: 77.18%\n",
      "              Val Loss: 1.0924289226531982, Val Acc: 67.81%\n",
      "Epoch: 7033,     Training Loss: 0.3245055377483368, Training Acc: 77.18%\n",
      "              Val Loss: 1.1177983283996582, Val Acc: 67.81%\n",
      "Epoch: 7034,     Training Loss: 0.3062504231929779, Training Acc: 77.18%\n",
      "              Val Loss: 1.1443507671356201, Val Acc: 67.81%\n",
      "Epoch: 7035,     Training Loss: 0.35204821825027466, Training Acc: 77.18%\n",
      "              Val Loss: 1.1258429288864136, Val Acc: 67.81%\n",
      "Epoch: 7036,     Training Loss: 0.315143883228302, Training Acc: 77.18%\n",
      "              Val Loss: 1.0683009624481201, Val Acc: 67.81%\n",
      "Epoch: 7037,     Training Loss: 0.3032594919204712, Training Acc: 77.19%\n",
      "              Val Loss: 1.0947474241256714, Val Acc: 67.81%\n",
      "Epoch: 7038,     Training Loss: 0.30543527007102966, Training Acc: 77.19%\n",
      "              Val Loss: 1.0860744714736938, Val Acc: 67.81%\n",
      "Epoch: 7039,     Training Loss: 0.29414352774620056, Training Acc: 77.19%\n",
      "              Val Loss: 1.1014938354492188, Val Acc: 67.81%\n",
      "Epoch: 7040,     Training Loss: 0.30516526103019714, Training Acc: 77.19%\n",
      "              Val Loss: 1.1241750717163086, Val Acc: 67.81%\n",
      "Epoch: 7041,     Training Loss: 0.2977946698665619, Training Acc: 77.19%\n",
      "              Val Loss: 1.1074610948562622, Val Acc: 67.81%\n",
      "Epoch: 7042,     Training Loss: 0.2870939373970032, Training Acc: 77.19%\n",
      "              Val Loss: 1.1061242818832397, Val Acc: 67.81%\n",
      "Epoch: 7043,     Training Loss: 0.29803401231765747, Training Acc: 77.19%\n",
      "              Val Loss: 1.1121854782104492, Val Acc: 67.81%\n",
      "Epoch: 7044,     Training Loss: 0.29480698704719543, Training Acc: 77.20%\n",
      "              Val Loss: 1.1080433130264282, Val Acc: 67.82%\n",
      "Epoch: 7045,     Training Loss: 0.2924547493457794, Training Acc: 77.20%\n",
      "              Val Loss: 1.0898340940475464, Val Acc: 67.82%\n",
      "Epoch: 7046,     Training Loss: 0.306205153465271, Training Acc: 77.20%\n",
      "              Val Loss: 1.126034140586853, Val Acc: 67.82%\n",
      "Epoch: 7047,     Training Loss: 0.30568987131118774, Training Acc: 77.20%\n",
      "              Val Loss: 1.1219583749771118, Val Acc: 67.82%\n",
      "Epoch: 7048,     Training Loss: 0.3521413803100586, Training Acc: 77.20%\n",
      "              Val Loss: 1.1653496026992798, Val Acc: 67.82%\n",
      "Epoch: 7049,     Training Loss: 0.34036877751350403, Training Acc: 77.20%\n",
      "              Val Loss: 1.1307179927825928, Val Acc: 67.82%\n",
      "Epoch: 7050,     Training Loss: 0.3721436560153961, Training Acc: 77.20%\n",
      "              Val Loss: 1.173543930053711, Val Acc: 67.82%\n",
      "Epoch: 7051,     Training Loss: 0.3411099910736084, Training Acc: 77.21%\n",
      "              Val Loss: 1.1278232336044312, Val Acc: 67.82%\n",
      "Epoch: 7052,     Training Loss: 0.3563982844352722, Training Acc: 77.21%\n",
      "              Val Loss: 1.1095480918884277, Val Acc: 67.82%\n",
      "Epoch: 7053,     Training Loss: 0.303622841835022, Training Acc: 77.21%\n",
      "              Val Loss: 1.1229751110076904, Val Acc: 67.82%\n",
      "Epoch: 7054,     Training Loss: 0.30382540822029114, Training Acc: 77.21%\n",
      "              Val Loss: 1.1081230640411377, Val Acc: 67.82%\n",
      "Epoch: 7055,     Training Loss: 0.3056543469429016, Training Acc: 77.21%\n",
      "              Val Loss: 1.1383697986602783, Val Acc: 67.82%\n",
      "Epoch: 7056,     Training Loss: 0.3165336549282074, Training Acc: 77.21%\n",
      "              Val Loss: 1.1100293397903442, Val Acc: 67.82%\n",
      "Epoch: 7057,     Training Loss: 0.3170652985572815, Training Acc: 77.21%\n",
      "              Val Loss: 1.1293840408325195, Val Acc: 67.82%\n",
      "Epoch: 7058,     Training Loss: 0.30828872323036194, Training Acc: 77.21%\n",
      "              Val Loss: 1.096264362335205, Val Acc: 67.82%\n",
      "Epoch: 7059,     Training Loss: 0.3326590061187744, Training Acc: 77.22%\n",
      "              Val Loss: 1.1347019672393799, Val Acc: 67.82%\n",
      "Epoch: 7060,     Training Loss: 0.3063761293888092, Training Acc: 77.22%\n",
      "              Val Loss: 1.094728946685791, Val Acc: 67.83%\n",
      "Epoch: 7061,     Training Loss: 0.2987913191318512, Training Acc: 77.22%\n",
      "              Val Loss: 1.1085835695266724, Val Acc: 67.83%\n",
      "Epoch: 7062,     Training Loss: 0.30103135108947754, Training Acc: 77.22%\n",
      "              Val Loss: 1.1075637340545654, Val Acc: 67.83%\n",
      "Epoch: 7063,     Training Loss: 0.3101956844329834, Training Acc: 77.22%\n",
      "              Val Loss: 1.1291069984436035, Val Acc: 67.83%\n",
      "Epoch: 7064,     Training Loss: 0.31481942534446716, Training Acc: 77.22%\n",
      "              Val Loss: 1.0975831747055054, Val Acc: 67.83%\n",
      "Epoch: 7065,     Training Loss: 0.316218763589859, Training Acc: 77.22%\n",
      "              Val Loss: 1.149520754814148, Val Acc: 67.83%\n",
      "Epoch: 7066,     Training Loss: 0.31281590461730957, Training Acc: 77.23%\n",
      "              Val Loss: 1.1641886234283447, Val Acc: 67.83%\n",
      "Epoch: 7067,     Training Loss: 0.36331772804260254, Training Acc: 77.23%\n",
      "              Val Loss: 1.1646554470062256, Val Acc: 67.83%\n",
      "Epoch: 7068,     Training Loss: 0.32530826330184937, Training Acc: 77.23%\n",
      "              Val Loss: 1.0850070714950562, Val Acc: 67.83%\n",
      "Epoch: 7069,     Training Loss: 0.3184513449668884, Training Acc: 77.23%\n",
      "              Val Loss: 1.1135345697402954, Val Acc: 67.83%\n",
      "Epoch: 7070,     Training Loss: 0.3087598383426666, Training Acc: 77.23%\n",
      "              Val Loss: 1.0896486043930054, Val Acc: 67.83%\n",
      "Epoch: 7071,     Training Loss: 0.3150498867034912, Training Acc: 77.23%\n",
      "              Val Loss: 1.1233587265014648, Val Acc: 67.83%\n",
      "Epoch: 7072,     Training Loss: 0.3116174042224884, Training Acc: 77.23%\n",
      "              Val Loss: 1.124067783355713, Val Acc: 67.83%\n",
      "Epoch: 7073,     Training Loss: 0.3129684329032898, Training Acc: 77.24%\n",
      "              Val Loss: 1.1346439123153687, Val Acc: 67.83%\n",
      "Epoch: 7074,     Training Loss: 0.29444003105163574, Training Acc: 77.24%\n",
      "              Val Loss: 1.0955547094345093, Val Acc: 67.83%\n",
      "Epoch: 7075,     Training Loss: 0.3089430332183838, Training Acc: 77.24%\n",
      "              Val Loss: 1.1319198608398438, Val Acc: 67.83%\n",
      "Epoch: 7076,     Training Loss: 0.3063947856426239, Training Acc: 77.24%\n",
      "              Val Loss: 1.096774935722351, Val Acc: 67.84%\n",
      "Epoch: 7077,     Training Loss: 0.3071803152561188, Training Acc: 77.24%\n",
      "              Val Loss: 1.1318684816360474, Val Acc: 67.84%\n",
      "Epoch: 7078,     Training Loss: 0.3124888837337494, Training Acc: 77.24%\n",
      "              Val Loss: 1.0961822271347046, Val Acc: 67.84%\n",
      "Epoch: 7079,     Training Loss: 0.310212105512619, Training Acc: 77.24%\n",
      "              Val Loss: 1.1250293254852295, Val Acc: 67.84%\n",
      "Epoch: 7080,     Training Loss: 0.313294917345047, Training Acc: 77.24%\n",
      "              Val Loss: 1.1015795469284058, Val Acc: 67.84%\n",
      "Epoch: 7081,     Training Loss: 0.33632758259773254, Training Acc: 77.25%\n",
      "              Val Loss: 1.1390162706375122, Val Acc: 67.84%\n",
      "Epoch: 7082,     Training Loss: 0.3114462196826935, Training Acc: 77.25%\n",
      "              Val Loss: 1.178207516670227, Val Acc: 67.84%\n",
      "Epoch: 7083,     Training Loss: 0.35016730427742004, Training Acc: 77.25%\n",
      "              Val Loss: 1.1510127782821655, Val Acc: 67.84%\n",
      "Epoch: 7084,     Training Loss: 0.3100918233394623, Training Acc: 77.25%\n",
      "              Val Loss: 1.1051678657531738, Val Acc: 67.84%\n",
      "Epoch: 7085,     Training Loss: 0.32423508167266846, Training Acc: 77.25%\n",
      "              Val Loss: 1.133043885231018, Val Acc: 67.84%\n",
      "Epoch: 7086,     Training Loss: 0.31360000371932983, Training Acc: 77.25%\n",
      "              Val Loss: 1.0829260349273682, Val Acc: 67.84%\n",
      "Epoch: 7087,     Training Loss: 0.30122077465057373, Training Acc: 77.25%\n",
      "              Val Loss: 1.1387730836868286, Val Acc: 67.84%\n",
      "Epoch: 7088,     Training Loss: 0.32960036396980286, Training Acc: 77.26%\n",
      "              Val Loss: 1.1400450468063354, Val Acc: 67.84%\n",
      "Epoch: 7089,     Training Loss: 0.327972948551178, Training Acc: 77.26%\n",
      "              Val Loss: 1.1958413124084473, Val Acc: 67.84%\n",
      "Epoch: 7090,     Training Loss: 0.3381032645702362, Training Acc: 77.26%\n",
      "              Val Loss: 1.1605361700057983, Val Acc: 67.84%\n",
      "Epoch: 7091,     Training Loss: 0.3927505910396576, Training Acc: 77.26%\n",
      "              Val Loss: 1.1906790733337402, Val Acc: 67.84%\n",
      "Epoch: 7092,     Training Loss: 0.36950740218162537, Training Acc: 77.26%\n",
      "              Val Loss: 1.193783164024353, Val Acc: 67.84%\n",
      "Epoch: 7093,     Training Loss: 0.39456799626350403, Training Acc: 77.26%\n",
      "              Val Loss: 1.203310489654541, Val Acc: 67.84%\n",
      "Epoch: 7094,     Training Loss: 0.34893539547920227, Training Acc: 77.26%\n",
      "              Val Loss: 1.1473106145858765, Val Acc: 67.85%\n",
      "Epoch: 7095,     Training Loss: 0.3548409640789032, Training Acc: 77.26%\n",
      "              Val Loss: 1.1221431493759155, Val Acc: 67.85%\n",
      "Epoch: 7096,     Training Loss: 0.3465724587440491, Training Acc: 77.26%\n",
      "              Val Loss: 1.1859354972839355, Val Acc: 67.85%\n",
      "Epoch: 7097,     Training Loss: 0.35915887355804443, Training Acc: 77.26%\n",
      "              Val Loss: 1.1168171167373657, Val Acc: 67.85%\n",
      "Epoch: 7098,     Training Loss: 0.32512161135673523, Training Acc: 77.27%\n",
      "              Val Loss: 1.159757137298584, Val Acc: 67.85%\n",
      "Epoch: 7099,     Training Loss: 0.3512822091579437, Training Acc: 77.27%\n",
      "              Val Loss: 1.173844337463379, Val Acc: 67.85%\n",
      "Epoch: 7100,     Training Loss: 0.37106087803840637, Training Acc: 77.27%\n",
      "              Val Loss: 1.2217342853546143, Val Acc: 67.85%\n",
      "Epoch: 7101,     Training Loss: 0.3375512957572937, Training Acc: 77.27%\n",
      "              Val Loss: 1.112990379333496, Val Acc: 67.85%\n",
      "Epoch: 7102,     Training Loss: 0.30903497338294983, Training Acc: 77.27%\n",
      "              Val Loss: 1.1801739931106567, Val Acc: 67.85%\n",
      "Epoch: 7103,     Training Loss: 0.35299474000930786, Training Acc: 77.27%\n",
      "              Val Loss: 1.0831533670425415, Val Acc: 67.85%\n",
      "Epoch: 7104,     Training Loss: 0.31572258472442627, Training Acc: 77.27%\n",
      "              Val Loss: 1.1293755769729614, Val Acc: 67.85%\n",
      "Epoch: 7105,     Training Loss: 0.3220316767692566, Training Acc: 77.27%\n",
      "              Val Loss: 1.0899196863174438, Val Acc: 67.85%\n",
      "Epoch: 7106,     Training Loss: 0.31896570324897766, Training Acc: 77.28%\n",
      "              Val Loss: 1.1295247077941895, Val Acc: 67.85%\n",
      "Epoch: 7107,     Training Loss: 0.34685173630714417, Training Acc: 77.28%\n",
      "              Val Loss: 1.1355336904525757, Val Acc: 67.85%\n",
      "Epoch: 7108,     Training Loss: 0.3264928460121155, Training Acc: 77.28%\n",
      "              Val Loss: 1.1522430181503296, Val Acc: 67.85%\n",
      "Epoch: 7109,     Training Loss: 0.30492985248565674, Training Acc: 77.28%\n",
      "              Val Loss: 1.1538307666778564, Val Acc: 67.85%\n",
      "Epoch: 7110,     Training Loss: 0.35379037261009216, Training Acc: 77.28%\n",
      "              Val Loss: 1.2036713361740112, Val Acc: 67.86%\n",
      "Epoch: 7111,     Training Loss: 0.331373393535614, Training Acc: 77.28%\n",
      "              Val Loss: 1.1790584325790405, Val Acc: 67.86%\n",
      "Epoch: 7112,     Training Loss: 0.34707576036453247, Training Acc: 77.28%\n",
      "              Val Loss: 1.149079442024231, Val Acc: 67.86%\n",
      "Epoch: 7113,     Training Loss: 0.31027424335479736, Training Acc: 77.28%\n",
      "              Val Loss: 1.1364272832870483, Val Acc: 67.86%\n",
      "Epoch: 7114,     Training Loss: 0.34182819724082947, Training Acc: 77.29%\n",
      "              Val Loss: 1.1623584032058716, Val Acc: 67.86%\n",
      "Epoch: 7115,     Training Loss: 0.33162200450897217, Training Acc: 77.29%\n",
      "              Val Loss: 1.1107367277145386, Val Acc: 67.86%\n",
      "Epoch: 7116,     Training Loss: 0.3123954236507416, Training Acc: 77.29%\n",
      "              Val Loss: 1.118374228477478, Val Acc: 67.86%\n",
      "Epoch: 7117,     Training Loss: 0.3049721419811249, Training Acc: 77.29%\n",
      "              Val Loss: 1.110952615737915, Val Acc: 67.86%\n",
      "Epoch: 7118,     Training Loss: 0.3067348003387451, Training Acc: 77.29%\n",
      "              Val Loss: 1.1709039211273193, Val Acc: 67.86%\n",
      "Epoch: 7119,     Training Loss: 0.3082325756549835, Training Acc: 77.29%\n",
      "              Val Loss: 1.1158061027526855, Val Acc: 67.86%\n",
      "Epoch: 7120,     Training Loss: 0.30544495582580566, Training Acc: 77.29%\n",
      "              Val Loss: 1.1474885940551758, Val Acc: 67.86%\n",
      "Epoch: 7121,     Training Loss: 0.29993361234664917, Training Acc: 77.30%\n",
      "              Val Loss: 1.1320157051086426, Val Acc: 67.86%\n",
      "Epoch: 7122,     Training Loss: 0.31880244612693787, Training Acc: 77.30%\n",
      "              Val Loss: 1.1570411920547485, Val Acc: 67.86%\n",
      "Epoch: 7123,     Training Loss: 0.3145628869533539, Training Acc: 77.30%\n",
      "              Val Loss: 1.1226557493209839, Val Acc: 67.86%\n",
      "Epoch: 7124,     Training Loss: 0.33611464500427246, Training Acc: 77.30%\n",
      "              Val Loss: 1.1607449054718018, Val Acc: 67.86%\n",
      "Epoch: 7125,     Training Loss: 0.3159250319004059, Training Acc: 77.30%\n",
      "              Val Loss: 1.1044936180114746, Val Acc: 67.86%\n",
      "Epoch: 7126,     Training Loss: 0.3263195753097534, Training Acc: 77.30%\n",
      "              Val Loss: 1.1580071449279785, Val Acc: 67.86%\n",
      "Epoch: 7127,     Training Loss: 0.3186633586883545, Training Acc: 77.30%\n",
      "              Val Loss: 1.1215546131134033, Val Acc: 67.86%\n",
      "Epoch: 7128,     Training Loss: 0.316190630197525, Training Acc: 77.31%\n",
      "              Val Loss: 1.1745012998580933, Val Acc: 67.87%\n",
      "Epoch: 7129,     Training Loss: 0.30524009466171265, Training Acc: 77.31%\n",
      "              Val Loss: 1.123410701751709, Val Acc: 67.87%\n",
      "Epoch: 7130,     Training Loss: 0.29825982451438904, Training Acc: 77.31%\n",
      "              Val Loss: 1.1251944303512573, Val Acc: 67.87%\n",
      "Epoch: 7131,     Training Loss: 0.2863829731941223, Training Acc: 77.31%\n",
      "              Val Loss: 1.1238702535629272, Val Acc: 67.87%\n",
      "Epoch: 7132,     Training Loss: 0.2830553352832794, Training Acc: 77.31%\n",
      "              Val Loss: 1.1367367506027222, Val Acc: 67.87%\n",
      "Epoch: 7133,     Training Loss: 0.2838544547557831, Training Acc: 77.31%\n",
      "              Val Loss: 1.1416579484939575, Val Acc: 67.87%\n",
      "Epoch: 7134,     Training Loss: 0.28418999910354614, Training Acc: 77.31%\n",
      "              Val Loss: 1.1382601261138916, Val Acc: 67.87%\n",
      "Epoch: 7135,     Training Loss: 0.28247717022895813, Training Acc: 77.32%\n",
      "              Val Loss: 1.137836217880249, Val Acc: 67.87%\n",
      "Epoch: 7136,     Training Loss: 0.28181174397468567, Training Acc: 77.32%\n",
      "              Val Loss: 1.1328333616256714, Val Acc: 67.87%\n",
      "Epoch: 7137,     Training Loss: 0.29069480299949646, Training Acc: 77.32%\n",
      "              Val Loss: 1.1956887245178223, Val Acc: 67.87%\n",
      "Epoch: 7138,     Training Loss: 0.30178651213645935, Training Acc: 77.32%\n",
      "              Val Loss: 1.170156478881836, Val Acc: 67.87%\n",
      "Epoch: 7139,     Training Loss: 0.3396877348423004, Training Acc: 77.32%\n",
      "              Val Loss: 1.2492666244506836, Val Acc: 67.87%\n",
      "Epoch: 7140,     Training Loss: 0.34866198897361755, Training Acc: 77.32%\n",
      "              Val Loss: 1.2338632345199585, Val Acc: 67.87%\n",
      "Epoch: 7141,     Training Loss: 0.4446665644645691, Training Acc: 77.32%\n",
      "              Val Loss: 1.1977194547653198, Val Acc: 67.87%\n",
      "Epoch: 7142,     Training Loss: 0.3192192316055298, Training Acc: 77.32%\n",
      "              Val Loss: 1.155397653579712, Val Acc: 67.87%\n",
      "Epoch: 7143,     Training Loss: 0.29395824670791626, Training Acc: 77.33%\n",
      "              Val Loss: 1.1547269821166992, Val Acc: 67.88%\n",
      "Epoch: 7144,     Training Loss: 0.33385416865348816, Training Acc: 77.33%\n",
      "              Val Loss: 1.2271596193313599, Val Acc: 67.88%\n",
      "Epoch: 7145,     Training Loss: 0.3463596701622009, Training Acc: 77.33%\n",
      "              Val Loss: 1.1771851778030396, Val Acc: 67.88%\n",
      "Epoch: 7146,     Training Loss: 0.3580056130886078, Training Acc: 77.33%\n",
      "              Val Loss: 1.192014217376709, Val Acc: 67.88%\n",
      "Epoch: 7147,     Training Loss: 0.3045365810394287, Training Acc: 77.33%\n",
      "              Val Loss: 1.1351392269134521, Val Acc: 67.88%\n",
      "Epoch: 7148,     Training Loss: 0.29274746775627136, Training Acc: 77.33%\n",
      "              Val Loss: 1.1320232152938843, Val Acc: 67.88%\n",
      "Epoch: 7149,     Training Loss: 0.3310627341270447, Training Acc: 77.33%\n",
      "              Val Loss: 1.2445812225341797, Val Acc: 67.88%\n",
      "Epoch: 7150,     Training Loss: 0.35602933168411255, Training Acc: 77.33%\n",
      "              Val Loss: 1.192989706993103, Val Acc: 67.88%\n",
      "Epoch: 7151,     Training Loss: 0.40270569920539856, Training Acc: 77.34%\n",
      "              Val Loss: 1.1936897039413452, Val Acc: 67.88%\n",
      "Epoch: 7152,     Training Loss: 0.32601264119148254, Training Acc: 77.34%\n",
      "              Val Loss: 1.1849074363708496, Val Acc: 67.88%\n",
      "Epoch: 7153,     Training Loss: 0.3209717273712158, Training Acc: 77.34%\n",
      "              Val Loss: 1.1702250242233276, Val Acc: 67.88%\n",
      "Epoch: 7154,     Training Loss: 0.3771943747997284, Training Acc: 77.34%\n",
      "              Val Loss: 1.2320497035980225, Val Acc: 67.88%\n",
      "Epoch: 7155,     Training Loss: 0.3863103985786438, Training Acc: 77.34%\n",
      "              Val Loss: 1.164554476737976, Val Acc: 67.88%\n",
      "Epoch: 7156,     Training Loss: 0.355148047208786, Training Acc: 77.34%\n",
      "              Val Loss: 1.2688062191009521, Val Acc: 67.88%\n",
      "Epoch: 7157,     Training Loss: 0.37142279744148254, Training Acc: 77.34%\n",
      "              Val Loss: 1.1607661247253418, Val Acc: 67.88%\n",
      "Epoch: 7158,     Training Loss: 0.329842209815979, Training Acc: 77.34%\n",
      "              Val Loss: 1.1519756317138672, Val Acc: 67.88%\n",
      "Epoch: 7159,     Training Loss: 0.3479577600955963, Training Acc: 77.34%\n",
      "              Val Loss: 1.1242320537567139, Val Acc: 67.88%\n",
      "Epoch: 7160,     Training Loss: 0.3251735270023346, Training Acc: 77.35%\n",
      "              Val Loss: 1.1461564302444458, Val Acc: 67.88%\n",
      "Epoch: 7161,     Training Loss: 0.3437569737434387, Training Acc: 77.35%\n",
      "              Val Loss: 1.1510109901428223, Val Acc: 67.88%\n",
      "Epoch: 7162,     Training Loss: 0.33790966868400574, Training Acc: 77.35%\n",
      "              Val Loss: 1.1786235570907593, Val Acc: 67.89%\n",
      "Epoch: 7163,     Training Loss: 0.31565216183662415, Training Acc: 77.35%\n",
      "              Val Loss: 1.2208020687103271, Val Acc: 67.89%\n",
      "Epoch: 7164,     Training Loss: 0.3479362726211548, Training Acc: 77.35%\n",
      "              Val Loss: 1.127606987953186, Val Acc: 67.89%\n",
      "Epoch: 7165,     Training Loss: 0.3358343243598938, Training Acc: 77.35%\n",
      "              Val Loss: 1.2476208209991455, Val Acc: 67.89%\n",
      "Epoch: 7166,     Training Loss: 0.4002460837364197, Training Acc: 77.35%\n",
      "              Val Loss: 1.2414844036102295, Val Acc: 67.89%\n",
      "Epoch: 7167,     Training Loss: 0.39391767978668213, Training Acc: 77.35%\n",
      "              Val Loss: 1.330073595046997, Val Acc: 67.89%\n",
      "Epoch: 7168,     Training Loss: 0.3711535632610321, Training Acc: 77.35%\n",
      "              Val Loss: 1.2394709587097168, Val Acc: 67.89%\n",
      "Epoch: 7169,     Training Loss: 0.3368651568889618, Training Acc: 77.36%\n",
      "              Val Loss: 1.2076283693313599, Val Acc: 67.89%\n",
      "Epoch: 7170,     Training Loss: 0.34277579188346863, Training Acc: 77.36%\n",
      "              Val Loss: 1.1574279069900513, Val Acc: 67.89%\n",
      "Epoch: 7171,     Training Loss: 0.31926238536834717, Training Acc: 77.36%\n",
      "              Val Loss: 1.1467491388320923, Val Acc: 67.89%\n",
      "Epoch: 7172,     Training Loss: 0.32806605100631714, Training Acc: 77.36%\n",
      "              Val Loss: 1.1339082717895508, Val Acc: 67.89%\n",
      "Epoch: 7173,     Training Loss: 0.31694361567497253, Training Acc: 77.36%\n",
      "              Val Loss: 1.1432406902313232, Val Acc: 67.89%\n",
      "Epoch: 7174,     Training Loss: 0.31966859102249146, Training Acc: 77.36%\n",
      "              Val Loss: 1.1509734392166138, Val Acc: 67.89%\n",
      "Epoch: 7175,     Training Loss: 0.31509530544281006, Training Acc: 77.36%\n",
      "              Val Loss: 1.2078022956848145, Val Acc: 67.89%\n",
      "Epoch: 7176,     Training Loss: 0.3143209218978882, Training Acc: 77.36%\n",
      "              Val Loss: 1.1547471284866333, Val Acc: 67.89%\n",
      "Epoch: 7177,     Training Loss: 0.3173709511756897, Training Acc: 77.37%\n",
      "              Val Loss: 1.2146782875061035, Val Acc: 67.89%\n",
      "Epoch: 7178,     Training Loss: 0.30682533979415894, Training Acc: 77.37%\n",
      "              Val Loss: 1.2166991233825684, Val Acc: 67.89%\n",
      "Epoch: 7179,     Training Loss: 0.31524530053138733, Training Acc: 77.37%\n",
      "              Val Loss: 1.1848448514938354, Val Acc: 67.89%\n",
      "Epoch: 7180,     Training Loss: 0.2836250960826874, Training Acc: 77.37%\n",
      "              Val Loss: 1.1627637147903442, Val Acc: 67.89%\n",
      "Epoch: 7181,     Training Loss: 0.2977403402328491, Training Acc: 77.37%\n",
      "              Val Loss: 1.1614115238189697, Val Acc: 67.90%\n",
      "Epoch: 7182,     Training Loss: 0.2863081097602844, Training Acc: 77.37%\n",
      "              Val Loss: 1.179314374923706, Val Acc: 67.90%\n",
      "Epoch: 7183,     Training Loss: 0.28526777029037476, Training Acc: 77.37%\n",
      "              Val Loss: 1.1808537244796753, Val Acc: 67.90%\n",
      "Epoch: 7184,     Training Loss: 0.2905835807323456, Training Acc: 77.38%\n",
      "              Val Loss: 1.1751084327697754, Val Acc: 67.90%\n",
      "Epoch: 7185,     Training Loss: 0.28047627210617065, Training Acc: 77.38%\n",
      "              Val Loss: 1.1601635217666626, Val Acc: 67.90%\n",
      "Epoch: 7186,     Training Loss: 0.28747251629829407, Training Acc: 77.38%\n",
      "              Val Loss: 1.1544616222381592, Val Acc: 67.90%\n",
      "Epoch: 7187,     Training Loss: 0.28826722502708435, Training Acc: 77.38%\n",
      "              Val Loss: 1.1410070657730103, Val Acc: 67.90%\n",
      "Epoch: 7188,     Training Loss: 0.30333054065704346, Training Acc: 77.38%\n",
      "              Val Loss: 1.2189760208129883, Val Acc: 67.90%\n",
      "Epoch: 7189,     Training Loss: 0.3190012276172638, Training Acc: 77.38%\n",
      "              Val Loss: 1.1884942054748535, Val Acc: 67.90%\n",
      "Epoch: 7190,     Training Loss: 0.3750336766242981, Training Acc: 77.38%\n",
      "              Val Loss: 1.265541672706604, Val Acc: 67.90%\n",
      "Epoch: 7191,     Training Loss: 0.35563430190086365, Training Acc: 77.38%\n",
      "              Val Loss: 1.1946824789047241, Val Acc: 67.90%\n",
      "Epoch: 7192,     Training Loss: 0.37760594487190247, Training Acc: 77.39%\n",
      "              Val Loss: 1.1806503534317017, Val Acc: 67.90%\n",
      "Epoch: 7193,     Training Loss: 0.3045441508293152, Training Acc: 77.39%\n",
      "              Val Loss: 1.1360032558441162, Val Acc: 67.90%\n",
      "Epoch: 7194,     Training Loss: 0.29246312379837036, Training Acc: 77.39%\n",
      "              Val Loss: 1.1146141290664673, Val Acc: 67.90%\n",
      "Epoch: 7195,     Training Loss: 0.302908331155777, Training Acc: 77.39%\n",
      "              Val Loss: 1.1737762689590454, Val Acc: 67.90%\n",
      "Epoch: 7196,     Training Loss: 0.3175959587097168, Training Acc: 77.39%\n",
      "              Val Loss: 1.1364117860794067, Val Acc: 67.90%\n",
      "Epoch: 7197,     Training Loss: 0.34274181723594666, Training Acc: 77.39%\n",
      "              Val Loss: 1.1822004318237305, Val Acc: 67.91%\n",
      "Epoch: 7198,     Training Loss: 0.31486064195632935, Training Acc: 77.39%\n",
      "              Val Loss: 1.1447826623916626, Val Acc: 67.91%\n",
      "Epoch: 7199,     Training Loss: 0.2856077551841736, Training Acc: 77.40%\n",
      "              Val Loss: 1.1252249479293823, Val Acc: 67.91%\n",
      "Epoch: 7200,     Training Loss: 0.2940242290496826, Training Acc: 77.40%\n",
      "              Val Loss: 1.2042065858840942, Val Acc: 67.91%\n",
      "Epoch: 7201,     Training Loss: 0.324180006980896, Training Acc: 77.40%\n",
      "              Val Loss: 1.207525372505188, Val Acc: 67.91%\n",
      "Epoch: 7202,     Training Loss: 0.37526920437812805, Training Acc: 77.40%\n",
      "              Val Loss: 1.25462007522583, Val Acc: 67.91%\n",
      "Epoch: 7203,     Training Loss: 0.3399505615234375, Training Acc: 77.40%\n",
      "              Val Loss: 1.1419748067855835, Val Acc: 67.91%\n",
      "Epoch: 7204,     Training Loss: 0.32009273767471313, Training Acc: 77.40%\n",
      "              Val Loss: 1.1708009243011475, Val Acc: 67.91%\n",
      "Epoch: 7205,     Training Loss: 0.31089067459106445, Training Acc: 77.40%\n",
      "              Val Loss: 1.1352050304412842, Val Acc: 67.91%\n",
      "Epoch: 7206,     Training Loss: 0.2895967960357666, Training Acc: 77.40%\n",
      "              Val Loss: 1.1450225114822388, Val Acc: 67.91%\n",
      "Epoch: 7207,     Training Loss: 0.2839301824569702, Training Acc: 77.41%\n",
      "              Val Loss: 1.1948480606079102, Val Acc: 67.91%\n",
      "Epoch: 7208,     Training Loss: 0.29784566164016724, Training Acc: 77.41%\n",
      "              Val Loss: 1.166122317314148, Val Acc: 67.91%\n",
      "Epoch: 7209,     Training Loss: 0.2955801486968994, Training Acc: 77.41%\n",
      "              Val Loss: 1.1788312196731567, Val Acc: 67.91%\n",
      "Epoch: 7210,     Training Loss: 0.29610759019851685, Training Acc: 77.41%\n",
      "              Val Loss: 1.126572608947754, Val Acc: 67.91%\n",
      "Epoch: 7211,     Training Loss: 0.29352042078971863, Training Acc: 77.41%\n",
      "              Val Loss: 1.1666553020477295, Val Acc: 67.91%\n",
      "Epoch: 7212,     Training Loss: 0.29311275482177734, Training Acc: 77.41%\n",
      "              Val Loss: 1.1417919397354126, Val Acc: 67.91%\n",
      "Epoch: 7213,     Training Loss: 0.29745134711265564, Training Acc: 77.41%\n",
      "              Val Loss: 1.1395008563995361, Val Acc: 67.91%\n",
      "Epoch: 7214,     Training Loss: 0.2849161624908447, Training Acc: 77.42%\n",
      "              Val Loss: 1.1039124727249146, Val Acc: 67.92%\n",
      "Epoch: 7215,     Training Loss: 0.2831648886203766, Training Acc: 77.42%\n",
      "              Val Loss: 1.1207785606384277, Val Acc: 67.92%\n",
      "Epoch: 7216,     Training Loss: 0.28143227100372314, Training Acc: 77.42%\n",
      "              Val Loss: 1.1203346252441406, Val Acc: 67.92%\n",
      "Epoch: 7217,     Training Loss: 0.2793331444263458, Training Acc: 77.42%\n",
      "              Val Loss: 1.1109882593154907, Val Acc: 67.92%\n",
      "Epoch: 7218,     Training Loss: 0.28141671419143677, Training Acc: 77.42%\n",
      "              Val Loss: 1.1428526639938354, Val Acc: 67.92%\n",
      "Epoch: 7219,     Training Loss: 0.2832884192466736, Training Acc: 77.42%\n",
      "              Val Loss: 1.122636079788208, Val Acc: 67.92%\n",
      "Epoch: 7220,     Training Loss: 0.2896382212638855, Training Acc: 77.43%\n",
      "              Val Loss: 1.1637529134750366, Val Acc: 67.92%\n",
      "Epoch: 7221,     Training Loss: 0.2950528860092163, Training Acc: 77.43%\n",
      "              Val Loss: 1.1319968700408936, Val Acc: 67.92%\n",
      "Epoch: 7222,     Training Loss: 0.31230998039245605, Training Acc: 77.43%\n",
      "              Val Loss: 1.1931029558181763, Val Acc: 67.92%\n",
      "Epoch: 7223,     Training Loss: 0.3090062737464905, Training Acc: 77.43%\n",
      "              Val Loss: 1.1432812213897705, Val Acc: 67.92%\n",
      "Epoch: 7224,     Training Loss: 0.33348479866981506, Training Acc: 77.43%\n",
      "              Val Loss: 1.180799961090088, Val Acc: 67.92%\n",
      "Epoch: 7225,     Training Loss: 0.3091351389884949, Training Acc: 77.43%\n",
      "              Val Loss: 1.124149203300476, Val Acc: 67.92%\n",
      "Epoch: 7226,     Training Loss: 0.3073172867298126, Training Acc: 77.43%\n",
      "              Val Loss: 1.1405502557754517, Val Acc: 67.92%\n",
      "Epoch: 7227,     Training Loss: 0.28009122610092163, Training Acc: 77.43%\n",
      "              Val Loss: 1.1289142370224, Val Acc: 67.92%\n",
      "Epoch: 7228,     Training Loss: 0.2720524072647095, Training Acc: 77.44%\n",
      "              Val Loss: 1.1286594867706299, Val Acc: 67.92%\n",
      "Epoch: 7229,     Training Loss: 0.27780234813690186, Training Acc: 77.44%\n",
      "              Val Loss: 1.1663432121276855, Val Acc: 67.93%\n",
      "Epoch: 7230,     Training Loss: 0.2894361615180969, Training Acc: 77.44%\n",
      "              Val Loss: 1.1581016778945923, Val Acc: 67.93%\n",
      "Epoch: 7231,     Training Loss: 0.31710493564605713, Training Acc: 77.44%\n",
      "              Val Loss: 1.2149560451507568, Val Acc: 67.93%\n",
      "Epoch: 7232,     Training Loss: 0.3078967034816742, Training Acc: 77.44%\n",
      "              Val Loss: 1.1468300819396973, Val Acc: 67.93%\n",
      "Epoch: 7233,     Training Loss: 0.31725966930389404, Training Acc: 77.44%\n",
      "              Val Loss: 1.1918256282806396, Val Acc: 67.93%\n",
      "Epoch: 7234,     Training Loss: 0.3071805536746979, Training Acc: 77.44%\n",
      "              Val Loss: 1.1226933002471924, Val Acc: 67.93%\n",
      "Epoch: 7235,     Training Loss: 0.28903043270111084, Training Acc: 77.45%\n",
      "              Val Loss: 1.152441143989563, Val Acc: 67.93%\n",
      "Epoch: 7236,     Training Loss: 0.2832444906234741, Training Acc: 77.45%\n",
      "              Val Loss: 1.1417546272277832, Val Acc: 67.93%\n",
      "Epoch: 7237,     Training Loss: 0.28535136580467224, Training Acc: 77.45%\n",
      "              Val Loss: 1.1211237907409668, Val Acc: 67.93%\n",
      "Epoch: 7238,     Training Loss: 0.28349757194519043, Training Acc: 77.45%\n",
      "              Val Loss: 1.1205570697784424, Val Acc: 67.93%\n",
      "Epoch: 7239,     Training Loss: 0.28227561712265015, Training Acc: 77.45%\n",
      "              Val Loss: 1.1217427253723145, Val Acc: 67.93%\n",
      "Epoch: 7240,     Training Loss: 0.27376341819763184, Training Acc: 77.45%\n",
      "              Val Loss: 1.1233007907867432, Val Acc: 67.93%\n",
      "Epoch: 7241,     Training Loss: 0.2711791396141052, Training Acc: 77.46%\n",
      "              Val Loss: 1.1333646774291992, Val Acc: 67.93%\n",
      "Epoch: 7242,     Training Loss: 0.27500247955322266, Training Acc: 77.46%\n",
      "              Val Loss: 1.1256862878799438, Val Acc: 67.93%\n",
      "Epoch: 7243,     Training Loss: 0.2760603427886963, Training Acc: 77.46%\n",
      "              Val Loss: 1.1281518936157227, Val Acc: 67.93%\n",
      "Epoch: 7244,     Training Loss: 0.27235686779022217, Training Acc: 77.46%\n",
      "              Val Loss: 1.1133220195770264, Val Acc: 67.94%\n",
      "Epoch: 7245,     Training Loss: 0.27254050970077515, Training Acc: 77.46%\n",
      "              Val Loss: 1.134135365486145, Val Acc: 67.94%\n",
      "Epoch: 7246,     Training Loss: 0.27282586693763733, Training Acc: 77.46%\n",
      "              Val Loss: 1.1200644969940186, Val Acc: 67.94%\n",
      "Epoch: 7247,     Training Loss: 0.28036823868751526, Training Acc: 77.47%\n",
      "              Val Loss: 1.168898344039917, Val Acc: 67.94%\n",
      "Epoch: 7248,     Training Loss: 0.29760679602622986, Training Acc: 77.47%\n",
      "              Val Loss: 1.1736716032028198, Val Acc: 67.94%\n",
      "Epoch: 7249,     Training Loss: 0.34798938035964966, Training Acc: 77.47%\n",
      "              Val Loss: 1.2462021112442017, Val Acc: 67.94%\n",
      "Epoch: 7250,     Training Loss: 0.33794689178466797, Training Acc: 77.47%\n",
      "              Val Loss: 1.1755295991897583, Val Acc: 67.94%\n",
      "Epoch: 7251,     Training Loss: 0.37653592228889465, Training Acc: 77.47%\n",
      "              Val Loss: 1.225467562675476, Val Acc: 67.94%\n",
      "Epoch: 7252,     Training Loss: 0.32834571599960327, Training Acc: 77.47%\n",
      "              Val Loss: 1.1331040859222412, Val Acc: 67.94%\n",
      "Epoch: 7253,     Training Loss: 0.30789488554000854, Training Acc: 77.47%\n",
      "              Val Loss: 1.138870120048523, Val Acc: 67.94%\n",
      "Epoch: 7254,     Training Loss: 0.27633213996887207, Training Acc: 77.47%\n",
      "              Val Loss: 1.1624531745910645, Val Acc: 67.94%\n",
      "Epoch: 7255,     Training Loss: 0.28353172540664673, Training Acc: 77.48%\n",
      "              Val Loss: 1.1552493572235107, Val Acc: 67.94%\n",
      "Epoch: 7256,     Training Loss: 0.3243122398853302, Training Acc: 77.48%\n",
      "              Val Loss: 1.2193574905395508, Val Acc: 67.94%\n",
      "Epoch: 7257,     Training Loss: 0.313823401927948, Training Acc: 77.48%\n",
      "              Val Loss: 1.1574758291244507, Val Acc: 67.94%\n",
      "Epoch: 7258,     Training Loss: 0.3219168782234192, Training Acc: 77.48%\n",
      "              Val Loss: 1.1843936443328857, Val Acc: 67.94%\n",
      "Epoch: 7259,     Training Loss: 0.29530590772628784, Training Acc: 77.48%\n",
      "              Val Loss: 1.1579729318618774, Val Acc: 67.94%\n",
      "Epoch: 7260,     Training Loss: 0.29845380783081055, Training Acc: 77.48%\n",
      "              Val Loss: 1.1331807374954224, Val Acc: 67.94%\n",
      "Epoch: 7261,     Training Loss: 0.3015398681163788, Training Acc: 77.48%\n",
      "              Val Loss: 1.1761651039123535, Val Acc: 67.95%\n",
      "Epoch: 7262,     Training Loss: 0.2956123948097229, Training Acc: 77.48%\n",
      "              Val Loss: 1.1501151323318481, Val Acc: 67.95%\n",
      "Epoch: 7263,     Training Loss: 0.3158425986766815, Training Acc: 77.49%\n",
      "              Val Loss: 1.1809742450714111, Val Acc: 67.95%\n",
      "Epoch: 7264,     Training Loss: 0.30283573269844055, Training Acc: 77.49%\n",
      "              Val Loss: 1.1585179567337036, Val Acc: 67.95%\n",
      "Epoch: 7265,     Training Loss: 0.2884245812892914, Training Acc: 77.49%\n",
      "              Val Loss: 1.1449036598205566, Val Acc: 67.95%\n",
      "Epoch: 7266,     Training Loss: 0.27776479721069336, Training Acc: 77.49%\n",
      "              Val Loss: 1.1505619287490845, Val Acc: 67.95%\n",
      "Epoch: 7267,     Training Loss: 0.27526265382766724, Training Acc: 77.49%\n",
      "              Val Loss: 1.1830748319625854, Val Acc: 67.95%\n",
      "Epoch: 7268,     Training Loss: 0.2833758592605591, Training Acc: 77.49%\n",
      "              Val Loss: 1.1792618036270142, Val Acc: 67.95%\n",
      "Epoch: 7269,     Training Loss: 0.27963295578956604, Training Acc: 77.50%\n",
      "              Val Loss: 1.1482529640197754, Val Acc: 67.95%\n",
      "Epoch: 7270,     Training Loss: 0.2828120291233063, Training Acc: 77.50%\n",
      "              Val Loss: 1.1784546375274658, Val Acc: 67.95%\n",
      "Epoch: 7271,     Training Loss: 0.28367459774017334, Training Acc: 77.50%\n",
      "              Val Loss: 1.1632548570632935, Val Acc: 67.95%\n",
      "Epoch: 7272,     Training Loss: 0.293236643075943, Training Acc: 77.50%\n",
      "              Val Loss: 1.235729694366455, Val Acc: 67.95%\n",
      "Epoch: 7273,     Training Loss: 0.31074607372283936, Training Acc: 77.50%\n",
      "              Val Loss: 1.179571509361267, Val Acc: 67.95%\n",
      "Epoch: 7274,     Training Loss: 0.32668811082839966, Training Acc: 77.50%\n",
      "              Val Loss: 1.2152740955352783, Val Acc: 67.95%\n",
      "Epoch: 7275,     Training Loss: 0.3063250184059143, Training Acc: 77.50%\n",
      "              Val Loss: 1.1528840065002441, Val Acc: 67.95%\n",
      "Epoch: 7276,     Training Loss: 0.3093615472316742, Training Acc: 77.50%\n",
      "              Val Loss: 1.1747252941131592, Val Acc: 67.96%\n",
      "Epoch: 7277,     Training Loss: 0.2805493175983429, Training Acc: 77.51%\n",
      "              Val Loss: 1.1770797967910767, Val Acc: 67.96%\n",
      "Epoch: 7278,     Training Loss: 0.27948904037475586, Training Acc: 77.51%\n",
      "              Val Loss: 1.1520839929580688, Val Acc: 67.96%\n",
      "Epoch: 7279,     Training Loss: 0.2756122648715973, Training Acc: 77.51%\n",
      "              Val Loss: 1.1797771453857422, Val Acc: 67.96%\n",
      "Epoch: 7280,     Training Loss: 0.2818853259086609, Training Acc: 77.51%\n",
      "              Val Loss: 1.193554162979126, Val Acc: 67.96%\n",
      "Epoch: 7281,     Training Loss: 0.31120359897613525, Training Acc: 77.51%\n",
      "              Val Loss: 1.2440211772918701, Val Acc: 67.96%\n",
      "Epoch: 7282,     Training Loss: 0.313872367143631, Training Acc: 77.51%\n",
      "              Val Loss: 1.1944966316223145, Val Acc: 67.96%\n",
      "Epoch: 7283,     Training Loss: 0.36644795536994934, Training Acc: 77.51%\n",
      "              Val Loss: 1.2506691217422485, Val Acc: 67.96%\n",
      "Epoch: 7284,     Training Loss: 0.3218502104282379, Training Acc: 77.52%\n",
      "              Val Loss: 1.1513465642929077, Val Acc: 67.96%\n",
      "Epoch: 7285,     Training Loss: 0.31548649072647095, Training Acc: 77.52%\n",
      "              Val Loss: 1.1666362285614014, Val Acc: 67.96%\n",
      "Epoch: 7286,     Training Loss: 0.2820669710636139, Training Acc: 77.52%\n",
      "              Val Loss: 1.1487948894500732, Val Acc: 67.96%\n",
      "Epoch: 7287,     Training Loss: 0.2691301107406616, Training Acc: 77.52%\n",
      "              Val Loss: 1.1501975059509277, Val Acc: 67.96%\n",
      "Epoch: 7288,     Training Loss: 0.2784572243690491, Training Acc: 77.52%\n",
      "              Val Loss: 1.194227933883667, Val Acc: 67.96%\n",
      "Epoch: 7289,     Training Loss: 0.2862017750740051, Training Acc: 77.52%\n",
      "              Val Loss: 1.1626702547073364, Val Acc: 67.96%\n",
      "Epoch: 7290,     Training Loss: 0.28989556431770325, Training Acc: 77.52%\n",
      "              Val Loss: 1.216222882270813, Val Acc: 67.96%\n",
      "Epoch: 7291,     Training Loss: 0.28989115357398987, Training Acc: 77.53%\n",
      "              Val Loss: 1.1946172714233398, Val Acc: 67.96%\n",
      "Epoch: 7292,     Training Loss: 0.32107216119766235, Training Acc: 77.53%\n",
      "              Val Loss: 1.2177479267120361, Val Acc: 67.97%\n",
      "Epoch: 7293,     Training Loss: 0.2965596616268158, Training Acc: 77.53%\n",
      "              Val Loss: 1.181174874305725, Val Acc: 67.97%\n",
      "Epoch: 7294,     Training Loss: 0.2892857789993286, Training Acc: 77.53%\n",
      "              Val Loss: 1.1725420951843262, Val Acc: 67.97%\n",
      "Epoch: 7295,     Training Loss: 0.2759116590023041, Training Acc: 77.53%\n",
      "              Val Loss: 1.161058783531189, Val Acc: 67.97%\n",
      "Epoch: 7296,     Training Loss: 0.27183255553245544, Training Acc: 77.53%\n",
      "              Val Loss: 1.202500581741333, Val Acc: 67.97%\n",
      "Epoch: 7297,     Training Loss: 0.28438881039619446, Training Acc: 77.53%\n",
      "              Val Loss: 1.1649225950241089, Val Acc: 67.97%\n",
      "Epoch: 7298,     Training Loss: 0.27630847692489624, Training Acc: 77.54%\n",
      "              Val Loss: 1.1570181846618652, Val Acc: 67.97%\n",
      "Epoch: 7299,     Training Loss: 0.26965662837028503, Training Acc: 77.54%\n",
      "              Val Loss: 1.1706684827804565, Val Acc: 67.97%\n",
      "Epoch: 7300,     Training Loss: 0.2717326581478119, Training Acc: 77.54%\n",
      "              Val Loss: 1.1527117490768433, Val Acc: 67.97%\n",
      "Epoch: 7301,     Training Loss: 0.2768150568008423, Training Acc: 77.54%\n",
      "              Val Loss: 1.1993622779846191, Val Acc: 67.97%\n",
      "Epoch: 7302,     Training Loss: 0.2796357572078705, Training Acc: 77.54%\n",
      "              Val Loss: 1.159840703010559, Val Acc: 67.97%\n",
      "Epoch: 7303,     Training Loss: 0.2957305312156677, Training Acc: 77.54%\n",
      "              Val Loss: 1.2307820320129395, Val Acc: 67.97%\n",
      "Epoch: 7304,     Training Loss: 0.308645635843277, Training Acc: 77.55%\n",
      "              Val Loss: 1.202660083770752, Val Acc: 67.97%\n",
      "Epoch: 7305,     Training Loss: 0.34819066524505615, Training Acc: 77.55%\n",
      "              Val Loss: 1.272822618484497, Val Acc: 67.97%\n",
      "Epoch: 7306,     Training Loss: 0.32719480991363525, Training Acc: 77.55%\n",
      "              Val Loss: 1.1810587644577026, Val Acc: 67.97%\n",
      "Epoch: 7307,     Training Loss: 0.3351595401763916, Training Acc: 77.55%\n",
      "              Val Loss: 1.2070021629333496, Val Acc: 67.97%\n",
      "Epoch: 7308,     Training Loss: 0.29448673129081726, Training Acc: 77.55%\n",
      "              Val Loss: 1.1678775548934937, Val Acc: 67.98%\n",
      "Epoch: 7309,     Training Loss: 0.28020596504211426, Training Acc: 77.55%\n",
      "              Val Loss: 1.1687884330749512, Val Acc: 67.98%\n",
      "Epoch: 7310,     Training Loss: 0.2736692428588867, Training Acc: 77.55%\n",
      "              Val Loss: 1.184872031211853, Val Acc: 67.98%\n",
      "Epoch: 7311,     Training Loss: 0.2713128328323364, Training Acc: 77.55%\n",
      "              Val Loss: 1.1665395498275757, Val Acc: 67.98%\n",
      "Epoch: 7312,     Training Loss: 0.2884301245212555, Training Acc: 77.56%\n",
      "              Val Loss: 1.2030861377716064, Val Acc: 67.98%\n",
      "Epoch: 7313,     Training Loss: 0.2899993062019348, Training Acc: 77.56%\n",
      "              Val Loss: 1.165366530418396, Val Acc: 67.98%\n",
      "Epoch: 7314,     Training Loss: 0.3012661039829254, Training Acc: 77.56%\n",
      "              Val Loss: 1.2456632852554321, Val Acc: 67.98%\n",
      "Epoch: 7315,     Training Loss: 0.30770206451416016, Training Acc: 77.56%\n",
      "              Val Loss: 1.1746656894683838, Val Acc: 67.98%\n",
      "Epoch: 7316,     Training Loss: 0.3299206495285034, Training Acc: 77.56%\n",
      "              Val Loss: 1.1987422704696655, Val Acc: 67.98%\n",
      "Epoch: 7317,     Training Loss: 0.29545530676841736, Training Acc: 77.56%\n",
      "              Val Loss: 1.1705392599105835, Val Acc: 67.98%\n",
      "Epoch: 7318,     Training Loss: 0.2947538197040558, Training Acc: 77.56%\n",
      "              Val Loss: 1.1689203977584839, Val Acc: 67.98%\n",
      "Epoch: 7319,     Training Loss: 0.2709941267967224, Training Acc: 77.57%\n",
      "              Val Loss: 1.1594570875167847, Val Acc: 67.98%\n",
      "Epoch: 7320,     Training Loss: 0.267365425825119, Training Acc: 77.57%\n",
      "              Val Loss: 1.1757797002792358, Val Acc: 67.98%\n",
      "Epoch: 7321,     Training Loss: 0.27699804306030273, Training Acc: 77.57%\n",
      "              Val Loss: 1.188441514968872, Val Acc: 67.98%\n",
      "Epoch: 7322,     Training Loss: 0.27631524205207825, Training Acc: 77.57%\n",
      "              Val Loss: 1.1685928106307983, Val Acc: 67.98%\n",
      "Epoch: 7323,     Training Loss: 0.2956298887729645, Training Acc: 77.57%\n",
      "              Val Loss: 1.2655431032180786, Val Acc: 67.98%\n",
      "Epoch: 7324,     Training Loss: 0.31085139513015747, Training Acc: 77.57%\n",
      "              Val Loss: 1.2019848823547363, Val Acc: 67.99%\n",
      "Epoch: 7325,     Training Loss: 0.3585747480392456, Training Acc: 77.57%\n",
      "              Val Loss: 1.246219277381897, Val Acc: 67.99%\n",
      "Epoch: 7326,     Training Loss: 0.3166579008102417, Training Acc: 77.57%\n",
      "              Val Loss: 1.1928316354751587, Val Acc: 67.99%\n",
      "Epoch: 7327,     Training Loss: 0.32502347230911255, Training Acc: 77.58%\n",
      "              Val Loss: 1.1652042865753174, Val Acc: 67.99%\n",
      "Epoch: 7328,     Training Loss: 0.27337563037872314, Training Acc: 77.58%\n",
      "              Val Loss: 1.179343819618225, Val Acc: 67.99%\n",
      "Epoch: 7329,     Training Loss: 0.27842071652412415, Training Acc: 77.58%\n",
      "              Val Loss: 1.1866825819015503, Val Acc: 67.99%\n",
      "Epoch: 7330,     Training Loss: 0.3118208050727844, Training Acc: 77.58%\n",
      "              Val Loss: 1.2329200506210327, Val Acc: 67.99%\n",
      "Epoch: 7331,     Training Loss: 0.301809698343277, Training Acc: 77.58%\n",
      "              Val Loss: 1.1906452178955078, Val Acc: 67.99%\n",
      "Epoch: 7332,     Training Loss: 0.3280985951423645, Training Acc: 77.58%\n",
      "              Val Loss: 1.2087537050247192, Val Acc: 67.99%\n",
      "Epoch: 7333,     Training Loss: 0.2805134057998657, Training Acc: 77.58%\n",
      "              Val Loss: 1.196319341659546, Val Acc: 67.99%\n",
      "Epoch: 7334,     Training Loss: 0.27232447266578674, Training Acc: 77.59%\n",
      "              Val Loss: 1.1608691215515137, Val Acc: 67.99%\n",
      "Epoch: 7335,     Training Loss: 0.2897183299064636, Training Acc: 77.59%\n",
      "              Val Loss: 1.2311490774154663, Val Acc: 67.99%\n",
      "Epoch: 7336,     Training Loss: 0.29707926511764526, Training Acc: 77.59%\n",
      "              Val Loss: 1.2159310579299927, Val Acc: 67.99%\n",
      "Epoch: 7337,     Training Loss: 0.3356494903564453, Training Acc: 77.59%\n",
      "              Val Loss: 1.225254774093628, Val Acc: 67.99%\n",
      "Epoch: 7338,     Training Loss: 0.29181480407714844, Training Acc: 77.59%\n",
      "              Val Loss: 1.1539465188980103, Val Acc: 67.99%\n",
      "Epoch: 7339,     Training Loss: 0.26555076241493225, Training Acc: 77.59%\n",
      "              Val Loss: 1.1756768226623535, Val Acc: 67.99%\n",
      "Epoch: 7340,     Training Loss: 0.27905046939849854, Training Acc: 77.59%\n",
      "              Val Loss: 1.2030634880065918, Val Acc: 67.99%\n",
      "Epoch: 7341,     Training Loss: 0.27753153443336487, Training Acc: 77.60%\n",
      "              Val Loss: 1.1976184844970703, Val Acc: 68.00%\n",
      "Epoch: 7342,     Training Loss: 0.30617427825927734, Training Acc: 77.60%\n",
      "              Val Loss: 1.2544127702713013, Val Acc: 68.00%\n",
      "Epoch: 7343,     Training Loss: 0.29382410645484924, Training Acc: 77.60%\n",
      "              Val Loss: 1.1683675050735474, Val Acc: 68.00%\n",
      "Epoch: 7344,     Training Loss: 0.27204883098602295, Training Acc: 77.60%\n",
      "              Val Loss: 1.2075982093811035, Val Acc: 68.00%\n",
      "Epoch: 7345,     Training Loss: 0.29005810618400574, Training Acc: 77.60%\n",
      "              Val Loss: 1.1715219020843506, Val Acc: 68.00%\n",
      "Epoch: 7346,     Training Loss: 0.27557647228240967, Training Acc: 77.60%\n",
      "              Val Loss: 1.2335304021835327, Val Acc: 68.00%\n",
      "Epoch: 7347,     Training Loss: 0.28843653202056885, Training Acc: 77.60%\n",
      "              Val Loss: 1.180871605873108, Val Acc: 68.00%\n",
      "Epoch: 7348,     Training Loss: 0.2910328209400177, Training Acc: 77.61%\n",
      "              Val Loss: 1.2080973386764526, Val Acc: 68.00%\n",
      "Epoch: 7349,     Training Loss: 0.2809259593486786, Training Acc: 77.61%\n",
      "              Val Loss: 1.1675857305526733, Val Acc: 68.00%\n",
      "Epoch: 7350,     Training Loss: 0.2811065912246704, Training Acc: 77.61%\n",
      "              Val Loss: 1.2121108770370483, Val Acc: 68.00%\n",
      "Epoch: 7351,     Training Loss: 0.27720728516578674, Training Acc: 77.61%\n",
      "              Val Loss: 1.1969935894012451, Val Acc: 68.00%\n",
      "Epoch: 7352,     Training Loss: 0.29107969999313354, Training Acc: 77.61%\n",
      "              Val Loss: 1.211957573890686, Val Acc: 68.00%\n",
      "Epoch: 7353,     Training Loss: 0.2734632194042206, Training Acc: 77.61%\n",
      "              Val Loss: 1.1640045642852783, Val Acc: 68.00%\n",
      "Epoch: 7354,     Training Loss: 0.26437243819236755, Training Acc: 77.61%\n",
      "              Val Loss: 1.1767712831497192, Val Acc: 68.00%\n",
      "Epoch: 7355,     Training Loss: 0.26440125703811646, Training Acc: 77.62%\n",
      "              Val Loss: 1.1903284788131714, Val Acc: 68.00%\n",
      "Epoch: 7356,     Training Loss: 0.26308050751686096, Training Acc: 77.62%\n",
      "              Val Loss: 1.18330717086792, Val Acc: 68.01%\n",
      "Epoch: 7357,     Training Loss: 0.270746111869812, Training Acc: 77.62%\n",
      "              Val Loss: 1.2249755859375, Val Acc: 68.01%\n",
      "Epoch: 7358,     Training Loss: 0.275471568107605, Training Acc: 77.62%\n",
      "              Val Loss: 1.1755578517913818, Val Acc: 68.01%\n",
      "Epoch: 7359,     Training Loss: 0.2992111146450043, Training Acc: 77.62%\n",
      "              Val Loss: 1.2642863988876343, Val Acc: 68.01%\n",
      "Epoch: 7360,     Training Loss: 0.3112947344779968, Training Acc: 77.62%\n",
      "              Val Loss: 1.2459003925323486, Val Acc: 68.01%\n",
      "Epoch: 7361,     Training Loss: 0.37065425515174866, Training Acc: 77.62%\n",
      "              Val Loss: 1.2665156126022339, Val Acc: 68.01%\n",
      "Epoch: 7362,     Training Loss: 0.3083457052707672, Training Acc: 77.63%\n",
      "              Val Loss: 1.166571855545044, Val Acc: 68.01%\n",
      "Epoch: 7363,     Training Loss: 0.26496970653533936, Training Acc: 77.63%\n",
      "              Val Loss: 1.1716331243515015, Val Acc: 68.01%\n",
      "Epoch: 7364,     Training Loss: 0.2800438404083252, Training Acc: 77.63%\n",
      "              Val Loss: 1.2119872570037842, Val Acc: 68.01%\n",
      "Epoch: 7365,     Training Loss: 0.2859343886375427, Training Acc: 77.63%\n",
      "              Val Loss: 1.2002537250518799, Val Acc: 68.01%\n",
      "Epoch: 7366,     Training Loss: 0.32228022813796997, Training Acc: 77.63%\n",
      "              Val Loss: 1.2675055265426636, Val Acc: 68.01%\n",
      "Epoch: 7367,     Training Loss: 0.30525365471839905, Training Acc: 77.63%\n",
      "              Val Loss: 1.1609408855438232, Val Acc: 68.01%\n",
      "Epoch: 7368,     Training Loss: 0.27118656039237976, Training Acc: 77.63%\n",
      "              Val Loss: 1.2025208473205566, Val Acc: 68.01%\n",
      "Epoch: 7369,     Training Loss: 0.291445255279541, Training Acc: 77.64%\n",
      "              Val Loss: 1.1736092567443848, Val Acc: 68.01%\n",
      "Epoch: 7370,     Training Loss: 0.27143967151641846, Training Acc: 77.64%\n",
      "              Val Loss: 1.218357801437378, Val Acc: 68.01%\n",
      "Epoch: 7371,     Training Loss: 0.2758963108062744, Training Acc: 77.64%\n",
      "              Val Loss: 1.2014058828353882, Val Acc: 68.01%\n",
      "Epoch: 7372,     Training Loss: 0.27244073152542114, Training Acc: 77.64%\n",
      "              Val Loss: 1.1982191801071167, Val Acc: 68.01%\n",
      "Epoch: 7373,     Training Loss: 0.26723960041999817, Training Acc: 77.64%\n",
      "              Val Loss: 1.191812515258789, Val Acc: 68.02%\n",
      "Epoch: 7374,     Training Loss: 0.2790205180644989, Training Acc: 77.64%\n",
      "              Val Loss: 1.1957730054855347, Val Acc: 68.02%\n",
      "Epoch: 7375,     Training Loss: 0.26614776253700256, Training Acc: 77.64%\n",
      "              Val Loss: 1.2068451642990112, Val Acc: 68.02%\n",
      "Epoch: 7376,     Training Loss: 0.2726113796234131, Training Acc: 77.65%\n",
      "              Val Loss: 1.1922794580459595, Val Acc: 68.02%\n",
      "Epoch: 7377,     Training Loss: 0.2698970139026642, Training Acc: 77.65%\n",
      "              Val Loss: 1.1711852550506592, Val Acc: 68.02%\n",
      "Epoch: 7378,     Training Loss: 0.2630710005760193, Training Acc: 77.65%\n",
      "              Val Loss: 1.1902074813842773, Val Acc: 68.02%\n",
      "Epoch: 7379,     Training Loss: 0.26410186290740967, Training Acc: 77.65%\n",
      "              Val Loss: 1.1828733682632446, Val Acc: 68.02%\n",
      "Epoch: 7380,     Training Loss: 0.2692527770996094, Training Acc: 77.65%\n",
      "              Val Loss: 1.2142359018325806, Val Acc: 68.02%\n",
      "Epoch: 7381,     Training Loss: 0.2637232542037964, Training Acc: 77.65%\n",
      "              Val Loss: 1.193120002746582, Val Acc: 68.02%\n",
      "Epoch: 7382,     Training Loss: 0.26365670561790466, Training Acc: 77.66%\n",
      "              Val Loss: 1.2106105089187622, Val Acc: 68.02%\n",
      "Epoch: 7383,     Training Loss: 0.27191099524497986, Training Acc: 77.66%\n",
      "              Val Loss: 1.188710331916809, Val Acc: 68.02%\n",
      "Epoch: 7384,     Training Loss: 0.26952508091926575, Training Acc: 77.66%\n",
      "              Val Loss: 1.2563692331314087, Val Acc: 68.02%\n",
      "Epoch: 7385,     Training Loss: 0.28701186180114746, Training Acc: 77.66%\n",
      "              Val Loss: 1.2226723432540894, Val Acc: 68.02%\n",
      "Epoch: 7386,     Training Loss: 0.3381907641887665, Training Acc: 77.66%\n",
      "              Val Loss: 1.2977832555770874, Val Acc: 68.02%\n",
      "Epoch: 7387,     Training Loss: 0.3204807937145233, Training Acc: 77.66%\n",
      "              Val Loss: 1.2599719762802124, Val Acc: 68.02%\n",
      "Epoch: 7388,     Training Loss: 0.37212276458740234, Training Acc: 77.66%\n",
      "              Val Loss: 1.2437511682510376, Val Acc: 68.02%\n",
      "Epoch: 7389,     Training Loss: 0.29166197776794434, Training Acc: 77.66%\n",
      "              Val Loss: 1.1806644201278687, Val Acc: 68.03%\n",
      "Epoch: 7390,     Training Loss: 0.26731279492378235, Training Acc: 77.67%\n",
      "              Val Loss: 1.1972007751464844, Val Acc: 68.03%\n",
      "Epoch: 7391,     Training Loss: 0.29535141587257385, Training Acc: 77.67%\n",
      "              Val Loss: 1.2582412958145142, Val Acc: 68.03%\n",
      "Epoch: 7392,     Training Loss: 0.310569167137146, Training Acc: 77.67%\n",
      "              Val Loss: 1.2253338098526, Val Acc: 68.03%\n",
      "Epoch: 7393,     Training Loss: 0.36431217193603516, Training Acc: 77.67%\n",
      "              Val Loss: 1.2992051839828491, Val Acc: 68.03%\n",
      "Epoch: 7394,     Training Loss: 0.313788503408432, Training Acc: 77.67%\n",
      "              Val Loss: 1.158420205116272, Val Acc: 68.03%\n",
      "Epoch: 7395,     Training Loss: 0.2794109284877777, Training Acc: 77.67%\n",
      "              Val Loss: 1.1820660829544067, Val Acc: 68.03%\n",
      "Epoch: 7396,     Training Loss: 0.2872808575630188, Training Acc: 77.67%\n",
      "              Val Loss: 1.1950554847717285, Val Acc: 68.03%\n",
      "Epoch: 7397,     Training Loss: 0.2763167917728424, Training Acc: 77.68%\n",
      "              Val Loss: 1.1968718767166138, Val Acc: 68.03%\n",
      "Epoch: 7398,     Training Loss: 0.29551881551742554, Training Acc: 77.68%\n",
      "              Val Loss: 1.2490003108978271, Val Acc: 68.03%\n",
      "Epoch: 7399,     Training Loss: 0.29113855957984924, Training Acc: 77.68%\n",
      "              Val Loss: 1.21340012550354, Val Acc: 68.03%\n",
      "Epoch: 7400,     Training Loss: 0.28592514991760254, Training Acc: 77.68%\n",
      "              Val Loss: 1.2397652864456177, Val Acc: 68.03%\n",
      "Epoch: 7401,     Training Loss: 0.3092520236968994, Training Acc: 77.68%\n",
      "              Val Loss: 1.1894259452819824, Val Acc: 68.03%\n",
      "Epoch: 7402,     Training Loss: 0.2980467677116394, Training Acc: 77.68%\n",
      "              Val Loss: 1.2795825004577637, Val Acc: 68.03%\n",
      "Epoch: 7403,     Training Loss: 0.30819159746170044, Training Acc: 77.68%\n",
      "              Val Loss: 1.1953957080841064, Val Acc: 68.03%\n",
      "Epoch: 7404,     Training Loss: 0.29266634583473206, Training Acc: 77.68%\n",
      "              Val Loss: 1.1906781196594238, Val Acc: 68.03%\n",
      "Epoch: 7405,     Training Loss: 0.2605319321155548, Training Acc: 77.69%\n",
      "              Val Loss: 1.2049989700317383, Val Acc: 68.03%\n",
      "Epoch: 7406,     Training Loss: 0.27876952290534973, Training Acc: 77.69%\n",
      "              Val Loss: 1.1845252513885498, Val Acc: 68.03%\n",
      "Epoch: 7407,     Training Loss: 0.2739323377609253, Training Acc: 77.69%\n",
      "              Val Loss: 1.2218836545944214, Val Acc: 68.04%\n",
      "Epoch: 7408,     Training Loss: 0.26927420496940613, Training Acc: 77.69%\n",
      "              Val Loss: 1.210839867591858, Val Acc: 68.04%\n",
      "Epoch: 7409,     Training Loss: 0.2886034846305847, Training Acc: 77.69%\n",
      "              Val Loss: 1.2448092699050903, Val Acc: 68.04%\n",
      "Epoch: 7410,     Training Loss: 0.29258185625076294, Training Acc: 77.69%\n",
      "              Val Loss: 1.2089918851852417, Val Acc: 68.04%\n",
      "Epoch: 7411,     Training Loss: 0.30848193168640137, Training Acc: 77.70%\n",
      "              Val Loss: 1.328314185142517, Val Acc: 68.04%\n",
      "Epoch: 7412,     Training Loss: 0.3425291180610657, Training Acc: 77.70%\n",
      "              Val Loss: 1.307856559753418, Val Acc: 68.04%\n",
      "Epoch: 7413,     Training Loss: 0.4613927900791168, Training Acc: 77.70%\n",
      "              Val Loss: 1.2383735179901123, Val Acc: 68.04%\n",
      "Epoch: 7414,     Training Loss: 0.3120373487472534, Training Acc: 77.70%\n",
      "              Val Loss: 1.433416485786438, Val Acc: 68.04%\n",
      "Epoch: 7415,     Training Loss: 0.4217040538787842, Training Acc: 77.70%\n",
      "              Val Loss: 1.3803200721740723, Val Acc: 68.04%\n",
      "Epoch: 7416,     Training Loss: 0.5601566433906555, Training Acc: 77.70%\n",
      "              Val Loss: 1.386164903640747, Val Acc: 68.04%\n",
      "Epoch: 7417,     Training Loss: 0.5256494283676147, Training Acc: 77.70%\n",
      "              Val Loss: 1.1753549575805664, Val Acc: 68.04%\n",
      "Epoch: 7418,     Training Loss: 0.3892073929309845, Training Acc: 77.70%\n",
      "              Val Loss: 1.2790610790252686, Val Acc: 68.04%\n",
      "Epoch: 7419,     Training Loss: 0.41476768255233765, Training Acc: 77.70%\n",
      "              Val Loss: 1.356111764907837, Val Acc: 68.04%\n",
      "Epoch: 7420,     Training Loss: 0.4382043778896332, Training Acc: 77.70%\n",
      "              Val Loss: 1.2441232204437256, Val Acc: 68.04%\n",
      "Epoch: 7421,     Training Loss: 0.43444764614105225, Training Acc: 77.70%\n",
      "              Val Loss: 1.204659342765808, Val Acc: 68.04%\n",
      "Epoch: 7422,     Training Loss: 0.4259939193725586, Training Acc: 77.70%\n",
      "              Val Loss: 1.189363718032837, Val Acc: 68.04%\n",
      "Epoch: 7423,     Training Loss: 0.4387073516845703, Training Acc: 77.70%\n",
      "              Val Loss: 1.182355523109436, Val Acc: 68.04%\n",
      "Epoch: 7424,     Training Loss: 0.3585645258426666, Training Acc: 77.70%\n",
      "              Val Loss: 1.4607566595077515, Val Acc: 68.04%\n",
      "Epoch: 7425,     Training Loss: 0.4929392337799072, Training Acc: 77.70%\n",
      "              Val Loss: 1.2612957954406738, Val Acc: 68.04%\n",
      "Epoch: 7426,     Training Loss: 0.4288747012615204, Training Acc: 77.70%\n",
      "              Val Loss: 1.3624927997589111, Val Acc: 68.04%\n",
      "Epoch: 7427,     Training Loss: 0.4553401470184326, Training Acc: 77.70%\n",
      "              Val Loss: 1.2414417266845703, Val Acc: 68.04%\n",
      "Epoch: 7428,     Training Loss: 0.35413840413093567, Training Acc: 77.71%\n",
      "              Val Loss: 1.451383352279663, Val Acc: 68.04%\n",
      "Epoch: 7429,     Training Loss: 0.44022664427757263, Training Acc: 77.71%\n",
      "              Val Loss: 1.2216334342956543, Val Acc: 68.04%\n",
      "Epoch: 7430,     Training Loss: 0.33765506744384766, Training Acc: 77.71%\n",
      "              Val Loss: 1.2254961729049683, Val Acc: 68.04%\n",
      "Epoch: 7431,     Training Loss: 0.3593309819698334, Training Acc: 77.71%\n",
      "              Val Loss: 1.194715142250061, Val Acc: 68.05%\n",
      "Epoch: 7432,     Training Loss: 0.3270716369152069, Training Acc: 77.71%\n",
      "              Val Loss: 1.2006504535675049, Val Acc: 68.05%\n",
      "Epoch: 7433,     Training Loss: 0.3358955383300781, Training Acc: 77.71%\n",
      "              Val Loss: 1.224046230316162, Val Acc: 68.05%\n",
      "Epoch: 7434,     Training Loss: 0.3362784683704376, Training Acc: 77.71%\n",
      "              Val Loss: 1.1857508420944214, Val Acc: 68.05%\n",
      "Epoch: 7435,     Training Loss: 0.30275458097457886, Training Acc: 77.71%\n",
      "              Val Loss: 1.1862690448760986, Val Acc: 68.05%\n",
      "Epoch: 7436,     Training Loss: 0.3244568705558777, Training Acc: 77.71%\n",
      "              Val Loss: 1.1804693937301636, Val Acc: 68.05%\n",
      "Epoch: 7437,     Training Loss: 0.2968239486217499, Training Acc: 77.72%\n",
      "              Val Loss: 1.2459015846252441, Val Acc: 68.05%\n",
      "Epoch: 7438,     Training Loss: 0.30589407682418823, Training Acc: 77.72%\n",
      "              Val Loss: 1.2396396398544312, Val Acc: 68.05%\n",
      "Epoch: 7439,     Training Loss: 0.33576878905296326, Training Acc: 77.72%\n",
      "              Val Loss: 1.2721222639083862, Val Acc: 68.05%\n",
      "Epoch: 7440,     Training Loss: 0.3277781009674072, Training Acc: 77.72%\n",
      "              Val Loss: 1.1625585556030273, Val Acc: 68.05%\n",
      "Epoch: 7441,     Training Loss: 0.3514026999473572, Training Acc: 77.72%\n",
      "              Val Loss: 1.1587265729904175, Val Acc: 68.05%\n",
      "Epoch: 7442,     Training Loss: 0.2902425527572632, Training Acc: 77.72%\n",
      "              Val Loss: 1.141905665397644, Val Acc: 68.05%\n",
      "Epoch: 7443,     Training Loss: 0.28229889273643494, Training Acc: 77.72%\n",
      "              Val Loss: 1.1524502038955688, Val Acc: 68.05%\n",
      "Epoch: 7444,     Training Loss: 0.3200322091579437, Training Acc: 77.72%\n",
      "              Val Loss: 1.2673826217651367, Val Acc: 68.05%\n",
      "Epoch: 7445,     Training Loss: 0.331120103597641, Training Acc: 77.73%\n",
      "              Val Loss: 1.2286732196807861, Val Acc: 68.05%\n",
      "Epoch: 7446,     Training Loss: 0.38557183742523193, Training Acc: 77.73%\n",
      "              Val Loss: 1.225450038909912, Val Acc: 68.05%\n",
      "Epoch: 7447,     Training Loss: 0.2922058403491974, Training Acc: 77.73%\n",
      "              Val Loss: 1.270127773284912, Val Acc: 68.05%\n",
      "Epoch: 7448,     Training Loss: 0.3198448121547699, Training Acc: 77.73%\n",
      "              Val Loss: 1.2902076244354248, Val Acc: 68.05%\n",
      "Epoch: 7449,     Training Loss: 0.42512741684913635, Training Acc: 77.73%\n",
      "              Val Loss: 1.2606357336044312, Val Acc: 68.05%\n",
      "Epoch: 7450,     Training Loss: 0.30812713503837585, Training Acc: 77.73%\n",
      "              Val Loss: 1.243331789970398, Val Acc: 68.05%\n",
      "Epoch: 7451,     Training Loss: 0.3053913712501526, Training Acc: 77.73%\n",
      "              Val Loss: 1.2232190370559692, Val Acc: 68.05%\n",
      "Epoch: 7452,     Training Loss: 0.35581284761428833, Training Acc: 77.73%\n",
      "              Val Loss: 1.2568678855895996, Val Acc: 68.05%\n",
      "Epoch: 7453,     Training Loss: 0.30737608671188354, Training Acc: 77.73%\n",
      "              Val Loss: 1.189897060394287, Val Acc: 68.06%\n",
      "Epoch: 7454,     Training Loss: 0.2798543870449066, Training Acc: 77.74%\n",
      "              Val Loss: 1.1825801134109497, Val Acc: 68.06%\n",
      "Epoch: 7455,     Training Loss: 0.3197977542877197, Training Acc: 77.74%\n",
      "              Val Loss: 1.2465028762817383, Val Acc: 68.06%\n",
      "Epoch: 7456,     Training Loss: 0.31277140974998474, Training Acc: 77.74%\n",
      "              Val Loss: 1.1549499034881592, Val Acc: 68.06%\n",
      "Epoch: 7457,     Training Loss: 0.2810855209827423, Training Acc: 77.74%\n",
      "              Val Loss: 1.1730204820632935, Val Acc: 68.06%\n",
      "Epoch: 7458,     Training Loss: 0.2807104289531708, Training Acc: 77.74%\n",
      "              Val Loss: 1.2502202987670898, Val Acc: 68.06%\n",
      "Epoch: 7459,     Training Loss: 0.29965147376060486, Training Acc: 77.74%\n",
      "              Val Loss: 1.1852059364318848, Val Acc: 68.06%\n",
      "Epoch: 7460,     Training Loss: 0.2918042838573456, Training Acc: 77.74%\n",
      "              Val Loss: 1.214920163154602, Val Acc: 68.06%\n",
      "Epoch: 7461,     Training Loss: 0.27810370922088623, Training Acc: 77.74%\n",
      "              Val Loss: 1.1932644844055176, Val Acc: 68.06%\n",
      "Epoch: 7462,     Training Loss: 0.27862849831581116, Training Acc: 77.75%\n",
      "              Val Loss: 1.146721601486206, Val Acc: 68.06%\n",
      "Epoch: 7463,     Training Loss: 0.2741636037826538, Training Acc: 77.75%\n",
      "              Val Loss: 1.1799383163452148, Val Acc: 68.06%\n",
      "Epoch: 7464,     Training Loss: 0.27935099601745605, Training Acc: 77.75%\n",
      "              Val Loss: 1.1635901927947998, Val Acc: 68.06%\n",
      "Epoch: 7465,     Training Loss: 0.2788015902042389, Training Acc: 77.75%\n",
      "              Val Loss: 1.1918214559555054, Val Acc: 68.06%\n",
      "Epoch: 7466,     Training Loss: 0.2656487226486206, Training Acc: 77.75%\n",
      "              Val Loss: 1.1854016780853271, Val Acc: 68.06%\n",
      "Epoch: 7467,     Training Loss: 0.2672520875930786, Training Acc: 77.75%\n",
      "              Val Loss: 1.1935172080993652, Val Acc: 68.06%\n",
      "Epoch: 7468,     Training Loss: 0.2734445631504059, Training Acc: 77.76%\n",
      "              Val Loss: 1.1899805068969727, Val Acc: 68.06%\n",
      "Epoch: 7469,     Training Loss: 0.26590800285339355, Training Acc: 77.76%\n",
      "              Val Loss: 1.177323579788208, Val Acc: 68.06%\n",
      "Epoch: 7470,     Training Loss: 0.2645213007926941, Training Acc: 77.76%\n",
      "              Val Loss: 1.1905006170272827, Val Acc: 68.06%\n",
      "Epoch: 7471,     Training Loss: 0.262159526348114, Training Acc: 77.76%\n",
      "              Val Loss: 1.1843873262405396, Val Acc: 68.06%\n",
      "Epoch: 7472,     Training Loss: 0.25771617889404297, Training Acc: 77.76%\n",
      "              Val Loss: 1.172243595123291, Val Acc: 68.07%\n",
      "Epoch: 7473,     Training Loss: 0.2623749077320099, Training Acc: 77.76%\n",
      "              Val Loss: 1.200535774230957, Val Acc: 68.07%\n",
      "Epoch: 7474,     Training Loss: 0.2630269229412079, Training Acc: 77.76%\n",
      "              Val Loss: 1.1839042901992798, Val Acc: 68.07%\n",
      "Epoch: 7475,     Training Loss: 0.260212779045105, Training Acc: 77.77%\n",
      "              Val Loss: 1.1986324787139893, Val Acc: 68.07%\n",
      "Epoch: 7476,     Training Loss: 0.2567741870880127, Training Acc: 77.77%\n",
      "              Val Loss: 1.1958551406860352, Val Acc: 68.07%\n",
      "Epoch: 7477,     Training Loss: 0.25577759742736816, Training Acc: 77.77%\n",
      "              Val Loss: 1.1892480850219727, Val Acc: 68.07%\n",
      "Epoch: 7478,     Training Loss: 0.2568477690219879, Training Acc: 77.77%\n",
      "              Val Loss: 1.2012434005737305, Val Acc: 68.07%\n",
      "Epoch: 7479,     Training Loss: 0.25693005323410034, Training Acc: 77.77%\n",
      "              Val Loss: 1.1970049142837524, Val Acc: 68.07%\n",
      "Epoch: 7480,     Training Loss: 0.2581927180290222, Training Acc: 77.77%\n",
      "              Val Loss: 1.1957221031188965, Val Acc: 68.07%\n",
      "Epoch: 7481,     Training Loss: 0.25718703866004944, Training Acc: 77.78%\n",
      "              Val Loss: 1.1909301280975342, Val Acc: 68.07%\n",
      "Epoch: 7482,     Training Loss: 0.2553107738494873, Training Acc: 77.78%\n",
      "              Val Loss: 1.187912106513977, Val Acc: 68.07%\n",
      "Epoch: 7483,     Training Loss: 0.25447705388069153, Training Acc: 77.78%\n",
      "              Val Loss: 1.2015776634216309, Val Acc: 68.07%\n",
      "Epoch: 7484,     Training Loss: 0.25600185990333557, Training Acc: 77.78%\n",
      "              Val Loss: 1.1904339790344238, Val Acc: 68.07%\n",
      "Epoch: 7485,     Training Loss: 0.2573663592338562, Training Acc: 77.78%\n",
      "              Val Loss: 1.2136255502700806, Val Acc: 68.07%\n",
      "Epoch: 7486,     Training Loss: 0.25880393385887146, Training Acc: 77.78%\n",
      "              Val Loss: 1.1827871799468994, Val Acc: 68.07%\n",
      "Epoch: 7487,     Training Loss: 0.26601311564445496, Training Acc: 77.79%\n",
      "              Val Loss: 1.2321950197219849, Val Acc: 68.07%\n",
      "Epoch: 7488,     Training Loss: 0.27110227942466736, Training Acc: 77.79%\n",
      "              Val Loss: 1.197310447692871, Val Acc: 68.08%\n",
      "Epoch: 7489,     Training Loss: 0.28780144453048706, Training Acc: 77.79%\n",
      "              Val Loss: 1.2384428977966309, Val Acc: 68.08%\n",
      "Epoch: 7490,     Training Loss: 0.27803710103034973, Training Acc: 77.79%\n",
      "              Val Loss: 1.1882295608520508, Val Acc: 68.08%\n",
      "Epoch: 7491,     Training Loss: 0.27699023485183716, Training Acc: 77.79%\n",
      "              Val Loss: 1.1982083320617676, Val Acc: 68.08%\n",
      "Epoch: 7492,     Training Loss: 0.26107949018478394, Training Acc: 77.79%\n",
      "              Val Loss: 1.1828733682632446, Val Acc: 68.08%\n",
      "Epoch: 7493,     Training Loss: 0.2534724175930023, Training Acc: 77.79%\n",
      "              Val Loss: 1.1865966320037842, Val Acc: 68.08%\n",
      "Epoch: 7494,     Training Loss: 0.2533758878707886, Training Acc: 77.80%\n",
      "              Val Loss: 1.2143000364303589, Val Acc: 68.08%\n",
      "Epoch: 7495,     Training Loss: 0.2604345977306366, Training Acc: 77.80%\n",
      "              Val Loss: 1.2018206119537354, Val Acc: 68.08%\n",
      "Epoch: 7496,     Training Loss: 0.27720096707344055, Training Acc: 77.80%\n",
      "              Val Loss: 1.2498301267623901, Val Acc: 68.08%\n",
      "Epoch: 7497,     Training Loss: 0.27915093302726746, Training Acc: 77.80%\n",
      "              Val Loss: 1.2183353900909424, Val Acc: 68.08%\n",
      "Epoch: 7498,     Training Loss: 0.2972049415111542, Training Acc: 77.80%\n",
      "              Val Loss: 1.2549152374267578, Val Acc: 68.08%\n",
      "Epoch: 7499,     Training Loss: 0.27530649304389954, Training Acc: 77.80%\n",
      "              Val Loss: 1.1945736408233643, Val Acc: 68.08%\n",
      "Epoch: 7500,     Training Loss: 0.2647128999233246, Training Acc: 77.81%\n",
      "              Val Loss: 1.2117865085601807, Val Acc: 68.08%\n",
      "Epoch: 7501,     Training Loss: 0.25668656826019287, Training Acc: 77.81%\n",
      "              Val Loss: 1.199891209602356, Val Acc: 68.08%\n",
      "Epoch: 7502,     Training Loss: 0.255134254693985, Training Acc: 77.81%\n",
      "              Val Loss: 1.2060158252716064, Val Acc: 68.08%\n",
      "Epoch: 7503,     Training Loss: 0.26020777225494385, Training Acc: 77.81%\n",
      "              Val Loss: 1.2344670295715332, Val Acc: 68.08%\n",
      "Epoch: 7504,     Training Loss: 0.26518866419792175, Training Acc: 77.81%\n",
      "              Val Loss: 1.203539252281189, Val Acc: 68.09%\n",
      "Epoch: 7505,     Training Loss: 0.2791987657546997, Training Acc: 77.81%\n",
      "              Val Loss: 1.2586328983306885, Val Acc: 68.09%\n",
      "Epoch: 7506,     Training Loss: 0.27626946568489075, Training Acc: 77.81%\n",
      "              Val Loss: 1.20906400680542, Val Acc: 68.09%\n",
      "Epoch: 7507,     Training Loss: 0.2885740101337433, Training Acc: 77.82%\n",
      "              Val Loss: 1.2655924558639526, Val Acc: 68.09%\n",
      "Epoch: 7508,     Training Loss: 0.2757445275783539, Training Acc: 77.82%\n",
      "              Val Loss: 1.1938382387161255, Val Acc: 68.09%\n",
      "Epoch: 7509,     Training Loss: 0.2703051269054413, Training Acc: 77.82%\n",
      "              Val Loss: 1.218185544013977, Val Acc: 68.09%\n",
      "Epoch: 7510,     Training Loss: 0.25916600227355957, Training Acc: 77.82%\n",
      "              Val Loss: 1.19386625289917, Val Acc: 68.09%\n",
      "Epoch: 7511,     Training Loss: 0.2517617344856262, Training Acc: 77.82%\n",
      "              Val Loss: 1.2004696130752563, Val Acc: 68.09%\n",
      "Epoch: 7512,     Training Loss: 0.2520711421966553, Training Acc: 77.82%\n",
      "              Val Loss: 1.2259317636489868, Val Acc: 68.09%\n",
      "Epoch: 7513,     Training Loss: 0.2546374797821045, Training Acc: 77.83%\n",
      "              Val Loss: 1.200239896774292, Val Acc: 68.09%\n",
      "Epoch: 7514,     Training Loss: 0.26005053520202637, Training Acc: 77.83%\n",
      "              Val Loss: 1.2490639686584473, Val Acc: 68.09%\n",
      "Epoch: 7515,     Training Loss: 0.26329144835472107, Training Acc: 77.83%\n",
      "              Val Loss: 1.2184436321258545, Val Acc: 68.09%\n",
      "Epoch: 7516,     Training Loss: 0.2763153910636902, Training Acc: 77.83%\n",
      "              Val Loss: 1.2695162296295166, Val Acc: 68.09%\n",
      "Epoch: 7517,     Training Loss: 0.2739056348800659, Training Acc: 77.83%\n",
      "              Val Loss: 1.2142460346221924, Val Acc: 68.09%\n",
      "Epoch: 7518,     Training Loss: 0.2824997007846832, Training Acc: 77.83%\n",
      "              Val Loss: 1.2459490299224854, Val Acc: 68.09%\n",
      "Epoch: 7519,     Training Loss: 0.2698932886123657, Training Acc: 77.83%\n",
      "              Val Loss: 1.2070413827896118, Val Acc: 68.09%\n",
      "Epoch: 7520,     Training Loss: 0.2663387656211853, Training Acc: 77.84%\n",
      "              Val Loss: 1.223409652709961, Val Acc: 68.09%\n",
      "Epoch: 7521,     Training Loss: 0.2539025843143463, Training Acc: 77.84%\n",
      "              Val Loss: 1.2157975435256958, Val Acc: 68.10%\n",
      "Epoch: 7522,     Training Loss: 0.24964232742786407, Training Acc: 77.84%\n",
      "              Val Loss: 1.2065260410308838, Val Acc: 68.10%\n",
      "Epoch: 7523,     Training Loss: 0.2556383013725281, Training Acc: 77.84%\n",
      "              Val Loss: 1.2548178434371948, Val Acc: 68.10%\n",
      "Epoch: 7524,     Training Loss: 0.2663474380970001, Training Acc: 77.84%\n",
      "              Val Loss: 1.2375181913375854, Val Acc: 68.10%\n",
      "Epoch: 7525,     Training Loss: 0.29378506541252136, Training Acc: 77.84%\n",
      "              Val Loss: 1.2938543558120728, Val Acc: 68.10%\n",
      "Epoch: 7526,     Training Loss: 0.28687378764152527, Training Acc: 77.84%\n",
      "              Val Loss: 1.2319700717926025, Val Acc: 68.10%\n",
      "Epoch: 7527,     Training Loss: 0.2959722578525543, Training Acc: 77.85%\n",
      "              Val Loss: 1.2625077962875366, Val Acc: 68.10%\n",
      "Epoch: 7528,     Training Loss: 0.27077046036720276, Training Acc: 77.85%\n",
      "              Val Loss: 1.2066411972045898, Val Acc: 68.10%\n",
      "Epoch: 7529,     Training Loss: 0.2595028281211853, Training Acc: 77.85%\n",
      "              Val Loss: 1.2374035120010376, Val Acc: 68.10%\n",
      "Epoch: 7530,     Training Loss: 0.2572382688522339, Training Acc: 77.85%\n",
      "              Val Loss: 1.2346917390823364, Val Acc: 68.10%\n",
      "Epoch: 7531,     Training Loss: 0.2605329751968384, Training Acc: 77.85%\n",
      "              Val Loss: 1.2242423295974731, Val Acc: 68.10%\n",
      "Epoch: 7532,     Training Loss: 0.27572569251060486, Training Acc: 77.85%\n",
      "              Val Loss: 1.2862839698791504, Val Acc: 68.10%\n",
      "Epoch: 7533,     Training Loss: 0.28005272150039673, Training Acc: 77.85%\n",
      "              Val Loss: 1.2336138486862183, Val Acc: 68.10%\n",
      "Epoch: 7534,     Training Loss: 0.30272772908210754, Training Acc: 77.86%\n",
      "              Val Loss: 1.290198802947998, Val Acc: 68.10%\n",
      "Epoch: 7535,     Training Loss: 0.2746802270412445, Training Acc: 77.86%\n",
      "              Val Loss: 1.2187436819076538, Val Acc: 68.10%\n",
      "Epoch: 7536,     Training Loss: 0.26823416352272034, Training Acc: 77.86%\n",
      "              Val Loss: 1.2475758790969849, Val Acc: 68.10%\n",
      "Epoch: 7537,     Training Loss: 0.26916182041168213, Training Acc: 77.86%\n",
      "              Val Loss: 1.2307261228561401, Val Acc: 68.10%\n",
      "Epoch: 7538,     Training Loss: 0.2617325484752655, Training Acc: 77.86%\n",
      "              Val Loss: 1.241206407546997, Val Acc: 68.11%\n",
      "Epoch: 7539,     Training Loss: 0.2613949775695801, Training Acc: 77.86%\n",
      "              Val Loss: 1.2591164112091064, Val Acc: 68.11%\n",
      "Epoch: 7540,     Training Loss: 0.26373282074928284, Training Acc: 77.86%\n",
      "              Val Loss: 1.2326469421386719, Val Acc: 68.11%\n",
      "Epoch: 7541,     Training Loss: 0.26948481798171997, Training Acc: 77.87%\n",
      "              Val Loss: 1.2804871797561646, Val Acc: 68.11%\n",
      "Epoch: 7542,     Training Loss: 0.2694453299045563, Training Acc: 77.87%\n",
      "              Val Loss: 1.230305552482605, Val Acc: 68.11%\n",
      "Epoch: 7543,     Training Loss: 0.2805706262588501, Training Acc: 77.87%\n",
      "              Val Loss: 1.3073523044586182, Val Acc: 68.11%\n",
      "Epoch: 7544,     Training Loss: 0.2855197489261627, Training Acc: 77.87%\n",
      "              Val Loss: 1.2191777229309082, Val Acc: 68.11%\n",
      "Epoch: 7545,     Training Loss: 0.2939612865447998, Training Acc: 77.87%\n",
      "              Val Loss: 1.2553644180297852, Val Acc: 68.11%\n",
      "Epoch: 7546,     Training Loss: 0.2658195197582245, Training Acc: 77.87%\n",
      "              Val Loss: 1.2442682981491089, Val Acc: 68.11%\n",
      "Epoch: 7547,     Training Loss: 0.26905450224876404, Training Acc: 77.87%\n",
      "              Val Loss: 1.2318135499954224, Val Acc: 68.11%\n",
      "Epoch: 7548,     Training Loss: 0.2740599513053894, Training Acc: 77.88%\n",
      "              Val Loss: 1.2640514373779297, Val Acc: 68.11%\n",
      "Epoch: 7549,     Training Loss: 0.26169365644454956, Training Acc: 77.88%\n",
      "              Val Loss: 1.2493535280227661, Val Acc: 68.11%\n",
      "Epoch: 7550,     Training Loss: 0.2803412675857544, Training Acc: 77.88%\n",
      "              Val Loss: 1.299103856086731, Val Acc: 68.11%\n",
      "Epoch: 7551,     Training Loss: 0.28343454003334045, Training Acc: 77.88%\n",
      "              Val Loss: 1.242417573928833, Val Acc: 68.11%\n",
      "Epoch: 7552,     Training Loss: 0.2762605845928192, Training Acc: 77.88%\n",
      "              Val Loss: 1.3016221523284912, Val Acc: 68.11%\n",
      "Epoch: 7553,     Training Loss: 0.27701446413993835, Training Acc: 77.88%\n",
      "              Val Loss: 1.237795352935791, Val Acc: 68.11%\n",
      "Epoch: 7554,     Training Loss: 0.29119202494621277, Training Acc: 77.88%\n",
      "              Val Loss: 1.2255555391311646, Val Acc: 68.11%\n",
      "Epoch: 7555,     Training Loss: 0.25760117173194885, Training Acc: 77.89%\n",
      "              Val Loss: 1.308883547782898, Val Acc: 68.11%\n",
      "Epoch: 7556,     Training Loss: 0.29213079810142517, Training Acc: 77.89%\n",
      "              Val Loss: 1.2505037784576416, Val Acc: 68.12%\n",
      "Epoch: 7557,     Training Loss: 0.3016175627708435, Training Acc: 77.89%\n",
      "              Val Loss: 1.2825143337249756, Val Acc: 68.12%\n",
      "Epoch: 7558,     Training Loss: 0.27112385630607605, Training Acc: 77.89%\n",
      "              Val Loss: 1.3157868385314941, Val Acc: 68.12%\n",
      "Epoch: 7559,     Training Loss: 0.33504989743232727, Training Acc: 77.89%\n",
      "              Val Loss: 1.2602994441986084, Val Acc: 68.12%\n",
      "Epoch: 7560,     Training Loss: 0.28248968720436096, Training Acc: 77.89%\n",
      "              Val Loss: 1.2319704294204712, Val Acc: 68.12%\n",
      "Epoch: 7561,     Training Loss: 0.27919644117355347, Training Acc: 77.89%\n",
      "              Val Loss: 1.2999026775360107, Val Acc: 68.12%\n",
      "Epoch: 7562,     Training Loss: 0.29005300998687744, Training Acc: 77.90%\n",
      "              Val Loss: 1.2465170621871948, Val Acc: 68.12%\n",
      "Epoch: 7563,     Training Loss: 0.25584638118743896, Training Acc: 77.90%\n",
      "              Val Loss: 1.220505714416504, Val Acc: 68.12%\n",
      "Epoch: 7564,     Training Loss: 0.27205589413642883, Training Acc: 77.90%\n",
      "              Val Loss: 1.2760252952575684, Val Acc: 68.12%\n",
      "Epoch: 7565,     Training Loss: 0.2678447961807251, Training Acc: 77.90%\n",
      "              Val Loss: 1.241068959236145, Val Acc: 68.12%\n",
      "Epoch: 7566,     Training Loss: 0.25312379002571106, Training Acc: 77.90%\n",
      "              Val Loss: 1.273037314414978, Val Acc: 68.12%\n",
      "Epoch: 7567,     Training Loss: 0.2668112516403198, Training Acc: 77.90%\n",
      "              Val Loss: 1.2572922706604004, Val Acc: 68.12%\n",
      "Epoch: 7568,     Training Loss: 0.2553483843803406, Training Acc: 77.90%\n",
      "              Val Loss: 1.2550570964813232, Val Acc: 68.12%\n",
      "Epoch: 7569,     Training Loss: 0.25470128655433655, Training Acc: 77.91%\n",
      "              Val Loss: 1.250095248222351, Val Acc: 68.12%\n",
      "Epoch: 7570,     Training Loss: 0.263845831155777, Training Acc: 77.91%\n",
      "              Val Loss: 1.2794119119644165, Val Acc: 68.12%\n",
      "Epoch: 7571,     Training Loss: 0.2683939039707184, Training Acc: 77.91%\n",
      "              Val Loss: 1.2732925415039062, Val Acc: 68.12%\n",
      "Epoch: 7572,     Training Loss: 0.2832276225090027, Training Acc: 77.91%\n",
      "              Val Loss: 1.281790018081665, Val Acc: 68.12%\n",
      "Epoch: 7573,     Training Loss: 0.27578479051589966, Training Acc: 77.91%\n",
      "              Val Loss: 1.2603737115859985, Val Acc: 68.12%\n",
      "Epoch: 7574,     Training Loss: 0.2778482437133789, Training Acc: 77.91%\n",
      "              Val Loss: 1.2882373332977295, Val Acc: 68.13%\n",
      "Epoch: 7575,     Training Loss: 0.2635955214500427, Training Acc: 77.91%\n",
      "              Val Loss: 1.2466825246810913, Val Acc: 68.13%\n",
      "Epoch: 7576,     Training Loss: 0.27491047978401184, Training Acc: 77.92%\n",
      "              Val Loss: 1.3247523307800293, Val Acc: 68.13%\n",
      "Epoch: 7577,     Training Loss: 0.2795102894306183, Training Acc: 77.92%\n",
      "              Val Loss: 1.2562568187713623, Val Acc: 68.13%\n",
      "Epoch: 7578,     Training Loss: 0.3032916784286499, Training Acc: 77.92%\n",
      "              Val Loss: 1.299890398979187, Val Acc: 68.13%\n",
      "Epoch: 7579,     Training Loss: 0.27713581919670105, Training Acc: 77.92%\n",
      "              Val Loss: 1.232224702835083, Val Acc: 68.13%\n",
      "Epoch: 7580,     Training Loss: 0.26597273349761963, Training Acc: 77.92%\n",
      "              Val Loss: 1.2459949254989624, Val Acc: 68.13%\n",
      "Epoch: 7581,     Training Loss: 0.255467027425766, Training Acc: 77.92%\n",
      "              Val Loss: 1.2668085098266602, Val Acc: 68.13%\n",
      "Epoch: 7582,     Training Loss: 0.2698069214820862, Training Acc: 77.92%\n",
      "              Val Loss: 1.2732815742492676, Val Acc: 68.13%\n",
      "Epoch: 7583,     Training Loss: 0.295164555311203, Training Acc: 77.93%\n",
      "              Val Loss: 1.3035023212432861, Val Acc: 68.13%\n",
      "Epoch: 7584,     Training Loss: 0.30877140164375305, Training Acc: 77.93%\n",
      "              Val Loss: 1.3125967979431152, Val Acc: 68.13%\n",
      "Epoch: 7585,     Training Loss: 0.28840991854667664, Training Acc: 77.93%\n",
      "              Val Loss: 1.2565865516662598, Val Acc: 68.13%\n",
      "Epoch: 7586,     Training Loss: 0.27311161160469055, Training Acc: 77.93%\n",
      "              Val Loss: 1.298647165298462, Val Acc: 68.13%\n",
      "Epoch: 7587,     Training Loss: 0.27208343148231506, Training Acc: 77.93%\n",
      "              Val Loss: 1.2846559286117554, Val Acc: 68.13%\n",
      "Epoch: 7588,     Training Loss: 0.3246815800666809, Training Acc: 77.93%\n",
      "              Val Loss: 1.3382033109664917, Val Acc: 68.13%\n",
      "Epoch: 7589,     Training Loss: 0.30346518754959106, Training Acc: 77.93%\n",
      "              Val Loss: 1.2523895502090454, Val Acc: 68.13%\n",
      "Epoch: 7590,     Training Loss: 0.30544182658195496, Training Acc: 77.93%\n",
      "              Val Loss: 1.258792519569397, Val Acc: 68.13%\n",
      "Epoch: 7591,     Training Loss: 0.2591073513031006, Training Acc: 77.94%\n",
      "              Val Loss: 1.2470952272415161, Val Acc: 68.13%\n",
      "Epoch: 7592,     Training Loss: 0.2624480426311493, Training Acc: 77.94%\n",
      "              Val Loss: 1.267160177230835, Val Acc: 68.13%\n",
      "Epoch: 7593,     Training Loss: 0.297005832195282, Training Acc: 77.94%\n",
      "              Val Loss: 1.2984871864318848, Val Acc: 68.13%\n",
      "Epoch: 7594,     Training Loss: 0.2958953380584717, Training Acc: 77.94%\n",
      "              Val Loss: 1.2961076498031616, Val Acc: 68.14%\n",
      "Epoch: 7595,     Training Loss: 0.27519071102142334, Training Acc: 77.94%\n",
      "              Val Loss: 1.2587970495224, Val Acc: 68.14%\n",
      "Epoch: 7596,     Training Loss: 0.2832581400871277, Training Acc: 77.94%\n",
      "              Val Loss: 1.363295078277588, Val Acc: 68.14%\n",
      "Epoch: 7597,     Training Loss: 0.29780852794647217, Training Acc: 77.94%\n",
      "              Val Loss: 1.3260208368301392, Val Acc: 68.14%\n",
      "Epoch: 7598,     Training Loss: 0.37170353531837463, Training Acc: 77.95%\n",
      "              Val Loss: 1.3438831567764282, Val Acc: 68.14%\n",
      "Epoch: 7599,     Training Loss: 0.2962244749069214, Training Acc: 77.95%\n",
      "              Val Loss: 1.233149528503418, Val Acc: 68.14%\n",
      "Epoch: 7600,     Training Loss: 0.27260372042655945, Training Acc: 77.95%\n",
      "              Val Loss: 1.2642946243286133, Val Acc: 68.14%\n",
      "Epoch: 7601,     Training Loss: 0.27315953373908997, Training Acc: 77.95%\n",
      "              Val Loss: 1.2939350605010986, Val Acc: 68.14%\n",
      "Epoch: 7602,     Training Loss: 0.30557525157928467, Training Acc: 77.95%\n",
      "              Val Loss: 1.281501293182373, Val Acc: 68.14%\n",
      "Epoch: 7603,     Training Loss: 0.30078810453414917, Training Acc: 77.95%\n",
      "              Val Loss: 1.245336890220642, Val Acc: 68.14%\n",
      "Epoch: 7604,     Training Loss: 0.27257630228996277, Training Acc: 77.95%\n",
      "              Val Loss: 1.310083031654358, Val Acc: 68.14%\n",
      "Epoch: 7605,     Training Loss: 0.27015724778175354, Training Acc: 77.95%\n",
      "              Val Loss: 1.2668668031692505, Val Acc: 68.14%\n",
      "Epoch: 7606,     Training Loss: 0.2971077263355255, Training Acc: 77.96%\n",
      "              Val Loss: 1.292471170425415, Val Acc: 68.14%\n",
      "Epoch: 7607,     Training Loss: 0.26382318139076233, Training Acc: 77.96%\n",
      "              Val Loss: 1.2610411643981934, Val Acc: 68.14%\n",
      "Epoch: 7608,     Training Loss: 0.24480174481868744, Training Acc: 77.96%\n",
      "              Val Loss: 1.2638455629348755, Val Acc: 68.14%\n",
      "Epoch: 7609,     Training Loss: 0.2540108859539032, Training Acc: 77.96%\n",
      "              Val Loss: 1.3225510120391846, Val Acc: 68.14%\n",
      "Epoch: 7610,     Training Loss: 0.26599013805389404, Training Acc: 77.96%\n",
      "              Val Loss: 1.2672741413116455, Val Acc: 68.14%\n",
      "Epoch: 7611,     Training Loss: 0.27764493227005005, Training Acc: 77.96%\n",
      "              Val Loss: 1.3069267272949219, Val Acc: 68.14%\n",
      "Epoch: 7612,     Training Loss: 0.26349982619285583, Training Acc: 77.97%\n",
      "              Val Loss: 1.2794852256774902, Val Acc: 68.14%\n",
      "Epoch: 7613,     Training Loss: 0.28120920062065125, Training Acc: 77.97%\n",
      "              Val Loss: 1.317929983139038, Val Acc: 68.14%\n",
      "Epoch: 7614,     Training Loss: 0.2899094820022583, Training Acc: 77.97%\n",
      "              Val Loss: 1.2862582206726074, Val Acc: 68.14%\n",
      "Epoch: 7615,     Training Loss: 0.28621405363082886, Training Acc: 77.97%\n",
      "              Val Loss: 1.2928446531295776, Val Acc: 68.15%\n",
      "Epoch: 7616,     Training Loss: 0.2583259642124176, Training Acc: 77.97%\n",
      "              Val Loss: 1.2645015716552734, Val Acc: 68.15%\n",
      "Epoch: 7617,     Training Loss: 0.26237794756889343, Training Acc: 77.97%\n",
      "              Val Loss: 1.318616509437561, Val Acc: 68.15%\n",
      "Epoch: 7618,     Training Loss: 0.27402010560035706, Training Acc: 77.97%\n",
      "              Val Loss: 1.2688637971878052, Val Acc: 68.15%\n",
      "Epoch: 7619,     Training Loss: 0.27772387862205505, Training Acc: 77.97%\n",
      "              Val Loss: 1.2880640029907227, Val Acc: 68.15%\n",
      "Epoch: 7620,     Training Loss: 0.2550787031650543, Training Acc: 77.98%\n",
      "              Val Loss: 1.2565760612487793, Val Acc: 68.15%\n",
      "Epoch: 7621,     Training Loss: 0.260947048664093, Training Acc: 77.98%\n",
      "              Val Loss: 1.3229930400848389, Val Acc: 68.15%\n",
      "Epoch: 7622,     Training Loss: 0.2845102548599243, Training Acc: 77.98%\n",
      "              Val Loss: 1.3074769973754883, Val Acc: 68.15%\n",
      "Epoch: 7623,     Training Loss: 0.3123578131198883, Training Acc: 77.98%\n",
      "              Val Loss: 1.3330410718917847, Val Acc: 68.15%\n",
      "Epoch: 7624,     Training Loss: 0.27621519565582275, Training Acc: 77.98%\n",
      "              Val Loss: 1.2804837226867676, Val Acc: 68.15%\n",
      "Epoch: 7625,     Training Loss: 0.27909019589424133, Training Acc: 77.98%\n",
      "              Val Loss: 1.3452502489089966, Val Acc: 68.15%\n",
      "Epoch: 7626,     Training Loss: 0.2824915945529938, Training Acc: 77.98%\n",
      "              Val Loss: 1.3009108304977417, Val Acc: 68.15%\n",
      "Epoch: 7627,     Training Loss: 0.3159402012825012, Training Acc: 77.99%\n",
      "              Val Loss: 1.3346110582351685, Val Acc: 68.15%\n",
      "Epoch: 7628,     Training Loss: 0.2728208303451538, Training Acc: 77.99%\n",
      "              Val Loss: 1.2550369501113892, Val Acc: 68.15%\n",
      "Epoch: 7629,     Training Loss: 0.2638199031352997, Training Acc: 77.99%\n",
      "              Val Loss: 1.2959479093551636, Val Acc: 68.15%\n",
      "Epoch: 7630,     Training Loss: 0.27256402373313904, Training Acc: 77.99%\n",
      "              Val Loss: 1.3029518127441406, Val Acc: 68.15%\n",
      "Epoch: 7631,     Training Loss: 0.2856695055961609, Training Acc: 77.99%\n",
      "              Val Loss: 1.2977683544158936, Val Acc: 68.15%\n",
      "Epoch: 7632,     Training Loss: 0.2665855884552002, Training Acc: 77.99%\n",
      "              Val Loss: 1.2731680870056152, Val Acc: 68.15%\n",
      "Epoch: 7633,     Training Loss: 0.2609548568725586, Training Acc: 77.99%\n",
      "              Val Loss: 1.3260095119476318, Val Acc: 68.15%\n",
      "Epoch: 7634,     Training Loss: 0.2630270719528198, Training Acc: 78.00%\n",
      "              Val Loss: 1.2787221670150757, Val Acc: 68.15%\n",
      "Epoch: 7635,     Training Loss: 0.280699223279953, Training Acc: 78.00%\n",
      "              Val Loss: 1.3329638242721558, Val Acc: 68.16%\n",
      "Epoch: 7636,     Training Loss: 0.2643665075302124, Training Acc: 78.00%\n",
      "              Val Loss: 1.2645540237426758, Val Acc: 68.16%\n",
      "Epoch: 7637,     Training Loss: 0.27073511481285095, Training Acc: 78.00%\n",
      "              Val Loss: 1.3233346939086914, Val Acc: 68.16%\n",
      "Epoch: 7638,     Training Loss: 0.27526241540908813, Training Acc: 78.00%\n",
      "              Val Loss: 1.2853528261184692, Val Acc: 68.16%\n",
      "Epoch: 7639,     Training Loss: 0.2997533082962036, Training Acc: 78.00%\n",
      "              Val Loss: 1.3289822340011597, Val Acc: 68.16%\n",
      "Epoch: 7640,     Training Loss: 0.2802039384841919, Training Acc: 78.00%\n",
      "              Val Loss: 1.2837945222854614, Val Acc: 68.16%\n",
      "Epoch: 7641,     Training Loss: 0.28907379508018494, Training Acc: 78.01%\n",
      "              Val Loss: 1.3040798902511597, Val Acc: 68.16%\n",
      "Epoch: 7642,     Training Loss: 0.26640084385871887, Training Acc: 78.01%\n",
      "              Val Loss: 1.25338876247406, Val Acc: 68.16%\n",
      "Epoch: 7643,     Training Loss: 0.259606271982193, Training Acc: 78.01%\n",
      "              Val Loss: 1.2829275131225586, Val Acc: 68.16%\n",
      "Epoch: 7644,     Training Loss: 0.25790566205978394, Training Acc: 78.01%\n",
      "              Val Loss: 1.2847334146499634, Val Acc: 68.16%\n",
      "Epoch: 7645,     Training Loss: 0.2641488015651703, Training Acc: 78.01%\n",
      "              Val Loss: 1.2632060050964355, Val Acc: 68.16%\n",
      "Epoch: 7646,     Training Loss: 0.2641926407814026, Training Acc: 78.01%\n",
      "              Val Loss: 1.3379652500152588, Val Acc: 68.16%\n",
      "Epoch: 7647,     Training Loss: 0.27179455757141113, Training Acc: 78.01%\n",
      "              Val Loss: 1.2704542875289917, Val Acc: 68.16%\n",
      "Epoch: 7648,     Training Loss: 0.31520411372184753, Training Acc: 78.01%\n",
      "              Val Loss: 1.3541690111160278, Val Acc: 68.16%\n",
      "Epoch: 7649,     Training Loss: 0.2843785583972931, Training Acc: 78.02%\n",
      "              Val Loss: 1.266675591468811, Val Acc: 68.16%\n",
      "Epoch: 7650,     Training Loss: 0.2981470823287964, Training Acc: 78.02%\n",
      "              Val Loss: 1.31195068359375, Val Acc: 68.16%\n",
      "Epoch: 7651,     Training Loss: 0.2877373993396759, Training Acc: 78.02%\n",
      "              Val Loss: 1.3050332069396973, Val Acc: 68.16%\n",
      "Epoch: 7652,     Training Loss: 0.29151082038879395, Training Acc: 78.02%\n",
      "              Val Loss: 1.252957820892334, Val Acc: 68.16%\n",
      "Epoch: 7653,     Training Loss: 0.25150448083877563, Training Acc: 78.02%\n",
      "              Val Loss: 1.2885419130325317, Val Acc: 68.16%\n",
      "Epoch: 7654,     Training Loss: 0.2574513852596283, Training Acc: 78.02%\n",
      "              Val Loss: 1.3047187328338623, Val Acc: 68.16%\n",
      "Epoch: 7655,     Training Loss: 0.3013550639152527, Training Acc: 78.02%\n",
      "              Val Loss: 1.346903681755066, Val Acc: 68.17%\n",
      "Epoch: 7656,     Training Loss: 0.28077805042266846, Training Acc: 78.03%\n",
      "              Val Loss: 1.2745939493179321, Val Acc: 68.17%\n",
      "Epoch: 7657,     Training Loss: 0.2730814814567566, Training Acc: 78.03%\n",
      "              Val Loss: 1.3429025411605835, Val Acc: 68.17%\n",
      "Epoch: 7658,     Training Loss: 0.26962974667549133, Training Acc: 78.03%\n",
      "              Val Loss: 1.2691491842269897, Val Acc: 68.17%\n",
      "Epoch: 7659,     Training Loss: 0.2706873416900635, Training Acc: 78.03%\n",
      "              Val Loss: 1.3010985851287842, Val Acc: 68.17%\n",
      "Epoch: 7660,     Training Loss: 0.2547076642513275, Training Acc: 78.03%\n",
      "              Val Loss: 1.281341552734375, Val Acc: 68.17%\n",
      "Epoch: 7661,     Training Loss: 0.26335227489471436, Training Acc: 78.03%\n",
      "              Val Loss: 1.2632864713668823, Val Acc: 68.17%\n",
      "Epoch: 7662,     Training Loss: 0.26204538345336914, Training Acc: 78.03%\n",
      "              Val Loss: 1.2794103622436523, Val Acc: 68.17%\n",
      "Epoch: 7663,     Training Loss: 0.25542446970939636, Training Acc: 78.04%\n",
      "              Val Loss: 1.286821722984314, Val Acc: 68.17%\n",
      "Epoch: 7664,     Training Loss: 0.26661399006843567, Training Acc: 78.04%\n",
      "              Val Loss: 1.2991621494293213, Val Acc: 68.17%\n",
      "Epoch: 7665,     Training Loss: 0.26937100291252136, Training Acc: 78.04%\n",
      "              Val Loss: 1.3041481971740723, Val Acc: 68.17%\n",
      "Epoch: 7666,     Training Loss: 0.24714961647987366, Training Acc: 78.04%\n",
      "              Val Loss: 1.2909168004989624, Val Acc: 68.17%\n",
      "Epoch: 7667,     Training Loss: 0.2503361999988556, Training Acc: 78.04%\n",
      "              Val Loss: 1.3306050300598145, Val Acc: 68.17%\n",
      "Epoch: 7668,     Training Loss: 0.26825135946273804, Training Acc: 78.04%\n",
      "              Val Loss: 1.2892255783081055, Val Acc: 68.17%\n",
      "Epoch: 7669,     Training Loss: 0.27564793825149536, Training Acc: 78.04%\n",
      "              Val Loss: 1.349216341972351, Val Acc: 68.17%\n",
      "Epoch: 7670,     Training Loss: 0.271847128868103, Training Acc: 78.05%\n",
      "              Val Loss: 1.2784035205841064, Val Acc: 68.17%\n",
      "Epoch: 7671,     Training Loss: 0.3279188275337219, Training Acc: 78.05%\n",
      "              Val Loss: 1.353532314300537, Val Acc: 68.17%\n",
      "Epoch: 7672,     Training Loss: 0.2978438436985016, Training Acc: 78.05%\n",
      "              Val Loss: 1.2877342700958252, Val Acc: 68.17%\n",
      "Epoch: 7673,     Training Loss: 0.33057278394699097, Training Acc: 78.05%\n",
      "              Val Loss: 1.3191990852355957, Val Acc: 68.17%\n",
      "Epoch: 7674,     Training Loss: 0.27507880330085754, Training Acc: 78.05%\n",
      "              Val Loss: 1.2687418460845947, Val Acc: 68.17%\n",
      "Epoch: 7675,     Training Loss: 0.2547013759613037, Training Acc: 78.05%\n",
      "              Val Loss: 1.2618762254714966, Val Acc: 68.18%\n",
      "Epoch: 7676,     Training Loss: 0.24866797029972076, Training Acc: 78.05%\n",
      "              Val Loss: 1.3251714706420898, Val Acc: 68.18%\n",
      "Epoch: 7677,     Training Loss: 0.26943570375442505, Training Acc: 78.05%\n",
      "              Val Loss: 1.3069348335266113, Val Acc: 68.18%\n",
      "Epoch: 7678,     Training Loss: 0.31117475032806396, Training Acc: 78.06%\n",
      "              Val Loss: 1.3936591148376465, Val Acc: 68.18%\n",
      "Epoch: 7679,     Training Loss: 0.29391804337501526, Training Acc: 78.06%\n",
      "              Val Loss: 1.2845954895019531, Val Acc: 68.18%\n",
      "Epoch: 7680,     Training Loss: 0.3232576847076416, Training Acc: 78.06%\n",
      "              Val Loss: 1.351675271987915, Val Acc: 68.18%\n",
      "Epoch: 7681,     Training Loss: 0.29344651103019714, Training Acc: 78.06%\n",
      "              Val Loss: 1.2528831958770752, Val Acc: 68.18%\n",
      "Epoch: 7682,     Training Loss: 0.26867660880088806, Training Acc: 78.06%\n",
      "              Val Loss: 1.2646400928497314, Val Acc: 68.18%\n",
      "Epoch: 7683,     Training Loss: 0.2552696466445923, Training Acc: 78.06%\n",
      "              Val Loss: 1.3671870231628418, Val Acc: 68.18%\n",
      "Epoch: 7684,     Training Loss: 0.2927486300468445, Training Acc: 78.06%\n",
      "              Val Loss: 1.2680264711380005, Val Acc: 68.18%\n",
      "Epoch: 7685,     Training Loss: 0.29755041003227234, Training Acc: 78.06%\n",
      "              Val Loss: 1.3094127178192139, Val Acc: 68.18%\n",
      "Epoch: 7686,     Training Loss: 0.26555824279785156, Training Acc: 78.07%\n",
      "              Val Loss: 1.3599870204925537, Val Acc: 68.18%\n",
      "Epoch: 7687,     Training Loss: 0.3075766861438751, Training Acc: 78.07%\n",
      "              Val Loss: 1.3063337802886963, Val Acc: 68.18%\n",
      "Epoch: 7688,     Training Loss: 0.26827752590179443, Training Acc: 78.07%\n",
      "              Val Loss: 1.3005582094192505, Val Acc: 68.18%\n",
      "Epoch: 7689,     Training Loss: 0.25308072566986084, Training Acc: 78.07%\n",
      "              Val Loss: 1.32746160030365, Val Acc: 68.18%\n",
      "Epoch: 7690,     Training Loss: 0.2842100262641907, Training Acc: 78.07%\n",
      "              Val Loss: 1.2840867042541504, Val Acc: 68.18%\n",
      "Epoch: 7691,     Training Loss: 0.25897514820098877, Training Acc: 78.07%\n",
      "              Val Loss: 1.2750014066696167, Val Acc: 68.18%\n",
      "Epoch: 7692,     Training Loss: 0.24924400448799133, Training Acc: 78.07%\n",
      "              Val Loss: 1.3214646577835083, Val Acc: 68.18%\n",
      "Epoch: 7693,     Training Loss: 0.2755318582057953, Training Acc: 78.08%\n",
      "              Val Loss: 1.2830777168273926, Val Acc: 68.18%\n",
      "Epoch: 7694,     Training Loss: 0.2629243731498718, Training Acc: 78.08%\n",
      "              Val Loss: 1.2506108283996582, Val Acc: 68.18%\n",
      "Epoch: 7695,     Training Loss: 0.2533729672431946, Training Acc: 78.08%\n",
      "              Val Loss: 1.3454142808914185, Val Acc: 68.18%\n",
      "Epoch: 7696,     Training Loss: 0.2754800021648407, Training Acc: 78.08%\n",
      "              Val Loss: 1.269616961479187, Val Acc: 68.19%\n",
      "Epoch: 7697,     Training Loss: 0.2752184569835663, Training Acc: 78.08%\n",
      "              Val Loss: 1.3381842374801636, Val Acc: 68.19%\n",
      "Epoch: 7698,     Training Loss: 0.2722536623477936, Training Acc: 78.08%\n",
      "              Val Loss: 1.3673509359359741, Val Acc: 68.19%\n",
      "Epoch: 7699,     Training Loss: 0.33170151710510254, Training Acc: 78.08%\n",
      "              Val Loss: 1.3512153625488281, Val Acc: 68.19%\n",
      "Epoch: 7700,     Training Loss: 0.273550808429718, Training Acc: 78.09%\n",
      "              Val Loss: 1.2699322700500488, Val Acc: 68.19%\n",
      "Epoch: 7701,     Training Loss: 0.2787443995475769, Training Acc: 78.09%\n",
      "              Val Loss: 1.3615074157714844, Val Acc: 68.19%\n",
      "Epoch: 7702,     Training Loss: 0.29265058040618896, Training Acc: 78.09%\n",
      "              Val Loss: 1.248903751373291, Val Acc: 68.19%\n",
      "Epoch: 7703,     Training Loss: 0.2706091105937958, Training Acc: 78.09%\n",
      "              Val Loss: 1.3064179420471191, Val Acc: 68.19%\n",
      "Epoch: 7704,     Training Loss: 0.27187928557395935, Training Acc: 78.09%\n",
      "              Val Loss: 1.354761004447937, Val Acc: 68.19%\n",
      "Epoch: 7705,     Training Loss: 0.30857932567596436, Training Acc: 78.09%\n",
      "              Val Loss: 1.284688115119934, Val Acc: 68.19%\n",
      "Epoch: 7706,     Training Loss: 0.2570357620716095, Training Acc: 78.09%\n",
      "              Val Loss: 1.284818410873413, Val Acc: 68.19%\n",
      "Epoch: 7707,     Training Loss: 0.25577056407928467, Training Acc: 78.09%\n",
      "              Val Loss: 1.2962524890899658, Val Acc: 68.19%\n",
      "Epoch: 7708,     Training Loss: 0.26175135374069214, Training Acc: 78.10%\n",
      "              Val Loss: 1.3312230110168457, Val Acc: 68.19%\n",
      "Epoch: 7709,     Training Loss: 0.259369432926178, Training Acc: 78.10%\n",
      "              Val Loss: 1.3053672313690186, Val Acc: 68.19%\n",
      "Epoch: 7710,     Training Loss: 0.29785022139549255, Training Acc: 78.10%\n",
      "              Val Loss: 1.3894758224487305, Val Acc: 68.19%\n",
      "Epoch: 7711,     Training Loss: 0.27524903416633606, Training Acc: 78.10%\n",
      "              Val Loss: 1.3044489622116089, Val Acc: 68.19%\n",
      "Epoch: 7712,     Training Loss: 0.30527180433273315, Training Acc: 78.10%\n",
      "              Val Loss: 1.3967076539993286, Val Acc: 68.19%\n",
      "Epoch: 7713,     Training Loss: 0.3101995587348938, Training Acc: 78.10%\n",
      "              Val Loss: 1.334330439567566, Val Acc: 68.19%\n",
      "Epoch: 7714,     Training Loss: 0.359247088432312, Training Acc: 78.10%\n",
      "              Val Loss: 1.392327070236206, Val Acc: 68.19%\n",
      "Epoch: 7715,     Training Loss: 0.3003426492214203, Training Acc: 78.10%\n",
      "              Val Loss: 1.2671664953231812, Val Acc: 68.19%\n",
      "Epoch: 7716,     Training Loss: 0.2976856529712677, Training Acc: 78.11%\n",
      "              Val Loss: 1.281295657157898, Val Acc: 68.19%\n",
      "Epoch: 7717,     Training Loss: 0.28661757707595825, Training Acc: 78.11%\n",
      "              Val Loss: 1.325966238975525, Val Acc: 68.19%\n",
      "Epoch: 7718,     Training Loss: 0.2798140048980713, Training Acc: 78.11%\n",
      "              Val Loss: 1.2866120338439941, Val Acc: 68.20%\n",
      "Epoch: 7719,     Training Loss: 0.26468026638031006, Training Acc: 78.11%\n",
      "              Val Loss: 1.299251675605774, Val Acc: 68.20%\n",
      "Epoch: 7720,     Training Loss: 0.2580483853816986, Training Acc: 78.11%\n",
      "              Val Loss: 1.340278148651123, Val Acc: 68.20%\n",
      "Epoch: 7721,     Training Loss: 0.2853254973888397, Training Acc: 78.11%\n",
      "              Val Loss: 1.2757976055145264, Val Acc: 68.20%\n",
      "Epoch: 7722,     Training Loss: 0.2622984051704407, Training Acc: 78.11%\n",
      "              Val Loss: 1.311405062675476, Val Acc: 68.20%\n",
      "Epoch: 7723,     Training Loss: 0.2637397050857544, Training Acc: 78.12%\n",
      "              Val Loss: 1.3369300365447998, Val Acc: 68.20%\n",
      "Epoch: 7724,     Training Loss: 0.29261454939842224, Training Acc: 78.12%\n",
      "              Val Loss: 1.357132911682129, Val Acc: 68.20%\n",
      "Epoch: 7725,     Training Loss: 0.2742522954940796, Training Acc: 78.12%\n",
      "              Val Loss: 1.2718513011932373, Val Acc: 68.20%\n",
      "Epoch: 7726,     Training Loss: 0.3022170960903168, Training Acc: 78.12%\n",
      "              Val Loss: 1.3276950120925903, Val Acc: 68.20%\n",
      "Epoch: 7727,     Training Loss: 0.2783421277999878, Training Acc: 78.12%\n",
      "              Val Loss: 1.3062607049942017, Val Acc: 68.20%\n",
      "Epoch: 7728,     Training Loss: 0.30097025632858276, Training Acc: 78.12%\n",
      "              Val Loss: 1.3528345823287964, Val Acc: 68.20%\n",
      "Epoch: 7729,     Training Loss: 0.27796471118927, Training Acc: 78.12%\n",
      "              Val Loss: 1.2732723951339722, Val Acc: 68.20%\n",
      "Epoch: 7730,     Training Loss: 0.26935315132141113, Training Acc: 78.12%\n",
      "              Val Loss: 1.344224214553833, Val Acc: 68.20%\n",
      "Epoch: 7731,     Training Loss: 0.2746847867965698, Training Acc: 78.13%\n",
      "              Val Loss: 1.2642624378204346, Val Acc: 68.20%\n",
      "Epoch: 7732,     Training Loss: 0.2597711682319641, Training Acc: 78.13%\n",
      "              Val Loss: 1.3245651721954346, Val Acc: 68.20%\n",
      "Epoch: 7733,     Training Loss: 0.2598675787448883, Training Acc: 78.13%\n",
      "              Val Loss: 1.3343921899795532, Val Acc: 68.20%\n",
      "Epoch: 7734,     Training Loss: 0.2803534269332886, Training Acc: 78.13%\n",
      "              Val Loss: 1.3219270706176758, Val Acc: 68.20%\n",
      "Epoch: 7735,     Training Loss: 0.2566666603088379, Training Acc: 78.13%\n",
      "              Val Loss: 1.299397587776184, Val Acc: 68.20%\n",
      "Epoch: 7736,     Training Loss: 0.24922114610671997, Training Acc: 78.13%\n",
      "              Val Loss: 1.2977691888809204, Val Acc: 68.20%\n",
      "Epoch: 7737,     Training Loss: 0.2559814751148224, Training Acc: 78.13%\n",
      "              Val Loss: 1.3047611713409424, Val Acc: 68.20%\n",
      "Epoch: 7738,     Training Loss: 0.2437770962715149, Training Acc: 78.14%\n",
      "              Val Loss: 1.2758678197860718, Val Acc: 68.20%\n",
      "Epoch: 7739,     Training Loss: 0.24589340388774872, Training Acc: 78.14%\n",
      "              Val Loss: 1.3191109895706177, Val Acc: 68.20%\n",
      "Epoch: 7740,     Training Loss: 0.24850910902023315, Training Acc: 78.14%\n",
      "              Val Loss: 1.2787373065948486, Val Acc: 68.21%\n",
      "Epoch: 7741,     Training Loss: 0.23821020126342773, Training Acc: 78.14%\n",
      "              Val Loss: 1.2901707887649536, Val Acc: 68.21%\n",
      "Epoch: 7742,     Training Loss: 0.2415304332971573, Training Acc: 78.14%\n",
      "              Val Loss: 1.2987573146820068, Val Acc: 68.21%\n",
      "Epoch: 7743,     Training Loss: 0.23853732645511627, Training Acc: 78.14%\n",
      "              Val Loss: 1.2924336194992065, Val Acc: 68.21%\n",
      "Epoch: 7744,     Training Loss: 0.23777255415916443, Training Acc: 78.15%\n",
      "              Val Loss: 1.3011431694030762, Val Acc: 68.21%\n",
      "Epoch: 7745,     Training Loss: 0.23801212012767792, Training Acc: 78.15%\n",
      "              Val Loss: 1.3116804361343384, Val Acc: 68.21%\n",
      "Epoch: 7746,     Training Loss: 0.23821742832660675, Training Acc: 78.15%\n",
      "              Val Loss: 1.315850853919983, Val Acc: 68.21%\n",
      "Epoch: 7747,     Training Loss: 0.2375219762325287, Training Acc: 78.15%\n",
      "              Val Loss: 1.304660439491272, Val Acc: 68.21%\n",
      "Epoch: 7748,     Training Loss: 0.23529668152332306, Training Acc: 78.15%\n",
      "              Val Loss: 1.3315349817276, Val Acc: 68.21%\n",
      "Epoch: 7749,     Training Loss: 0.23970989882946014, Training Acc: 78.15%\n",
      "              Val Loss: 1.2951847314834595, Val Acc: 68.21%\n",
      "Epoch: 7750,     Training Loss: 0.2478378266096115, Training Acc: 78.15%\n",
      "              Val Loss: 1.364108681678772, Val Acc: 68.21%\n",
      "Epoch: 7751,     Training Loss: 0.2635258436203003, Training Acc: 78.16%\n",
      "              Val Loss: 1.3397703170776367, Val Acc: 68.21%\n",
      "Epoch: 7752,     Training Loss: 0.34174296259880066, Training Acc: 78.16%\n",
      "              Val Loss: 1.4784015417099, Val Acc: 68.21%\n",
      "Epoch: 7753,     Training Loss: 0.3528499901294708, Training Acc: 78.16%\n",
      "              Val Loss: 1.4487087726593018, Val Acc: 68.21%\n",
      "Epoch: 7754,     Training Loss: 0.5161540508270264, Training Acc: 78.16%\n",
      "              Val Loss: 1.4392753839492798, Val Acc: 68.21%\n",
      "Epoch: 7755,     Training Loss: 0.309972882270813, Training Acc: 78.16%\n",
      "              Val Loss: 1.3134551048278809, Val Acc: 68.21%\n",
      "Epoch: 7756,     Training Loss: 0.287000834941864, Training Acc: 78.16%\n",
      "              Val Loss: 1.3225346803665161, Val Acc: 68.21%\n",
      "Epoch: 7757,     Training Loss: 0.3528464436531067, Training Acc: 78.16%\n",
      "              Val Loss: 1.4176435470581055, Val Acc: 68.21%\n",
      "Epoch: 7758,     Training Loss: 0.32520362734794617, Training Acc: 78.16%\n",
      "              Val Loss: 1.3169333934783936, Val Acc: 68.21%\n",
      "Epoch: 7759,     Training Loss: 0.35274460911750793, Training Acc: 78.16%\n",
      "              Val Loss: 1.3744148015975952, Val Acc: 68.21%\n",
      "Epoch: 7760,     Training Loss: 0.30354607105255127, Training Acc: 78.16%\n",
      "              Val Loss: 1.331969141960144, Val Acc: 68.21%\n",
      "Epoch: 7761,     Training Loss: 0.3079996109008789, Training Acc: 78.17%\n",
      "              Val Loss: 1.257645845413208, Val Acc: 68.21%\n",
      "Epoch: 7762,     Training Loss: 0.29729893803596497, Training Acc: 78.17%\n",
      "              Val Loss: 1.3367887735366821, Val Acc: 68.21%\n",
      "Epoch: 7763,     Training Loss: 0.2964603304862976, Training Acc: 78.17%\n",
      "              Val Loss: 1.3846948146820068, Val Acc: 68.21%\n",
      "Epoch: 7764,     Training Loss: 0.3721628189086914, Training Acc: 78.17%\n",
      "              Val Loss: 1.3446317911148071, Val Acc: 68.21%\n",
      "Epoch: 7765,     Training Loss: 0.2822306752204895, Training Acc: 78.17%\n",
      "              Val Loss: 1.3278433084487915, Val Acc: 68.22%\n",
      "Epoch: 7766,     Training Loss: 0.2725929915904999, Training Acc: 78.17%\n",
      "              Val Loss: 1.3387809991836548, Val Acc: 68.22%\n",
      "Epoch: 7767,     Training Loss: 0.3088315725326538, Training Acc: 78.17%\n",
      "              Val Loss: 1.3860856294631958, Val Acc: 68.22%\n",
      "Epoch: 7768,     Training Loss: 0.27837562561035156, Training Acc: 78.17%\n",
      "              Val Loss: 1.3113534450531006, Val Acc: 68.22%\n",
      "Epoch: 7769,     Training Loss: 0.2780699133872986, Training Acc: 78.18%\n",
      "              Val Loss: 1.3271827697753906, Val Acc: 68.22%\n",
      "Epoch: 7770,     Training Loss: 0.25505536794662476, Training Acc: 78.18%\n",
      "              Val Loss: 1.3153316974639893, Val Acc: 68.22%\n",
      "Epoch: 7771,     Training Loss: 0.25508129596710205, Training Acc: 78.18%\n",
      "              Val Loss: 1.2640546560287476, Val Acc: 68.22%\n",
      "Epoch: 7772,     Training Loss: 0.2718386948108673, Training Acc: 78.18%\n",
      "              Val Loss: 1.3196094036102295, Val Acc: 68.22%\n",
      "Epoch: 7773,     Training Loss: 0.252341091632843, Training Acc: 78.18%\n",
      "              Val Loss: 1.296249270439148, Val Acc: 68.22%\n",
      "Epoch: 7774,     Training Loss: 0.2472902536392212, Training Acc: 78.18%\n",
      "              Val Loss: 1.3123619556427002, Val Acc: 68.22%\n",
      "Epoch: 7775,     Training Loss: 0.25232017040252686, Training Acc: 78.18%\n",
      "              Val Loss: 1.3389692306518555, Val Acc: 68.22%\n",
      "Epoch: 7776,     Training Loss: 0.25646254420280457, Training Acc: 78.19%\n",
      "              Val Loss: 1.312018871307373, Val Acc: 68.22%\n",
      "Epoch: 7777,     Training Loss: 0.2492791712284088, Training Acc: 78.19%\n",
      "              Val Loss: 1.323032021522522, Val Acc: 68.22%\n",
      "Epoch: 7778,     Training Loss: 0.2376406341791153, Training Acc: 78.19%\n",
      "              Val Loss: 1.3299037218093872, Val Acc: 68.22%\n",
      "Epoch: 7779,     Training Loss: 0.2474045753479004, Training Acc: 78.19%\n",
      "              Val Loss: 1.3350448608398438, Val Acc: 68.22%\n",
      "Epoch: 7780,     Training Loss: 0.25206124782562256, Training Acc: 78.19%\n",
      "              Val Loss: 1.3122884035110474, Val Acc: 68.22%\n",
      "Epoch: 7781,     Training Loss: 0.24829548597335815, Training Acc: 78.19%\n",
      "              Val Loss: 1.3173065185546875, Val Acc: 68.22%\n",
      "Epoch: 7782,     Training Loss: 0.24133041501045227, Training Acc: 78.19%\n",
      "              Val Loss: 1.311904788017273, Val Acc: 68.22%\n",
      "Epoch: 7783,     Training Loss: 0.23723194003105164, Training Acc: 78.20%\n",
      "              Val Loss: 1.362677812576294, Val Acc: 68.22%\n",
      "Epoch: 7784,     Training Loss: 0.25034117698669434, Training Acc: 78.20%\n",
      "              Val Loss: 1.3225420713424683, Val Acc: 68.22%\n",
      "Epoch: 7785,     Training Loss: 0.268904447555542, Training Acc: 78.20%\n",
      "              Val Loss: 1.4009240865707397, Val Acc: 68.22%\n",
      "Epoch: 7786,     Training Loss: 0.2788260281085968, Training Acc: 78.20%\n",
      "              Val Loss: 1.3403667211532593, Val Acc: 68.22%\n",
      "Epoch: 7787,     Training Loss: 0.3388330936431885, Training Acc: 78.20%\n",
      "              Val Loss: 1.4537293910980225, Val Acc: 68.23%\n",
      "Epoch: 7788,     Training Loss: 0.31283360719680786, Training Acc: 78.20%\n",
      "              Val Loss: 1.3374872207641602, Val Acc: 68.23%\n",
      "Epoch: 7789,     Training Loss: 0.34592628479003906, Training Acc: 78.20%\n",
      "              Val Loss: 1.348347783088684, Val Acc: 68.23%\n",
      "Epoch: 7790,     Training Loss: 0.2632996439933777, Training Acc: 78.20%\n",
      "              Val Loss: 1.3288780450820923, Val Acc: 68.23%\n",
      "Epoch: 7791,     Training Loss: 0.24468198418617249, Training Acc: 78.21%\n",
      "              Val Loss: 1.3188236951828003, Val Acc: 68.23%\n",
      "Epoch: 7792,     Training Loss: 0.2781003713607788, Training Acc: 78.21%\n",
      "              Val Loss: 1.3803856372833252, Val Acc: 68.23%\n",
      "Epoch: 7793,     Training Loss: 0.2634259760379791, Training Acc: 78.21%\n",
      "              Val Loss: 1.3415433168411255, Val Acc: 68.23%\n",
      "Epoch: 7794,     Training Loss: 0.2757205069065094, Training Acc: 78.21%\n",
      "              Val Loss: 1.3416695594787598, Val Acc: 68.23%\n",
      "Epoch: 7795,     Training Loss: 0.25722265243530273, Training Acc: 78.21%\n",
      "              Val Loss: 1.3109992742538452, Val Acc: 68.23%\n",
      "Epoch: 7796,     Training Loss: 0.25524836778640747, Training Acc: 78.21%\n",
      "              Val Loss: 1.3800342082977295, Val Acc: 68.23%\n",
      "Epoch: 7797,     Training Loss: 0.27178505063056946, Training Acc: 78.21%\n",
      "              Val Loss: 1.3152128458023071, Val Acc: 68.23%\n",
      "Epoch: 7798,     Training Loss: 0.2465445101261139, Training Acc: 78.22%\n",
      "              Val Loss: 1.292852759361267, Val Acc: 68.23%\n",
      "Epoch: 7799,     Training Loss: 0.2395317405462265, Training Acc: 78.22%\n",
      "              Val Loss: 1.3418558835983276, Val Acc: 68.23%\n",
      "Epoch: 7800,     Training Loss: 0.2530342936515808, Training Acc: 78.22%\n",
      "              Val Loss: 1.3070063591003418, Val Acc: 68.23%\n",
      "Epoch: 7801,     Training Loss: 0.2463466227054596, Training Acc: 78.22%\n",
      "              Val Loss: 1.3418256044387817, Val Acc: 68.23%\n",
      "Epoch: 7802,     Training Loss: 0.23964686691761017, Training Acc: 78.22%\n",
      "              Val Loss: 1.3416917324066162, Val Acc: 68.23%\n",
      "Epoch: 7803,     Training Loss: 0.24908466637134552, Training Acc: 78.22%\n",
      "              Val Loss: 1.3462464809417725, Val Acc: 68.23%\n",
      "Epoch: 7804,     Training Loss: 0.2491566240787506, Training Acc: 78.23%\n",
      "              Val Loss: 1.3167576789855957, Val Acc: 68.23%\n",
      "Epoch: 7805,     Training Loss: 0.2462211549282074, Training Acc: 78.23%\n",
      "              Val Loss: 1.4029072523117065, Val Acc: 68.23%\n",
      "Epoch: 7806,     Training Loss: 0.2700817584991455, Training Acc: 78.23%\n",
      "              Val Loss: 1.3364715576171875, Val Acc: 68.23%\n",
      "Epoch: 7807,     Training Loss: 0.3180101811885834, Training Acc: 78.23%\n",
      "              Val Loss: 1.4307708740234375, Val Acc: 68.23%\n",
      "Epoch: 7808,     Training Loss: 0.2952023148536682, Training Acc: 78.23%\n",
      "              Val Loss: 1.4096041917800903, Val Acc: 68.23%\n",
      "Epoch: 7809,     Training Loss: 0.3839605450630188, Training Acc: 78.23%\n",
      "              Val Loss: 1.3857342004776, Val Acc: 68.24%\n",
      "Epoch: 7810,     Training Loss: 0.2820165157318115, Training Acc: 78.23%\n",
      "              Val Loss: 1.2863181829452515, Val Acc: 68.24%\n",
      "Epoch: 7811,     Training Loss: 0.2421996295452118, Training Acc: 78.23%\n",
      "              Val Loss: 1.3099256753921509, Val Acc: 68.24%\n",
      "Epoch: 7812,     Training Loss: 0.25795191526412964, Training Acc: 78.23%\n",
      "              Val Loss: 1.3499157428741455, Val Acc: 68.24%\n",
      "Epoch: 7813,     Training Loss: 0.26098981499671936, Training Acc: 78.24%\n",
      "              Val Loss: 1.2940528392791748, Val Acc: 68.24%\n",
      "Epoch: 7814,     Training Loss: 0.2760258913040161, Training Acc: 78.24%\n",
      "              Val Loss: 1.3994275331497192, Val Acc: 68.24%\n",
      "Epoch: 7815,     Training Loss: 0.27277621626853943, Training Acc: 78.24%\n",
      "              Val Loss: 1.2971762418746948, Val Acc: 68.24%\n",
      "Epoch: 7816,     Training Loss: 0.2717183828353882, Training Acc: 78.24%\n",
      "              Val Loss: 1.3391095399856567, Val Acc: 68.24%\n",
      "Epoch: 7817,     Training Loss: 0.2544836103916168, Training Acc: 78.24%\n",
      "              Val Loss: 1.3532198667526245, Val Acc: 68.24%\n",
      "Epoch: 7818,     Training Loss: 0.2527731657028198, Training Acc: 78.24%\n",
      "              Val Loss: 1.3253631591796875, Val Acc: 68.24%\n",
      "Epoch: 7819,     Training Loss: 0.2483242005109787, Training Acc: 78.24%\n",
      "              Val Loss: 1.365446925163269, Val Acc: 68.24%\n",
      "Epoch: 7820,     Training Loss: 0.24718661606311798, Training Acc: 78.25%\n",
      "              Val Loss: 1.3397172689437866, Val Acc: 68.24%\n",
      "Epoch: 7821,     Training Loss: 0.27074533700942993, Training Acc: 78.25%\n",
      "              Val Loss: 1.3628509044647217, Val Acc: 68.24%\n",
      "Epoch: 7822,     Training Loss: 0.2609751224517822, Training Acc: 78.25%\n",
      "              Val Loss: 1.311633586883545, Val Acc: 68.24%\n",
      "Epoch: 7823,     Training Loss: 0.2616150379180908, Training Acc: 78.25%\n",
      "              Val Loss: 1.3963782787322998, Val Acc: 68.24%\n",
      "Epoch: 7824,     Training Loss: 0.26890018582344055, Training Acc: 78.25%\n",
      "              Val Loss: 1.3045748472213745, Val Acc: 68.24%\n",
      "Epoch: 7825,     Training Loss: 0.26918819546699524, Training Acc: 78.25%\n",
      "              Val Loss: 1.346513032913208, Val Acc: 68.24%\n",
      "Epoch: 7826,     Training Loss: 0.25400689244270325, Training Acc: 78.25%\n",
      "              Val Loss: 1.3371343612670898, Val Acc: 68.24%\n",
      "Epoch: 7827,     Training Loss: 0.26508429646492004, Training Acc: 78.26%\n",
      "              Val Loss: 1.3545020818710327, Val Acc: 68.24%\n",
      "Epoch: 7828,     Training Loss: 0.25189343094825745, Training Acc: 78.26%\n",
      "              Val Loss: 1.3188552856445312, Val Acc: 68.24%\n",
      "Epoch: 7829,     Training Loss: 0.23965448141098022, Training Acc: 78.26%\n",
      "              Val Loss: 1.3713880777359009, Val Acc: 68.24%\n",
      "Epoch: 7830,     Training Loss: 0.2524958848953247, Training Acc: 78.26%\n",
      "              Val Loss: 1.3124445676803589, Val Acc: 68.25%\n",
      "Epoch: 7831,     Training Loss: 0.2455022931098938, Training Acc: 78.26%\n",
      "              Val Loss: 1.3440535068511963, Val Acc: 68.25%\n",
      "Epoch: 7832,     Training Loss: 0.23995789885520935, Training Acc: 78.26%\n",
      "              Val Loss: 1.3665945529937744, Val Acc: 68.25%\n",
      "Epoch: 7833,     Training Loss: 0.2626626193523407, Training Acc: 78.26%\n",
      "              Val Loss: 1.3448004722595215, Val Acc: 68.25%\n",
      "Epoch: 7834,     Training Loss: 0.2435627579689026, Training Acc: 78.27%\n",
      "              Val Loss: 1.319382667541504, Val Acc: 68.25%\n",
      "Epoch: 7835,     Training Loss: 0.2380441129207611, Training Acc: 78.27%\n",
      "              Val Loss: 1.3453972339630127, Val Acc: 68.25%\n",
      "Epoch: 7836,     Training Loss: 0.24165873229503632, Training Acc: 78.27%\n",
      "              Val Loss: 1.3248928785324097, Val Acc: 68.25%\n",
      "Epoch: 7837,     Training Loss: 0.23798736929893494, Training Acc: 78.27%\n",
      "              Val Loss: 1.336012840270996, Val Acc: 68.25%\n",
      "Epoch: 7838,     Training Loss: 0.23161716759204865, Training Acc: 78.27%\n",
      "              Val Loss: 1.3477128744125366, Val Acc: 68.25%\n",
      "Epoch: 7839,     Training Loss: 0.241245836019516, Training Acc: 78.27%\n",
      "              Val Loss: 1.3367063999176025, Val Acc: 68.25%\n",
      "Epoch: 7840,     Training Loss: 0.23913109302520752, Training Acc: 78.28%\n",
      "              Val Loss: 1.3197028636932373, Val Acc: 68.25%\n",
      "Epoch: 7841,     Training Loss: 0.23386864364147186, Training Acc: 78.28%\n",
      "              Val Loss: 1.3890117406845093, Val Acc: 68.25%\n",
      "Epoch: 7842,     Training Loss: 0.25040724873542786, Training Acc: 78.28%\n",
      "              Val Loss: 1.325994610786438, Val Acc: 68.25%\n",
      "Epoch: 7843,     Training Loss: 0.27638527750968933, Training Acc: 78.28%\n",
      "              Val Loss: 1.441116213798523, Val Acc: 68.25%\n",
      "Epoch: 7844,     Training Loss: 0.28718674182891846, Training Acc: 78.28%\n",
      "              Val Loss: 1.4328663349151611, Val Acc: 68.25%\n",
      "Epoch: 7845,     Training Loss: 0.39153099060058594, Training Acc: 78.28%\n",
      "              Val Loss: 1.4524379968643188, Val Acc: 68.25%\n",
      "Epoch: 7846,     Training Loss: 0.29605767130851746, Training Acc: 78.28%\n",
      "              Val Loss: 1.3024014234542847, Val Acc: 68.25%\n",
      "Epoch: 7847,     Training Loss: 0.2616114914417267, Training Acc: 78.28%\n",
      "              Val Loss: 1.3328983783721924, Val Acc: 68.25%\n",
      "Epoch: 7848,     Training Loss: 0.2536584436893463, Training Acc: 78.29%\n",
      "              Val Loss: 1.330054521560669, Val Acc: 68.25%\n",
      "Epoch: 7849,     Training Loss: 0.2445434033870697, Training Acc: 78.29%\n",
      "              Val Loss: 1.3015333414077759, Val Acc: 68.25%\n",
      "Epoch: 7850,     Training Loss: 0.26217132806777954, Training Acc: 78.29%\n",
      "              Val Loss: 1.4093023538589478, Val Acc: 68.25%\n",
      "Epoch: 7851,     Training Loss: 0.2691110372543335, Training Acc: 78.29%\n",
      "              Val Loss: 1.2938629388809204, Val Acc: 68.25%\n",
      "Epoch: 7852,     Training Loss: 0.27589094638824463, Training Acc: 78.29%\n",
      "              Val Loss: 1.3543457984924316, Val Acc: 68.26%\n",
      "Epoch: 7853,     Training Loss: 0.2607956528663635, Training Acc: 78.29%\n",
      "              Val Loss: 1.3615514039993286, Val Acc: 68.26%\n",
      "Epoch: 7854,     Training Loss: 0.27942970395088196, Training Acc: 78.29%\n",
      "              Val Loss: 1.3619141578674316, Val Acc: 68.26%\n",
      "Epoch: 7855,     Training Loss: 0.2556205987930298, Training Acc: 78.29%\n",
      "              Val Loss: 1.3185855150222778, Val Acc: 68.26%\n",
      "Epoch: 7856,     Training Loss: 0.2350890338420868, Training Acc: 78.30%\n",
      "              Val Loss: 1.3429034948349, Val Acc: 68.26%\n",
      "Epoch: 7857,     Training Loss: 0.2479507476091385, Training Acc: 78.30%\n",
      "              Val Loss: 1.3174127340316772, Val Acc: 68.26%\n",
      "Epoch: 7858,     Training Loss: 0.23520831763744354, Training Acc: 78.30%\n",
      "              Val Loss: 1.344757080078125, Val Acc: 68.26%\n",
      "Epoch: 7859,     Training Loss: 0.23570966720581055, Training Acc: 78.30%\n",
      "              Val Loss: 1.3720924854278564, Val Acc: 68.26%\n",
      "Epoch: 7860,     Training Loss: 0.2491331845521927, Training Acc: 78.30%\n",
      "              Val Loss: 1.332844853401184, Val Acc: 68.26%\n",
      "Epoch: 7861,     Training Loss: 0.23920319974422455, Training Acc: 78.30%\n",
      "              Val Loss: 1.3132890462875366, Val Acc: 68.26%\n",
      "Epoch: 7862,     Training Loss: 0.23715326189994812, Training Acc: 78.31%\n",
      "              Val Loss: 1.3579435348510742, Val Acc: 68.26%\n",
      "Epoch: 7863,     Training Loss: 0.2420450747013092, Training Acc: 78.31%\n",
      "              Val Loss: 1.3243396282196045, Val Acc: 68.26%\n",
      "Epoch: 7864,     Training Loss: 0.24410568177700043, Training Acc: 78.31%\n",
      "              Val Loss: 1.3575844764709473, Val Acc: 68.26%\n",
      "Epoch: 7865,     Training Loss: 0.23822784423828125, Training Acc: 78.31%\n",
      "              Val Loss: 1.3499670028686523, Val Acc: 68.26%\n",
      "Epoch: 7866,     Training Loss: 0.26428911089897156, Training Acc: 78.31%\n",
      "              Val Loss: 1.3922747373580933, Val Acc: 68.26%\n",
      "Epoch: 7867,     Training Loss: 0.2634684443473816, Training Acc: 78.31%\n",
      "              Val Loss: 1.3460144996643066, Val Acc: 68.26%\n",
      "Epoch: 7868,     Training Loss: 0.28938916325569153, Training Acc: 78.31%\n",
      "              Val Loss: 1.4771249294281006, Val Acc: 68.26%\n",
      "Epoch: 7869,     Training Loss: 0.2967471480369568, Training Acc: 78.32%\n",
      "              Val Loss: 1.3554329872131348, Val Acc: 68.26%\n",
      "Epoch: 7870,     Training Loss: 0.35564887523651123, Training Acc: 78.32%\n",
      "              Val Loss: 1.4510302543640137, Val Acc: 68.26%\n",
      "Epoch: 7871,     Training Loss: 0.31144124269485474, Training Acc: 78.32%\n",
      "              Val Loss: 1.3865269422531128, Val Acc: 68.26%\n",
      "Epoch: 7872,     Training Loss: 0.33196571469306946, Training Acc: 78.32%\n",
      "              Val Loss: 1.3607323169708252, Val Acc: 68.26%\n",
      "Epoch: 7873,     Training Loss: 0.2582695782184601, Training Acc: 78.32%\n",
      "              Val Loss: 1.3714163303375244, Val Acc: 68.26%\n",
      "Epoch: 7874,     Training Loss: 0.2628336250782013, Training Acc: 78.32%\n",
      "              Val Loss: 1.3917797803878784, Val Acc: 68.26%\n",
      "Epoch: 7875,     Training Loss: 0.3573359251022339, Training Acc: 78.32%\n",
      "              Val Loss: 1.429691195487976, Val Acc: 68.26%\n",
      "Epoch: 7876,     Training Loss: 0.2876647710800171, Training Acc: 78.32%\n",
      "              Val Loss: 1.341405987739563, Val Acc: 68.26%\n",
      "Epoch: 7877,     Training Loss: 0.2916215658187866, Training Acc: 78.32%\n",
      "              Val Loss: 1.417314887046814, Val Acc: 68.27%\n",
      "Epoch: 7878,     Training Loss: 0.2625282108783722, Training Acc: 78.33%\n",
      "              Val Loss: 1.3717734813690186, Val Acc: 68.27%\n",
      "Epoch: 7879,     Training Loss: 0.24776020646095276, Training Acc: 78.33%\n",
      "              Val Loss: 1.3335930109024048, Val Acc: 68.27%\n",
      "Epoch: 7880,     Training Loss: 0.2910502851009369, Training Acc: 78.33%\n",
      "              Val Loss: 1.3842072486877441, Val Acc: 68.27%\n",
      "Epoch: 7881,     Training Loss: 0.2585679292678833, Training Acc: 78.33%\n",
      "              Val Loss: 1.342980980873108, Val Acc: 68.27%\n",
      "Epoch: 7882,     Training Loss: 0.2687385678291321, Training Acc: 78.33%\n",
      "              Val Loss: 1.3955339193344116, Val Acc: 68.27%\n",
      "Epoch: 7883,     Training Loss: 0.2571451663970947, Training Acc: 78.33%\n",
      "              Val Loss: 1.3470906019210815, Val Acc: 68.27%\n",
      "Epoch: 7884,     Training Loss: 0.2526451051235199, Training Acc: 78.33%\n",
      "              Val Loss: 1.3660295009613037, Val Acc: 68.27%\n",
      "Epoch: 7885,     Training Loss: 0.28710731863975525, Training Acc: 78.33%\n",
      "              Val Loss: 1.3656930923461914, Val Acc: 68.27%\n",
      "Epoch: 7886,     Training Loss: 0.2795293927192688, Training Acc: 78.34%\n",
      "              Val Loss: 1.4171470403671265, Val Acc: 68.27%\n",
      "Epoch: 7887,     Training Loss: 0.2828339636325836, Training Acc: 78.34%\n",
      "              Val Loss: 1.311470627784729, Val Acc: 68.27%\n",
      "Epoch: 7888,     Training Loss: 0.26985010504722595, Training Acc: 78.34%\n",
      "              Val Loss: 1.3907394409179688, Val Acc: 68.27%\n",
      "Epoch: 7889,     Training Loss: 0.2872367799282074, Training Acc: 78.34%\n",
      "              Val Loss: 1.3611944913864136, Val Acc: 68.27%\n",
      "Epoch: 7890,     Training Loss: 0.32880017161369324, Training Acc: 78.34%\n",
      "              Val Loss: 1.4273252487182617, Val Acc: 68.27%\n",
      "Epoch: 7891,     Training Loss: 0.2862807810306549, Training Acc: 78.34%\n",
      "              Val Loss: 1.3277864456176758, Val Acc: 68.27%\n",
      "Epoch: 7892,     Training Loss: 0.289577454328537, Training Acc: 78.34%\n",
      "              Val Loss: 1.3751493692398071, Val Acc: 68.27%\n",
      "Epoch: 7893,     Training Loss: 0.25471702218055725, Training Acc: 78.34%\n",
      "              Val Loss: 1.3325026035308838, Val Acc: 68.27%\n",
      "Epoch: 7894,     Training Loss: 0.26350855827331543, Training Acc: 78.35%\n",
      "              Val Loss: 1.3808561563491821, Val Acc: 68.27%\n",
      "Epoch: 7895,     Training Loss: 0.2995326519012451, Training Acc: 78.35%\n",
      "              Val Loss: 1.401930332183838, Val Acc: 68.27%\n",
      "Epoch: 7896,     Training Loss: 0.3257141411304474, Training Acc: 78.35%\n",
      "              Val Loss: 1.3750395774841309, Val Acc: 68.27%\n",
      "Epoch: 7897,     Training Loss: 0.26465052366256714, Training Acc: 78.35%\n",
      "              Val Loss: 1.301021695137024, Val Acc: 68.27%\n",
      "Epoch: 7898,     Training Loss: 0.25634539127349854, Training Acc: 78.35%\n",
      "              Val Loss: 1.3789020776748657, Val Acc: 68.27%\n",
      "Epoch: 7899,     Training Loss: 0.2710615396499634, Training Acc: 78.35%\n",
      "              Val Loss: 1.357896327972412, Val Acc: 68.27%\n",
      "Epoch: 7900,     Training Loss: 0.2939200699329376, Training Acc: 78.35%\n",
      "              Val Loss: 1.363730788230896, Val Acc: 68.27%\n",
      "Epoch: 7901,     Training Loss: 0.2579677104949951, Training Acc: 78.35%\n",
      "              Val Loss: 1.3237305879592896, Val Acc: 68.27%\n",
      "Epoch: 7902,     Training Loss: 0.2335534244775772, Training Acc: 78.36%\n",
      "              Val Loss: 1.3440302610397339, Val Acc: 68.28%\n",
      "Epoch: 7903,     Training Loss: 0.25964969396591187, Training Acc: 78.36%\n",
      "              Val Loss: 1.3495292663574219, Val Acc: 68.28%\n",
      "Epoch: 7904,     Training Loss: 0.29411789774894714, Training Acc: 78.36%\n",
      "              Val Loss: 1.3827691078186035, Val Acc: 68.28%\n",
      "Epoch: 7905,     Training Loss: 0.2637709677219391, Training Acc: 78.36%\n",
      "              Val Loss: 1.3349305391311646, Val Acc: 68.28%\n",
      "Epoch: 7906,     Training Loss: 0.26604464650154114, Training Acc: 78.36%\n",
      "              Val Loss: 1.3909469842910767, Val Acc: 68.28%\n",
      "Epoch: 7907,     Training Loss: 0.2682921290397644, Training Acc: 78.36%\n",
      "              Val Loss: 1.3522228002548218, Val Acc: 68.28%\n",
      "Epoch: 7908,     Training Loss: 0.3006322979927063, Training Acc: 78.36%\n",
      "              Val Loss: 1.4103389978408813, Val Acc: 68.28%\n",
      "Epoch: 7909,     Training Loss: 0.2762036919593811, Training Acc: 78.37%\n",
      "              Val Loss: 1.3200591802597046, Val Acc: 68.28%\n",
      "Epoch: 7910,     Training Loss: 0.2863955497741699, Training Acc: 78.37%\n",
      "              Val Loss: 1.4038004875183105, Val Acc: 68.28%\n",
      "Epoch: 7911,     Training Loss: 0.2585945129394531, Training Acc: 78.37%\n",
      "              Val Loss: 1.361977219581604, Val Acc: 68.28%\n",
      "Epoch: 7912,     Training Loss: 0.27302953600883484, Training Acc: 78.37%\n",
      "              Val Loss: 1.3591405153274536, Val Acc: 68.28%\n",
      "Epoch: 7913,     Training Loss: 0.25980597734451294, Training Acc: 78.37%\n",
      "              Val Loss: 1.3358769416809082, Val Acc: 68.28%\n",
      "Epoch: 7914,     Training Loss: 0.23614688217639923, Training Acc: 78.37%\n",
      "              Val Loss: 1.3655216693878174, Val Acc: 68.28%\n",
      "Epoch: 7915,     Training Loss: 0.2365337610244751, Training Acc: 78.37%\n",
      "              Val Loss: 1.3349589109420776, Val Acc: 68.28%\n",
      "Epoch: 7916,     Training Loss: 0.24358652532100677, Training Acc: 78.38%\n",
      "              Val Loss: 1.3577275276184082, Val Acc: 68.28%\n",
      "Epoch: 7917,     Training Loss: 0.24323433637619019, Training Acc: 78.38%\n",
      "              Val Loss: 1.3609145879745483, Val Acc: 68.28%\n",
      "Epoch: 7918,     Training Loss: 0.23991794884204865, Training Acc: 78.38%\n",
      "              Val Loss: 1.3332844972610474, Val Acc: 68.28%\n",
      "Epoch: 7919,     Training Loss: 0.2390184998512268, Training Acc: 78.38%\n",
      "              Val Loss: 1.380152702331543, Val Acc: 68.28%\n",
      "Epoch: 7920,     Training Loss: 0.24025531113147736, Training Acc: 78.38%\n",
      "              Val Loss: 1.3337812423706055, Val Acc: 68.28%\n",
      "Epoch: 7921,     Training Loss: 0.266323983669281, Training Acc: 78.38%\n",
      "              Val Loss: 1.412964940071106, Val Acc: 68.28%\n",
      "Epoch: 7922,     Training Loss: 0.2720102369785309, Training Acc: 78.38%\n",
      "              Val Loss: 1.3311450481414795, Val Acc: 68.28%\n",
      "Epoch: 7923,     Training Loss: 0.2902839481830597, Training Acc: 78.38%\n",
      "              Val Loss: 1.420475959777832, Val Acc: 68.28%\n",
      "Epoch: 7924,     Training Loss: 0.2652469873428345, Training Acc: 78.39%\n",
      "              Val Loss: 1.318220615386963, Val Acc: 68.28%\n",
      "Epoch: 7925,     Training Loss: 0.27666276693344116, Training Acc: 78.39%\n",
      "              Val Loss: 1.3472294807434082, Val Acc: 68.28%\n",
      "Epoch: 7926,     Training Loss: 0.24443857371807098, Training Acc: 78.39%\n",
      "              Val Loss: 1.3596264123916626, Val Acc: 68.29%\n",
      "Epoch: 7927,     Training Loss: 0.23735544085502625, Training Acc: 78.39%\n",
      "              Val Loss: 1.3577345609664917, Val Acc: 68.29%\n",
      "Epoch: 7928,     Training Loss: 0.25228482484817505, Training Acc: 78.39%\n",
      "              Val Loss: 1.3829150199890137, Val Acc: 68.29%\n",
      "Epoch: 7929,     Training Loss: 0.23648229241371155, Training Acc: 78.39%\n",
      "              Val Loss: 1.3796637058258057, Val Acc: 68.29%\n",
      "Epoch: 7930,     Training Loss: 0.2582908570766449, Training Acc: 78.39%\n",
      "              Val Loss: 1.39170241355896, Val Acc: 68.29%\n",
      "Epoch: 7931,     Training Loss: 0.25429272651672363, Training Acc: 78.40%\n",
      "              Val Loss: 1.3406604528427124, Val Acc: 68.29%\n",
      "Epoch: 7932,     Training Loss: 0.2629983425140381, Training Acc: 78.40%\n",
      "              Val Loss: 1.4795622825622559, Val Acc: 68.29%\n",
      "Epoch: 7933,     Training Loss: 0.28675803542137146, Training Acc: 78.40%\n",
      "              Val Loss: 1.3463081121444702, Val Acc: 68.29%\n",
      "Epoch: 7934,     Training Loss: 0.33788612484931946, Training Acc: 78.40%\n",
      "              Val Loss: 1.4249528646469116, Val Acc: 68.29%\n",
      "Epoch: 7935,     Training Loss: 0.29044315218925476, Training Acc: 78.40%\n",
      "              Val Loss: 1.395675539970398, Val Acc: 68.29%\n",
      "Epoch: 7936,     Training Loss: 0.3210347890853882, Training Acc: 78.40%\n",
      "              Val Loss: 1.3646066188812256, Val Acc: 68.29%\n",
      "Epoch: 7937,     Training Loss: 0.2606661915779114, Training Acc: 78.40%\n",
      "              Val Loss: 1.382814645767212, Val Acc: 68.29%\n",
      "Epoch: 7938,     Training Loss: 0.251850962638855, Training Acc: 78.40%\n",
      "              Val Loss: 1.3812512159347534, Val Acc: 68.29%\n",
      "Epoch: 7939,     Training Loss: 0.3043014109134674, Training Acc: 78.41%\n",
      "              Val Loss: 1.38383150100708, Val Acc: 68.29%\n",
      "Epoch: 7940,     Training Loss: 0.24633106589317322, Training Acc: 78.41%\n",
      "              Val Loss: 1.363111972808838, Val Acc: 68.29%\n",
      "Epoch: 7941,     Training Loss: 0.252419650554657, Training Acc: 78.41%\n",
      "              Val Loss: 1.4060683250427246, Val Acc: 68.29%\n",
      "Epoch: 7942,     Training Loss: 0.2678526043891907, Training Acc: 78.41%\n",
      "              Val Loss: 1.367598533630371, Val Acc: 68.29%\n",
      "Epoch: 7943,     Training Loss: 0.24066197872161865, Training Acc: 78.41%\n",
      "              Val Loss: 1.343265175819397, Val Acc: 68.29%\n",
      "Epoch: 7944,     Training Loss: 0.24181795120239258, Training Acc: 78.41%\n",
      "              Val Loss: 1.3575400114059448, Val Acc: 68.29%\n",
      "Epoch: 7945,     Training Loss: 0.23872904479503632, Training Acc: 78.41%\n",
      "              Val Loss: 1.3894271850585938, Val Acc: 68.29%\n",
      "Epoch: 7946,     Training Loss: 0.23515769839286804, Training Acc: 78.42%\n",
      "              Val Loss: 1.339506983757019, Val Acc: 68.29%\n",
      "Epoch: 7947,     Training Loss: 0.24522796273231506, Training Acc: 78.42%\n",
      "              Val Loss: 1.4115209579467773, Val Acc: 68.29%\n",
      "Epoch: 7948,     Training Loss: 0.24827171862125397, Training Acc: 78.42%\n",
      "              Val Loss: 1.3386600017547607, Val Acc: 68.29%\n",
      "Epoch: 7949,     Training Loss: 0.25165554881095886, Training Acc: 78.42%\n",
      "              Val Loss: 1.4070968627929688, Val Acc: 68.29%\n",
      "Epoch: 7950,     Training Loss: 0.25321200489997864, Training Acc: 78.42%\n",
      "              Val Loss: 1.3821806907653809, Val Acc: 68.29%\n",
      "Epoch: 7951,     Training Loss: 0.2731499671936035, Training Acc: 78.42%\n",
      "              Val Loss: 1.3894063234329224, Val Acc: 68.30%\n",
      "Epoch: 7952,     Training Loss: 0.2420666664838791, Training Acc: 78.42%\n",
      "              Val Loss: 1.3419318199157715, Val Acc: 68.30%\n",
      "Epoch: 7953,     Training Loss: 0.2309250831604004, Training Acc: 78.43%\n",
      "              Val Loss: 1.3691993951797485, Val Acc: 68.30%\n",
      "Epoch: 7954,     Training Loss: 0.2297920286655426, Training Acc: 78.43%\n",
      "              Val Loss: 1.3593542575836182, Val Acc: 68.30%\n",
      "Epoch: 7955,     Training Loss: 0.22804145514965057, Training Acc: 78.43%\n",
      "              Val Loss: 1.3527408838272095, Val Acc: 68.30%\n",
      "Epoch: 7956,     Training Loss: 0.2302320897579193, Training Acc: 78.43%\n",
      "              Val Loss: 1.3879460096359253, Val Acc: 68.30%\n",
      "Epoch: 7957,     Training Loss: 0.23319736123085022, Training Acc: 78.43%\n",
      "              Val Loss: 1.339817762374878, Val Acc: 68.30%\n",
      "Epoch: 7958,     Training Loss: 0.24150806665420532, Training Acc: 78.43%\n",
      "              Val Loss: 1.4280776977539062, Val Acc: 68.30%\n",
      "Epoch: 7959,     Training Loss: 0.2564902603626251, Training Acc: 78.43%\n",
      "              Val Loss: 1.384823203086853, Val Acc: 68.30%\n",
      "Epoch: 7960,     Training Loss: 0.31887874007225037, Training Acc: 78.44%\n",
      "              Val Loss: 1.4581069946289062, Val Acc: 68.30%\n",
      "Epoch: 7961,     Training Loss: 0.27415427565574646, Training Acc: 78.44%\n",
      "              Val Loss: 1.3381074666976929, Val Acc: 68.30%\n",
      "Epoch: 7962,     Training Loss: 0.2833050489425659, Training Acc: 78.44%\n",
      "              Val Loss: 1.4016997814178467, Val Acc: 68.30%\n",
      "Epoch: 7963,     Training Loss: 0.2520606219768524, Training Acc: 78.44%\n",
      "              Val Loss: 1.331459403038025, Val Acc: 68.30%\n",
      "Epoch: 7964,     Training Loss: 0.2411707639694214, Training Acc: 78.44%\n",
      "              Val Loss: 1.3452900648117065, Val Acc: 68.30%\n",
      "Epoch: 7965,     Training Loss: 0.22645793855190277, Training Acc: 78.44%\n",
      "              Val Loss: 1.3908390998840332, Val Acc: 68.30%\n",
      "Epoch: 7966,     Training Loss: 0.23678213357925415, Training Acc: 78.44%\n",
      "              Val Loss: 1.339943289756775, Val Acc: 68.30%\n",
      "Epoch: 7967,     Training Loss: 0.2545725703239441, Training Acc: 78.45%\n",
      "              Val Loss: 1.4265265464782715, Val Acc: 68.30%\n",
      "Epoch: 7968,     Training Loss: 0.25811564922332764, Training Acc: 78.45%\n",
      "              Val Loss: 1.4070849418640137, Val Acc: 68.30%\n",
      "Epoch: 7969,     Training Loss: 0.3084304928779602, Training Acc: 78.45%\n",
      "              Val Loss: 1.4396567344665527, Val Acc: 68.30%\n",
      "Epoch: 7970,     Training Loss: 0.2589839696884155, Training Acc: 78.45%\n",
      "              Val Loss: 1.3352421522140503, Val Acc: 68.30%\n",
      "Epoch: 7971,     Training Loss: 0.24647097289562225, Training Acc: 78.45%\n",
      "              Val Loss: 1.3779597282409668, Val Acc: 68.30%\n",
      "Epoch: 7972,     Training Loss: 0.23968614637851715, Training Acc: 78.45%\n",
      "              Val Loss: 1.350063443183899, Val Acc: 68.30%\n",
      "Epoch: 7973,     Training Loss: 0.23183554410934448, Training Acc: 78.45%\n",
      "              Val Loss: 1.3410638570785522, Val Acc: 68.30%\n",
      "Epoch: 7974,     Training Loss: 0.2300003618001938, Training Acc: 78.45%\n",
      "              Val Loss: 1.4119774103164673, Val Acc: 68.30%\n",
      "Epoch: 7975,     Training Loss: 0.24365802109241486, Training Acc: 78.46%\n",
      "              Val Loss: 1.3493822813034058, Val Acc: 68.31%\n",
      "Epoch: 7976,     Training Loss: 0.26412075757980347, Training Acc: 78.46%\n",
      "              Val Loss: 1.4264658689498901, Val Acc: 68.31%\n",
      "Epoch: 7977,     Training Loss: 0.25507551431655884, Training Acc: 78.46%\n",
      "              Val Loss: 1.4323458671569824, Val Acc: 68.31%\n",
      "Epoch: 7978,     Training Loss: 0.2997601330280304, Training Acc: 78.46%\n",
      "              Val Loss: 1.4475932121276855, Val Acc: 68.31%\n",
      "Epoch: 7979,     Training Loss: 0.2568294405937195, Training Acc: 78.46%\n",
      "              Val Loss: 1.3491694927215576, Val Acc: 68.31%\n",
      "Epoch: 7980,     Training Loss: 0.23691827058792114, Training Acc: 78.46%\n",
      "              Val Loss: 1.3842068910598755, Val Acc: 68.31%\n",
      "Epoch: 7981,     Training Loss: 0.24293331801891327, Training Acc: 78.46%\n",
      "              Val Loss: 1.3498599529266357, Val Acc: 68.31%\n",
      "Epoch: 7982,     Training Loss: 0.23488323390483856, Training Acc: 78.47%\n",
      "              Val Loss: 1.3621649742126465, Val Acc: 68.31%\n",
      "Epoch: 7983,     Training Loss: 0.2273230105638504, Training Acc: 78.47%\n",
      "              Val Loss: 1.3906910419464111, Val Acc: 68.31%\n",
      "Epoch: 7984,     Training Loss: 0.2359839826822281, Training Acc: 78.47%\n",
      "              Val Loss: 1.3474117517471313, Val Acc: 68.31%\n",
      "Epoch: 7985,     Training Loss: 0.23912954330444336, Training Acc: 78.47%\n",
      "              Val Loss: 1.3596264123916626, Val Acc: 68.31%\n",
      "Epoch: 7986,     Training Loss: 0.2263169139623642, Training Acc: 78.47%\n",
      "              Val Loss: 1.4148471355438232, Val Acc: 68.31%\n",
      "Epoch: 7987,     Training Loss: 0.2498389482498169, Training Acc: 78.47%\n",
      "              Val Loss: 1.388279676437378, Val Acc: 68.31%\n",
      "Epoch: 7988,     Training Loss: 0.24949686229228973, Training Acc: 78.47%\n",
      "              Val Loss: 1.3604097366333008, Val Acc: 68.31%\n",
      "Epoch: 7989,     Training Loss: 0.22429470717906952, Training Acc: 78.48%\n",
      "              Val Loss: 1.4279584884643555, Val Acc: 68.31%\n",
      "Epoch: 7990,     Training Loss: 0.24644462764263153, Training Acc: 78.48%\n",
      "              Val Loss: 1.3686691522598267, Val Acc: 68.31%\n",
      "Epoch: 7991,     Training Loss: 0.2529512047767639, Training Acc: 78.48%\n",
      "              Val Loss: 1.4234445095062256, Val Acc: 68.31%\n",
      "Epoch: 7992,     Training Loss: 0.24105796217918396, Training Acc: 78.48%\n",
      "              Val Loss: 1.431374192237854, Val Acc: 68.31%\n",
      "Epoch: 7993,     Training Loss: 0.2991108298301697, Training Acc: 78.48%\n",
      "              Val Loss: 1.4530229568481445, Val Acc: 68.31%\n",
      "Epoch: 7994,     Training Loss: 0.2688376307487488, Training Acc: 78.48%\n",
      "              Val Loss: 1.3707271814346313, Val Acc: 68.31%\n",
      "Epoch: 7995,     Training Loss: 0.28044191002845764, Training Acc: 78.48%\n",
      "              Val Loss: 1.505455732345581, Val Acc: 68.31%\n",
      "Epoch: 7996,     Training Loss: 0.28473252058029175, Training Acc: 78.48%\n",
      "              Val Loss: 1.3606593608856201, Val Acc: 68.31%\n",
      "Epoch: 7997,     Training Loss: 0.29872700572013855, Training Acc: 78.49%\n",
      "              Val Loss: 1.4238308668136597, Val Acc: 68.31%\n",
      "Epoch: 7998,     Training Loss: 0.2662356495857239, Training Acc: 78.49%\n",
      "              Val Loss: 1.4429786205291748, Val Acc: 68.31%\n",
      "Epoch: 7999,     Training Loss: 0.3100489377975464, Training Acc: 78.49%\n",
      "              Val Loss: 1.40494704246521, Val Acc: 68.31%\n",
      "Epoch: 8000,     Training Loss: 0.2462446391582489, Training Acc: 78.49%\n",
      "              Val Loss: 1.3662458658218384, Val Acc: 68.32%\n",
      "Epoch: 8001,     Training Loss: 0.2374294102191925, Training Acc: 78.49%\n",
      "              Val Loss: 1.3897404670715332, Val Acc: 68.32%\n",
      "Epoch: 8002,     Training Loss: 0.2496062070131302, Training Acc: 78.49%\n",
      "              Val Loss: 1.3798598051071167, Val Acc: 68.32%\n",
      "Epoch: 8003,     Training Loss: 0.22572244703769684, Training Acc: 78.49%\n",
      "              Val Loss: 1.3759245872497559, Val Acc: 68.32%\n",
      "Epoch: 8004,     Training Loss: 0.24336780607700348, Training Acc: 78.50%\n",
      "              Val Loss: 1.4292988777160645, Val Acc: 68.32%\n",
      "Epoch: 8005,     Training Loss: 0.2343624085187912, Training Acc: 78.50%\n",
      "              Val Loss: 1.3747879266738892, Val Acc: 68.32%\n",
      "Epoch: 8006,     Training Loss: 0.22332030534744263, Training Acc: 78.50%\n",
      "              Val Loss: 1.3778586387634277, Val Acc: 68.32%\n",
      "Epoch: 8007,     Training Loss: 0.23226478695869446, Training Acc: 78.50%\n",
      "              Val Loss: 1.3801777362823486, Val Acc: 68.32%\n",
      "Epoch: 8008,     Training Loss: 0.2232748419046402, Training Acc: 78.50%\n",
      "              Val Loss: 1.395003080368042, Val Acc: 68.32%\n",
      "Epoch: 8009,     Training Loss: 0.22456945478916168, Training Acc: 78.50%\n",
      "              Val Loss: 1.3718284368515015, Val Acc: 68.32%\n",
      "Epoch: 8010,     Training Loss: 0.23059947788715363, Training Acc: 78.50%\n",
      "              Val Loss: 1.4026119709014893, Val Acc: 68.32%\n",
      "Epoch: 8011,     Training Loss: 0.23003998398780823, Training Acc: 78.51%\n",
      "              Val Loss: 1.3860622644424438, Val Acc: 68.32%\n",
      "Epoch: 8012,     Training Loss: 0.23846369981765747, Training Acc: 78.51%\n",
      "              Val Loss: 1.4583746194839478, Val Acc: 68.32%\n",
      "Epoch: 8013,     Training Loss: 0.25422751903533936, Training Acc: 78.51%\n",
      "              Val Loss: 1.4159762859344482, Val Acc: 68.32%\n",
      "Epoch: 8014,     Training Loss: 0.2989475429058075, Training Acc: 78.51%\n",
      "              Val Loss: 1.5439165830612183, Val Acc: 68.32%\n",
      "Epoch: 8015,     Training Loss: 0.30744338035583496, Training Acc: 78.51%\n",
      "              Val Loss: 1.4532681703567505, Val Acc: 68.32%\n",
      "Epoch: 8016,     Training Loss: 0.4277336001396179, Training Acc: 78.51%\n",
      "              Val Loss: 1.5418182611465454, Val Acc: 68.32%\n",
      "Epoch: 8017,     Training Loss: 0.308663547039032, Training Acc: 78.51%\n",
      "              Val Loss: 1.3859992027282715, Val Acc: 68.32%\n",
      "Epoch: 8018,     Training Loss: 0.29328417778015137, Training Acc: 78.51%\n",
      "              Val Loss: 1.3291118144989014, Val Acc: 68.32%\n",
      "Epoch: 8019,     Training Loss: 0.24378906190395355, Training Acc: 78.52%\n",
      "              Val Loss: 1.429390549659729, Val Acc: 68.32%\n",
      "Epoch: 8020,     Training Loss: 0.286738783121109, Training Acc: 78.52%\n",
      "              Val Loss: 1.4484350681304932, Val Acc: 68.32%\n",
      "Epoch: 8021,     Training Loss: 0.388960599899292, Training Acc: 78.52%\n",
      "              Val Loss: 1.4705291986465454, Val Acc: 68.32%\n",
      "Epoch: 8022,     Training Loss: 0.2769257426261902, Training Acc: 78.52%\n",
      "              Val Loss: 1.3955447673797607, Val Acc: 68.32%\n",
      "Epoch: 8023,     Training Loss: 0.28806671500205994, Training Acc: 78.52%\n",
      "              Val Loss: 1.4153892993927002, Val Acc: 68.32%\n",
      "Epoch: 8024,     Training Loss: 0.30754387378692627, Training Acc: 78.52%\n",
      "              Val Loss: 1.4967340230941772, Val Acc: 68.32%\n",
      "Epoch: 8025,     Training Loss: 0.29144182801246643, Training Acc: 78.52%\n",
      "              Val Loss: 1.3797639608383179, Val Acc: 68.32%\n",
      "Epoch: 8026,     Training Loss: 0.29936838150024414, Training Acc: 78.52%\n",
      "              Val Loss: 1.3912471532821655, Val Acc: 68.32%\n",
      "Epoch: 8027,     Training Loss: 0.24495214223861694, Training Acc: 78.52%\n",
      "              Val Loss: 1.4173208475112915, Val Acc: 68.32%\n",
      "Epoch: 8028,     Training Loss: 0.2640361487865448, Training Acc: 78.53%\n",
      "              Val Loss: 1.3457127809524536, Val Acc: 68.33%\n",
      "Epoch: 8029,     Training Loss: 0.2897019684314728, Training Acc: 78.53%\n",
      "              Val Loss: 1.4143856763839722, Val Acc: 68.33%\n",
      "Epoch: 8030,     Training Loss: 0.2610877752304077, Training Acc: 78.53%\n",
      "              Val Loss: 1.4746900796890259, Val Acc: 68.33%\n",
      "Epoch: 8031,     Training Loss: 0.2862425148487091, Training Acc: 78.53%\n",
      "              Val Loss: 1.3617459535598755, Val Acc: 68.33%\n",
      "Epoch: 8032,     Training Loss: 0.24622558057308197, Training Acc: 78.53%\n",
      "              Val Loss: 1.450066089630127, Val Acc: 68.33%\n",
      "Epoch: 8033,     Training Loss: 0.27237024903297424, Training Acc: 78.53%\n",
      "              Val Loss: 1.4528316259384155, Val Acc: 68.33%\n",
      "Epoch: 8034,     Training Loss: 0.34670859575271606, Training Acc: 78.53%\n",
      "              Val Loss: 1.417343020439148, Val Acc: 68.33%\n",
      "Epoch: 8035,     Training Loss: 0.246633380651474, Training Acc: 78.53%\n",
      "              Val Loss: 1.3807677030563354, Val Acc: 68.33%\n",
      "Epoch: 8036,     Training Loss: 0.2577723562717438, Training Acc: 78.53%\n",
      "              Val Loss: 1.3722500801086426, Val Acc: 68.33%\n",
      "Epoch: 8037,     Training Loss: 0.2636260688304901, Training Acc: 78.54%\n",
      "              Val Loss: 1.467918038368225, Val Acc: 68.33%\n",
      "Epoch: 8038,     Training Loss: 0.27366524934768677, Training Acc: 78.54%\n",
      "              Val Loss: 1.3946996927261353, Val Acc: 68.33%\n",
      "Epoch: 8039,     Training Loss: 0.32402125000953674, Training Acc: 78.54%\n",
      "              Val Loss: 1.4481000900268555, Val Acc: 68.33%\n",
      "Epoch: 8040,     Training Loss: 0.2611835300922394, Training Acc: 78.54%\n",
      "              Val Loss: 1.4394875764846802, Val Acc: 68.33%\n",
      "Epoch: 8041,     Training Loss: 0.28085944056510925, Training Acc: 78.54%\n",
      "              Val Loss: 1.3541481494903564, Val Acc: 68.33%\n",
      "Epoch: 8042,     Training Loss: 0.2463078498840332, Training Acc: 78.54%\n",
      "              Val Loss: 1.4199252128601074, Val Acc: 68.33%\n",
      "Epoch: 8043,     Training Loss: 0.2676021158695221, Training Acc: 78.54%\n",
      "              Val Loss: 1.4321233034133911, Val Acc: 68.33%\n",
      "Epoch: 8044,     Training Loss: 0.3241944909095764, Training Acc: 78.54%\n",
      "              Val Loss: 1.4712926149368286, Val Acc: 68.33%\n",
      "Epoch: 8045,     Training Loss: 0.26084277033805847, Training Acc: 78.55%\n",
      "              Val Loss: 1.3839895725250244, Val Acc: 68.33%\n",
      "Epoch: 8046,     Training Loss: 0.28494736552238464, Training Acc: 78.55%\n",
      "              Val Loss: 1.3788851499557495, Val Acc: 68.33%\n",
      "Epoch: 8047,     Training Loss: 0.23698118329048157, Training Acc: 78.55%\n",
      "              Val Loss: 1.4612432718276978, Val Acc: 68.33%\n",
      "Epoch: 8048,     Training Loss: 0.26498642563819885, Training Acc: 78.55%\n",
      "              Val Loss: 1.3785678148269653, Val Acc: 68.33%\n",
      "Epoch: 8049,     Training Loss: 0.3038661479949951, Training Acc: 78.55%\n",
      "              Val Loss: 1.4406325817108154, Val Acc: 68.33%\n",
      "Epoch: 8050,     Training Loss: 0.2849476933479309, Training Acc: 78.55%\n",
      "              Val Loss: 1.5166385173797607, Val Acc: 68.33%\n",
      "Epoch: 8051,     Training Loss: 0.3226044774055481, Training Acc: 78.55%\n",
      "              Val Loss: 1.3726614713668823, Val Acc: 68.33%\n",
      "Epoch: 8052,     Training Loss: 0.24826860427856445, Training Acc: 78.55%\n",
      "              Val Loss: 1.4060968160629272, Val Acc: 68.33%\n",
      "Epoch: 8053,     Training Loss: 0.2833414375782013, Training Acc: 78.56%\n",
      "              Val Loss: 1.3791764974594116, Val Acc: 68.33%\n",
      "Epoch: 8054,     Training Loss: 0.25427621603012085, Training Acc: 78.56%\n",
      "              Val Loss: 1.6301448345184326, Val Acc: 68.33%\n",
      "Epoch: 8055,     Training Loss: 0.3632386326789856, Training Acc: 78.56%\n",
      "              Val Loss: 1.5443220138549805, Val Acc: 68.33%\n",
      "Epoch: 8056,     Training Loss: 0.5518360733985901, Training Acc: 78.56%\n",
      "              Val Loss: 1.5178515911102295, Val Acc: 68.33%\n",
      "Epoch: 8057,     Training Loss: 0.4242919683456421, Training Acc: 78.56%\n",
      "              Val Loss: 1.460886836051941, Val Acc: 68.33%\n",
      "Epoch: 8058,     Training Loss: 0.4231829345226288, Training Acc: 78.56%\n",
      "              Val Loss: 1.4802414178848267, Val Acc: 68.34%\n",
      "Epoch: 8059,     Training Loss: 0.4065900146961212, Training Acc: 78.56%\n",
      "              Val Loss: 1.610142707824707, Val Acc: 68.34%\n",
      "Epoch: 8060,     Training Loss: 0.4986914098262787, Training Acc: 78.56%\n",
      "              Val Loss: 1.5954426527023315, Val Acc: 68.34%\n",
      "Epoch: 8061,     Training Loss: 0.6337510943412781, Training Acc: 78.56%\n",
      "              Val Loss: 1.5362725257873535, Val Acc: 68.33%\n",
      "Epoch: 8062,     Training Loss: 0.4699687063694, Training Acc: 78.56%\n",
      "              Val Loss: 1.6658384799957275, Val Acc: 68.33%\n",
      "Epoch: 8063,     Training Loss: 0.48649367690086365, Training Acc: 78.56%\n",
      "              Val Loss: 1.722261905670166, Val Acc: 68.33%\n",
      "Epoch: 8064,     Training Loss: 0.7297874689102173, Training Acc: 78.56%\n",
      "              Val Loss: 1.4888479709625244, Val Acc: 68.33%\n",
      "Epoch: 8065,     Training Loss: 0.47179850935935974, Training Acc: 78.56%\n",
      "              Val Loss: 1.694657802581787, Val Acc: 68.33%\n",
      "Epoch: 8066,     Training Loss: 0.6704585552215576, Training Acc: 78.56%\n",
      "              Val Loss: 1.4550986289978027, Val Acc: 68.33%\n",
      "Epoch: 8067,     Training Loss: 0.544216513633728, Training Acc: 78.56%\n",
      "              Val Loss: 1.564924955368042, Val Acc: 68.33%\n",
      "Epoch: 8068,     Training Loss: 0.5284937024116516, Training Acc: 78.56%\n",
      "              Val Loss: 1.787919044494629, Val Acc: 68.33%\n",
      "Epoch: 8069,     Training Loss: 0.6640434265136719, Training Acc: 78.56%\n",
      "              Val Loss: 1.353935956954956, Val Acc: 68.33%\n",
      "Epoch: 8070,     Training Loss: 0.4202410578727722, Training Acc: 78.56%\n",
      "              Val Loss: 1.4242732524871826, Val Acc: 68.33%\n",
      "Epoch: 8071,     Training Loss: 0.5094988942146301, Training Acc: 78.56%\n",
      "              Val Loss: 1.4506165981292725, Val Acc: 68.33%\n",
      "Epoch: 8072,     Training Loss: 0.43743932247161865, Training Acc: 78.56%\n",
      "              Val Loss: 1.480317234992981, Val Acc: 68.33%\n",
      "Epoch: 8073,     Training Loss: 0.41469618678092957, Training Acc: 78.56%\n",
      "              Val Loss: 1.450038194656372, Val Acc: 68.33%\n",
      "Epoch: 8074,     Training Loss: 0.4290671944618225, Training Acc: 78.56%\n",
      "              Val Loss: 1.334160327911377, Val Acc: 68.33%\n",
      "Epoch: 8075,     Training Loss: 0.39732253551483154, Training Acc: 78.56%\n",
      "              Val Loss: 1.417421579360962, Val Acc: 68.34%\n",
      "Epoch: 8076,     Training Loss: 0.42595356702804565, Training Acc: 78.56%\n",
      "              Val Loss: 1.3080297708511353, Val Acc: 68.34%\n",
      "Epoch: 8077,     Training Loss: 0.3254983127117157, Training Acc: 78.56%\n",
      "              Val Loss: 1.3881295919418335, Val Acc: 68.34%\n",
      "Epoch: 8078,     Training Loss: 0.3640679121017456, Training Acc: 78.56%\n",
      "              Val Loss: 1.4403456449508667, Val Acc: 68.34%\n",
      "Epoch: 8079,     Training Loss: 0.33849579095840454, Training Acc: 78.56%\n",
      "              Val Loss: 1.439660668373108, Val Acc: 68.34%\n",
      "Epoch: 8080,     Training Loss: 0.3341408669948578, Training Acc: 78.56%\n",
      "              Val Loss: 1.3639624118804932, Val Acc: 68.34%\n",
      "Epoch: 8081,     Training Loss: 0.2874663472175598, Training Acc: 78.57%\n",
      "              Val Loss: 1.3790631294250488, Val Acc: 68.34%\n",
      "Epoch: 8082,     Training Loss: 0.3216665983200073, Training Acc: 78.57%\n",
      "              Val Loss: 1.329724907875061, Val Acc: 68.34%\n",
      "Epoch: 8083,     Training Loss: 0.30476322770118713, Training Acc: 78.57%\n",
      "              Val Loss: 1.3734686374664307, Val Acc: 68.34%\n",
      "Epoch: 8084,     Training Loss: 0.3033653497695923, Training Acc: 78.57%\n",
      "              Val Loss: 1.3222819566726685, Val Acc: 68.34%\n",
      "Epoch: 8085,     Training Loss: 0.3286338150501251, Training Acc: 78.57%\n",
      "              Val Loss: 1.3577325344085693, Val Acc: 68.34%\n",
      "Epoch: 8086,     Training Loss: 0.2840319573879242, Training Acc: 78.57%\n",
      "              Val Loss: 1.385941505432129, Val Acc: 68.34%\n",
      "Epoch: 8087,     Training Loss: 0.30627676844596863, Training Acc: 78.57%\n",
      "              Val Loss: 1.3367959260940552, Val Acc: 68.34%\n",
      "Epoch: 8088,     Training Loss: 0.30383145809173584, Training Acc: 78.57%\n",
      "              Val Loss: 1.4108612537384033, Val Acc: 68.34%\n",
      "Epoch: 8089,     Training Loss: 0.2883399426937103, Training Acc: 78.57%\n",
      "              Val Loss: 1.3566169738769531, Val Acc: 68.34%\n",
      "Epoch: 8090,     Training Loss: 0.271526575088501, Training Acc: 78.57%\n",
      "              Val Loss: 1.3360137939453125, Val Acc: 68.34%\n",
      "Epoch: 8091,     Training Loss: 0.2783251404762268, Training Acc: 78.58%\n",
      "              Val Loss: 1.410728096961975, Val Acc: 68.34%\n",
      "Epoch: 8092,     Training Loss: 0.27113598585128784, Training Acc: 78.58%\n",
      "              Val Loss: 1.3916319608688354, Val Acc: 68.34%\n",
      "Epoch: 8093,     Training Loss: 0.27518028020858765, Training Acc: 78.58%\n",
      "              Val Loss: 1.3626512289047241, Val Acc: 68.34%\n",
      "Epoch: 8094,     Training Loss: 0.25531482696533203, Training Acc: 78.58%\n",
      "              Val Loss: 1.3482284545898438, Val Acc: 68.34%\n",
      "Epoch: 8095,     Training Loss: 0.25478267669677734, Training Acc: 78.58%\n",
      "              Val Loss: 1.3437176942825317, Val Acc: 68.34%\n",
      "Epoch: 8096,     Training Loss: 0.26195210218429565, Training Acc: 78.58%\n",
      "              Val Loss: 1.3567168712615967, Val Acc: 68.34%\n",
      "Epoch: 8097,     Training Loss: 0.246097132563591, Training Acc: 78.58%\n",
      "              Val Loss: 1.3152142763137817, Val Acc: 68.34%\n",
      "Epoch: 8098,     Training Loss: 0.24946799874305725, Training Acc: 78.59%\n",
      "              Val Loss: 1.3674519062042236, Val Acc: 68.34%\n",
      "Epoch: 8099,     Training Loss: 0.24034877121448517, Training Acc: 78.59%\n",
      "              Val Loss: 1.3885188102722168, Val Acc: 68.34%\n",
      "Epoch: 8100,     Training Loss: 0.23964403569698334, Training Acc: 78.59%\n",
      "              Val Loss: 1.3793067932128906, Val Acc: 68.34%\n",
      "Epoch: 8101,     Training Loss: 0.2391912043094635, Training Acc: 78.59%\n",
      "              Val Loss: 1.4089264869689941, Val Acc: 68.34%\n",
      "Epoch: 8102,     Training Loss: 0.24149374663829803, Training Acc: 78.59%\n",
      "              Val Loss: 1.3864006996154785, Val Acc: 68.34%\n",
      "Epoch: 8103,     Training Loss: 0.24506978690624237, Training Acc: 78.59%\n",
      "              Val Loss: 1.4059311151504517, Val Acc: 68.34%\n",
      "Epoch: 8104,     Training Loss: 0.23529276251792908, Training Acc: 78.59%\n",
      "              Val Loss: 1.3911203145980835, Val Acc: 68.34%\n",
      "Epoch: 8105,     Training Loss: 0.23641380667686462, Training Acc: 78.60%\n",
      "              Val Loss: 1.4139208793640137, Val Acc: 68.34%\n",
      "Epoch: 8106,     Training Loss: 0.23122209310531616, Training Acc: 78.60%\n",
      "              Val Loss: 1.422799825668335, Val Acc: 68.34%\n",
      "Epoch: 8107,     Training Loss: 0.2309279888868332, Training Acc: 78.60%\n",
      "              Val Loss: 1.397567868232727, Val Acc: 68.35%\n",
      "Epoch: 8108,     Training Loss: 0.23257037997245789, Training Acc: 78.60%\n",
      "              Val Loss: 1.4169344902038574, Val Acc: 68.35%\n",
      "Epoch: 8109,     Training Loss: 0.2310713827610016, Training Acc: 78.60%\n",
      "              Val Loss: 1.400014042854309, Val Acc: 68.35%\n",
      "Epoch: 8110,     Training Loss: 0.23491641879081726, Training Acc: 78.60%\n",
      "              Val Loss: 1.4183220863342285, Val Acc: 68.35%\n",
      "Epoch: 8111,     Training Loss: 0.22821441292762756, Training Acc: 78.60%\n",
      "              Val Loss: 1.3768105506896973, Val Acc: 68.35%\n",
      "Epoch: 8112,     Training Loss: 0.23027119040489197, Training Acc: 78.61%\n",
      "              Val Loss: 1.415333867073059, Val Acc: 68.35%\n",
      "Epoch: 8113,     Training Loss: 0.2311716228723526, Training Acc: 78.61%\n",
      "              Val Loss: 1.381886601448059, Val Acc: 68.35%\n",
      "Epoch: 8114,     Training Loss: 0.23459434509277344, Training Acc: 78.61%\n",
      "              Val Loss: 1.4407864809036255, Val Acc: 68.35%\n",
      "Epoch: 8115,     Training Loss: 0.23898731172084808, Training Acc: 78.61%\n",
      "              Val Loss: 1.391627311706543, Val Acc: 68.35%\n",
      "Epoch: 8116,     Training Loss: 0.2567403316497803, Training Acc: 78.61%\n",
      "              Val Loss: 1.4727269411087036, Val Acc: 68.35%\n",
      "Epoch: 8117,     Training Loss: 0.25286373496055603, Training Acc: 78.61%\n",
      "              Val Loss: 1.384523630142212, Val Acc: 68.35%\n",
      "Epoch: 8118,     Training Loss: 0.26429831981658936, Training Acc: 78.61%\n",
      "              Val Loss: 1.449055790901184, Val Acc: 68.35%\n",
      "Epoch: 8119,     Training Loss: 0.24243658781051636, Training Acc: 78.62%\n",
      "              Val Loss: 1.394016146659851, Val Acc: 68.35%\n",
      "Epoch: 8120,     Training Loss: 0.23404255509376526, Training Acc: 78.62%\n",
      "              Val Loss: 1.399962306022644, Val Acc: 68.35%\n",
      "Epoch: 8121,     Training Loss: 0.2222784161567688, Training Acc: 78.62%\n",
      "              Val Loss: 1.4247727394104004, Val Acc: 68.35%\n",
      "Epoch: 8122,     Training Loss: 0.22843171656131744, Training Acc: 78.62%\n",
      "              Val Loss: 1.3934229612350464, Val Acc: 68.35%\n",
      "Epoch: 8123,     Training Loss: 0.24112501740455627, Training Acc: 78.62%\n",
      "              Val Loss: 1.4558861255645752, Val Acc: 68.35%\n",
      "Epoch: 8124,     Training Loss: 0.23583535850048065, Training Acc: 78.62%\n",
      "              Val Loss: 1.3944215774536133, Val Acc: 68.35%\n",
      "Epoch: 8125,     Training Loss: 0.23852287232875824, Training Acc: 78.62%\n",
      "              Val Loss: 1.4444493055343628, Val Acc: 68.35%\n",
      "Epoch: 8126,     Training Loss: 0.2279525250196457, Training Acc: 78.63%\n",
      "              Val Loss: 1.3986762762069702, Val Acc: 68.35%\n",
      "Epoch: 8127,     Training Loss: 0.22515608370304108, Training Acc: 78.63%\n",
      "              Val Loss: 1.401289701461792, Val Acc: 68.35%\n",
      "Epoch: 8128,     Training Loss: 0.22108295559883118, Training Acc: 78.63%\n",
      "              Val Loss: 1.3956853151321411, Val Acc: 68.35%\n",
      "Epoch: 8129,     Training Loss: 0.21880604326725006, Training Acc: 78.63%\n",
      "              Val Loss: 1.3959060907363892, Val Acc: 68.35%\n",
      "Epoch: 8130,     Training Loss: 0.22223615646362305, Training Acc: 78.63%\n",
      "              Val Loss: 1.4032434225082397, Val Acc: 68.35%\n",
      "Epoch: 8131,     Training Loss: 0.2204817235469818, Training Acc: 78.63%\n",
      "              Val Loss: 1.3768370151519775, Val Acc: 68.36%\n",
      "Epoch: 8132,     Training Loss: 0.22239072620868683, Training Acc: 78.64%\n",
      "              Val Loss: 1.4279342889785767, Val Acc: 68.36%\n",
      "Epoch: 8133,     Training Loss: 0.22502747178077698, Training Acc: 78.64%\n",
      "              Val Loss: 1.3900096416473389, Val Acc: 68.36%\n",
      "Epoch: 8134,     Training Loss: 0.22990873456001282, Training Acc: 78.64%\n",
      "              Val Loss: 1.4510350227355957, Val Acc: 68.36%\n",
      "Epoch: 8135,     Training Loss: 0.23253391683101654, Training Acc: 78.64%\n",
      "              Val Loss: 1.399296522140503, Val Acc: 68.36%\n",
      "Epoch: 8136,     Training Loss: 0.24553000926971436, Training Acc: 78.64%\n",
      "              Val Loss: 1.4602845907211304, Val Acc: 68.36%\n",
      "Epoch: 8137,     Training Loss: 0.2412252426147461, Training Acc: 78.64%\n",
      "              Val Loss: 1.3832179307937622, Val Acc: 68.36%\n",
      "Epoch: 8138,     Training Loss: 0.2482512891292572, Training Acc: 78.64%\n",
      "              Val Loss: 1.4491304159164429, Val Acc: 68.36%\n",
      "Epoch: 8139,     Training Loss: 0.2361340969800949, Training Acc: 78.65%\n",
      "              Val Loss: 1.3753395080566406, Val Acc: 68.36%\n",
      "Epoch: 8140,     Training Loss: 0.2337305098772049, Training Acc: 78.65%\n",
      "              Val Loss: 1.4102977514266968, Val Acc: 68.36%\n",
      "Epoch: 8141,     Training Loss: 0.22791922092437744, Training Acc: 78.65%\n",
      "              Val Loss: 1.402681589126587, Val Acc: 68.36%\n",
      "Epoch: 8142,     Training Loss: 0.2222713828086853, Training Acc: 78.65%\n",
      "              Val Loss: 1.4126274585723877, Val Acc: 68.36%\n",
      "Epoch: 8143,     Training Loss: 0.21660493314266205, Training Acc: 78.65%\n",
      "              Val Loss: 1.4290369749069214, Val Acc: 68.36%\n",
      "Epoch: 8144,     Training Loss: 0.2198643684387207, Training Acc: 78.65%\n",
      "              Val Loss: 1.4078152179718018, Val Acc: 68.36%\n",
      "Epoch: 8145,     Training Loss: 0.22771455347537994, Training Acc: 78.65%\n",
      "              Val Loss: 1.4570720195770264, Val Acc: 68.36%\n",
      "Epoch: 8146,     Training Loss: 0.2330230176448822, Training Acc: 78.66%\n",
      "              Val Loss: 1.3917292356491089, Val Acc: 68.36%\n",
      "Epoch: 8147,     Training Loss: 0.24894829094409943, Training Acc: 78.66%\n",
      "              Val Loss: 1.4750338792800903, Val Acc: 68.36%\n",
      "Epoch: 8148,     Training Loss: 0.24752996861934662, Training Acc: 78.66%\n",
      "              Val Loss: 1.3879592418670654, Val Acc: 68.36%\n",
      "Epoch: 8149,     Training Loss: 0.2736678719520569, Training Acc: 78.66%\n",
      "              Val Loss: 1.455275297164917, Val Acc: 68.36%\n",
      "Epoch: 8150,     Training Loss: 0.2549949586391449, Training Acc: 78.66%\n",
      "              Val Loss: 1.3714747428894043, Val Acc: 68.36%\n",
      "Epoch: 8151,     Training Loss: 0.25424402952194214, Training Acc: 78.66%\n",
      "              Val Loss: 1.4349380731582642, Val Acc: 68.36%\n",
      "Epoch: 8152,     Training Loss: 0.2317456603050232, Training Acc: 78.66%\n",
      "              Val Loss: 1.3897818326950073, Val Acc: 68.36%\n",
      "Epoch: 8153,     Training Loss: 0.22583279013633728, Training Acc: 78.67%\n",
      "              Val Loss: 1.4038852453231812, Val Acc: 68.36%\n",
      "Epoch: 8154,     Training Loss: 0.22541479766368866, Training Acc: 78.67%\n",
      "              Val Loss: 1.447210669517517, Val Acc: 68.36%\n",
      "Epoch: 8155,     Training Loss: 0.22333315014839172, Training Acc: 78.67%\n",
      "              Val Loss: 1.4153097867965698, Val Acc: 68.36%\n",
      "Epoch: 8156,     Training Loss: 0.23059694468975067, Training Acc: 78.67%\n",
      "              Val Loss: 1.468007206916809, Val Acc: 68.37%\n",
      "Epoch: 8157,     Training Loss: 0.2324625849723816, Training Acc: 78.67%\n",
      "              Val Loss: 1.4104413986206055, Val Acc: 68.37%\n",
      "Epoch: 8158,     Training Loss: 0.2427176684141159, Training Acc: 78.67%\n",
      "              Val Loss: 1.4381295442581177, Val Acc: 68.37%\n",
      "Epoch: 8159,     Training Loss: 0.23155273497104645, Training Acc: 78.67%\n",
      "              Val Loss: 1.3908417224884033, Val Acc: 68.37%\n",
      "Epoch: 8160,     Training Loss: 0.22669921815395355, Training Acc: 78.68%\n",
      "              Val Loss: 1.4380160570144653, Val Acc: 68.37%\n",
      "Epoch: 8161,     Training Loss: 0.224884495139122, Training Acc: 78.68%\n",
      "              Val Loss: 1.3927335739135742, Val Acc: 68.37%\n",
      "Epoch: 8162,     Training Loss: 0.22308118641376495, Training Acc: 78.68%\n",
      "              Val Loss: 1.4115800857543945, Val Acc: 68.37%\n",
      "Epoch: 8163,     Training Loss: 0.21839794516563416, Training Acc: 78.68%\n",
      "              Val Loss: 1.4023607969284058, Val Acc: 68.37%\n",
      "Epoch: 8164,     Training Loss: 0.21540500223636627, Training Acc: 78.68%\n",
      "              Val Loss: 1.422857642173767, Val Acc: 68.37%\n",
      "Epoch: 8165,     Training Loss: 0.21609900891780853, Training Acc: 78.68%\n",
      "              Val Loss: 1.435225009918213, Val Acc: 68.37%\n",
      "Epoch: 8166,     Training Loss: 0.2168300747871399, Training Acc: 78.69%\n",
      "              Val Loss: 1.4300438165664673, Val Acc: 68.37%\n",
      "Epoch: 8167,     Training Loss: 0.2148297280073166, Training Acc: 78.69%\n",
      "              Val Loss: 1.4365365505218506, Val Acc: 68.37%\n",
      "Epoch: 8168,     Training Loss: 0.21412540972232819, Training Acc: 78.69%\n",
      "              Val Loss: 1.4319871664047241, Val Acc: 68.37%\n",
      "Epoch: 8169,     Training Loss: 0.21473893523216248, Training Acc: 78.69%\n",
      "              Val Loss: 1.4502456188201904, Val Acc: 68.37%\n",
      "Epoch: 8170,     Training Loss: 0.2180512398481369, Training Acc: 78.69%\n",
      "              Val Loss: 1.4204659461975098, Val Acc: 68.37%\n",
      "Epoch: 8171,     Training Loss: 0.22275356948375702, Training Acc: 78.69%\n",
      "              Val Loss: 1.4599778652191162, Val Acc: 68.37%\n",
      "Epoch: 8172,     Training Loss: 0.22763366997241974, Training Acc: 78.69%\n",
      "              Val Loss: 1.4123343229293823, Val Acc: 68.37%\n",
      "Epoch: 8173,     Training Loss: 0.24882665276527405, Training Acc: 78.70%\n",
      "              Val Loss: 1.5190461874008179, Val Acc: 68.37%\n",
      "Epoch: 8174,     Training Loss: 0.2617690861225128, Training Acc: 78.70%\n",
      "              Val Loss: 1.4430309534072876, Val Acc: 68.37%\n",
      "Epoch: 8175,     Training Loss: 0.3245527148246765, Training Acc: 78.70%\n",
      "              Val Loss: 1.5284080505371094, Val Acc: 68.37%\n",
      "Epoch: 8176,     Training Loss: 0.27457571029663086, Training Acc: 78.70%\n",
      "              Val Loss: 1.389081597328186, Val Acc: 68.37%\n",
      "Epoch: 8177,     Training Loss: 0.2669708728790283, Training Acc: 78.70%\n",
      "              Val Loss: 1.4239414930343628, Val Acc: 68.37%\n",
      "Epoch: 8178,     Training Loss: 0.22484315931797028, Training Acc: 78.70%\n",
      "              Val Loss: 1.4365893602371216, Val Acc: 68.37%\n",
      "Epoch: 8179,     Training Loss: 0.23011274635791779, Training Acc: 78.70%\n",
      "              Val Loss: 1.4001879692077637, Val Acc: 68.37%\n",
      "Epoch: 8180,     Training Loss: 0.2475641965866089, Training Acc: 78.70%\n",
      "              Val Loss: 1.467726469039917, Val Acc: 68.37%\n",
      "Epoch: 8181,     Training Loss: 0.23508240282535553, Training Acc: 78.71%\n",
      "              Val Loss: 1.419052004814148, Val Acc: 68.37%\n",
      "Epoch: 8182,     Training Loss: 0.2389991730451584, Training Acc: 78.71%\n",
      "              Val Loss: 1.4647855758666992, Val Acc: 68.38%\n",
      "Epoch: 8183,     Training Loss: 0.23693175613880157, Training Acc: 78.71%\n",
      "              Val Loss: 1.446137547492981, Val Acc: 68.38%\n",
      "Epoch: 8184,     Training Loss: 0.2340974360704422, Training Acc: 78.71%\n",
      "              Val Loss: 1.4302700757980347, Val Acc: 68.38%\n",
      "Epoch: 8185,     Training Loss: 0.22190529108047485, Training Acc: 78.71%\n",
      "              Val Loss: 1.4362901449203491, Val Acc: 68.38%\n",
      "Epoch: 8186,     Training Loss: 0.21512097120285034, Training Acc: 78.71%\n",
      "              Val Loss: 1.4180828332901, Val Acc: 68.38%\n",
      "Epoch: 8187,     Training Loss: 0.22338806092739105, Training Acc: 78.72%\n",
      "              Val Loss: 1.447597622871399, Val Acc: 68.38%\n",
      "Epoch: 8188,     Training Loss: 0.22789840400218964, Training Acc: 78.72%\n",
      "              Val Loss: 1.4065947532653809, Val Acc: 68.38%\n",
      "Epoch: 8189,     Training Loss: 0.23071913421154022, Training Acc: 78.72%\n",
      "              Val Loss: 1.4409072399139404, Val Acc: 68.38%\n",
      "Epoch: 8190,     Training Loss: 0.2223266363143921, Training Acc: 78.72%\n",
      "              Val Loss: 1.4125876426696777, Val Acc: 68.38%\n",
      "Epoch: 8191,     Training Loss: 0.22540917992591858, Training Acc: 78.72%\n",
      "              Val Loss: 1.4691890478134155, Val Acc: 68.38%\n",
      "Epoch: 8192,     Training Loss: 0.22891487181186676, Training Acc: 78.72%\n",
      "              Val Loss: 1.4213491678237915, Val Acc: 68.38%\n",
      "Epoch: 8193,     Training Loss: 0.2387896329164505, Training Acc: 78.72%\n",
      "              Val Loss: 1.4822654724121094, Val Acc: 68.38%\n",
      "Epoch: 8194,     Training Loss: 0.23512494564056396, Training Acc: 78.73%\n",
      "              Val Loss: 1.421565294265747, Val Acc: 68.38%\n",
      "Epoch: 8195,     Training Loss: 0.25060877203941345, Training Acc: 78.73%\n",
      "              Val Loss: 1.5077743530273438, Val Acc: 68.38%\n",
      "Epoch: 8196,     Training Loss: 0.25084570050239563, Training Acc: 78.73%\n",
      "              Val Loss: 1.4271864891052246, Val Acc: 68.38%\n",
      "Epoch: 8197,     Training Loss: 0.271941214799881, Training Acc: 78.73%\n",
      "              Val Loss: 1.4746251106262207, Val Acc: 68.38%\n",
      "Epoch: 8198,     Training Loss: 0.24027402698993683, Training Acc: 78.73%\n",
      "              Val Loss: 1.4055103063583374, Val Acc: 68.38%\n",
      "Epoch: 8199,     Training Loss: 0.22644834220409393, Training Acc: 78.73%\n",
      "              Val Loss: 1.4450526237487793, Val Acc: 68.38%\n",
      "Epoch: 8200,     Training Loss: 0.2169181853532791, Training Acc: 78.73%\n",
      "              Val Loss: 1.4337513446807861, Val Acc: 68.38%\n",
      "Epoch: 8201,     Training Loss: 0.21662026643753052, Training Acc: 78.74%\n",
      "              Val Loss: 1.4143263101577759, Val Acc: 68.38%\n",
      "Epoch: 8202,     Training Loss: 0.22340279817581177, Training Acc: 78.74%\n",
      "              Val Loss: 1.4647239446640015, Val Acc: 68.38%\n",
      "Epoch: 8203,     Training Loss: 0.22843247652053833, Training Acc: 78.74%\n",
      "              Val Loss: 1.4245392084121704, Val Acc: 68.38%\n",
      "Epoch: 8204,     Training Loss: 0.24661137163639069, Training Acc: 78.74%\n",
      "              Val Loss: 1.5119905471801758, Val Acc: 68.38%\n",
      "Epoch: 8205,     Training Loss: 0.24974483251571655, Training Acc: 78.74%\n",
      "              Val Loss: 1.423919677734375, Val Acc: 68.38%\n",
      "Epoch: 8206,     Training Loss: 0.28527724742889404, Training Acc: 78.74%\n",
      "              Val Loss: 1.513968825340271, Val Acc: 68.38%\n",
      "Epoch: 8207,     Training Loss: 0.2591010630130768, Training Acc: 78.74%\n",
      "              Val Loss: 1.4068139791488647, Val Acc: 68.38%\n",
      "Epoch: 8208,     Training Loss: 0.2538381814956665, Training Acc: 78.74%\n",
      "              Val Loss: 1.4692214727401733, Val Acc: 68.38%\n",
      "Epoch: 8209,     Training Loss: 0.22955694794654846, Training Acc: 78.75%\n",
      "              Val Loss: 1.4276115894317627, Val Acc: 68.38%\n",
      "Epoch: 8210,     Training Loss: 0.22266285121440887, Training Acc: 78.75%\n",
      "              Val Loss: 1.4184160232543945, Val Acc: 68.39%\n",
      "Epoch: 8211,     Training Loss: 0.22750209271907806, Training Acc: 78.75%\n",
      "              Val Loss: 1.462202787399292, Val Acc: 68.39%\n",
      "Epoch: 8212,     Training Loss: 0.21936629712581635, Training Acc: 78.75%\n",
      "              Val Loss: 1.4457589387893677, Val Acc: 68.39%\n",
      "Epoch: 8213,     Training Loss: 0.22395534813404083, Training Acc: 78.75%\n",
      "              Val Loss: 1.4856675863265991, Val Acc: 68.39%\n",
      "Epoch: 8214,     Training Loss: 0.2249118983745575, Training Acc: 78.75%\n",
      "              Val Loss: 1.4450966119766235, Val Acc: 68.39%\n",
      "Epoch: 8215,     Training Loss: 0.2315831035375595, Training Acc: 78.75%\n",
      "              Val Loss: 1.4725569486618042, Val Acc: 68.39%\n",
      "Epoch: 8216,     Training Loss: 0.22853916883468628, Training Acc: 78.76%\n",
      "              Val Loss: 1.4366496801376343, Val Acc: 68.39%\n",
      "Epoch: 8217,     Training Loss: 0.22089529037475586, Training Acc: 78.76%\n",
      "              Val Loss: 1.4737950563430786, Val Acc: 68.39%\n",
      "Epoch: 8218,     Training Loss: 0.2208915501832962, Training Acc: 78.76%\n",
      "              Val Loss: 1.4266204833984375, Val Acc: 68.39%\n",
      "Epoch: 8219,     Training Loss: 0.22665345668792725, Training Acc: 78.76%\n",
      "              Val Loss: 1.4698330163955688, Val Acc: 68.39%\n",
      "Epoch: 8220,     Training Loss: 0.2329970896244049, Training Acc: 78.76%\n",
      "              Val Loss: 1.4150506258010864, Val Acc: 68.39%\n",
      "Epoch: 8221,     Training Loss: 0.24757133424282074, Training Acc: 78.76%\n",
      "              Val Loss: 1.5225452184677124, Val Acc: 68.39%\n",
      "Epoch: 8222,     Training Loss: 0.25244656205177307, Training Acc: 78.76%\n",
      "              Val Loss: 1.4293427467346191, Val Acc: 68.39%\n",
      "Epoch: 8223,     Training Loss: 0.28929606080055237, Training Acc: 78.77%\n",
      "              Val Loss: 1.50520658493042, Val Acc: 68.39%\n",
      "Epoch: 8224,     Training Loss: 0.24735711514949799, Training Acc: 78.77%\n",
      "              Val Loss: 1.4236294031143188, Val Acc: 68.39%\n",
      "Epoch: 8225,     Training Loss: 0.23110820353031158, Training Acc: 78.77%\n",
      "              Val Loss: 1.4453223943710327, Val Acc: 68.39%\n",
      "Epoch: 8226,     Training Loss: 0.2159799039363861, Training Acc: 78.77%\n",
      "              Val Loss: 1.4790493249893188, Val Acc: 68.39%\n",
      "Epoch: 8227,     Training Loss: 0.2193787395954132, Training Acc: 78.77%\n",
      "              Val Loss: 1.4390803575515747, Val Acc: 68.39%\n",
      "Epoch: 8228,     Training Loss: 0.2407608926296234, Training Acc: 78.77%\n",
      "              Val Loss: 1.5203852653503418, Val Acc: 68.39%\n",
      "Epoch: 8229,     Training Loss: 0.24083207547664642, Training Acc: 78.77%\n",
      "              Val Loss: 1.4489191770553589, Val Acc: 68.39%\n",
      "Epoch: 8230,     Training Loss: 0.26025429368019104, Training Acc: 78.78%\n",
      "              Val Loss: 1.5050079822540283, Val Acc: 68.39%\n",
      "Epoch: 8231,     Training Loss: 0.23235833644866943, Training Acc: 78.78%\n",
      "              Val Loss: 1.427371621131897, Val Acc: 68.39%\n",
      "Epoch: 8232,     Training Loss: 0.22409109771251678, Training Acc: 78.78%\n",
      "              Val Loss: 1.4455554485321045, Val Acc: 68.39%\n",
      "Epoch: 8233,     Training Loss: 0.21490198373794556, Training Acc: 78.78%\n",
      "              Val Loss: 1.4384427070617676, Val Acc: 68.39%\n",
      "Epoch: 8234,     Training Loss: 0.21313898265361786, Training Acc: 78.78%\n",
      "              Val Loss: 1.4191062450408936, Val Acc: 68.39%\n",
      "Epoch: 8235,     Training Loss: 0.220511794090271, Training Acc: 78.78%\n",
      "              Val Loss: 1.4775036573410034, Val Acc: 68.39%\n",
      "Epoch: 8236,     Training Loss: 0.2252022624015808, Training Acc: 78.78%\n",
      "              Val Loss: 1.4268591403961182, Val Acc: 68.39%\n",
      "Epoch: 8237,     Training Loss: 0.23856696486473083, Training Acc: 78.79%\n",
      "              Val Loss: 1.5209109783172607, Val Acc: 68.39%\n",
      "Epoch: 8238,     Training Loss: 0.23753908276557922, Training Acc: 78.79%\n",
      "              Val Loss: 1.4492093324661255, Val Acc: 68.39%\n",
      "Epoch: 8239,     Training Loss: 0.266090452671051, Training Acc: 78.79%\n",
      "              Val Loss: 1.5427229404449463, Val Acc: 68.40%\n",
      "Epoch: 8240,     Training Loss: 0.24714010953903198, Training Acc: 78.79%\n",
      "              Val Loss: 1.4301701784133911, Val Acc: 68.40%\n",
      "Epoch: 8241,     Training Loss: 0.24728307127952576, Training Acc: 78.79%\n",
      "              Val Loss: 1.4736143350601196, Val Acc: 68.40%\n",
      "Epoch: 8242,     Training Loss: 0.22275659441947937, Training Acc: 78.79%\n",
      "              Val Loss: 1.4413321018218994, Val Acc: 68.40%\n",
      "Epoch: 8243,     Training Loss: 0.21655377745628357, Training Acc: 78.79%\n",
      "              Val Loss: 1.4378243684768677, Val Acc: 68.40%\n",
      "Epoch: 8244,     Training Loss: 0.22043104469776154, Training Acc: 78.80%\n",
      "              Val Loss: 1.472991943359375, Val Acc: 68.40%\n",
      "Epoch: 8245,     Training Loss: 0.2196619063615799, Training Acc: 78.80%\n",
      "              Val Loss: 1.4450701475143433, Val Acc: 68.40%\n",
      "Epoch: 8246,     Training Loss: 0.21882745623588562, Training Acc: 78.80%\n",
      "              Val Loss: 1.482295036315918, Val Acc: 68.40%\n",
      "Epoch: 8247,     Training Loss: 0.21661661565303802, Training Acc: 78.80%\n",
      "              Val Loss: 1.4613178968429565, Val Acc: 68.40%\n",
      "Epoch: 8248,     Training Loss: 0.2217036783695221, Training Acc: 78.80%\n",
      "              Val Loss: 1.4878480434417725, Val Acc: 68.40%\n",
      "Epoch: 8249,     Training Loss: 0.22438572347164154, Training Acc: 78.80%\n",
      "              Val Loss: 1.4562565088272095, Val Acc: 68.40%\n",
      "Epoch: 8250,     Training Loss: 0.2341112643480301, Training Acc: 78.80%\n",
      "              Val Loss: 1.4827684164047241, Val Acc: 68.40%\n",
      "Epoch: 8251,     Training Loss: 0.223578542470932, Training Acc: 78.81%\n",
      "              Val Loss: 1.4385219812393188, Val Acc: 68.40%\n",
      "Epoch: 8252,     Training Loss: 0.21986804902553558, Training Acc: 78.81%\n",
      "              Val Loss: 1.4783101081848145, Val Acc: 68.40%\n",
      "Epoch: 8253,     Training Loss: 0.21788029372692108, Training Acc: 78.81%\n",
      "              Val Loss: 1.452744483947754, Val Acc: 68.40%\n",
      "Epoch: 8254,     Training Loss: 0.23216091096401215, Training Acc: 78.81%\n",
      "              Val Loss: 1.5083284378051758, Val Acc: 68.40%\n",
      "Epoch: 8255,     Training Loss: 0.23434434831142426, Training Acc: 78.81%\n",
      "              Val Loss: 1.4556090831756592, Val Acc: 68.40%\n",
      "Epoch: 8256,     Training Loss: 0.25826388597488403, Training Acc: 78.81%\n",
      "              Val Loss: 1.5530835390090942, Val Acc: 68.40%\n",
      "Epoch: 8257,     Training Loss: 0.25461700558662415, Training Acc: 78.81%\n",
      "              Val Loss: 1.451329231262207, Val Acc: 68.40%\n",
      "Epoch: 8258,     Training Loss: 0.2977212071418762, Training Acc: 78.82%\n",
      "              Val Loss: 1.53813898563385, Val Acc: 68.40%\n",
      "Epoch: 8259,     Training Loss: 0.2597905993461609, Training Acc: 78.82%\n",
      "              Val Loss: 1.4467713832855225, Val Acc: 68.40%\n",
      "Epoch: 8260,     Training Loss: 0.26899898052215576, Training Acc: 78.82%\n",
      "              Val Loss: 1.4622597694396973, Val Acc: 68.40%\n",
      "Epoch: 8261,     Training Loss: 0.2334681898355484, Training Acc: 78.82%\n",
      "              Val Loss: 1.4791383743286133, Val Acc: 68.40%\n",
      "Epoch: 8262,     Training Loss: 0.2259538620710373, Training Acc: 78.82%\n",
      "              Val Loss: 1.434639573097229, Val Acc: 68.40%\n",
      "Epoch: 8263,     Training Loss: 0.2420271337032318, Training Acc: 78.82%\n",
      "              Val Loss: 1.5243239402770996, Val Acc: 68.40%\n",
      "Epoch: 8264,     Training Loss: 0.2494843304157257, Training Acc: 78.82%\n",
      "              Val Loss: 1.489711046218872, Val Acc: 68.40%\n",
      "Epoch: 8265,     Training Loss: 0.2735086679458618, Training Acc: 78.82%\n",
      "              Val Loss: 1.4944859743118286, Val Acc: 68.40%\n",
      "Epoch: 8266,     Training Loss: 0.2251356840133667, Training Acc: 78.83%\n",
      "              Val Loss: 1.4523773193359375, Val Acc: 68.40%\n",
      "Epoch: 8267,     Training Loss: 0.2163509726524353, Training Acc: 78.83%\n",
      "              Val Loss: 1.4520392417907715, Val Acc: 68.40%\n",
      "Epoch: 8268,     Training Loss: 0.24450372159481049, Training Acc: 78.83%\n",
      "              Val Loss: 1.4938632249832153, Val Acc: 68.40%\n",
      "Epoch: 8269,     Training Loss: 0.2339078187942505, Training Acc: 78.83%\n",
      "              Val Loss: 1.4278819561004639, Val Acc: 68.40%\n",
      "Epoch: 8270,     Training Loss: 0.24270080029964447, Training Acc: 78.83%\n",
      "              Val Loss: 1.5020115375518799, Val Acc: 68.41%\n",
      "Epoch: 8271,     Training Loss: 0.2317231148481369, Training Acc: 78.83%\n",
      "              Val Loss: 1.4339284896850586, Val Acc: 68.41%\n",
      "Epoch: 8272,     Training Loss: 0.2365453839302063, Training Acc: 78.83%\n",
      "              Val Loss: 1.481440782546997, Val Acc: 68.41%\n",
      "Epoch: 8273,     Training Loss: 0.22922222316265106, Training Acc: 78.84%\n",
      "              Val Loss: 1.4925754070281982, Val Acc: 68.41%\n",
      "Epoch: 8274,     Training Loss: 0.2303582727909088, Training Acc: 78.84%\n",
      "              Val Loss: 1.4637881517410278, Val Acc: 68.41%\n",
      "Epoch: 8275,     Training Loss: 0.24004808068275452, Training Acc: 78.84%\n",
      "              Val Loss: 1.5076696872711182, Val Acc: 68.41%\n",
      "Epoch: 8276,     Training Loss: 0.22664248943328857, Training Acc: 78.84%\n",
      "              Val Loss: 1.4610835313796997, Val Acc: 68.41%\n",
      "Epoch: 8277,     Training Loss: 0.2555524408817291, Training Acc: 78.84%\n",
      "              Val Loss: 1.5307872295379639, Val Acc: 68.41%\n",
      "Epoch: 8278,     Training Loss: 0.25521302223205566, Training Acc: 78.84%\n",
      "              Val Loss: 1.465357780456543, Val Acc: 68.41%\n",
      "Epoch: 8279,     Training Loss: 0.2848154604434967, Training Acc: 78.84%\n",
      "              Val Loss: 1.5347956418991089, Val Acc: 68.41%\n",
      "Epoch: 8280,     Training Loss: 0.24958917498588562, Training Acc: 78.84%\n",
      "              Val Loss: 1.4339543581008911, Val Acc: 68.41%\n",
      "Epoch: 8281,     Training Loss: 0.2501765787601471, Training Acc: 78.85%\n",
      "              Val Loss: 1.4874011278152466, Val Acc: 68.41%\n",
      "Epoch: 8282,     Training Loss: 0.23899324238300323, Training Acc: 78.85%\n",
      "              Val Loss: 1.4793704748153687, Val Acc: 68.41%\n",
      "Epoch: 8283,     Training Loss: 0.242823988199234, Training Acc: 78.85%\n",
      "              Val Loss: 1.478376865386963, Val Acc: 68.41%\n",
      "Epoch: 8284,     Training Loss: 0.23481778800487518, Training Acc: 78.85%\n",
      "              Val Loss: 1.4732388257980347, Val Acc: 68.41%\n",
      "Epoch: 8285,     Training Loss: 0.2152998000383377, Training Acc: 78.85%\n",
      "              Val Loss: 1.46083402633667, Val Acc: 68.41%\n",
      "Epoch: 8286,     Training Loss: 0.2135186642408371, Training Acc: 78.85%\n",
      "              Val Loss: 1.4746251106262207, Val Acc: 68.41%\n",
      "Epoch: 8287,     Training Loss: 0.228434219956398, Training Acc: 78.85%\n",
      "              Val Loss: 1.4974360466003418, Val Acc: 68.41%\n",
      "Epoch: 8288,     Training Loss: 0.23486898839473724, Training Acc: 78.86%\n",
      "              Val Loss: 1.4799704551696777, Val Acc: 68.41%\n",
      "Epoch: 8289,     Training Loss: 0.22334691882133484, Training Acc: 78.86%\n",
      "              Val Loss: 1.4602314233779907, Val Acc: 68.41%\n",
      "Epoch: 8290,     Training Loss: 0.20939886569976807, Training Acc: 78.86%\n",
      "              Val Loss: 1.4713201522827148, Val Acc: 68.41%\n",
      "Epoch: 8291,     Training Loss: 0.21185900270938873, Training Acc: 78.86%\n",
      "              Val Loss: 1.4689526557922363, Val Acc: 68.41%\n",
      "Epoch: 8292,     Training Loss: 0.2159247249364853, Training Acc: 78.86%\n",
      "              Val Loss: 1.4709528684616089, Val Acc: 68.41%\n",
      "Epoch: 8293,     Training Loss: 0.22163112461566925, Training Acc: 78.86%\n",
      "              Val Loss: 1.4866530895233154, Val Acc: 68.41%\n",
      "Epoch: 8294,     Training Loss: 0.21966136991977692, Training Acc: 78.86%\n",
      "              Val Loss: 1.4485048055648804, Val Acc: 68.41%\n",
      "Epoch: 8295,     Training Loss: 0.2266167849302292, Training Acc: 78.87%\n",
      "              Val Loss: 1.5247204303741455, Val Acc: 68.41%\n",
      "Epoch: 8296,     Training Loss: 0.23047398030757904, Training Acc: 78.87%\n",
      "              Val Loss: 1.480188012123108, Val Acc: 68.41%\n",
      "Epoch: 8297,     Training Loss: 0.27092698216438293, Training Acc: 78.87%\n",
      "              Val Loss: 1.6259056329727173, Val Acc: 68.41%\n",
      "Epoch: 8298,     Training Loss: 0.29301586747169495, Training Acc: 78.87%\n",
      "              Val Loss: 1.5611993074417114, Val Acc: 68.41%\n",
      "Epoch: 8299,     Training Loss: 0.4021700322628021, Training Acc: 78.87%\n",
      "              Val Loss: 1.5899885892868042, Val Acc: 68.41%\n",
      "Epoch: 8300,     Training Loss: 0.2707502841949463, Training Acc: 78.87%\n",
      "              Val Loss: 1.4523884057998657, Val Acc: 68.41%\n",
      "Epoch: 8301,     Training Loss: 0.2437576800584793, Training Acc: 78.87%\n",
      "              Val Loss: 1.4595723152160645, Val Acc: 68.42%\n",
      "Epoch: 8302,     Training Loss: 0.2428322732448578, Training Acc: 78.87%\n",
      "              Val Loss: 1.520363450050354, Val Acc: 68.42%\n",
      "Epoch: 8303,     Training Loss: 0.24556997418403625, Training Acc: 78.88%\n",
      "              Val Loss: 1.4369986057281494, Val Acc: 68.42%\n",
      "Epoch: 8304,     Training Loss: 0.24783337116241455, Training Acc: 78.88%\n",
      "              Val Loss: 1.5009242296218872, Val Acc: 68.42%\n",
      "Epoch: 8305,     Training Loss: 0.23149685561656952, Training Acc: 78.88%\n",
      "              Val Loss: 1.4885573387145996, Val Acc: 68.42%\n",
      "Epoch: 8306,     Training Loss: 0.24567611515522003, Training Acc: 78.88%\n",
      "              Val Loss: 1.5052157640457153, Val Acc: 68.42%\n",
      "Epoch: 8307,     Training Loss: 0.2544502913951874, Training Acc: 78.88%\n",
      "              Val Loss: 1.5229792594909668, Val Acc: 68.42%\n",
      "Epoch: 8308,     Training Loss: 0.23936909437179565, Training Acc: 78.88%\n",
      "              Val Loss: 1.4739717245101929, Val Acc: 68.42%\n",
      "Epoch: 8309,     Training Loss: 0.21538536250591278, Training Acc: 78.88%\n",
      "              Val Loss: 1.493202805519104, Val Acc: 68.42%\n",
      "Epoch: 8310,     Training Loss: 0.21724683046340942, Training Acc: 78.89%\n",
      "              Val Loss: 1.4923014640808105, Val Acc: 68.42%\n",
      "Epoch: 8311,     Training Loss: 0.23825585842132568, Training Acc: 78.89%\n",
      "              Val Loss: 1.4928518533706665, Val Acc: 68.42%\n",
      "Epoch: 8312,     Training Loss: 0.22538034617900848, Training Acc: 78.89%\n",
      "              Val Loss: 1.468083381652832, Val Acc: 68.42%\n",
      "Epoch: 8313,     Training Loss: 0.21504217386245728, Training Acc: 78.89%\n",
      "              Val Loss: 1.5052056312561035, Val Acc: 68.42%\n",
      "Epoch: 8314,     Training Loss: 0.21621328592300415, Training Acc: 78.89%\n",
      "              Val Loss: 1.470036268234253, Val Acc: 68.42%\n",
      "Epoch: 8315,     Training Loss: 0.22158417105674744, Training Acc: 78.89%\n",
      "              Val Loss: 1.5191044807434082, Val Acc: 68.42%\n",
      "Epoch: 8316,     Training Loss: 0.21683849394321442, Training Acc: 78.89%\n",
      "              Val Loss: 1.4930387735366821, Val Acc: 68.42%\n",
      "Epoch: 8317,     Training Loss: 0.23127195239067078, Training Acc: 78.90%\n",
      "              Val Loss: 1.5224195718765259, Val Acc: 68.42%\n",
      "Epoch: 8318,     Training Loss: 0.2307131141424179, Training Acc: 78.90%\n",
      "              Val Loss: 1.4774272441864014, Val Acc: 68.42%\n",
      "Epoch: 8319,     Training Loss: 0.2384061962366104, Training Acc: 78.90%\n",
      "              Val Loss: 1.5540738105773926, Val Acc: 68.42%\n",
      "Epoch: 8320,     Training Loss: 0.25047528743743896, Training Acc: 78.90%\n",
      "              Val Loss: 1.5119549036026, Val Acc: 68.42%\n",
      "Epoch: 8321,     Training Loss: 0.3296322524547577, Training Acc: 78.90%\n",
      "              Val Loss: 1.5516146421432495, Val Acc: 68.42%\n",
      "Epoch: 8322,     Training Loss: 0.24159730970859528, Training Acc: 78.90%\n",
      "              Val Loss: 1.4603338241577148, Val Acc: 68.42%\n",
      "Epoch: 8323,     Training Loss: 0.21964861452579498, Training Acc: 78.90%\n",
      "              Val Loss: 1.466784954071045, Val Acc: 68.42%\n",
      "Epoch: 8324,     Training Loss: 0.23423710465431213, Training Acc: 78.90%\n",
      "              Val Loss: 1.4728621244430542, Val Acc: 68.42%\n",
      "Epoch: 8325,     Training Loss: 0.22672736644744873, Training Acc: 78.91%\n",
      "              Val Loss: 1.4802656173706055, Val Acc: 68.42%\n",
      "Epoch: 8326,     Training Loss: 0.2252994328737259, Training Acc: 78.91%\n",
      "              Val Loss: 1.4648752212524414, Val Acc: 68.42%\n",
      "Epoch: 8327,     Training Loss: 0.22456537187099457, Training Acc: 78.91%\n",
      "              Val Loss: 1.4565913677215576, Val Acc: 68.42%\n",
      "Epoch: 8328,     Training Loss: 0.2134222835302353, Training Acc: 78.91%\n",
      "              Val Loss: 1.5084004402160645, Val Acc: 68.42%\n",
      "Epoch: 8329,     Training Loss: 0.22003944218158722, Training Acc: 78.91%\n",
      "              Val Loss: 1.4740960597991943, Val Acc: 68.42%\n",
      "Epoch: 8330,     Training Loss: 0.24103866517543793, Training Acc: 78.91%\n",
      "              Val Loss: 1.5676627159118652, Val Acc: 68.43%\n",
      "Epoch: 8331,     Training Loss: 0.2434215396642685, Training Acc: 78.91%\n",
      "              Val Loss: 1.4810501337051392, Val Acc: 68.43%\n",
      "Epoch: 8332,     Training Loss: 0.3022645115852356, Training Acc: 78.91%\n",
      "              Val Loss: 1.5886049270629883, Val Acc: 68.43%\n",
      "Epoch: 8333,     Training Loss: 0.2776997685432434, Training Acc: 78.92%\n",
      "              Val Loss: 1.5029019117355347, Val Acc: 68.43%\n",
      "Epoch: 8334,     Training Loss: 0.31446704268455505, Training Acc: 78.92%\n",
      "              Val Loss: 1.5224450826644897, Val Acc: 68.43%\n",
      "Epoch: 8335,     Training Loss: 0.24078334867954254, Training Acc: 78.92%\n",
      "              Val Loss: 1.503170371055603, Val Acc: 68.43%\n",
      "Epoch: 8336,     Training Loss: 0.23044613003730774, Training Acc: 78.92%\n",
      "              Val Loss: 1.4660688638687134, Val Acc: 68.43%\n",
      "Epoch: 8337,     Training Loss: 0.25338494777679443, Training Acc: 78.92%\n",
      "              Val Loss: 1.5482407808303833, Val Acc: 68.43%\n",
      "Epoch: 8338,     Training Loss: 0.24047020077705383, Training Acc: 78.92%\n",
      "              Val Loss: 1.5093779563903809, Val Acc: 68.43%\n",
      "Epoch: 8339,     Training Loss: 0.27589938044548035, Training Acc: 78.92%\n",
      "              Val Loss: 1.4989093542099, Val Acc: 68.43%\n",
      "Epoch: 8340,     Training Loss: 0.22181925177574158, Training Acc: 78.92%\n",
      "              Val Loss: 1.5332354307174683, Val Acc: 68.43%\n",
      "Epoch: 8341,     Training Loss: 0.23651240766048431, Training Acc: 78.93%\n",
      "              Val Loss: 1.4608081579208374, Val Acc: 68.43%\n",
      "Epoch: 8342,     Training Loss: 0.27635395526885986, Training Acc: 78.93%\n",
      "              Val Loss: 1.5632379055023193, Val Acc: 68.43%\n",
      "Epoch: 8343,     Training Loss: 0.26871877908706665, Training Acc: 78.93%\n",
      "              Val Loss: 1.664217472076416, Val Acc: 68.43%\n",
      "Epoch: 8344,     Training Loss: 0.3972952961921692, Training Acc: 78.93%\n",
      "              Val Loss: 1.5618916749954224, Val Acc: 68.43%\n",
      "Epoch: 8345,     Training Loss: 0.290321946144104, Training Acc: 78.93%\n",
      "              Val Loss: 1.4668656587600708, Val Acc: 68.43%\n",
      "Epoch: 8346,     Training Loss: 0.2275371104478836, Training Acc: 78.93%\n",
      "              Val Loss: 1.542761206626892, Val Acc: 68.43%\n",
      "Epoch: 8347,     Training Loss: 0.2974545955657959, Training Acc: 78.93%\n",
      "              Val Loss: 1.4719078540802002, Val Acc: 68.43%\n",
      "Epoch: 8348,     Training Loss: 0.24583058059215546, Training Acc: 78.93%\n",
      "              Val Loss: 1.5248128175735474, Val Acc: 68.43%\n",
      "Epoch: 8349,     Training Loss: 0.2831977605819702, Training Acc: 78.93%\n",
      "              Val Loss: 1.5903944969177246, Val Acc: 68.43%\n",
      "Epoch: 8350,     Training Loss: 0.3048431873321533, Training Acc: 78.94%\n",
      "              Val Loss: 1.49503493309021, Val Acc: 68.43%\n",
      "Epoch: 8351,     Training Loss: 0.22370454668998718, Training Acc: 78.94%\n",
      "              Val Loss: 1.5756251811981201, Val Acc: 68.43%\n",
      "Epoch: 8352,     Training Loss: 0.30340102314949036, Training Acc: 78.94%\n",
      "              Val Loss: 1.6027919054031372, Val Acc: 68.43%\n",
      "Epoch: 8353,     Training Loss: 0.35117629170417786, Training Acc: 78.94%\n",
      "              Val Loss: 1.7202589511871338, Val Acc: 68.43%\n",
      "Epoch: 8354,     Training Loss: 0.34668463468551636, Training Acc: 78.94%\n",
      "              Val Loss: 1.6228663921356201, Val Acc: 68.43%\n",
      "Epoch: 8355,     Training Loss: 0.4650772213935852, Training Acc: 78.94%\n",
      "              Val Loss: 1.6035538911819458, Val Acc: 68.43%\n",
      "Epoch: 8356,     Training Loss: 0.4183029234409332, Training Acc: 78.94%\n",
      "              Val Loss: 1.6809487342834473, Val Acc: 68.43%\n",
      "Epoch: 8357,     Training Loss: 0.5773051381111145, Training Acc: 78.94%\n",
      "              Val Loss: 1.628819227218628, Val Acc: 68.43%\n",
      "Epoch: 8358,     Training Loss: 0.3773573040962219, Training Acc: 78.94%\n",
      "              Val Loss: 1.5586864948272705, Val Acc: 68.43%\n",
      "Epoch: 8359,     Training Loss: 0.4363819360733032, Training Acc: 78.94%\n",
      "              Val Loss: 1.8898485898971558, Val Acc: 68.43%\n",
      "Epoch: 8360,     Training Loss: 0.9069269299507141, Training Acc: 78.94%\n",
      "              Val Loss: 1.566254734992981, Val Acc: 68.43%\n",
      "Epoch: 8361,     Training Loss: 0.4580221176147461, Training Acc: 78.94%\n",
      "              Val Loss: 1.6988601684570312, Val Acc: 68.43%\n",
      "Epoch: 8362,     Training Loss: 0.5310573577880859, Training Acc: 78.94%\n",
      "              Val Loss: 1.5763167142868042, Val Acc: 68.43%\n",
      "Epoch: 8363,     Training Loss: 0.4715403616428375, Training Acc: 78.94%\n",
      "              Val Loss: 1.5683153867721558, Val Acc: 68.43%\n",
      "Epoch: 8364,     Training Loss: 0.4332786798477173, Training Acc: 78.94%\n",
      "              Val Loss: 1.7396670579910278, Val Acc: 68.43%\n",
      "Epoch: 8365,     Training Loss: 0.5926557779312134, Training Acc: 78.94%\n",
      "              Val Loss: 1.7879462242126465, Val Acc: 68.43%\n",
      "Epoch: 8366,     Training Loss: 0.6349106431007385, Training Acc: 78.94%\n",
      "              Val Loss: 1.7776645421981812, Val Acc: 68.43%\n",
      "Epoch: 8367,     Training Loss: 0.5627548098564148, Training Acc: 78.94%\n",
      "              Val Loss: 1.686244249343872, Val Acc: 68.43%\n",
      "Epoch: 8368,     Training Loss: 0.5476081967353821, Training Acc: 78.94%\n",
      "              Val Loss: 1.5160709619522095, Val Acc: 68.43%\n",
      "Epoch: 8369,     Training Loss: 0.4923536777496338, Training Acc: 78.94%\n",
      "              Val Loss: 1.8110113143920898, Val Acc: 68.43%\n",
      "Epoch: 8370,     Training Loss: 0.6013226509094238, Training Acc: 78.94%\n",
      "              Val Loss: 1.3032962083816528, Val Acc: 68.43%\n",
      "Epoch: 8371,     Training Loss: 0.39177459478378296, Training Acc: 78.94%\n",
      "              Val Loss: 1.3623955249786377, Val Acc: 68.43%\n",
      "Epoch: 8372,     Training Loss: 0.4811929762363434, Training Acc: 78.94%\n",
      "              Val Loss: 1.3073517084121704, Val Acc: 68.43%\n",
      "Epoch: 8373,     Training Loss: 0.4006221890449524, Training Acc: 78.94%\n",
      "              Val Loss: 1.3421216011047363, Val Acc: 68.43%\n",
      "Epoch: 8374,     Training Loss: 0.38934436440467834, Training Acc: 78.94%\n",
      "              Val Loss: 1.4028626680374146, Val Acc: 68.43%\n",
      "Epoch: 8375,     Training Loss: 0.3710710406303406, Training Acc: 78.94%\n",
      "              Val Loss: 1.422701358795166, Val Acc: 68.43%\n",
      "Epoch: 8376,     Training Loss: 0.3716392517089844, Training Acc: 78.94%\n",
      "              Val Loss: 1.4026471376419067, Val Acc: 68.43%\n",
      "Epoch: 8377,     Training Loss: 0.3895861506462097, Training Acc: 78.94%\n",
      "              Val Loss: 1.3521572351455688, Val Acc: 68.43%\n",
      "Epoch: 8378,     Training Loss: 0.3285410404205322, Training Acc: 78.94%\n",
      "              Val Loss: 1.3702970743179321, Val Acc: 68.43%\n",
      "Epoch: 8379,     Training Loss: 0.3479278087615967, Training Acc: 78.95%\n",
      "              Val Loss: 1.281814694404602, Val Acc: 68.43%\n",
      "Epoch: 8380,     Training Loss: 0.29806429147720337, Training Acc: 78.95%\n",
      "              Val Loss: 1.3909094333648682, Val Acc: 68.43%\n",
      "Epoch: 8381,     Training Loss: 0.35197240114212036, Training Acc: 78.95%\n",
      "              Val Loss: 1.4184080362319946, Val Acc: 68.43%\n",
      "Epoch: 8382,     Training Loss: 0.32783451676368713, Training Acc: 78.95%\n",
      "              Val Loss: 1.52693772315979, Val Acc: 68.43%\n",
      "Epoch: 8383,     Training Loss: 0.2931327819824219, Training Acc: 78.95%\n",
      "              Val Loss: 1.6120965480804443, Val Acc: 68.43%\n",
      "Epoch: 8384,     Training Loss: 0.33499613404273987, Training Acc: 78.95%\n",
      "              Val Loss: 1.473900318145752, Val Acc: 68.43%\n",
      "Epoch: 8385,     Training Loss: 0.2813732624053955, Training Acc: 78.95%\n",
      "              Val Loss: 1.5900896787643433, Val Acc: 68.43%\n",
      "Epoch: 8386,     Training Loss: 0.3487011790275574, Training Acc: 78.95%\n",
      "              Val Loss: 1.492678165435791, Val Acc: 68.43%\n",
      "Epoch: 8387,     Training Loss: 0.3634011149406433, Training Acc: 78.95%\n",
      "              Val Loss: 1.4746986627578735, Val Acc: 68.43%\n",
      "Epoch: 8388,     Training Loss: 0.2902144491672516, Training Acc: 78.95%\n",
      "              Val Loss: 1.5435773134231567, Val Acc: 68.43%\n",
      "Epoch: 8389,     Training Loss: 0.3582010269165039, Training Acc: 78.95%\n",
      "              Val Loss: 1.3964656591415405, Val Acc: 68.43%\n",
      "Epoch: 8390,     Training Loss: 0.31115439534187317, Training Acc: 78.96%\n",
      "              Val Loss: 1.492729902267456, Val Acc: 68.43%\n",
      "Epoch: 8391,     Training Loss: 0.3502049744129181, Training Acc: 78.96%\n",
      "              Val Loss: 1.335135817527771, Val Acc: 68.43%\n",
      "Epoch: 8392,     Training Loss: 0.28240683674812317, Training Acc: 78.96%\n",
      "              Val Loss: 1.3611013889312744, Val Acc: 68.43%\n",
      "Epoch: 8393,     Training Loss: 0.29965662956237793, Training Acc: 78.96%\n",
      "              Val Loss: 1.4563158750534058, Val Acc: 68.43%\n",
      "Epoch: 8394,     Training Loss: 0.29169848561286926, Training Acc: 78.96%\n",
      "              Val Loss: 1.3696898221969604, Val Acc: 68.43%\n",
      "Epoch: 8395,     Training Loss: 0.2831566035747528, Training Acc: 78.96%\n",
      "              Val Loss: 1.427927851676941, Val Acc: 68.43%\n",
      "Epoch: 8396,     Training Loss: 0.28975147008895874, Training Acc: 78.96%\n",
      "              Val Loss: 1.3460005521774292, Val Acc: 68.44%\n",
      "Epoch: 8397,     Training Loss: 0.2524208724498749, Training Acc: 78.96%\n",
      "              Val Loss: 1.3613775968551636, Val Acc: 68.44%\n",
      "Epoch: 8398,     Training Loss: 0.26052626967430115, Training Acc: 78.96%\n",
      "              Val Loss: 1.2834850549697876, Val Acc: 68.44%\n",
      "Epoch: 8399,     Training Loss: 0.2458757758140564, Training Acc: 78.96%\n",
      "              Val Loss: 1.290461778640747, Val Acc: 68.44%\n",
      "Epoch: 8400,     Training Loss: 0.24763217568397522, Training Acc: 78.97%\n",
      "              Val Loss: 1.3381669521331787, Val Acc: 68.44%\n",
      "Epoch: 8401,     Training Loss: 0.2552144527435303, Training Acc: 78.97%\n",
      "              Val Loss: 1.2963539361953735, Val Acc: 68.44%\n",
      "Epoch: 8402,     Training Loss: 0.23459617793560028, Training Acc: 78.97%\n",
      "              Val Loss: 1.3568233251571655, Val Acc: 68.44%\n",
      "Epoch: 8403,     Training Loss: 0.24970310926437378, Training Acc: 78.97%\n",
      "              Val Loss: 1.3662254810333252, Val Acc: 68.44%\n",
      "Epoch: 8404,     Training Loss: 0.24435323476791382, Training Acc: 78.97%\n",
      "              Val Loss: 1.4126988649368286, Val Acc: 68.44%\n",
      "Epoch: 8405,     Training Loss: 0.24072551727294922, Training Acc: 78.97%\n",
      "              Val Loss: 1.3547935485839844, Val Acc: 68.44%\n",
      "Epoch: 8406,     Training Loss: 0.247094064950943, Training Acc: 78.97%\n",
      "              Val Loss: 1.3542656898498535, Val Acc: 68.44%\n",
      "Epoch: 8407,     Training Loss: 0.2242390215396881, Training Acc: 78.98%\n",
      "              Val Loss: 1.4043781757354736, Val Acc: 68.44%\n",
      "Epoch: 8408,     Training Loss: 0.2545188367366791, Training Acc: 78.98%\n",
      "              Val Loss: 1.3255409002304077, Val Acc: 68.44%\n",
      "Epoch: 8409,     Training Loss: 0.24286451935768127, Training Acc: 78.98%\n",
      "              Val Loss: 1.3988614082336426, Val Acc: 68.44%\n",
      "Epoch: 8410,     Training Loss: 0.2556006908416748, Training Acc: 78.98%\n",
      "              Val Loss: 1.3683727979660034, Val Acc: 68.44%\n",
      "Epoch: 8411,     Training Loss: 0.2698856592178345, Training Acc: 78.98%\n",
      "              Val Loss: 1.4308652877807617, Val Acc: 68.44%\n",
      "Epoch: 8412,     Training Loss: 0.23788070678710938, Training Acc: 78.98%\n",
      "              Val Loss: 1.3778935670852661, Val Acc: 68.44%\n",
      "Epoch: 8413,     Training Loss: 0.2538326382637024, Training Acc: 78.98%\n",
      "              Val Loss: 1.3549761772155762, Val Acc: 68.44%\n",
      "Epoch: 8414,     Training Loss: 0.22833634912967682, Training Acc: 78.98%\n",
      "              Val Loss: 1.442542552947998, Val Acc: 68.44%\n",
      "Epoch: 8415,     Training Loss: 0.260952353477478, Training Acc: 78.99%\n",
      "              Val Loss: 1.3375564813613892, Val Acc: 68.44%\n",
      "Epoch: 8416,     Training Loss: 0.28731799125671387, Training Acc: 78.99%\n",
      "              Val Loss: 1.3721330165863037, Val Acc: 68.44%\n",
      "Epoch: 8417,     Training Loss: 0.25047561526298523, Training Acc: 78.99%\n",
      "              Val Loss: 1.3668338060379028, Val Acc: 68.44%\n",
      "Epoch: 8418,     Training Loss: 0.26185640692710876, Training Acc: 78.99%\n",
      "              Val Loss: 1.3518637418746948, Val Acc: 68.44%\n",
      "Epoch: 8419,     Training Loss: 0.2233106940984726, Training Acc: 78.99%\n",
      "              Val Loss: 1.3834412097930908, Val Acc: 68.44%\n",
      "Epoch: 8420,     Training Loss: 0.2573690414428711, Training Acc: 78.99%\n",
      "              Val Loss: 1.3472172021865845, Val Acc: 68.44%\n",
      "Epoch: 8421,     Training Loss: 0.3059876561164856, Training Acc: 78.99%\n",
      "              Val Loss: 1.4756042957305908, Val Acc: 68.44%\n",
      "Epoch: 8422,     Training Loss: 0.29665544629096985, Training Acc: 78.99%\n",
      "              Val Loss: 1.3951383829116821, Val Acc: 68.44%\n",
      "Epoch: 8423,     Training Loss: 0.3992944359779358, Training Acc: 78.99%\n",
      "              Val Loss: 1.3429419994354248, Val Acc: 68.44%\n",
      "Epoch: 8424,     Training Loss: 0.2452000081539154, Training Acc: 78.99%\n",
      "              Val Loss: 1.5997997522354126, Val Acc: 68.44%\n",
      "Epoch: 8425,     Training Loss: 0.39834198355674744, Training Acc: 79.00%\n",
      "              Val Loss: 1.6389098167419434, Val Acc: 68.44%\n",
      "Epoch: 8426,     Training Loss: 0.663057804107666, Training Acc: 78.99%\n",
      "              Val Loss: 1.4683605432510376, Val Acc: 68.44%\n",
      "Epoch: 8427,     Training Loss: 0.38429078459739685, Training Acc: 79.00%\n",
      "              Val Loss: 1.6444611549377441, Val Acc: 68.44%\n",
      "Epoch: 8428,     Training Loss: 0.4365549385547638, Training Acc: 79.00%\n",
      "              Val Loss: 1.579574704170227, Val Acc: 68.44%\n",
      "Epoch: 8429,     Training Loss: 0.5699498653411865, Training Acc: 79.00%\n",
      "              Val Loss: 1.4161639213562012, Val Acc: 68.44%\n",
      "Epoch: 8430,     Training Loss: 0.33663350343704224, Training Acc: 79.00%\n",
      "              Val Loss: 1.5812034606933594, Val Acc: 68.44%\n",
      "Epoch: 8431,     Training Loss: 0.4598603844642639, Training Acc: 79.00%\n",
      "              Val Loss: 1.673484206199646, Val Acc: 68.44%\n",
      "Epoch: 8432,     Training Loss: 0.8324009776115417, Training Acc: 79.00%\n",
      "              Val Loss: 1.4553619623184204, Val Acc: 68.44%\n",
      "Epoch: 8433,     Training Loss: 0.48384997248649597, Training Acc: 79.00%\n",
      "              Val Loss: 2.0284790992736816, Val Acc: 68.44%\n",
      "Epoch: 8434,     Training Loss: 0.8209195733070374, Training Acc: 78.99%\n",
      "              Val Loss: 1.5406538248062134, Val Acc: 68.44%\n",
      "Epoch: 8435,     Training Loss: 0.6814361810684204, Training Acc: 78.99%\n",
      "              Val Loss: 1.5652706623077393, Val Acc: 68.44%\n",
      "Epoch: 8436,     Training Loss: 0.5516762137413025, Training Acc: 78.99%\n",
      "              Val Loss: 2.129701852798462, Val Acc: 68.44%\n",
      "Epoch: 8437,     Training Loss: 0.8530523777008057, Training Acc: 78.99%\n",
      "              Val Loss: 1.5294362306594849, Val Acc: 68.44%\n",
      "Epoch: 8438,     Training Loss: 0.6083683967590332, Training Acc: 78.99%\n",
      "              Val Loss: 1.735231637954712, Val Acc: 68.44%\n",
      "Epoch: 8439,     Training Loss: 0.8208375573158264, Training Acc: 78.99%\n",
      "              Val Loss: 1.3813705444335938, Val Acc: 68.44%\n",
      "Epoch: 8440,     Training Loss: 0.4979497790336609, Training Acc: 78.99%\n",
      "              Val Loss: 1.6939888000488281, Val Acc: 68.44%\n",
      "Epoch: 8441,     Training Loss: 0.6718788146972656, Training Acc: 78.99%\n",
      "              Val Loss: 1.5453720092773438, Val Acc: 68.44%\n",
      "Epoch: 8442,     Training Loss: 0.5793254971504211, Training Acc: 78.99%\n",
      "              Val Loss: 1.5071057081222534, Val Acc: 68.44%\n",
      "Epoch: 8443,     Training Loss: 0.6209754347801208, Training Acc: 78.99%\n",
      "              Val Loss: 1.4066550731658936, Val Acc: 68.44%\n",
      "Epoch: 8444,     Training Loss: 0.528770923614502, Training Acc: 78.99%\n",
      "              Val Loss: 1.3788851499557495, Val Acc: 68.44%\n",
      "Epoch: 8445,     Training Loss: 0.5561893582344055, Training Acc: 78.99%\n",
      "              Val Loss: 1.2015324831008911, Val Acc: 68.44%\n",
      "Epoch: 8446,     Training Loss: 0.4689711332321167, Training Acc: 78.99%\n",
      "              Val Loss: 1.2220889329910278, Val Acc: 68.44%\n",
      "Epoch: 8447,     Training Loss: 0.46746593713760376, Training Acc: 78.99%\n",
      "              Val Loss: 1.3213562965393066, Val Acc: 68.44%\n",
      "Epoch: 8448,     Training Loss: 0.5070223808288574, Training Acc: 78.99%\n",
      "              Val Loss: 1.193567156791687, Val Acc: 68.44%\n",
      "Epoch: 8449,     Training Loss: 0.4057125151157379, Training Acc: 78.99%\n",
      "              Val Loss: 1.1618566513061523, Val Acc: 68.44%\n",
      "Epoch: 8450,     Training Loss: 0.4398268759250641, Training Acc: 78.99%\n",
      "              Val Loss: 1.1496624946594238, Val Acc: 68.44%\n",
      "Epoch: 8451,     Training Loss: 0.4271354377269745, Training Acc: 78.99%\n",
      "              Val Loss: 1.186833381652832, Val Acc: 68.44%\n",
      "Epoch: 8452,     Training Loss: 0.39811840653419495, Training Acc: 78.99%\n",
      "              Val Loss: 1.171393632888794, Val Acc: 68.44%\n",
      "Epoch: 8453,     Training Loss: 0.41336631774902344, Training Acc: 78.99%\n",
      "              Val Loss: 1.1409014463424683, Val Acc: 68.44%\n",
      "Epoch: 8454,     Training Loss: 0.41150879859924316, Training Acc: 78.99%\n",
      "              Val Loss: 1.179715633392334, Val Acc: 68.44%\n",
      "Epoch: 8455,     Training Loss: 0.3921535611152649, Training Acc: 78.99%\n",
      "              Val Loss: 1.1957390308380127, Val Acc: 68.44%\n",
      "Epoch: 8456,     Training Loss: 0.4064432382583618, Training Acc: 78.99%\n",
      "              Val Loss: 1.1667779684066772, Val Acc: 68.44%\n",
      "Epoch: 8457,     Training Loss: 0.3737851679325104, Training Acc: 78.99%\n",
      "              Val Loss: 1.2152924537658691, Val Acc: 68.44%\n",
      "Epoch: 8458,     Training Loss: 0.357145756483078, Training Acc: 79.00%\n",
      "              Val Loss: 1.335752010345459, Val Acc: 68.44%\n",
      "Epoch: 8459,     Training Loss: 0.3921780288219452, Training Acc: 79.00%\n",
      "              Val Loss: 1.2455252408981323, Val Acc: 68.44%\n",
      "Epoch: 8460,     Training Loss: 0.3475355803966522, Training Acc: 79.00%\n",
      "              Val Loss: 1.2087304592132568, Val Acc: 68.44%\n",
      "Epoch: 8461,     Training Loss: 0.34092387557029724, Training Acc: 79.00%\n",
      "              Val Loss: 1.176568627357483, Val Acc: 68.44%\n",
      "Epoch: 8462,     Training Loss: 0.32999587059020996, Training Acc: 79.00%\n",
      "              Val Loss: 1.1609467267990112, Val Acc: 68.44%\n",
      "Epoch: 8463,     Training Loss: 0.34374430775642395, Training Acc: 79.00%\n",
      "              Val Loss: 1.1818350553512573, Val Acc: 68.44%\n",
      "Epoch: 8464,     Training Loss: 0.34689658880233765, Training Acc: 79.00%\n",
      "              Val Loss: 1.1497727632522583, Val Acc: 68.44%\n",
      "Epoch: 8465,     Training Loss: 0.31739628314971924, Training Acc: 79.00%\n",
      "              Val Loss: 1.2050682306289673, Val Acc: 68.44%\n",
      "Epoch: 8466,     Training Loss: 0.3245612680912018, Training Acc: 79.00%\n",
      "              Val Loss: 1.277632236480713, Val Acc: 68.44%\n",
      "Epoch: 8467,     Training Loss: 0.3318347632884979, Training Acc: 79.00%\n",
      "              Val Loss: 1.2190765142440796, Val Acc: 68.44%\n",
      "Epoch: 8468,     Training Loss: 0.30218905210494995, Training Acc: 79.00%\n",
      "              Val Loss: 1.2346404790878296, Val Acc: 68.44%\n",
      "Epoch: 8469,     Training Loss: 0.30629196763038635, Training Acc: 79.00%\n",
      "              Val Loss: 1.2643964290618896, Val Acc: 68.44%\n",
      "Epoch: 8470,     Training Loss: 0.3040236234664917, Training Acc: 79.01%\n",
      "              Val Loss: 1.2618441581726074, Val Acc: 68.44%\n",
      "Epoch: 8471,     Training Loss: 0.2902265191078186, Training Acc: 79.01%\n",
      "              Val Loss: 1.2886379957199097, Val Acc: 68.44%\n",
      "Epoch: 8472,     Training Loss: 0.2954917252063751, Training Acc: 79.01%\n",
      "              Val Loss: 1.3199442625045776, Val Acc: 68.44%\n",
      "Epoch: 8473,     Training Loss: 0.28432023525238037, Training Acc: 79.01%\n",
      "              Val Loss: 1.3359386920928955, Val Acc: 68.44%\n",
      "Epoch: 8474,     Training Loss: 0.284274697303772, Training Acc: 79.01%\n",
      "              Val Loss: 1.327803134918213, Val Acc: 68.45%\n",
      "Epoch: 8475,     Training Loss: 0.27837634086608887, Training Acc: 79.01%\n",
      "              Val Loss: 1.3306738138198853, Val Acc: 68.45%\n",
      "Epoch: 8476,     Training Loss: 0.2729575037956238, Training Acc: 79.01%\n",
      "              Val Loss: 1.3468486070632935, Val Acc: 68.45%\n",
      "Epoch: 8477,     Training Loss: 0.272646963596344, Training Acc: 79.01%\n",
      "              Val Loss: 1.3428372144699097, Val Acc: 68.45%\n",
      "Epoch: 8478,     Training Loss: 0.26498711109161377, Training Acc: 79.01%\n",
      "              Val Loss: 1.3360360860824585, Val Acc: 68.45%\n",
      "Epoch: 8479,     Training Loss: 0.2662334144115448, Training Acc: 79.02%\n",
      "              Val Loss: 1.339066982269287, Val Acc: 68.45%\n",
      "Epoch: 8480,     Training Loss: 0.2624141573905945, Training Acc: 79.02%\n",
      "              Val Loss: 1.3606626987457275, Val Acc: 68.45%\n",
      "Epoch: 8481,     Training Loss: 0.26059848070144653, Training Acc: 79.02%\n",
      "              Val Loss: 1.3580994606018066, Val Acc: 68.45%\n",
      "Epoch: 8482,     Training Loss: 0.25970789790153503, Training Acc: 79.02%\n",
      "              Val Loss: 1.352040410041809, Val Acc: 68.45%\n",
      "Epoch: 8483,     Training Loss: 0.2561942934989929, Training Acc: 79.02%\n",
      "              Val Loss: 1.3548989295959473, Val Acc: 68.45%\n",
      "Epoch: 8484,     Training Loss: 0.25507763028144836, Training Acc: 79.02%\n",
      "              Val Loss: 1.3559837341308594, Val Acc: 68.45%\n",
      "Epoch: 8485,     Training Loss: 0.25332188606262207, Training Acc: 79.02%\n",
      "              Val Loss: 1.3542876243591309, Val Acc: 68.45%\n",
      "Epoch: 8486,     Training Loss: 0.251575231552124, Training Acc: 79.02%\n",
      "              Val Loss: 1.3564833402633667, Val Acc: 68.45%\n",
      "Epoch: 8487,     Training Loss: 0.2503303289413452, Training Acc: 79.03%\n",
      "              Val Loss: 1.368381381034851, Val Acc: 68.45%\n",
      "Epoch: 8488,     Training Loss: 0.24801132082939148, Training Acc: 79.03%\n",
      "              Val Loss: 1.361660361289978, Val Acc: 68.45%\n",
      "Epoch: 8489,     Training Loss: 0.2469252347946167, Training Acc: 79.03%\n",
      "              Val Loss: 1.36454439163208, Val Acc: 68.45%\n",
      "Epoch: 8490,     Training Loss: 0.24551557004451752, Training Acc: 79.03%\n",
      "              Val Loss: 1.3755115270614624, Val Acc: 68.45%\n",
      "Epoch: 8491,     Training Loss: 0.24432101845741272, Training Acc: 79.03%\n",
      "              Val Loss: 1.3638757467269897, Val Acc: 68.45%\n",
      "Epoch: 8492,     Training Loss: 0.24345113337039948, Training Acc: 79.03%\n",
      "              Val Loss: 1.3624616861343384, Val Acc: 68.45%\n",
      "Epoch: 8493,     Training Loss: 0.2422284483909607, Training Acc: 79.03%\n",
      "              Val Loss: 1.366661787033081, Val Acc: 68.45%\n",
      "Epoch: 8494,     Training Loss: 0.2409486323595047, Training Acc: 79.04%\n",
      "              Val Loss: 1.3666102886199951, Val Acc: 68.45%\n",
      "Epoch: 8495,     Training Loss: 0.23918043076992035, Training Acc: 79.04%\n",
      "              Val Loss: 1.3720544576644897, Val Acc: 68.45%\n",
      "Epoch: 8496,     Training Loss: 0.23848828673362732, Training Acc: 79.04%\n",
      "              Val Loss: 1.3657357692718506, Val Acc: 68.46%\n",
      "Epoch: 8497,     Training Loss: 0.23768575489521027, Training Acc: 79.04%\n",
      "              Val Loss: 1.3677977323532104, Val Acc: 68.46%\n",
      "Epoch: 8498,     Training Loss: 0.23673398792743683, Training Acc: 79.04%\n",
      "              Val Loss: 1.355722188949585, Val Acc: 68.46%\n",
      "Epoch: 8499,     Training Loss: 0.23563124239444733, Training Acc: 79.04%\n",
      "              Val Loss: 1.3676698207855225, Val Acc: 68.46%\n",
      "Epoch: 8500,     Training Loss: 0.2346804291009903, Training Acc: 79.04%\n",
      "              Val Loss: 1.3596069812774658, Val Acc: 68.46%\n",
      "Epoch: 8501,     Training Loss: 0.23401322960853577, Training Acc: 79.05%\n",
      "              Val Loss: 1.361244559288025, Val Acc: 68.46%\n",
      "Epoch: 8502,     Training Loss: 0.23286624252796173, Training Acc: 79.05%\n",
      "              Val Loss: 1.3582464456558228, Val Acc: 68.46%\n",
      "Epoch: 8503,     Training Loss: 0.2318672239780426, Training Acc: 79.05%\n",
      "              Val Loss: 1.3669867515563965, Val Acc: 68.46%\n",
      "Epoch: 8504,     Training Loss: 0.23114395141601562, Training Acc: 79.05%\n",
      "              Val Loss: 1.3738288879394531, Val Acc: 68.46%\n",
      "Epoch: 8505,     Training Loss: 0.23032088577747345, Training Acc: 79.05%\n",
      "              Val Loss: 1.3756197690963745, Val Acc: 68.46%\n",
      "Epoch: 8506,     Training Loss: 0.2294677197933197, Training Acc: 79.05%\n",
      "              Val Loss: 1.3815722465515137, Val Acc: 68.46%\n",
      "Epoch: 8507,     Training Loss: 0.22872799634933472, Training Acc: 79.05%\n",
      "              Val Loss: 1.380277395248413, Val Acc: 68.46%\n",
      "Epoch: 8508,     Training Loss: 0.22819888591766357, Training Acc: 79.06%\n",
      "              Val Loss: 1.3930000066757202, Val Acc: 68.46%\n",
      "Epoch: 8509,     Training Loss: 0.22756394743919373, Training Acc: 79.06%\n",
      "              Val Loss: 1.3884263038635254, Val Acc: 68.46%\n",
      "Epoch: 8510,     Training Loss: 0.22703716158866882, Training Acc: 79.06%\n",
      "              Val Loss: 1.3990974426269531, Val Acc: 68.46%\n",
      "Epoch: 8511,     Training Loss: 0.22663933038711548, Training Acc: 79.06%\n",
      "              Val Loss: 1.3842350244522095, Val Acc: 68.46%\n",
      "Epoch: 8512,     Training Loss: 0.2266261726617813, Training Acc: 79.06%\n",
      "              Val Loss: 1.4021950960159302, Val Acc: 68.46%\n",
      "Epoch: 8513,     Training Loss: 0.2260676622390747, Training Acc: 79.06%\n",
      "              Val Loss: 1.3890985250473022, Val Acc: 68.46%\n",
      "Epoch: 8514,     Training Loss: 0.22603560984134674, Training Acc: 79.06%\n",
      "              Val Loss: 1.4113266468048096, Val Acc: 68.46%\n",
      "Epoch: 8515,     Training Loss: 0.22467738389968872, Training Acc: 79.07%\n",
      "              Val Loss: 1.4027900695800781, Val Acc: 68.46%\n",
      "Epoch: 8516,     Training Loss: 0.22360286116600037, Training Acc: 79.07%\n",
      "              Val Loss: 1.4121872186660767, Val Acc: 68.46%\n",
      "Epoch: 8517,     Training Loss: 0.22248272597789764, Training Acc: 79.07%\n",
      "              Val Loss: 1.4148412942886353, Val Acc: 68.46%\n",
      "Epoch: 8518,     Training Loss: 0.2219296246767044, Training Acc: 79.07%\n",
      "              Val Loss: 1.4135828018188477, Val Acc: 68.46%\n",
      "Epoch: 8519,     Training Loss: 0.2217770367860794, Training Acc: 79.07%\n",
      "              Val Loss: 1.4229843616485596, Val Acc: 68.46%\n",
      "Epoch: 8520,     Training Loss: 0.2220264971256256, Training Acc: 79.07%\n",
      "              Val Loss: 1.4035835266113281, Val Acc: 68.46%\n",
      "Epoch: 8521,     Training Loss: 0.22283826768398285, Training Acc: 79.07%\n",
      "              Val Loss: 1.4275641441345215, Val Acc: 68.47%\n",
      "Epoch: 8522,     Training Loss: 0.2234838604927063, Training Acc: 79.08%\n",
      "              Val Loss: 1.4052374362945557, Val Acc: 68.47%\n",
      "Epoch: 8523,     Training Loss: 0.22537319362163544, Training Acc: 79.08%\n",
      "              Val Loss: 1.4328347444534302, Val Acc: 68.47%\n",
      "Epoch: 8524,     Training Loss: 0.22328893840312958, Training Acc: 79.08%\n",
      "              Val Loss: 1.4056084156036377, Val Acc: 68.47%\n",
      "Epoch: 8525,     Training Loss: 0.2219448983669281, Training Acc: 79.08%\n",
      "              Val Loss: 1.4189567565917969, Val Acc: 68.47%\n",
      "Epoch: 8526,     Training Loss: 0.2194664627313614, Training Acc: 79.08%\n",
      "              Val Loss: 1.413167119026184, Val Acc: 68.47%\n",
      "Epoch: 8527,     Training Loss: 0.21836644411087036, Training Acc: 79.08%\n",
      "              Val Loss: 1.407047152519226, Val Acc: 68.47%\n",
      "Epoch: 8528,     Training Loss: 0.2189653515815735, Training Acc: 79.08%\n",
      "              Val Loss: 1.4295988082885742, Val Acc: 68.47%\n",
      "Epoch: 8529,     Training Loss: 0.2212747037410736, Training Acc: 79.09%\n",
      "              Val Loss: 1.4052321910858154, Val Acc: 68.47%\n",
      "Epoch: 8530,     Training Loss: 0.2243756800889969, Training Acc: 79.09%\n",
      "              Val Loss: 1.4343661069869995, Val Acc: 68.47%\n",
      "Epoch: 8531,     Training Loss: 0.22337493300437927, Training Acc: 79.09%\n",
      "              Val Loss: 1.405482292175293, Val Acc: 68.47%\n",
      "Epoch: 8532,     Training Loss: 0.2228594422340393, Training Acc: 79.09%\n",
      "              Val Loss: 1.4307652711868286, Val Acc: 68.47%\n",
      "Epoch: 8533,     Training Loss: 0.21913114190101624, Training Acc: 79.09%\n",
      "              Val Loss: 1.4141738414764404, Val Acc: 68.47%\n",
      "Epoch: 8534,     Training Loss: 0.21684566140174866, Training Acc: 79.09%\n",
      "              Val Loss: 1.4171181917190552, Val Acc: 68.47%\n",
      "Epoch: 8535,     Training Loss: 0.21602760255336761, Training Acc: 79.09%\n",
      "              Val Loss: 1.425498604774475, Val Acc: 68.47%\n",
      "Epoch: 8536,     Training Loss: 0.21639879047870636, Training Acc: 79.10%\n",
      "              Val Loss: 1.413000464439392, Val Acc: 68.47%\n",
      "Epoch: 8537,     Training Loss: 0.2180357724428177, Training Acc: 79.10%\n",
      "              Val Loss: 1.4364008903503418, Val Acc: 68.47%\n",
      "Epoch: 8538,     Training Loss: 0.21952465176582336, Training Acc: 79.10%\n",
      "              Val Loss: 1.4109097719192505, Val Acc: 68.47%\n",
      "Epoch: 8539,     Training Loss: 0.22142022848129272, Training Acc: 79.10%\n",
      "              Val Loss: 1.4386671781539917, Val Acc: 68.47%\n",
      "Epoch: 8540,     Training Loss: 0.22008125483989716, Training Acc: 79.10%\n",
      "              Val Loss: 1.410354495048523, Val Acc: 68.47%\n",
      "Epoch: 8541,     Training Loss: 0.21927474439144135, Training Acc: 79.10%\n",
      "              Val Loss: 1.431633472442627, Val Acc: 68.47%\n",
      "Epoch: 8542,     Training Loss: 0.21673263609409332, Training Acc: 79.10%\n",
      "              Val Loss: 1.4146716594696045, Val Acc: 68.47%\n",
      "Epoch: 8543,     Training Loss: 0.21466203033924103, Training Acc: 79.11%\n",
      "              Val Loss: 1.4156510829925537, Val Acc: 68.47%\n",
      "Epoch: 8544,     Training Loss: 0.213974267244339, Training Acc: 79.11%\n",
      "              Val Loss: 1.4244160652160645, Val Acc: 68.47%\n",
      "Epoch: 8545,     Training Loss: 0.21423158049583435, Training Acc: 79.11%\n",
      "              Val Loss: 1.4156079292297363, Val Acc: 68.47%\n",
      "Epoch: 8546,     Training Loss: 0.21518634259700775, Training Acc: 79.11%\n",
      "              Val Loss: 1.434887409210205, Val Acc: 68.48%\n",
      "Epoch: 8547,     Training Loss: 0.2161731719970703, Training Acc: 79.11%\n",
      "              Val Loss: 1.4144668579101562, Val Acc: 68.48%\n",
      "Epoch: 8548,     Training Loss: 0.21758808195590973, Training Acc: 79.11%\n",
      "              Val Loss: 1.440354585647583, Val Acc: 68.48%\n",
      "Epoch: 8549,     Training Loss: 0.2177472561597824, Training Acc: 79.12%\n",
      "              Val Loss: 1.4129213094711304, Val Acc: 68.48%\n",
      "Epoch: 8550,     Training Loss: 0.2191016525030136, Training Acc: 79.12%\n",
      "              Val Loss: 1.4412810802459717, Val Acc: 68.48%\n",
      "Epoch: 8551,     Training Loss: 0.21672159433364868, Training Acc: 79.12%\n",
      "              Val Loss: 1.415708065032959, Val Acc: 68.48%\n",
      "Epoch: 8552,     Training Loss: 0.21459928154945374, Training Acc: 79.12%\n",
      "              Val Loss: 1.4277818202972412, Val Acc: 68.48%\n",
      "Epoch: 8553,     Training Loss: 0.21306675672531128, Training Acc: 79.12%\n",
      "              Val Loss: 1.423342227935791, Val Acc: 68.48%\n",
      "Epoch: 8554,     Training Loss: 0.21203283965587616, Training Acc: 79.12%\n",
      "              Val Loss: 1.425672173500061, Val Acc: 68.48%\n",
      "Epoch: 8555,     Training Loss: 0.21164926886558533, Training Acc: 79.12%\n",
      "              Val Loss: 1.4305421113967896, Val Acc: 68.48%\n",
      "Epoch: 8556,     Training Loss: 0.21181945502758026, Training Acc: 79.13%\n",
      "              Val Loss: 1.425003170967102, Val Acc: 68.48%\n",
      "Epoch: 8557,     Training Loss: 0.21298843622207642, Training Acc: 79.13%\n",
      "              Val Loss: 1.4425724744796753, Val Acc: 68.48%\n",
      "Epoch: 8558,     Training Loss: 0.21454326808452606, Training Acc: 79.13%\n",
      "              Val Loss: 1.4166604280471802, Val Acc: 68.48%\n",
      "Epoch: 8559,     Training Loss: 0.2183649092912674, Training Acc: 79.13%\n",
      "              Val Loss: 1.451794147491455, Val Acc: 68.48%\n",
      "Epoch: 8560,     Training Loss: 0.21821095049381256, Training Acc: 79.13%\n",
      "              Val Loss: 1.4150885343551636, Val Acc: 68.48%\n",
      "Epoch: 8561,     Training Loss: 0.21884168684482574, Training Acc: 79.13%\n",
      "              Val Loss: 1.4430221319198608, Val Acc: 68.48%\n",
      "Epoch: 8562,     Training Loss: 0.2150820940732956, Training Acc: 79.13%\n",
      "              Val Loss: 1.4217647314071655, Val Acc: 68.48%\n",
      "Epoch: 8563,     Training Loss: 0.21271392703056335, Training Acc: 79.14%\n",
      "              Val Loss: 1.4336340427398682, Val Acc: 68.48%\n",
      "Epoch: 8564,     Training Loss: 0.21047508716583252, Training Acc: 79.14%\n",
      "              Val Loss: 1.4337294101715088, Val Acc: 68.48%\n",
      "Epoch: 8565,     Training Loss: 0.21003717184066772, Training Acc: 79.14%\n",
      "              Val Loss: 1.4268348217010498, Val Acc: 68.48%\n",
      "Epoch: 8566,     Training Loss: 0.21137896180152893, Training Acc: 79.14%\n",
      "              Val Loss: 1.4443022012710571, Val Acc: 68.48%\n",
      "Epoch: 8567,     Training Loss: 0.2130877673625946, Training Acc: 79.14%\n",
      "              Val Loss: 1.4166303873062134, Val Acc: 68.48%\n",
      "Epoch: 8568,     Training Loss: 0.21690532565116882, Training Acc: 79.14%\n",
      "              Val Loss: 1.4521182775497437, Val Acc: 68.48%\n",
      "Epoch: 8569,     Training Loss: 0.21711742877960205, Training Acc: 79.15%\n",
      "              Val Loss: 1.4149507284164429, Val Acc: 68.48%\n",
      "Epoch: 8570,     Training Loss: 0.2191808670759201, Training Acc: 79.15%\n",
      "              Val Loss: 1.4451110363006592, Val Acc: 68.48%\n",
      "Epoch: 8571,     Training Loss: 0.21406130492687225, Training Acc: 79.15%\n",
      "              Val Loss: 1.417673945426941, Val Acc: 68.48%\n",
      "Epoch: 8572,     Training Loss: 0.2115270495414734, Training Acc: 79.15%\n",
      "              Val Loss: 1.4326401948928833, Val Acc: 68.49%\n",
      "Epoch: 8573,     Training Loss: 0.20926304161548615, Training Acc: 79.15%\n",
      "              Val Loss: 1.431431770324707, Val Acc: 68.49%\n",
      "Epoch: 8574,     Training Loss: 0.20817942917346954, Training Acc: 79.15%\n",
      "              Val Loss: 1.4318050146102905, Val Acc: 68.49%\n",
      "Epoch: 8575,     Training Loss: 0.20863695442676544, Training Acc: 79.15%\n",
      "              Val Loss: 1.4459375143051147, Val Acc: 68.49%\n",
      "Epoch: 8576,     Training Loss: 0.21042361855506897, Training Acc: 79.16%\n",
      "              Val Loss: 1.4228237867355347, Val Acc: 68.49%\n",
      "Epoch: 8577,     Training Loss: 0.21411579847335815, Training Acc: 79.16%\n",
      "              Val Loss: 1.4630956649780273, Val Acc: 68.49%\n",
      "Epoch: 8578,     Training Loss: 0.2166038453578949, Training Acc: 79.16%\n",
      "              Val Loss: 1.425298810005188, Val Acc: 68.49%\n",
      "Epoch: 8579,     Training Loss: 0.22409573197364807, Training Acc: 79.16%\n",
      "              Val Loss: 1.469672441482544, Val Acc: 68.49%\n",
      "Epoch: 8580,     Training Loss: 0.21808263659477234, Training Acc: 79.16%\n",
      "              Val Loss: 1.4220722913742065, Val Acc: 68.49%\n",
      "Epoch: 8581,     Training Loss: 0.21702104806900024, Training Acc: 79.16%\n",
      "              Val Loss: 1.4497954845428467, Val Acc: 68.49%\n",
      "Epoch: 8582,     Training Loss: 0.2113763391971588, Training Acc: 79.16%\n",
      "              Val Loss: 1.430633544921875, Val Acc: 68.49%\n",
      "Epoch: 8583,     Training Loss: 0.2078961431980133, Training Acc: 79.17%\n",
      "              Val Loss: 1.4415748119354248, Val Acc: 68.49%\n",
      "Epoch: 8584,     Training Loss: 0.20655325055122375, Training Acc: 79.17%\n",
      "              Val Loss: 1.4431527853012085, Val Acc: 68.49%\n",
      "Epoch: 8585,     Training Loss: 0.20657920837402344, Training Acc: 79.17%\n",
      "              Val Loss: 1.427069902420044, Val Acc: 68.49%\n",
      "Epoch: 8586,     Training Loss: 0.20857518911361694, Training Acc: 79.17%\n",
      "              Val Loss: 1.457974910736084, Val Acc: 68.49%\n",
      "Epoch: 8587,     Training Loss: 0.21123988926410675, Training Acc: 79.17%\n",
      "              Val Loss: 1.427121877670288, Val Acc: 68.49%\n",
      "Epoch: 8588,     Training Loss: 0.2194964438676834, Training Acc: 79.17%\n",
      "              Val Loss: 1.481677532196045, Val Acc: 68.49%\n",
      "Epoch: 8589,     Training Loss: 0.22317898273468018, Training Acc: 79.17%\n",
      "              Val Loss: 1.4282282590866089, Val Acc: 68.49%\n",
      "Epoch: 8590,     Training Loss: 0.23751753568649292, Training Acc: 79.18%\n",
      "              Val Loss: 1.4782580137252808, Val Acc: 68.49%\n",
      "Epoch: 8591,     Training Loss: 0.2232700139284134, Training Acc: 79.18%\n",
      "              Val Loss: 1.4225990772247314, Val Acc: 68.49%\n",
      "Epoch: 8592,     Training Loss: 0.21681027114391327, Training Acc: 79.18%\n",
      "              Val Loss: 1.4482063055038452, Val Acc: 68.49%\n",
      "Epoch: 8593,     Training Loss: 0.20727720856666565, Training Acc: 79.18%\n",
      "              Val Loss: 1.4460655450820923, Val Acc: 68.49%\n",
      "Epoch: 8594,     Training Loss: 0.20711156725883484, Training Acc: 79.18%\n",
      "              Val Loss: 1.4235435724258423, Val Acc: 68.49%\n",
      "Epoch: 8595,     Training Loss: 0.21538789570331573, Training Acc: 79.18%\n",
      "              Val Loss: 1.4824397563934326, Val Acc: 68.49%\n",
      "Epoch: 8596,     Training Loss: 0.22153259813785553, Training Acc: 79.18%\n",
      "              Val Loss: 1.4286009073257446, Val Acc: 68.49%\n",
      "Epoch: 8597,     Training Loss: 0.23651129007339478, Training Acc: 79.19%\n",
      "              Val Loss: 1.4768131971359253, Val Acc: 68.49%\n",
      "Epoch: 8598,     Training Loss: 0.219150111079216, Training Acc: 79.19%\n",
      "              Val Loss: 1.4227781295776367, Val Acc: 68.49%\n",
      "Epoch: 8599,     Training Loss: 0.21214476227760315, Training Acc: 79.19%\n",
      "              Val Loss: 1.4401005506515503, Val Acc: 68.50%\n",
      "Epoch: 8600,     Training Loss: 0.20534485578536987, Training Acc: 79.19%\n",
      "              Val Loss: 1.4400227069854736, Val Acc: 68.50%\n",
      "Epoch: 8601,     Training Loss: 0.2045077085494995, Training Acc: 79.19%\n",
      "              Val Loss: 1.4336415529251099, Val Acc: 68.50%\n",
      "Epoch: 8602,     Training Loss: 0.20722340047359467, Training Acc: 79.19%\n",
      "              Val Loss: 1.4686291217803955, Val Acc: 68.50%\n",
      "Epoch: 8603,     Training Loss: 0.21106834709644318, Training Acc: 79.19%\n",
      "              Val Loss: 1.4257229566574097, Val Acc: 68.50%\n",
      "Epoch: 8604,     Training Loss: 0.2227436602115631, Training Acc: 79.20%\n",
      "              Val Loss: 1.4836748838424683, Val Acc: 68.50%\n",
      "Epoch: 8605,     Training Loss: 0.21925842761993408, Training Acc: 79.20%\n",
      "              Val Loss: 1.426871657371521, Val Acc: 68.50%\n",
      "Epoch: 8606,     Training Loss: 0.22315338253974915, Training Acc: 79.20%\n",
      "              Val Loss: 1.4717833995819092, Val Acc: 68.50%\n",
      "Epoch: 8607,     Training Loss: 0.21362896263599396, Training Acc: 79.20%\n",
      "              Val Loss: 1.4309130907058716, Val Acc: 68.50%\n",
      "Epoch: 8608,     Training Loss: 0.20854827761650085, Training Acc: 79.20%\n",
      "              Val Loss: 1.4446369409561157, Val Acc: 68.50%\n",
      "Epoch: 8609,     Training Loss: 0.20398178696632385, Training Acc: 79.20%\n",
      "              Val Loss: 1.4572546482086182, Val Acc: 68.50%\n",
      "Epoch: 8610,     Training Loss: 0.203994482755661, Training Acc: 79.20%\n",
      "              Val Loss: 1.4439289569854736, Val Acc: 68.50%\n",
      "Epoch: 8611,     Training Loss: 0.20830674469470978, Training Acc: 79.21%\n",
      "              Val Loss: 1.4813308715820312, Val Acc: 68.50%\n",
      "Epoch: 8612,     Training Loss: 0.2111872136592865, Training Acc: 79.21%\n",
      "              Val Loss: 1.4298691749572754, Val Acc: 68.50%\n",
      "Epoch: 8613,     Training Loss: 0.22513046860694885, Training Acc: 79.21%\n",
      "              Val Loss: 1.501826524734497, Val Acc: 68.50%\n",
      "Epoch: 8614,     Training Loss: 0.22689862549304962, Training Acc: 79.21%\n",
      "              Val Loss: 1.440749168395996, Val Acc: 68.50%\n",
      "Epoch: 8615,     Training Loss: 0.24723082780838013, Training Acc: 79.21%\n",
      "              Val Loss: 1.507256269454956, Val Acc: 68.50%\n",
      "Epoch: 8616,     Training Loss: 0.22736385464668274, Training Acc: 79.21%\n",
      "              Val Loss: 1.4207420349121094, Val Acc: 68.50%\n",
      "Epoch: 8617,     Training Loss: 0.2177189588546753, Training Acc: 79.21%\n",
      "              Val Loss: 1.440616250038147, Val Acc: 68.50%\n",
      "Epoch: 8618,     Training Loss: 0.2069481611251831, Training Acc: 79.22%\n",
      "              Val Loss: 1.4472929239273071, Val Acc: 68.50%\n",
      "Epoch: 8619,     Training Loss: 0.20385272800922394, Training Acc: 79.22%\n",
      "              Val Loss: 1.4375982284545898, Val Acc: 68.50%\n",
      "Epoch: 8620,     Training Loss: 0.2133645862340927, Training Acc: 79.22%\n",
      "              Val Loss: 1.4900513887405396, Val Acc: 68.50%\n",
      "Epoch: 8621,     Training Loss: 0.21308693289756775, Training Acc: 79.22%\n",
      "              Val Loss: 1.4239163398742676, Val Acc: 68.50%\n",
      "Epoch: 8622,     Training Loss: 0.2211080938577652, Training Acc: 79.22%\n",
      "              Val Loss: 1.4807353019714355, Val Acc: 68.50%\n",
      "Epoch: 8623,     Training Loss: 0.21553577482700348, Training Acc: 79.22%\n",
      "              Val Loss: 1.4448014497756958, Val Acc: 68.50%\n",
      "Epoch: 8624,     Training Loss: 0.21412323415279388, Training Acc: 79.22%\n",
      "              Val Loss: 1.4931602478027344, Val Acc: 68.50%\n",
      "Epoch: 8625,     Training Loss: 0.21087807416915894, Training Acc: 79.23%\n",
      "              Val Loss: 1.4411697387695312, Val Acc: 68.50%\n",
      "Epoch: 8626,     Training Loss: 0.20583637058734894, Training Acc: 79.23%\n",
      "              Val Loss: 1.4630181789398193, Val Acc: 68.50%\n",
      "Epoch: 8627,     Training Loss: 0.20697544515132904, Training Acc: 79.23%\n",
      "              Val Loss: 1.4384509325027466, Val Acc: 68.50%\n",
      "Epoch: 8628,     Training Loss: 0.20313765108585358, Training Acc: 79.23%\n",
      "              Val Loss: 1.4796186685562134, Val Acc: 68.50%\n",
      "Epoch: 8629,     Training Loss: 0.2041265368461609, Training Acc: 79.23%\n",
      "              Val Loss: 1.4490946531295776, Val Acc: 68.51%\n",
      "Epoch: 8630,     Training Loss: 0.20290404558181763, Training Acc: 79.23%\n",
      "              Val Loss: 1.4704519510269165, Val Acc: 68.51%\n",
      "Epoch: 8631,     Training Loss: 0.20401506125926971, Training Acc: 79.23%\n",
      "              Val Loss: 1.4448344707489014, Val Acc: 68.51%\n",
      "Epoch: 8632,     Training Loss: 0.2080063372850418, Training Acc: 79.24%\n",
      "              Val Loss: 1.5053826570510864, Val Acc: 68.51%\n",
      "Epoch: 8633,     Training Loss: 0.21215103566646576, Training Acc: 79.24%\n",
      "              Val Loss: 1.4510388374328613, Val Acc: 68.51%\n",
      "Epoch: 8634,     Training Loss: 0.2305491864681244, Training Acc: 79.24%\n",
      "              Val Loss: 1.5332589149475098, Val Acc: 68.51%\n",
      "Epoch: 8635,     Training Loss: 0.22951766848564148, Training Acc: 79.24%\n",
      "              Val Loss: 1.4407728910446167, Val Acc: 68.51%\n",
      "Epoch: 8636,     Training Loss: 0.2510056793689728, Training Acc: 79.24%\n",
      "              Val Loss: 1.5243335962295532, Val Acc: 68.51%\n",
      "Epoch: 8637,     Training Loss: 0.23275989294052124, Training Acc: 79.24%\n",
      "              Val Loss: 1.4357807636260986, Val Acc: 68.51%\n",
      "Epoch: 8638,     Training Loss: 0.2315150499343872, Training Acc: 79.24%\n",
      "              Val Loss: 1.4856332540512085, Val Acc: 68.51%\n",
      "Epoch: 8639,     Training Loss: 0.2082030326128006, Training Acc: 79.24%\n",
      "              Val Loss: 1.4558979272842407, Val Acc: 68.51%\n",
      "Epoch: 8640,     Training Loss: 0.20095792412757874, Training Acc: 79.25%\n",
      "              Val Loss: 1.4346342086791992, Val Acc: 68.51%\n",
      "Epoch: 8641,     Training Loss: 0.20822080969810486, Training Acc: 79.25%\n",
      "              Val Loss: 1.5045180320739746, Val Acc: 68.51%\n",
      "Epoch: 8642,     Training Loss: 0.21508967876434326, Training Acc: 79.25%\n",
      "              Val Loss: 1.4571248292922974, Val Acc: 68.51%\n",
      "Epoch: 8643,     Training Loss: 0.23212076723575592, Training Acc: 79.25%\n",
      "              Val Loss: 1.5257964134216309, Val Acc: 68.51%\n",
      "Epoch: 8644,     Training Loss: 0.21854045987129211, Training Acc: 79.25%\n",
      "              Val Loss: 1.4465484619140625, Val Acc: 68.51%\n",
      "Epoch: 8645,     Training Loss: 0.21476711332798004, Training Acc: 79.25%\n",
      "              Val Loss: 1.4837719202041626, Val Acc: 68.51%\n",
      "Epoch: 8646,     Training Loss: 0.2087070643901825, Training Acc: 79.25%\n",
      "              Val Loss: 1.4554283618927002, Val Acc: 68.51%\n",
      "Epoch: 8647,     Training Loss: 0.20096853375434875, Training Acc: 79.26%\n",
      "              Val Loss: 1.482925534248352, Val Acc: 68.51%\n",
      "Epoch: 8648,     Training Loss: 0.20145396888256073, Training Acc: 79.26%\n",
      "              Val Loss: 1.470025897026062, Val Acc: 68.51%\n",
      "Epoch: 8649,     Training Loss: 0.19926834106445312, Training Acc: 79.26%\n",
      "              Val Loss: 1.4618569612503052, Val Acc: 68.51%\n",
      "Epoch: 8650,     Training Loss: 0.19991812109947205, Training Acc: 79.26%\n",
      "              Val Loss: 1.4767132997512817, Val Acc: 68.51%\n",
      "Epoch: 8651,     Training Loss: 0.19832438230514526, Training Acc: 79.26%\n",
      "              Val Loss: 1.4790372848510742, Val Acc: 68.51%\n",
      "Epoch: 8652,     Training Loss: 0.2011539340019226, Training Acc: 79.26%\n",
      "              Val Loss: 1.4934593439102173, Val Acc: 68.51%\n",
      "Epoch: 8653,     Training Loss: 0.20019197463989258, Training Acc: 79.27%\n",
      "              Val Loss: 1.4614825248718262, Val Acc: 68.51%\n",
      "Epoch: 8654,     Training Loss: 0.19996167719364166, Training Acc: 79.27%\n",
      "              Val Loss: 1.4991439580917358, Val Acc: 68.51%\n",
      "Epoch: 8655,     Training Loss: 0.20725944638252258, Training Acc: 79.27%\n",
      "              Val Loss: 1.464651346206665, Val Acc: 68.51%\n",
      "Epoch: 8656,     Training Loss: 0.22482700645923615, Training Acc: 79.27%\n",
      "              Val Loss: 1.571476697921753, Val Acc: 68.51%\n",
      "Epoch: 8657,     Training Loss: 0.23980098962783813, Training Acc: 79.27%\n",
      "              Val Loss: 1.480855107307434, Val Acc: 68.51%\n",
      "Epoch: 8658,     Training Loss: 0.2981390655040741, Training Acc: 79.27%\n",
      "              Val Loss: 1.588526725769043, Val Acc: 68.51%\n",
      "Epoch: 8659,     Training Loss: 0.2590882480144501, Training Acc: 79.27%\n",
      "              Val Loss: 1.451979637145996, Val Acc: 68.51%\n",
      "Epoch: 8660,     Training Loss: 0.26492369174957275, Training Acc: 79.27%\n",
      "              Val Loss: 1.494329810142517, Val Acc: 68.51%\n",
      "Epoch: 8661,     Training Loss: 0.2076009213924408, Training Acc: 79.28%\n",
      "              Val Loss: 1.5058010816574097, Val Acc: 68.51%\n",
      "Epoch: 8662,     Training Loss: 0.21552367508411407, Training Acc: 79.28%\n",
      "              Val Loss: 1.46309494972229, Val Acc: 68.51%\n",
      "Epoch: 8663,     Training Loss: 0.2803172767162323, Training Acc: 79.28%\n",
      "              Val Loss: 1.5856493711471558, Val Acc: 68.51%\n",
      "Epoch: 8664,     Training Loss: 0.2528963088989258, Training Acc: 79.28%\n",
      "              Val Loss: 1.4557640552520752, Val Acc: 68.52%\n",
      "Epoch: 8665,     Training Loss: 0.25254082679748535, Training Acc: 79.28%\n",
      "              Val Loss: 1.492699384689331, Val Acc: 68.52%\n",
      "Epoch: 8666,     Training Loss: 0.20381221175193787, Training Acc: 79.28%\n",
      "              Val Loss: 1.5167497396469116, Val Acc: 68.52%\n",
      "Epoch: 8667,     Training Loss: 0.21487578749656677, Training Acc: 79.28%\n",
      "              Val Loss: 1.4801242351531982, Val Acc: 68.52%\n",
      "Epoch: 8668,     Training Loss: 0.2798888087272644, Training Acc: 79.28%\n",
      "              Val Loss: 1.5717452764511108, Val Acc: 68.52%\n",
      "Epoch: 8669,     Training Loss: 0.24218660593032837, Training Acc: 79.28%\n",
      "              Val Loss: 1.4484678506851196, Val Acc: 68.52%\n",
      "Epoch: 8670,     Training Loss: 0.22544310986995697, Training Acc: 79.29%\n",
      "              Val Loss: 1.4671298265457153, Val Acc: 68.52%\n",
      "Epoch: 8671,     Training Loss: 0.20327267050743103, Training Acc: 79.29%\n",
      "              Val Loss: 1.51088547706604, Val Acc: 68.52%\n",
      "Epoch: 8672,     Training Loss: 0.21575550734996796, Training Acc: 79.29%\n",
      "              Val Loss: 1.4608813524246216, Val Acc: 68.52%\n",
      "Epoch: 8673,     Training Loss: 0.2528267800807953, Training Acc: 79.29%\n",
      "              Val Loss: 1.5396941900253296, Val Acc: 68.52%\n",
      "Epoch: 8674,     Training Loss: 0.2212037593126297, Training Acc: 79.29%\n",
      "              Val Loss: 1.4612524509429932, Val Acc: 68.52%\n",
      "Epoch: 8675,     Training Loss: 0.1999848484992981, Training Acc: 79.29%\n",
      "              Val Loss: 1.4513137340545654, Val Acc: 68.52%\n",
      "Epoch: 8676,     Training Loss: 0.20813977718353271, Training Acc: 79.29%\n",
      "              Val Loss: 1.5168949365615845, Val Acc: 68.52%\n",
      "Epoch: 8677,     Training Loss: 0.21199212968349457, Training Acc: 79.30%\n",
      "              Val Loss: 1.4716262817382812, Val Acc: 68.52%\n",
      "Epoch: 8678,     Training Loss: 0.22165700793266296, Training Acc: 79.30%\n",
      "              Val Loss: 1.533658504486084, Val Acc: 68.52%\n",
      "Epoch: 8679,     Training Loss: 0.21116741001605988, Training Acc: 79.30%\n",
      "              Val Loss: 1.4758081436157227, Val Acc: 68.52%\n",
      "Epoch: 8680,     Training Loss: 0.1998666524887085, Training Acc: 79.30%\n",
      "              Val Loss: 1.4695672988891602, Val Acc: 68.52%\n",
      "Epoch: 8681,     Training Loss: 0.2023962140083313, Training Acc: 79.30%\n",
      "              Val Loss: 1.4926105737686157, Val Acc: 68.52%\n",
      "Epoch: 8682,     Training Loss: 0.1988726109266281, Training Acc: 79.30%\n",
      "              Val Loss: 1.4890544414520264, Val Acc: 68.52%\n",
      "Epoch: 8683,     Training Loss: 0.20567190647125244, Training Acc: 79.30%\n",
      "              Val Loss: 1.5285621881484985, Val Acc: 68.52%\n",
      "Epoch: 8684,     Training Loss: 0.20675598084926605, Training Acc: 79.31%\n",
      "              Val Loss: 1.4666668176651, Val Acc: 68.52%\n",
      "Epoch: 8685,     Training Loss: 0.20766496658325195, Training Acc: 79.31%\n",
      "              Val Loss: 1.5121738910675049, Val Acc: 68.52%\n",
      "Epoch: 8686,     Training Loss: 0.21383948624134064, Training Acc: 79.31%\n",
      "              Val Loss: 1.4748533964157104, Val Acc: 68.52%\n",
      "Epoch: 8687,     Training Loss: 0.21793149411678314, Training Acc: 79.31%\n",
      "              Val Loss: 1.5673696994781494, Val Acc: 68.52%\n",
      "Epoch: 8688,     Training Loss: 0.22315579652786255, Training Acc: 79.31%\n",
      "              Val Loss: 1.469336748123169, Val Acc: 68.52%\n",
      "Epoch: 8689,     Training Loss: 0.2276766002178192, Training Acc: 79.31%\n",
      "              Val Loss: 1.5396209955215454, Val Acc: 68.52%\n",
      "Epoch: 8690,     Training Loss: 0.22627638280391693, Training Acc: 79.31%\n",
      "              Val Loss: 1.4627325534820557, Val Acc: 68.52%\n",
      "Epoch: 8691,     Training Loss: 0.22221212089061737, Training Acc: 79.32%\n",
      "              Val Loss: 1.5439889430999756, Val Acc: 68.52%\n",
      "Epoch: 8692,     Training Loss: 0.21230773627758026, Training Acc: 79.32%\n",
      "              Val Loss: 1.485465407371521, Val Acc: 68.52%\n",
      "Epoch: 8693,     Training Loss: 0.2064078003168106, Training Acc: 79.32%\n",
      "              Val Loss: 1.4996334314346313, Val Acc: 68.52%\n",
      "Epoch: 8694,     Training Loss: 0.19979967176914215, Training Acc: 79.32%\n",
      "              Val Loss: 1.4912631511688232, Val Acc: 68.52%\n",
      "Epoch: 8695,     Training Loss: 0.19530637562274933, Training Acc: 79.32%\n",
      "              Val Loss: 1.5007538795471191, Val Acc: 68.52%\n",
      "Epoch: 8696,     Training Loss: 0.19577708840370178, Training Acc: 79.32%\n",
      "              Val Loss: 1.5306777954101562, Val Acc: 68.52%\n",
      "Epoch: 8697,     Training Loss: 0.20135635137557983, Training Acc: 79.32%\n",
      "              Val Loss: 1.4869320392608643, Val Acc: 68.52%\n",
      "Epoch: 8698,     Training Loss: 0.20811225473880768, Training Acc: 79.33%\n",
      "              Val Loss: 1.546730637550354, Val Acc: 68.53%\n",
      "Epoch: 8699,     Training Loss: 0.21774548292160034, Training Acc: 79.33%\n",
      "              Val Loss: 1.4858274459838867, Val Acc: 68.53%\n",
      "Epoch: 8700,     Training Loss: 0.2472372055053711, Training Acc: 79.33%\n",
      "              Val Loss: 1.6092681884765625, Val Acc: 68.53%\n",
      "Epoch: 8701,     Training Loss: 0.2485811412334442, Training Acc: 79.33%\n",
      "              Val Loss: 1.4883770942687988, Val Acc: 68.53%\n",
      "Epoch: 8702,     Training Loss: 0.2911243736743927, Training Acc: 79.33%\n",
      "              Val Loss: 1.5693210363388062, Val Acc: 68.53%\n",
      "Epoch: 8703,     Training Loss: 0.24065563082695007, Training Acc: 79.33%\n",
      "              Val Loss: 1.4455277919769287, Val Acc: 68.53%\n",
      "Epoch: 8704,     Training Loss: 0.2146942913532257, Training Acc: 79.33%\n",
      "              Val Loss: 1.476030707359314, Val Acc: 68.53%\n",
      "Epoch: 8705,     Training Loss: 0.20144203305244446, Training Acc: 79.33%\n",
      "              Val Loss: 1.5366841554641724, Val Acc: 68.53%\n",
      "Epoch: 8706,     Training Loss: 0.21302945911884308, Training Acc: 79.34%\n",
      "              Val Loss: 1.4732694625854492, Val Acc: 68.53%\n",
      "Epoch: 8707,     Training Loss: 0.24304457008838654, Training Acc: 79.34%\n",
      "              Val Loss: 1.5811717510223389, Val Acc: 68.53%\n",
      "Epoch: 8708,     Training Loss: 0.2349735051393509, Training Acc: 79.34%\n",
      "              Val Loss: 1.538512110710144, Val Acc: 68.53%\n",
      "Epoch: 8709,     Training Loss: 0.2612766921520233, Training Acc: 79.34%\n",
      "              Val Loss: 1.5625540018081665, Val Acc: 68.53%\n",
      "Epoch: 8710,     Training Loss: 0.2221352458000183, Training Acc: 79.34%\n",
      "              Val Loss: 1.5097585916519165, Val Acc: 68.53%\n",
      "Epoch: 8711,     Training Loss: 0.19816794991493225, Training Acc: 79.34%\n",
      "              Val Loss: 1.4873138666152954, Val Acc: 68.53%\n",
      "Epoch: 8712,     Training Loss: 0.20753249526023865, Training Acc: 79.34%\n",
      "              Val Loss: 1.5293073654174805, Val Acc: 68.53%\n",
      "Epoch: 8713,     Training Loss: 0.21472352743148804, Training Acc: 79.35%\n",
      "              Val Loss: 1.482452392578125, Val Acc: 68.53%\n",
      "Epoch: 8714,     Training Loss: 0.215390145778656, Training Acc: 79.35%\n",
      "              Val Loss: 1.5268256664276123, Val Acc: 68.53%\n",
      "Epoch: 8715,     Training Loss: 0.2032080888748169, Training Acc: 79.35%\n",
      "              Val Loss: 1.475473165512085, Val Acc: 68.53%\n",
      "Epoch: 8716,     Training Loss: 0.20743152499198914, Training Acc: 79.35%\n",
      "              Val Loss: 1.4809443950653076, Val Acc: 68.53%\n",
      "Epoch: 8717,     Training Loss: 0.20485149323940277, Training Acc: 79.35%\n",
      "              Val Loss: 1.5542417764663696, Val Acc: 68.53%\n",
      "Epoch: 8718,     Training Loss: 0.2134302258491516, Training Acc: 79.35%\n",
      "              Val Loss: 1.498964548110962, Val Acc: 68.53%\n",
      "Epoch: 8719,     Training Loss: 0.25948095321655273, Training Acc: 79.35%\n",
      "              Val Loss: 1.6269346475601196, Val Acc: 68.53%\n",
      "Epoch: 8720,     Training Loss: 0.24654743075370789, Training Acc: 79.35%\n",
      "              Val Loss: 1.4968185424804688, Val Acc: 68.53%\n",
      "Epoch: 8721,     Training Loss: 0.2808750569820404, Training Acc: 79.36%\n",
      "              Val Loss: 1.5730057954788208, Val Acc: 68.53%\n",
      "Epoch: 8722,     Training Loss: 0.23936641216278076, Training Acc: 79.36%\n",
      "              Val Loss: 1.4944168329238892, Val Acc: 68.53%\n",
      "Epoch: 8723,     Training Loss: 0.21508537232875824, Training Acc: 79.36%\n",
      "              Val Loss: 1.529943823814392, Val Acc: 68.53%\n",
      "Epoch: 8724,     Training Loss: 0.21372894942760468, Training Acc: 79.36%\n",
      "              Val Loss: 1.5378836393356323, Val Acc: 68.53%\n",
      "Epoch: 8725,     Training Loss: 0.2042420357465744, Training Acc: 79.36%\n",
      "              Val Loss: 1.4847462177276611, Val Acc: 68.53%\n",
      "Epoch: 8726,     Training Loss: 0.2111371010541916, Training Acc: 79.36%\n",
      "              Val Loss: 1.5308499336242676, Val Acc: 68.53%\n",
      "Epoch: 8727,     Training Loss: 0.21393857896327972, Training Acc: 79.36%\n",
      "              Val Loss: 1.516197919845581, Val Acc: 68.53%\n",
      "Epoch: 8728,     Training Loss: 0.21645110845565796, Training Acc: 79.36%\n",
      "              Val Loss: 1.5543307065963745, Val Acc: 68.53%\n",
      "Epoch: 8729,     Training Loss: 0.20767715573310852, Training Acc: 79.37%\n",
      "              Val Loss: 1.4868965148925781, Val Acc: 68.53%\n",
      "Epoch: 8730,     Training Loss: 0.1985192745923996, Training Acc: 79.37%\n",
      "              Val Loss: 1.518439531326294, Val Acc: 68.53%\n",
      "Epoch: 8731,     Training Loss: 0.2110482156276703, Training Acc: 79.37%\n",
      "              Val Loss: 1.5003803968429565, Val Acc: 68.53%\n",
      "Epoch: 8732,     Training Loss: 0.21204596757888794, Training Acc: 79.37%\n",
      "              Val Loss: 1.536421298980713, Val Acc: 68.53%\n",
      "Epoch: 8733,     Training Loss: 0.204899862408638, Training Acc: 79.37%\n",
      "              Val Loss: 1.5027967691421509, Val Acc: 68.53%\n",
      "Epoch: 8734,     Training Loss: 0.20428454875946045, Training Acc: 79.37%\n",
      "              Val Loss: 1.5353928804397583, Val Acc: 68.53%\n",
      "Epoch: 8735,     Training Loss: 0.20923492312431335, Training Acc: 79.37%\n",
      "              Val Loss: 1.4940364360809326, Val Acc: 68.53%\n",
      "Epoch: 8736,     Training Loss: 0.21755829453468323, Training Acc: 79.38%\n",
      "              Val Loss: 1.5586477518081665, Val Acc: 68.54%\n",
      "Epoch: 8737,     Training Loss: 0.20502449572086334, Training Acc: 79.38%\n",
      "              Val Loss: 1.5080302953720093, Val Acc: 68.54%\n",
      "Epoch: 8738,     Training Loss: 0.21058295667171478, Training Acc: 79.38%\n",
      "              Val Loss: 1.558498501777649, Val Acc: 68.54%\n",
      "Epoch: 8739,     Training Loss: 0.20429053902626038, Training Acc: 79.38%\n",
      "              Val Loss: 1.4965319633483887, Val Acc: 68.54%\n",
      "Epoch: 8740,     Training Loss: 0.20430141687393188, Training Acc: 79.38%\n",
      "              Val Loss: 1.525122880935669, Val Acc: 68.54%\n",
      "Epoch: 8741,     Training Loss: 0.19452528655529022, Training Acc: 79.38%\n",
      "              Val Loss: 1.5261383056640625, Val Acc: 68.54%\n",
      "Epoch: 8742,     Training Loss: 0.19763776659965515, Training Acc: 79.38%\n",
      "              Val Loss: 1.541896104812622, Val Acc: 68.54%\n",
      "Epoch: 8743,     Training Loss: 0.2036180943250656, Training Acc: 79.39%\n",
      "              Val Loss: 1.5335016250610352, Val Acc: 68.54%\n",
      "Epoch: 8744,     Training Loss: 0.19514738023281097, Training Acc: 79.39%\n",
      "              Val Loss: 1.5247917175292969, Val Acc: 68.54%\n",
      "Epoch: 8745,     Training Loss: 0.19231264293193817, Training Acc: 79.39%\n",
      "              Val Loss: 1.5286258459091187, Val Acc: 68.54%\n",
      "Epoch: 8746,     Training Loss: 0.19461753964424133, Training Acc: 79.39%\n",
      "              Val Loss: 1.5360264778137207, Val Acc: 68.54%\n",
      "Epoch: 8747,     Training Loss: 0.19681023061275482, Training Acc: 79.39%\n",
      "              Val Loss: 1.5075433254241943, Val Acc: 68.54%\n",
      "Epoch: 8748,     Training Loss: 0.19606494903564453, Training Acc: 79.39%\n",
      "              Val Loss: 1.532727837562561, Val Acc: 68.54%\n",
      "Epoch: 8749,     Training Loss: 0.19740372896194458, Training Acc: 79.40%\n",
      "              Val Loss: 1.489280343055725, Val Acc: 68.54%\n",
      "Epoch: 8750,     Training Loss: 0.21169215440750122, Training Acc: 79.40%\n",
      "              Val Loss: 1.583357810974121, Val Acc: 68.54%\n",
      "Epoch: 8751,     Training Loss: 0.2234824001789093, Training Acc: 79.40%\n",
      "              Val Loss: 1.5152162313461304, Val Acc: 68.54%\n",
      "Epoch: 8752,     Training Loss: 0.26858726143836975, Training Acc: 79.40%\n",
      "              Val Loss: 1.6197004318237305, Val Acc: 68.54%\n",
      "Epoch: 8753,     Training Loss: 0.2353583723306656, Training Acc: 79.40%\n",
      "              Val Loss: 1.5169388055801392, Val Acc: 68.54%\n",
      "Epoch: 8754,     Training Loss: 0.25953713059425354, Training Acc: 79.40%\n",
      "              Val Loss: 1.591984748840332, Val Acc: 68.54%\n",
      "Epoch: 8755,     Training Loss: 0.22542411088943481, Training Acc: 79.40%\n",
      "              Val Loss: 1.4917045831680298, Val Acc: 68.54%\n",
      "Epoch: 8756,     Training Loss: 0.21588623523712158, Training Acc: 79.40%\n",
      "              Val Loss: 1.5393729209899902, Val Acc: 68.54%\n",
      "Epoch: 8757,     Training Loss: 0.20042213797569275, Training Acc: 79.41%\n",
      "              Val Loss: 1.5099852085113525, Val Acc: 68.54%\n",
      "Epoch: 8758,     Training Loss: 0.2052835077047348, Training Acc: 79.41%\n",
      "              Val Loss: 1.5140042304992676, Val Acc: 68.54%\n",
      "Epoch: 8759,     Training Loss: 0.20268747210502625, Training Acc: 79.41%\n",
      "              Val Loss: 1.5293792486190796, Val Acc: 68.54%\n",
      "Epoch: 8760,     Training Loss: 0.1950683742761612, Training Acc: 79.41%\n",
      "              Val Loss: 1.5324729681015015, Val Acc: 68.54%\n",
      "Epoch: 8761,     Training Loss: 0.19892358779907227, Training Acc: 79.41%\n",
      "              Val Loss: 1.532420039176941, Val Acc: 68.54%\n",
      "Epoch: 8762,     Training Loss: 0.20061542093753815, Training Acc: 79.41%\n",
      "              Val Loss: 1.5538010597229004, Val Acc: 68.54%\n",
      "Epoch: 8763,     Training Loss: 0.19668972492218018, Training Acc: 79.41%\n",
      "              Val Loss: 1.5047036409378052, Val Acc: 68.54%\n",
      "Epoch: 8764,     Training Loss: 0.2007742077112198, Training Acc: 79.42%\n",
      "              Val Loss: 1.5612072944641113, Val Acc: 68.54%\n",
      "Epoch: 8765,     Training Loss: 0.20284956693649292, Training Acc: 79.42%\n",
      "              Val Loss: 1.502770185470581, Val Acc: 68.54%\n",
      "Epoch: 8766,     Training Loss: 0.21578797698020935, Training Acc: 79.42%\n",
      "              Val Loss: 1.5680155754089355, Val Acc: 68.54%\n",
      "Epoch: 8767,     Training Loss: 0.21373456716537476, Training Acc: 79.42%\n",
      "              Val Loss: 1.500373363494873, Val Acc: 68.54%\n",
      "Epoch: 8768,     Training Loss: 0.2258472889661789, Training Acc: 79.42%\n",
      "              Val Loss: 1.5787990093231201, Val Acc: 68.54%\n",
      "Epoch: 8769,     Training Loss: 0.21472465991973877, Training Acc: 79.42%\n",
      "              Val Loss: 1.5079665184020996, Val Acc: 68.54%\n",
      "Epoch: 8770,     Training Loss: 0.22326107323169708, Training Acc: 79.42%\n",
      "              Val Loss: 1.589253544807434, Val Acc: 68.54%\n",
      "Epoch: 8771,     Training Loss: 0.20951856672763824, Training Acc: 79.42%\n",
      "              Val Loss: 1.4997787475585938, Val Acc: 68.54%\n",
      "Epoch: 8772,     Training Loss: 0.20760077238082886, Training Acc: 79.43%\n",
      "              Val Loss: 1.5568928718566895, Val Acc: 68.55%\n",
      "Epoch: 8773,     Training Loss: 0.19935642182826996, Training Acc: 79.43%\n",
      "              Val Loss: 1.5302412509918213, Val Acc: 68.55%\n",
      "Epoch: 8774,     Training Loss: 0.20141281187534332, Training Acc: 79.43%\n",
      "              Val Loss: 1.5528045892715454, Val Acc: 68.55%\n",
      "Epoch: 8775,     Training Loss: 0.20223863422870636, Training Acc: 79.43%\n",
      "              Val Loss: 1.5421655178070068, Val Acc: 68.55%\n",
      "Epoch: 8776,     Training Loss: 0.2005460560321808, Training Acc: 79.43%\n",
      "              Val Loss: 1.5392757654190063, Val Acc: 68.55%\n",
      "Epoch: 8777,     Training Loss: 0.19980517029762268, Training Acc: 79.43%\n",
      "              Val Loss: 1.5134166479110718, Val Acc: 68.55%\n",
      "Epoch: 8778,     Training Loss: 0.200543612241745, Training Acc: 79.43%\n",
      "              Val Loss: 1.5905125141143799, Val Acc: 68.55%\n",
      "Epoch: 8779,     Training Loss: 0.21106959879398346, Training Acc: 79.44%\n",
      "              Val Loss: 1.5061780214309692, Val Acc: 68.55%\n",
      "Epoch: 8780,     Training Loss: 0.24235187470912933, Training Acc: 79.44%\n",
      "              Val Loss: 1.6339470148086548, Val Acc: 68.55%\n",
      "Epoch: 8781,     Training Loss: 0.2557980418205261, Training Acc: 79.44%\n",
      "              Val Loss: 1.5511689186096191, Val Acc: 68.55%\n",
      "Epoch: 8782,     Training Loss: 0.35829707980155945, Training Acc: 79.44%\n",
      "              Val Loss: 1.6889957189559937, Val Acc: 68.55%\n",
      "Epoch: 8783,     Training Loss: 0.28238093852996826, Training Acc: 79.44%\n",
      "              Val Loss: 1.4987047910690308, Val Acc: 68.55%\n",
      "Epoch: 8784,     Training Loss: 0.2592097818851471, Training Acc: 79.44%\n",
      "              Val Loss: 1.5007615089416504, Val Acc: 68.55%\n",
      "Epoch: 8785,     Training Loss: 0.21161380410194397, Training Acc: 79.44%\n",
      "              Val Loss: 1.5941015481948853, Val Acc: 68.55%\n",
      "Epoch: 8786,     Training Loss: 0.24248218536376953, Training Acc: 79.44%\n",
      "              Val Loss: 1.6016929149627686, Val Acc: 68.55%\n",
      "Epoch: 8787,     Training Loss: 0.36154815554618835, Training Acc: 79.44%\n",
      "              Val Loss: 1.6365814208984375, Val Acc: 68.55%\n",
      "Epoch: 8788,     Training Loss: 0.24783878028392792, Training Acc: 79.45%\n",
      "              Val Loss: 1.5397578477859497, Val Acc: 68.55%\n",
      "Epoch: 8789,     Training Loss: 0.20380209386348724, Training Acc: 79.45%\n",
      "              Val Loss: 1.5235037803649902, Val Acc: 68.55%\n",
      "Epoch: 8790,     Training Loss: 0.25277650356292725, Training Acc: 79.45%\n",
      "              Val Loss: 1.577845811843872, Val Acc: 68.55%\n",
      "Epoch: 8791,     Training Loss: 0.2197141796350479, Training Acc: 79.45%\n",
      "              Val Loss: 1.5433546304702759, Val Acc: 68.55%\n",
      "Epoch: 8792,     Training Loss: 0.2168498933315277, Training Acc: 79.45%\n",
      "              Val Loss: 1.602293848991394, Val Acc: 68.55%\n",
      "Epoch: 8793,     Training Loss: 0.230219304561615, Training Acc: 79.45%\n",
      "              Val Loss: 1.54219651222229, Val Acc: 68.55%\n",
      "Epoch: 8794,     Training Loss: 0.22501176595687866, Training Acc: 79.45%\n",
      "              Val Loss: 1.5217138528823853, Val Acc: 68.55%\n",
      "Epoch: 8795,     Training Loss: 0.23658984899520874, Training Acc: 79.45%\n",
      "              Val Loss: 1.581593632698059, Val Acc: 68.55%\n",
      "Epoch: 8796,     Training Loss: 0.22787129878997803, Training Acc: 79.46%\n",
      "              Val Loss: 1.5417413711547852, Val Acc: 68.55%\n",
      "Epoch: 8797,     Training Loss: 0.24452833831310272, Training Acc: 79.46%\n",
      "              Val Loss: 1.6409717798233032, Val Acc: 68.55%\n",
      "Epoch: 8798,     Training Loss: 0.23255722224712372, Training Acc: 79.46%\n",
      "              Val Loss: 1.5410914421081543, Val Acc: 68.55%\n",
      "Epoch: 8799,     Training Loss: 0.23572313785552979, Training Acc: 79.46%\n",
      "              Val Loss: 1.5970029830932617, Val Acc: 68.55%\n",
      "Epoch: 8800,     Training Loss: 0.26272067427635193, Training Acc: 79.46%\n",
      "              Val Loss: 1.509802222251892, Val Acc: 68.55%\n",
      "Epoch: 8801,     Training Loss: 0.28359898924827576, Training Acc: 79.46%\n",
      "              Val Loss: 1.7002567052841187, Val Acc: 68.55%\n",
      "Epoch: 8802,     Training Loss: 0.28803086280822754, Training Acc: 79.46%\n",
      "              Val Loss: 1.5624022483825684, Val Acc: 68.55%\n",
      "Epoch: 8803,     Training Loss: 0.38185545802116394, Training Acc: 79.46%\n",
      "              Val Loss: 1.571221113204956, Val Acc: 68.55%\n",
      "Epoch: 8804,     Training Loss: 0.23800387978553772, Training Acc: 79.46%\n",
      "              Val Loss: 1.7173727750778198, Val Acc: 68.55%\n",
      "Epoch: 8805,     Training Loss: 0.3152703046798706, Training Acc: 79.46%\n",
      "              Val Loss: 1.6000239849090576, Val Acc: 68.55%\n",
      "Epoch: 8806,     Training Loss: 0.45889055728912354, Training Acc: 79.46%\n",
      "              Val Loss: 1.682968258857727, Val Acc: 68.55%\n",
      "Epoch: 8807,     Training Loss: 0.4554992914199829, Training Acc: 79.46%\n",
      "              Val Loss: 1.5754485130310059, Val Acc: 68.55%\n",
      "Epoch: 8808,     Training Loss: 0.4357723593711853, Training Acc: 79.47%\n",
      "              Val Loss: 1.891300916671753, Val Acc: 68.55%\n",
      "Epoch: 8809,     Training Loss: 0.5189996957778931, Training Acc: 79.47%\n",
      "              Val Loss: 1.4924838542938232, Val Acc: 68.55%\n",
      "Epoch: 8810,     Training Loss: 0.3296774625778198, Training Acc: 79.47%\n",
      "              Val Loss: 1.6618157625198364, Val Acc: 68.55%\n",
      "Epoch: 8811,     Training Loss: 0.5109084844589233, Training Acc: 79.47%\n",
      "              Val Loss: 1.550338864326477, Val Acc: 68.55%\n",
      "Epoch: 8812,     Training Loss: 0.38101592659950256, Training Acc: 79.47%\n",
      "              Val Loss: 1.5822632312774658, Val Acc: 68.55%\n",
      "Epoch: 8813,     Training Loss: 0.42856940627098083, Training Acc: 79.47%\n",
      "              Val Loss: 1.6265989542007446, Val Acc: 68.55%\n",
      "Epoch: 8814,     Training Loss: 0.40107449889183044, Training Acc: 79.47%\n",
      "              Val Loss: 1.5741257667541504, Val Acc: 68.55%\n",
      "Epoch: 8815,     Training Loss: 0.46247485280036926, Training Acc: 79.47%\n",
      "              Val Loss: 1.5926101207733154, Val Acc: 68.55%\n",
      "Epoch: 8816,     Training Loss: 0.3916242718696594, Training Acc: 79.47%\n",
      "              Val Loss: 1.8934898376464844, Val Acc: 68.55%\n",
      "Epoch: 8817,     Training Loss: 0.43548253178596497, Training Acc: 79.47%\n",
      "              Val Loss: 1.8636764287948608, Val Acc: 68.55%\n",
      "Epoch: 8818,     Training Loss: 0.5496687889099121, Training Acc: 79.47%\n",
      "              Val Loss: 1.5601881742477417, Val Acc: 68.55%\n",
      "Epoch: 8819,     Training Loss: 0.3172363340854645, Training Acc: 79.47%\n",
      "              Val Loss: 1.7153488397598267, Val Acc: 68.55%\n",
      "Epoch: 8820,     Training Loss: 0.5148102045059204, Training Acc: 79.47%\n",
      "              Val Loss: 1.5612640380859375, Val Acc: 68.55%\n",
      "Epoch: 8821,     Training Loss: 0.4986792802810669, Training Acc: 79.47%\n",
      "              Val Loss: 1.6340194940567017, Val Acc: 68.55%\n",
      "Epoch: 8822,     Training Loss: 0.3903067111968994, Training Acc: 79.47%\n",
      "              Val Loss: 1.8044642210006714, Val Acc: 68.55%\n",
      "Epoch: 8823,     Training Loss: 0.5243246555328369, Training Acc: 79.47%\n",
      "              Val Loss: 1.5287131071090698, Val Acc: 68.55%\n",
      "Epoch: 8824,     Training Loss: 0.5644031167030334, Training Acc: 79.47%\n",
      "              Val Loss: 1.5343329906463623, Val Acc: 68.55%\n",
      "Epoch: 8825,     Training Loss: 0.5301183462142944, Training Acc: 79.47%\n",
      "              Val Loss: 1.4312576055526733, Val Acc: 68.55%\n",
      "Epoch: 8826,     Training Loss: 0.4033217132091522, Training Acc: 79.47%\n",
      "              Val Loss: 1.5566471815109253, Val Acc: 68.55%\n",
      "Epoch: 8827,     Training Loss: 0.4244117736816406, Training Acc: 79.47%\n",
      "              Val Loss: 1.7717252969741821, Val Acc: 68.55%\n",
      "Epoch: 8828,     Training Loss: 0.48051926493644714, Training Acc: 79.47%\n",
      "              Val Loss: 1.5580954551696777, Val Acc: 68.55%\n",
      "Epoch: 8829,     Training Loss: 0.4127616584300995, Training Acc: 79.47%\n",
      "              Val Loss: 1.4704763889312744, Val Acc: 68.55%\n",
      "Epoch: 8830,     Training Loss: 0.34588873386383057, Training Acc: 79.47%\n",
      "              Val Loss: 1.5276706218719482, Val Acc: 68.55%\n",
      "Epoch: 8831,     Training Loss: 0.37535327672958374, Training Acc: 79.47%\n",
      "              Val Loss: 1.3802709579467773, Val Acc: 68.55%\n",
      "Epoch: 8832,     Training Loss: 0.42847129702568054, Training Acc: 79.47%\n",
      "              Val Loss: 1.3989930152893066, Val Acc: 68.55%\n",
      "Epoch: 8833,     Training Loss: 0.3225986957550049, Training Acc: 79.47%\n",
      "              Val Loss: 1.7004753351211548, Val Acc: 68.55%\n",
      "Epoch: 8834,     Training Loss: 0.4352213144302368, Training Acc: 79.47%\n",
      "              Val Loss: 1.7602615356445312, Val Acc: 68.55%\n",
      "Epoch: 8835,     Training Loss: 0.6715366244316101, Training Acc: 79.47%\n",
      "              Val Loss: 1.6895190477371216, Val Acc: 68.55%\n",
      "Epoch: 8836,     Training Loss: 0.4419378638267517, Training Acc: 79.47%\n",
      "              Val Loss: 2.312939405441284, Val Acc: 68.55%\n",
      "Epoch: 8837,     Training Loss: 0.7815220355987549, Training Acc: 79.47%\n",
      "              Val Loss: 2.434570074081421, Val Acc: 68.55%\n",
      "Epoch: 8838,     Training Loss: 1.4911646842956543, Training Acc: 79.47%\n",
      "              Val Loss: 1.6544057130813599, Val Acc: 68.55%\n",
      "Epoch: 8839,     Training Loss: 0.6478279232978821, Training Acc: 79.47%\n",
      "              Val Loss: 2.8826987743377686, Val Acc: 68.55%\n",
      "Epoch: 8840,     Training Loss: 1.5890344381332397, Training Acc: 79.47%\n",
      "              Val Loss: 2.108196258544922, Val Acc: 68.54%\n",
      "Epoch: 8841,     Training Loss: 1.2290370464324951, Training Acc: 79.47%\n",
      "              Val Loss: 2.4619109630584717, Val Acc: 68.54%\n",
      "Epoch: 8842,     Training Loss: 1.6610838174819946, Training Acc: 79.46%\n",
      "              Val Loss: 1.665887713432312, Val Acc: 68.54%\n",
      "Epoch: 8843,     Training Loss: 0.7886946797370911, Training Acc: 79.46%\n",
      "              Val Loss: 2.4549286365509033, Val Acc: 68.54%\n",
      "Epoch: 8844,     Training Loss: 1.4523509740829468, Training Acc: 79.46%\n",
      "              Val Loss: 1.7802939414978027, Val Acc: 68.54%\n",
      "Epoch: 8845,     Training Loss: 0.9934382438659668, Training Acc: 79.46%\n",
      "              Val Loss: 1.4393583536148071, Val Acc: 68.54%\n",
      "Epoch: 8846,     Training Loss: 0.8485568165779114, Training Acc: 79.46%\n",
      "              Val Loss: 1.5845692157745361, Val Acc: 68.54%\n",
      "Epoch: 8847,     Training Loss: 1.0364373922348022, Training Acc: 79.46%\n",
      "              Val Loss: 1.5786199569702148, Val Acc: 68.54%\n",
      "Epoch: 8848,     Training Loss: 0.939608097076416, Training Acc: 79.46%\n",
      "              Val Loss: 1.3275266885757446, Val Acc: 68.54%\n",
      "Epoch: 8849,     Training Loss: 0.7166144847869873, Training Acc: 79.45%\n",
      "              Val Loss: 1.418867826461792, Val Acc: 68.54%\n",
      "Epoch: 8850,     Training Loss: 0.762759268283844, Training Acc: 79.45%\n",
      "              Val Loss: 1.484352469444275, Val Acc: 68.54%\n",
      "Epoch: 8851,     Training Loss: 0.8081596493721008, Training Acc: 79.45%\n",
      "              Val Loss: 1.4723505973815918, Val Acc: 68.54%\n",
      "Epoch: 8852,     Training Loss: 0.7777352929115295, Training Acc: 79.45%\n",
      "              Val Loss: 1.4168132543563843, Val Acc: 68.54%\n",
      "Epoch: 8853,     Training Loss: 0.6801660060882568, Training Acc: 79.45%\n",
      "              Val Loss: 1.4393762350082397, Val Acc: 68.53%\n",
      "Epoch: 8854,     Training Loss: 0.6408647298812866, Training Acc: 79.45%\n",
      "              Val Loss: 1.4404715299606323, Val Acc: 68.53%\n",
      "Epoch: 8855,     Training Loss: 0.6276417374610901, Training Acc: 79.45%\n",
      "              Val Loss: 1.3846620321273804, Val Acc: 68.53%\n",
      "Epoch: 8856,     Training Loss: 0.5701913237571716, Training Acc: 79.45%\n",
      "              Val Loss: 1.31251859664917, Val Acc: 68.53%\n",
      "Epoch: 8857,     Training Loss: 0.5597447752952576, Training Acc: 79.45%\n",
      "              Val Loss: 1.3253517150878906, Val Acc: 68.53%\n",
      "Epoch: 8858,     Training Loss: 0.5624164342880249, Training Acc: 79.45%\n",
      "              Val Loss: 1.275221347808838, Val Acc: 68.53%\n",
      "Epoch: 8859,     Training Loss: 0.5262364149093628, Training Acc: 79.45%\n",
      "              Val Loss: 1.2385013103485107, Val Acc: 68.53%\n",
      "Epoch: 8860,     Training Loss: 0.5053607225418091, Training Acc: 79.45%\n",
      "              Val Loss: 1.2236610651016235, Val Acc: 68.53%\n",
      "Epoch: 8861,     Training Loss: 0.4970250427722931, Training Acc: 79.45%\n",
      "              Val Loss: 1.183546543121338, Val Acc: 68.53%\n",
      "Epoch: 8862,     Training Loss: 0.4641577899456024, Training Acc: 79.45%\n",
      "              Val Loss: 1.1510621309280396, Val Acc: 68.53%\n",
      "Epoch: 8863,     Training Loss: 0.4603794813156128, Training Acc: 79.45%\n",
      "              Val Loss: 1.0738768577575684, Val Acc: 68.53%\n",
      "Epoch: 8864,     Training Loss: 0.43424805998802185, Training Acc: 79.45%\n",
      "              Val Loss: 1.0498818159103394, Val Acc: 68.53%\n",
      "Epoch: 8865,     Training Loss: 0.44200921058654785, Training Acc: 79.45%\n",
      "              Val Loss: 1.0230830907821655, Val Acc: 68.53%\n",
      "Epoch: 8866,     Training Loss: 0.41664913296699524, Training Acc: 79.45%\n",
      "              Val Loss: 1.0556161403656006, Val Acc: 68.53%\n",
      "Epoch: 8867,     Training Loss: 0.4165918827056885, Training Acc: 79.45%\n",
      "              Val Loss: 1.0537296533584595, Val Acc: 68.53%\n",
      "Epoch: 8868,     Training Loss: 0.38938939571380615, Training Acc: 79.45%\n",
      "              Val Loss: 1.0779958963394165, Val Acc: 68.53%\n",
      "Epoch: 8869,     Training Loss: 0.39354538917541504, Training Acc: 79.45%\n",
      "              Val Loss: 1.1057542562484741, Val Acc: 68.53%\n",
      "Epoch: 8870,     Training Loss: 0.3870126008987427, Training Acc: 79.45%\n",
      "              Val Loss: 1.1323984861373901, Val Acc: 68.53%\n",
      "Epoch: 8871,     Training Loss: 0.37590935826301575, Training Acc: 79.45%\n",
      "              Val Loss: 1.1373169422149658, Val Acc: 68.53%\n",
      "Epoch: 8872,     Training Loss: 0.362152099609375, Training Acc: 79.45%\n",
      "              Val Loss: 1.1405671834945679, Val Acc: 68.53%\n",
      "Epoch: 8873,     Training Loss: 0.35750073194503784, Training Acc: 79.45%\n",
      "              Val Loss: 1.1599186658859253, Val Acc: 68.54%\n",
      "Epoch: 8874,     Training Loss: 0.35110488533973694, Training Acc: 79.45%\n",
      "              Val Loss: 1.1878938674926758, Val Acc: 68.54%\n",
      "Epoch: 8875,     Training Loss: 0.3465896546840668, Training Acc: 79.45%\n",
      "              Val Loss: 1.1967355012893677, Val Acc: 68.54%\n",
      "Epoch: 8876,     Training Loss: 0.3377537429332733, Training Acc: 79.46%\n",
      "              Val Loss: 1.1991848945617676, Val Acc: 68.54%\n",
      "Epoch: 8877,     Training Loss: 0.3366146981716156, Training Acc: 79.46%\n",
      "              Val Loss: 1.2024894952774048, Val Acc: 68.54%\n",
      "Epoch: 8878,     Training Loss: 0.3288366198539734, Training Acc: 79.46%\n",
      "              Val Loss: 1.2064937353134155, Val Acc: 68.54%\n",
      "Epoch: 8879,     Training Loss: 0.3238409459590912, Training Acc: 79.46%\n",
      "              Val Loss: 1.1936084032058716, Val Acc: 68.54%\n",
      "Epoch: 8880,     Training Loss: 0.31341275572776794, Training Acc: 79.46%\n",
      "              Val Loss: 1.1911723613739014, Val Acc: 68.54%\n",
      "Epoch: 8881,     Training Loss: 0.3117657005786896, Training Acc: 79.46%\n",
      "              Val Loss: 1.2069836854934692, Val Acc: 68.54%\n",
      "Epoch: 8882,     Training Loss: 0.3126124143600464, Training Acc: 79.46%\n",
      "              Val Loss: 1.1993499994277954, Val Acc: 68.54%\n",
      "Epoch: 8883,     Training Loss: 0.3059801161289215, Training Acc: 79.46%\n",
      "              Val Loss: 1.2077689170837402, Val Acc: 68.54%\n",
      "Epoch: 8884,     Training Loss: 0.30350804328918457, Training Acc: 79.46%\n",
      "              Val Loss: 1.222028374671936, Val Acc: 68.54%\n",
      "Epoch: 8885,     Training Loss: 0.3000161647796631, Training Acc: 79.46%\n",
      "              Val Loss: 1.2212563753128052, Val Acc: 68.54%\n",
      "Epoch: 8886,     Training Loss: 0.29727432131767273, Training Acc: 79.46%\n",
      "              Val Loss: 1.2111268043518066, Val Acc: 68.54%\n",
      "Epoch: 8887,     Training Loss: 0.2938896715641022, Training Acc: 79.47%\n",
      "              Val Loss: 1.2050673961639404, Val Acc: 68.54%\n",
      "Epoch: 8888,     Training Loss: 0.28948596119880676, Training Acc: 79.47%\n",
      "              Val Loss: 1.2016575336456299, Val Acc: 68.54%\n",
      "Epoch: 8889,     Training Loss: 0.2865936756134033, Training Acc: 79.47%\n",
      "              Val Loss: 1.201364517211914, Val Acc: 68.54%\n",
      "Epoch: 8890,     Training Loss: 0.2861801087856293, Training Acc: 79.47%\n",
      "              Val Loss: 1.2036662101745605, Val Acc: 68.54%\n",
      "Epoch: 8891,     Training Loss: 0.2824961543083191, Training Acc: 79.47%\n",
      "              Val Loss: 1.2078315019607544, Val Acc: 68.54%\n",
      "Epoch: 8892,     Training Loss: 0.2796732187271118, Training Acc: 79.47%\n",
      "              Val Loss: 1.2086142301559448, Val Acc: 68.54%\n",
      "Epoch: 8893,     Training Loss: 0.27672240138053894, Training Acc: 79.47%\n",
      "              Val Loss: 1.2075473070144653, Val Acc: 68.54%\n",
      "Epoch: 8894,     Training Loss: 0.2746359705924988, Training Acc: 79.47%\n",
      "              Val Loss: 1.2056567668914795, Val Acc: 68.54%\n",
      "Epoch: 8895,     Training Loss: 0.2732187807559967, Training Acc: 79.47%\n",
      "              Val Loss: 1.20628023147583, Val Acc: 68.54%\n",
      "Epoch: 8896,     Training Loss: 0.27141043543815613, Training Acc: 79.48%\n",
      "              Val Loss: 1.2152855396270752, Val Acc: 68.54%\n",
      "Epoch: 8897,     Training Loss: 0.2691621482372284, Training Acc: 79.48%\n",
      "              Val Loss: 1.2304880619049072, Val Acc: 68.54%\n",
      "Epoch: 8898,     Training Loss: 0.2678314447402954, Training Acc: 79.48%\n",
      "              Val Loss: 1.2398113012313843, Val Acc: 68.54%\n",
      "Epoch: 8899,     Training Loss: 0.2655511796474457, Training Acc: 79.48%\n",
      "              Val Loss: 1.2483115196228027, Val Acc: 68.54%\n",
      "Epoch: 8900,     Training Loss: 0.263846218585968, Training Acc: 79.48%\n",
      "              Val Loss: 1.2565257549285889, Val Acc: 68.54%\n",
      "Epoch: 8901,     Training Loss: 0.26282235980033875, Training Acc: 79.48%\n",
      "              Val Loss: 1.2584738731384277, Val Acc: 68.54%\n",
      "Epoch: 8902,     Training Loss: 0.2613137662410736, Training Acc: 79.48%\n",
      "              Val Loss: 1.2636362314224243, Val Acc: 68.54%\n",
      "Epoch: 8903,     Training Loss: 0.2598370313644409, Training Acc: 79.48%\n",
      "              Val Loss: 1.2703739404678345, Val Acc: 68.55%\n",
      "Epoch: 8904,     Training Loss: 0.25891757011413574, Training Acc: 79.48%\n",
      "              Val Loss: 1.2690104246139526, Val Acc: 68.55%\n",
      "Epoch: 8905,     Training Loss: 0.25766947865486145, Training Acc: 79.49%\n",
      "              Val Loss: 1.2726713418960571, Val Acc: 68.55%\n",
      "Epoch: 8906,     Training Loss: 0.25630950927734375, Training Acc: 79.49%\n",
      "              Val Loss: 1.277451992034912, Val Acc: 68.55%\n",
      "Epoch: 8907,     Training Loss: 0.2553621232509613, Training Acc: 79.49%\n",
      "              Val Loss: 1.2742563486099243, Val Acc: 68.55%\n",
      "Epoch: 8908,     Training Loss: 0.25428465008735657, Training Acc: 79.49%\n",
      "              Val Loss: 1.2806020975112915, Val Acc: 68.55%\n",
      "Epoch: 8909,     Training Loss: 0.25240689516067505, Training Acc: 79.49%\n",
      "              Val Loss: 1.2818214893341064, Val Acc: 68.55%\n",
      "Epoch: 8910,     Training Loss: 0.2512187659740448, Training Acc: 79.49%\n",
      "              Val Loss: 1.2766700983047485, Val Acc: 68.55%\n",
      "Epoch: 8911,     Training Loss: 0.2504376471042633, Training Acc: 79.49%\n",
      "              Val Loss: 1.2789448499679565, Val Acc: 68.55%\n",
      "Epoch: 8912,     Training Loss: 0.24904517829418182, Training Acc: 79.49%\n",
      "              Val Loss: 1.2751225233078003, Val Acc: 68.55%\n",
      "Epoch: 8913,     Training Loss: 0.2477830946445465, Training Acc: 79.49%\n",
      "              Val Loss: 1.2692004442214966, Val Acc: 68.55%\n",
      "Epoch: 8914,     Training Loss: 0.2469964176416397, Training Acc: 79.50%\n",
      "              Val Loss: 1.2743830680847168, Val Acc: 68.55%\n",
      "Epoch: 8915,     Training Loss: 0.24609367549419403, Training Acc: 79.50%\n",
      "              Val Loss: 1.2760860919952393, Val Acc: 68.55%\n",
      "Epoch: 8916,     Training Loss: 0.24466079473495483, Training Acc: 79.50%\n",
      "              Val Loss: 1.2798690795898438, Val Acc: 68.55%\n",
      "Epoch: 8917,     Training Loss: 0.2438524216413498, Training Acc: 79.50%\n",
      "              Val Loss: 1.286515474319458, Val Acc: 68.55%\n",
      "Epoch: 8918,     Training Loss: 0.24321609735488892, Training Acc: 79.50%\n",
      "              Val Loss: 1.2887632846832275, Val Acc: 68.55%\n",
      "Epoch: 8919,     Training Loss: 0.24207857251167297, Training Acc: 79.50%\n",
      "              Val Loss: 1.2960636615753174, Val Acc: 68.55%\n",
      "Epoch: 8920,     Training Loss: 0.24093374609947205, Training Acc: 79.50%\n",
      "              Val Loss: 1.300438404083252, Val Acc: 68.55%\n",
      "Epoch: 8921,     Training Loss: 0.24012410640716553, Training Acc: 79.50%\n",
      "              Val Loss: 1.299845576286316, Val Acc: 68.55%\n",
      "Epoch: 8922,     Training Loss: 0.2395126223564148, Training Acc: 79.51%\n",
      "              Val Loss: 1.3123409748077393, Val Acc: 68.55%\n",
      "Epoch: 8923,     Training Loss: 0.2384311854839325, Training Acc: 79.51%\n",
      "              Val Loss: 1.3104859590530396, Val Acc: 68.55%\n",
      "Epoch: 8924,     Training Loss: 0.23715099692344666, Training Acc: 79.51%\n",
      "              Val Loss: 1.310182809829712, Val Acc: 68.55%\n",
      "Epoch: 8925,     Training Loss: 0.2360648363828659, Training Acc: 79.51%\n",
      "              Val Loss: 1.3151295185089111, Val Acc: 68.55%\n",
      "Epoch: 8926,     Training Loss: 0.2351922243833542, Training Acc: 79.51%\n",
      "              Val Loss: 1.3178225755691528, Val Acc: 68.55%\n",
      "Epoch: 8927,     Training Loss: 0.23442167043685913, Training Acc: 79.51%\n",
      "              Val Loss: 1.3230714797973633, Val Acc: 68.55%\n",
      "Epoch: 8928,     Training Loss: 0.23319442570209503, Training Acc: 79.51%\n",
      "              Val Loss: 1.3189834356307983, Val Acc: 68.55%\n",
      "Epoch: 8929,     Training Loss: 0.23199939727783203, Training Acc: 79.51%\n",
      "              Val Loss: 1.3261058330535889, Val Acc: 68.55%\n",
      "Epoch: 8930,     Training Loss: 0.23068122565746307, Training Acc: 79.52%\n",
      "              Val Loss: 1.3313099145889282, Val Acc: 68.55%\n",
      "Epoch: 8931,     Training Loss: 0.2296462059020996, Training Acc: 79.52%\n",
      "              Val Loss: 1.3308907747268677, Val Acc: 68.55%\n",
      "Epoch: 8932,     Training Loss: 0.2283676117658615, Training Acc: 79.52%\n",
      "              Val Loss: 1.3368339538574219, Val Acc: 68.55%\n",
      "Epoch: 8933,     Training Loss: 0.2273927927017212, Training Acc: 79.52%\n",
      "              Val Loss: 1.3379528522491455, Val Acc: 68.55%\n",
      "Epoch: 8934,     Training Loss: 0.22644324600696564, Training Acc: 79.52%\n",
      "              Val Loss: 1.3503968715667725, Val Acc: 68.56%\n",
      "Epoch: 8935,     Training Loss: 0.22546936571598053, Training Acc: 79.52%\n",
      "              Val Loss: 1.3437092304229736, Val Acc: 68.56%\n",
      "Epoch: 8936,     Training Loss: 0.2243674099445343, Training Acc: 79.52%\n",
      "              Val Loss: 1.3534258604049683, Val Acc: 68.56%\n",
      "Epoch: 8937,     Training Loss: 0.22313889861106873, Training Acc: 79.53%\n",
      "              Val Loss: 1.3581100702285767, Val Acc: 68.56%\n",
      "Epoch: 8938,     Training Loss: 0.2222428172826767, Training Acc: 79.53%\n",
      "              Val Loss: 1.3553030490875244, Val Acc: 68.56%\n",
      "Epoch: 8939,     Training Loss: 0.22147130966186523, Training Acc: 79.53%\n",
      "              Val Loss: 1.3624519109725952, Val Acc: 68.56%\n",
      "Epoch: 8940,     Training Loss: 0.22081810235977173, Training Acc: 79.53%\n",
      "              Val Loss: 1.3574751615524292, Val Acc: 68.56%\n",
      "Epoch: 8941,     Training Loss: 0.22016654908657074, Training Acc: 79.53%\n",
      "              Val Loss: 1.3652927875518799, Val Acc: 68.56%\n",
      "Epoch: 8942,     Training Loss: 0.21909284591674805, Training Acc: 79.53%\n",
      "              Val Loss: 1.364631175994873, Val Acc: 68.56%\n",
      "Epoch: 8943,     Training Loss: 0.21820001304149628, Training Acc: 79.53%\n",
      "              Val Loss: 1.3680955171585083, Val Acc: 68.56%\n",
      "Epoch: 8944,     Training Loss: 0.21748653054237366, Training Acc: 79.54%\n",
      "              Val Loss: 1.376072645187378, Val Acc: 68.56%\n",
      "Epoch: 8945,     Training Loss: 0.2168482393026352, Training Acc: 79.54%\n",
      "              Val Loss: 1.3706295490264893, Val Acc: 68.56%\n",
      "Epoch: 8946,     Training Loss: 0.21647711098194122, Training Acc: 79.54%\n",
      "              Val Loss: 1.3798370361328125, Val Acc: 68.56%\n",
      "Epoch: 8947,     Training Loss: 0.2158898115158081, Training Acc: 79.54%\n",
      "              Val Loss: 1.3719455003738403, Val Acc: 68.56%\n",
      "Epoch: 8948,     Training Loss: 0.2153508961200714, Training Acc: 79.54%\n",
      "              Val Loss: 1.378485918045044, Val Acc: 68.56%\n",
      "Epoch: 8949,     Training Loss: 0.21457283198833466, Training Acc: 79.54%\n",
      "              Val Loss: 1.3753715753555298, Val Acc: 68.56%\n",
      "Epoch: 8950,     Training Loss: 0.21366383135318756, Training Acc: 79.54%\n",
      "              Val Loss: 1.3814467191696167, Val Acc: 68.56%\n",
      "Epoch: 8951,     Training Loss: 0.21315361559391022, Training Acc: 79.54%\n",
      "              Val Loss: 1.3757851123809814, Val Acc: 68.56%\n",
      "Epoch: 8952,     Training Loss: 0.21260137856006622, Training Acc: 79.55%\n",
      "              Val Loss: 1.378793478012085, Val Acc: 68.56%\n",
      "Epoch: 8953,     Training Loss: 0.21218806505203247, Training Acc: 79.55%\n",
      "              Val Loss: 1.3753405809402466, Val Acc: 68.56%\n",
      "Epoch: 8954,     Training Loss: 0.21191658079624176, Training Acc: 79.55%\n",
      "              Val Loss: 1.3819952011108398, Val Acc: 68.56%\n",
      "Epoch: 8955,     Training Loss: 0.211586132645607, Training Acc: 79.55%\n",
      "              Val Loss: 1.3725101947784424, Val Acc: 68.56%\n",
      "Epoch: 8956,     Training Loss: 0.21167099475860596, Training Acc: 79.55%\n",
      "              Val Loss: 1.3905450105667114, Val Acc: 68.56%\n",
      "Epoch: 8957,     Training Loss: 0.21240299940109253, Training Acc: 79.55%\n",
      "              Val Loss: 1.3694289922714233, Val Acc: 68.56%\n",
      "Epoch: 8958,     Training Loss: 0.21299006044864655, Training Acc: 79.55%\n",
      "              Val Loss: 1.388961672782898, Val Acc: 68.56%\n",
      "Epoch: 8959,     Training Loss: 0.21310842037200928, Training Acc: 79.56%\n",
      "              Val Loss: 1.367762565612793, Val Acc: 68.56%\n",
      "Epoch: 8960,     Training Loss: 0.21325752139091492, Training Acc: 79.56%\n",
      "              Val Loss: 1.3905541896820068, Val Acc: 68.56%\n",
      "Epoch: 8961,     Training Loss: 0.2128256857395172, Training Acc: 79.56%\n",
      "              Val Loss: 1.3666523694992065, Val Acc: 68.56%\n",
      "Epoch: 8962,     Training Loss: 0.21189653873443604, Training Acc: 79.56%\n",
      "              Val Loss: 1.387538194656372, Val Acc: 68.56%\n",
      "Epoch: 8963,     Training Loss: 0.2103729099035263, Training Acc: 79.56%\n",
      "              Val Loss: 1.3710054159164429, Val Acc: 68.56%\n",
      "Epoch: 8964,     Training Loss: 0.20908832550048828, Training Acc: 79.56%\n",
      "              Val Loss: 1.3843127489089966, Val Acc: 68.56%\n",
      "Epoch: 8965,     Training Loss: 0.2082342952489853, Training Acc: 79.56%\n",
      "              Val Loss: 1.3744505643844604, Val Acc: 68.56%\n",
      "Epoch: 8966,     Training Loss: 0.20730769634246826, Training Acc: 79.57%\n",
      "              Val Loss: 1.3867559432983398, Val Acc: 68.56%\n",
      "Epoch: 8967,     Training Loss: 0.20691539347171783, Training Acc: 79.57%\n",
      "              Val Loss: 1.3719041347503662, Val Acc: 68.56%\n",
      "Epoch: 8968,     Training Loss: 0.20654384791851044, Training Acc: 79.57%\n",
      "              Val Loss: 1.3835493326187134, Val Acc: 68.56%\n",
      "Epoch: 8969,     Training Loss: 0.20630523562431335, Training Acc: 79.57%\n",
      "              Val Loss: 1.3677983283996582, Val Acc: 68.56%\n",
      "Epoch: 8970,     Training Loss: 0.20615221560001373, Training Acc: 79.57%\n",
      "              Val Loss: 1.381568193435669, Val Acc: 68.56%\n",
      "Epoch: 8971,     Training Loss: 0.20691600441932678, Training Acc: 79.57%\n",
      "              Val Loss: 1.3633265495300293, Val Acc: 68.56%\n",
      "Epoch: 8972,     Training Loss: 0.207938551902771, Training Acc: 79.57%\n",
      "              Val Loss: 1.3898556232452393, Val Acc: 68.56%\n",
      "Epoch: 8973,     Training Loss: 0.21002262830734253, Training Acc: 79.57%\n",
      "              Val Loss: 1.358119010925293, Val Acc: 68.56%\n",
      "Epoch: 8974,     Training Loss: 0.21218115091323853, Training Acc: 79.58%\n",
      "              Val Loss: 1.3941344022750854, Val Acc: 68.56%\n",
      "Epoch: 8975,     Training Loss: 0.21233788132667542, Training Acc: 79.58%\n",
      "              Val Loss: 1.3583018779754639, Val Acc: 68.56%\n",
      "Epoch: 8976,     Training Loss: 0.21205595135688782, Training Acc: 79.58%\n",
      "              Val Loss: 1.3859564065933228, Val Acc: 68.56%\n",
      "Epoch: 8977,     Training Loss: 0.20988625288009644, Training Acc: 79.58%\n",
      "              Val Loss: 1.3583731651306152, Val Acc: 68.56%\n",
      "Epoch: 8978,     Training Loss: 0.20589196681976318, Training Acc: 79.58%\n",
      "              Val Loss: 1.3703405857086182, Val Acc: 68.56%\n",
      "Epoch: 8979,     Training Loss: 0.20298725366592407, Training Acc: 79.58%\n",
      "              Val Loss: 1.377589464187622, Val Acc: 68.56%\n",
      "Epoch: 8980,     Training Loss: 0.20447660982608795, Training Acc: 79.58%\n",
      "              Val Loss: 1.3600784540176392, Val Acc: 68.56%\n",
      "Epoch: 8981,     Training Loss: 0.20957183837890625, Training Acc: 79.59%\n",
      "              Val Loss: 1.4018266201019287, Val Acc: 68.56%\n",
      "Epoch: 8982,     Training Loss: 0.2145104557275772, Training Acc: 79.59%\n",
      "              Val Loss: 1.3547786474227905, Val Acc: 68.56%\n",
      "Epoch: 8983,     Training Loss: 0.22019962966442108, Training Acc: 79.59%\n",
      "              Val Loss: 1.3937629461288452, Val Acc: 68.56%\n",
      "Epoch: 8984,     Training Loss: 0.21044103801250458, Training Acc: 79.59%\n",
      "              Val Loss: 1.3571661710739136, Val Acc: 68.56%\n",
      "Epoch: 8985,     Training Loss: 0.20428365468978882, Training Acc: 79.59%\n",
      "              Val Loss: 1.3650538921356201, Val Acc: 68.57%\n",
      "Epoch: 8986,     Training Loss: 0.20129747688770294, Training Acc: 79.59%\n",
      "              Val Loss: 1.3761711120605469, Val Acc: 68.57%\n",
      "Epoch: 8987,     Training Loss: 0.20195244252681732, Training Acc: 79.59%\n",
      "              Val Loss: 1.3619987964630127, Val Acc: 68.57%\n",
      "Epoch: 8988,     Training Loss: 0.20374122262001038, Training Acc: 79.60%\n",
      "              Val Loss: 1.391209363937378, Val Acc: 68.57%\n",
      "Epoch: 8989,     Training Loss: 0.20556703209877014, Training Acc: 79.60%\n",
      "              Val Loss: 1.3551712036132812, Val Acc: 68.57%\n",
      "Epoch: 8990,     Training Loss: 0.2096269279718399, Training Acc: 79.60%\n",
      "              Val Loss: 1.3871498107910156, Val Acc: 68.57%\n",
      "Epoch: 8991,     Training Loss: 0.20900671184062958, Training Acc: 79.60%\n",
      "              Val Loss: 1.3542633056640625, Val Acc: 68.57%\n",
      "Epoch: 8992,     Training Loss: 0.2096463143825531, Training Acc: 79.60%\n",
      "              Val Loss: 1.3909780979156494, Val Acc: 68.57%\n",
      "Epoch: 8993,     Training Loss: 0.20656274259090424, Training Acc: 79.60%\n",
      "              Val Loss: 1.3573417663574219, Val Acc: 68.57%\n",
      "Epoch: 8994,     Training Loss: 0.2048286646604538, Training Acc: 79.60%\n",
      "              Val Loss: 1.3814316987991333, Val Acc: 68.57%\n",
      "Epoch: 8995,     Training Loss: 0.20092611014842987, Training Acc: 79.60%\n",
      "              Val Loss: 1.3675410747528076, Val Acc: 68.57%\n",
      "Epoch: 8996,     Training Loss: 0.1990547776222229, Training Acc: 79.61%\n",
      "              Val Loss: 1.371063232421875, Val Acc: 68.57%\n",
      "Epoch: 8997,     Training Loss: 0.19808736443519592, Training Acc: 79.61%\n",
      "              Val Loss: 1.3832497596740723, Val Acc: 68.57%\n",
      "Epoch: 8998,     Training Loss: 0.19847826659679413, Training Acc: 79.61%\n",
      "              Val Loss: 1.3699030876159668, Val Acc: 68.57%\n",
      "Epoch: 8999,     Training Loss: 0.20017746090888977, Training Acc: 79.61%\n",
      "              Val Loss: 1.393823266029358, Val Acc: 68.57%\n",
      "Epoch: 9000,     Training Loss: 0.2025439441204071, Training Acc: 79.61%\n",
      "              Val Loss: 1.368198275566101, Val Acc: 68.57%\n",
      "Epoch: 9001,     Training Loss: 0.20898370444774628, Training Acc: 79.61%\n",
      "              Val Loss: 1.416630744934082, Val Acc: 68.57%\n",
      "Epoch: 9002,     Training Loss: 0.21400421857833862, Training Acc: 79.61%\n",
      "              Val Loss: 1.3658491373062134, Val Acc: 68.57%\n",
      "Epoch: 9003,     Training Loss: 0.23026682436466217, Training Acc: 79.62%\n",
      "              Val Loss: 1.423939824104309, Val Acc: 68.57%\n",
      "Epoch: 9004,     Training Loss: 0.2150169312953949, Training Acc: 79.62%\n",
      "              Val Loss: 1.3588393926620483, Val Acc: 68.57%\n",
      "Epoch: 9005,     Training Loss: 0.20710523426532745, Training Acc: 79.62%\n",
      "              Val Loss: 1.3805832862854004, Val Acc: 68.57%\n",
      "Epoch: 9006,     Training Loss: 0.19783537089824677, Training Acc: 79.62%\n",
      "              Val Loss: 1.3963253498077393, Val Acc: 68.57%\n",
      "Epoch: 9007,     Training Loss: 0.20082220435142517, Training Acc: 79.62%\n",
      "              Val Loss: 1.3600825071334839, Val Acc: 68.57%\n",
      "Epoch: 9008,     Training Loss: 0.21433968842029572, Training Acc: 79.62%\n",
      "              Val Loss: 1.4238287210464478, Val Acc: 68.57%\n",
      "Epoch: 9009,     Training Loss: 0.2136353999376297, Training Acc: 79.62%\n",
      "              Val Loss: 1.3691916465759277, Val Acc: 68.57%\n",
      "Epoch: 9010,     Training Loss: 0.2191316783428192, Training Acc: 79.63%\n",
      "              Val Loss: 1.4057191610336304, Val Acc: 68.57%\n",
      "Epoch: 9011,     Training Loss: 0.20466667413711548, Training Acc: 79.63%\n",
      "              Val Loss: 1.3754075765609741, Val Acc: 68.57%\n",
      "Epoch: 9012,     Training Loss: 0.19758372008800507, Training Acc: 79.63%\n",
      "              Val Loss: 1.387068271636963, Val Acc: 68.57%\n",
      "Epoch: 9013,     Training Loss: 0.19613441824913025, Training Acc: 79.63%\n",
      "              Val Loss: 1.4054865837097168, Val Acc: 68.57%\n",
      "Epoch: 9014,     Training Loss: 0.19866175949573517, Training Acc: 79.63%\n",
      "              Val Loss: 1.3780311346054077, Val Acc: 68.57%\n",
      "Epoch: 9015,     Training Loss: 0.206024631857872, Training Acc: 79.63%\n",
      "              Val Loss: 1.42551851272583, Val Acc: 68.57%\n",
      "Epoch: 9016,     Training Loss: 0.20545369386672974, Training Acc: 79.63%\n",
      "              Val Loss: 1.37461519241333, Val Acc: 68.57%\n",
      "Epoch: 9017,     Training Loss: 0.20883800089359283, Training Acc: 79.63%\n",
      "              Val Loss: 1.4147398471832275, Val Acc: 68.57%\n",
      "Epoch: 9018,     Training Loss: 0.20066328346729279, Training Acc: 79.64%\n",
      "              Val Loss: 1.378416895866394, Val Acc: 68.57%\n",
      "Epoch: 9019,     Training Loss: 0.1973586231470108, Training Acc: 79.64%\n",
      "              Val Loss: 1.3917787075042725, Val Acc: 68.57%\n",
      "Epoch: 9020,     Training Loss: 0.19414913654327393, Training Acc: 79.64%\n",
      "              Val Loss: 1.392244577407837, Val Acc: 68.57%\n",
      "Epoch: 9021,     Training Loss: 0.19402655959129333, Training Acc: 79.64%\n",
      "              Val Loss: 1.380719780921936, Val Acc: 68.57%\n",
      "Epoch: 9022,     Training Loss: 0.19502095878124237, Training Acc: 79.64%\n",
      "              Val Loss: 1.4009579420089722, Val Acc: 68.57%\n",
      "Epoch: 9023,     Training Loss: 0.19440847635269165, Training Acc: 79.64%\n",
      "              Val Loss: 1.386278510093689, Val Acc: 68.57%\n",
      "Epoch: 9024,     Training Loss: 0.19732262194156647, Training Acc: 79.64%\n",
      "              Val Loss: 1.410791277885437, Val Acc: 68.57%\n",
      "Epoch: 9025,     Training Loss: 0.19891543686389923, Training Acc: 79.65%\n",
      "              Val Loss: 1.3879917860031128, Val Acc: 68.57%\n",
      "Epoch: 9026,     Training Loss: 0.19942417740821838, Training Acc: 79.65%\n",
      "              Val Loss: 1.4276933670043945, Val Acc: 68.57%\n",
      "Epoch: 9027,     Training Loss: 0.20076362788677216, Training Acc: 79.65%\n",
      "              Val Loss: 1.3848779201507568, Val Acc: 68.57%\n",
      "Epoch: 9028,     Training Loss: 0.2103898674249649, Training Acc: 79.65%\n",
      "              Val Loss: 1.4485098123550415, Val Acc: 68.57%\n",
      "Epoch: 9029,     Training Loss: 0.2121373564004898, Training Acc: 79.65%\n",
      "              Val Loss: 1.3736222982406616, Val Acc: 68.57%\n",
      "Epoch: 9030,     Training Loss: 0.2284858375787735, Training Acc: 79.65%\n",
      "              Val Loss: 1.4442858695983887, Val Acc: 68.57%\n",
      "Epoch: 9031,     Training Loss: 0.21733544766902924, Training Acc: 79.65%\n",
      "              Val Loss: 1.3709368705749512, Val Acc: 68.57%\n",
      "Epoch: 9032,     Training Loss: 0.21680878102779388, Training Acc: 79.66%\n",
      "              Val Loss: 1.4042795896530151, Val Acc: 68.57%\n",
      "Epoch: 9033,     Training Loss: 0.1977349817752838, Training Acc: 79.66%\n",
      "              Val Loss: 1.403756856918335, Val Acc: 68.57%\n",
      "Epoch: 9034,     Training Loss: 0.19350683689117432, Training Acc: 79.66%\n",
      "              Val Loss: 1.3845769166946411, Val Acc: 68.57%\n",
      "Epoch: 9035,     Training Loss: 0.20122234523296356, Training Acc: 79.66%\n",
      "              Val Loss: 1.4404107332229614, Val Acc: 68.58%\n",
      "Epoch: 9036,     Training Loss: 0.2076844424009323, Training Acc: 79.66%\n",
      "              Val Loss: 1.3971774578094482, Val Acc: 68.58%\n",
      "Epoch: 9037,     Training Loss: 0.2208385318517685, Training Acc: 79.66%\n",
      "              Val Loss: 1.4564491510391235, Val Acc: 68.58%\n",
      "Epoch: 9038,     Training Loss: 0.21219110488891602, Training Acc: 79.66%\n",
      "              Val Loss: 1.3808611631393433, Val Acc: 68.58%\n",
      "Epoch: 9039,     Training Loss: 0.21409335732460022, Training Acc: 79.66%\n",
      "              Val Loss: 1.4359854459762573, Val Acc: 68.58%\n",
      "Epoch: 9040,     Training Loss: 0.20197398960590363, Training Acc: 79.67%\n",
      "              Val Loss: 1.3863897323608398, Val Acc: 68.58%\n",
      "Epoch: 9041,     Training Loss: 0.1951783001422882, Training Acc: 79.67%\n",
      "              Val Loss: 1.4026784896850586, Val Acc: 68.58%\n",
      "Epoch: 9042,     Training Loss: 0.19137296080589294, Training Acc: 79.67%\n",
      "              Val Loss: 1.424631953239441, Val Acc: 68.58%\n",
      "Epoch: 9043,     Training Loss: 0.19412140548229218, Training Acc: 79.67%\n",
      "              Val Loss: 1.3805655241012573, Val Acc: 68.58%\n",
      "Epoch: 9044,     Training Loss: 0.20128890872001648, Training Acc: 79.67%\n",
      "              Val Loss: 1.4408307075500488, Val Acc: 68.58%\n",
      "Epoch: 9045,     Training Loss: 0.2043566107749939, Training Acc: 79.67%\n",
      "              Val Loss: 1.395943284034729, Val Acc: 68.58%\n",
      "Epoch: 9046,     Training Loss: 0.21936321258544922, Training Acc: 79.67%\n",
      "              Val Loss: 1.4475139379501343, Val Acc: 68.58%\n",
      "Epoch: 9047,     Training Loss: 0.21246390044689178, Training Acc: 79.68%\n",
      "              Val Loss: 1.3894081115722656, Val Acc: 68.58%\n",
      "Epoch: 9048,     Training Loss: 0.21112364530563354, Training Acc: 79.68%\n",
      "              Val Loss: 1.4318336248397827, Val Acc: 68.58%\n",
      "Epoch: 9049,     Training Loss: 0.19746257364749908, Training Acc: 79.68%\n",
      "              Val Loss: 1.389697551727295, Val Acc: 68.58%\n",
      "Epoch: 9050,     Training Loss: 0.194280207157135, Training Acc: 79.68%\n",
      "              Val Loss: 1.406095266342163, Val Acc: 68.58%\n",
      "Epoch: 9051,     Training Loss: 0.1907917559146881, Training Acc: 79.68%\n",
      "              Val Loss: 1.4344712495803833, Val Acc: 68.58%\n",
      "Epoch: 9052,     Training Loss: 0.19581849873065948, Training Acc: 79.68%\n",
      "              Val Loss: 1.3828386068344116, Val Acc: 68.58%\n",
      "Epoch: 9053,     Training Loss: 0.21356764435768127, Training Acc: 79.68%\n",
      "              Val Loss: 1.4717429876327515, Val Acc: 68.58%\n",
      "Epoch: 9054,     Training Loss: 0.2181343138217926, Training Acc: 79.68%\n",
      "              Val Loss: 1.394834280014038, Val Acc: 68.58%\n",
      "Epoch: 9055,     Training Loss: 0.2483694702386856, Training Acc: 79.69%\n",
      "              Val Loss: 1.4643065929412842, Val Acc: 68.58%\n",
      "Epoch: 9056,     Training Loss: 0.21560566127300262, Training Acc: 79.69%\n",
      "              Val Loss: 1.3987547159194946, Val Acc: 68.58%\n",
      "Epoch: 9057,     Training Loss: 0.2051077038049698, Training Acc: 79.69%\n",
      "              Val Loss: 1.408933401107788, Val Acc: 68.58%\n",
      "Epoch: 9058,     Training Loss: 0.19331231713294983, Training Acc: 79.69%\n",
      "              Val Loss: 1.4372036457061768, Val Acc: 68.58%\n",
      "Epoch: 9059,     Training Loss: 0.1979847550392151, Training Acc: 79.69%\n",
      "              Val Loss: 1.4016313552856445, Val Acc: 68.58%\n",
      "Epoch: 9060,     Training Loss: 0.21702934801578522, Training Acc: 79.69%\n",
      "              Val Loss: 1.4601068496704102, Val Acc: 68.58%\n",
      "Epoch: 9061,     Training Loss: 0.20924104750156403, Training Acc: 79.69%\n",
      "              Val Loss: 1.3900638818740845, Val Acc: 68.58%\n",
      "Epoch: 9062,     Training Loss: 0.20613808929920197, Training Acc: 79.70%\n",
      "              Val Loss: 1.4375240802764893, Val Acc: 68.58%\n",
      "Epoch: 9063,     Training Loss: 0.1937122344970703, Training Acc: 79.70%\n",
      "              Val Loss: 1.408800482749939, Val Acc: 68.58%\n",
      "Epoch: 9064,     Training Loss: 0.19495493173599243, Training Acc: 79.70%\n",
      "              Val Loss: 1.4047024250030518, Val Acc: 68.58%\n",
      "Epoch: 9065,     Training Loss: 0.19294600188732147, Training Acc: 79.70%\n",
      "              Val Loss: 1.4498018026351929, Val Acc: 68.58%\n",
      "Epoch: 9066,     Training Loss: 0.19745029509067535, Training Acc: 79.70%\n",
      "              Val Loss: 1.3907427787780762, Val Acc: 68.58%\n",
      "Epoch: 9067,     Training Loss: 0.21681833267211914, Training Acc: 79.70%\n",
      "              Val Loss: 1.4659874439239502, Val Acc: 68.58%\n",
      "Epoch: 9068,     Training Loss: 0.2116343080997467, Training Acc: 79.70%\n",
      "              Val Loss: 1.3944091796875, Val Acc: 68.58%\n",
      "Epoch: 9069,     Training Loss: 0.2202925831079483, Training Acc: 79.70%\n",
      "              Val Loss: 1.442297339439392, Val Acc: 68.58%\n",
      "Epoch: 9070,     Training Loss: 0.20225980877876282, Training Acc: 79.71%\n",
      "              Val Loss: 1.4058754444122314, Val Acc: 68.58%\n",
      "Epoch: 9071,     Training Loss: 0.19299250841140747, Training Acc: 79.71%\n",
      "              Val Loss: 1.4204537868499756, Val Acc: 68.58%\n",
      "Epoch: 9072,     Training Loss: 0.18803434073925018, Training Acc: 79.71%\n",
      "              Val Loss: 1.4426661729812622, Val Acc: 68.58%\n",
      "Epoch: 9073,     Training Loss: 0.19176536798477173, Training Acc: 79.71%\n",
      "              Val Loss: 1.408157229423523, Val Acc: 68.58%\n",
      "Epoch: 9074,     Training Loss: 0.20316265523433685, Training Acc: 79.71%\n",
      "              Val Loss: 1.463722825050354, Val Acc: 68.58%\n",
      "Epoch: 9075,     Training Loss: 0.19931232929229736, Training Acc: 79.71%\n",
      "              Val Loss: 1.402323603630066, Val Acc: 68.58%\n",
      "Epoch: 9076,     Training Loss: 0.20538344979286194, Training Acc: 79.71%\n",
      "              Val Loss: 1.4662683010101318, Val Acc: 68.58%\n",
      "Epoch: 9077,     Training Loss: 0.2026948481798172, Training Acc: 79.72%\n",
      "              Val Loss: 1.3930467367172241, Val Acc: 68.58%\n",
      "Epoch: 9078,     Training Loss: 0.20859389007091522, Training Acc: 79.72%\n",
      "              Val Loss: 1.4506109952926636, Val Acc: 68.58%\n",
      "Epoch: 9079,     Training Loss: 0.19977493584156036, Training Acc: 79.72%\n",
      "              Val Loss: 1.3973400592803955, Val Acc: 68.58%\n",
      "Epoch: 9080,     Training Loss: 0.19983354210853577, Training Acc: 79.72%\n",
      "              Val Loss: 1.436428189277649, Val Acc: 68.58%\n",
      "Epoch: 9081,     Training Loss: 0.19511497020721436, Training Acc: 79.72%\n",
      "              Val Loss: 1.4234603643417358, Val Acc: 68.58%\n",
      "Epoch: 9082,     Training Loss: 0.18872010707855225, Training Acc: 79.72%\n",
      "              Val Loss: 1.4291045665740967, Val Acc: 68.58%\n",
      "Epoch: 9083,     Training Loss: 0.18582755327224731, Training Acc: 79.72%\n",
      "              Val Loss: 1.4423727989196777, Val Acc: 68.58%\n",
      "Epoch: 9084,     Training Loss: 0.18778584897518158, Training Acc: 79.73%\n",
      "              Val Loss: 1.4264118671417236, Val Acc: 68.58%\n",
      "Epoch: 9085,     Training Loss: 0.1932564526796341, Training Acc: 79.73%\n",
      "              Val Loss: 1.4676634073257446, Val Acc: 68.58%\n",
      "Epoch: 9086,     Training Loss: 0.20023109018802643, Training Acc: 79.73%\n",
      "              Val Loss: 1.4081155061721802, Val Acc: 68.58%\n",
      "Epoch: 9087,     Training Loss: 0.2199024260044098, Training Acc: 79.73%\n",
      "              Val Loss: 1.4959206581115723, Val Acc: 68.58%\n",
      "Epoch: 9088,     Training Loss: 0.2240065336227417, Training Acc: 79.73%\n",
      "              Val Loss: 1.4101454019546509, Val Acc: 68.58%\n",
      "Epoch: 9089,     Training Loss: 0.2527484595775604, Training Acc: 79.73%\n",
      "              Val Loss: 1.4788496494293213, Val Acc: 68.58%\n",
      "Epoch: 9090,     Training Loss: 0.2087187021970749, Training Acc: 79.73%\n",
      "              Val Loss: 1.4030908346176147, Val Acc: 68.58%\n",
      "Epoch: 9091,     Training Loss: 0.1914782077074051, Training Acc: 79.73%\n",
      "              Val Loss: 1.4006026983261108, Val Acc: 68.59%\n",
      "Epoch: 9092,     Training Loss: 0.19189834594726562, Training Acc: 79.74%\n",
      "              Val Loss: 1.4699063301086426, Val Acc: 68.59%\n",
      "Epoch: 9093,     Training Loss: 0.20168258249759674, Training Acc: 79.74%\n",
      "              Val Loss: 1.4120614528656006, Val Acc: 68.59%\n",
      "Epoch: 9094,     Training Loss: 0.22411958873271942, Training Acc: 79.74%\n",
      "              Val Loss: 1.5025618076324463, Val Acc: 68.59%\n",
      "Epoch: 9095,     Training Loss: 0.21191948652267456, Training Acc: 79.74%\n",
      "              Val Loss: 1.4161888360977173, Val Acc: 68.59%\n",
      "Epoch: 9096,     Training Loss: 0.21278899908065796, Training Acc: 79.74%\n",
      "              Val Loss: 1.4631640911102295, Val Acc: 68.59%\n",
      "Epoch: 9097,     Training Loss: 0.2003353238105774, Training Acc: 79.74%\n",
      "              Val Loss: 1.423649787902832, Val Acc: 68.59%\n",
      "Epoch: 9098,     Training Loss: 0.1915244460105896, Training Acc: 79.74%\n",
      "              Val Loss: 1.4493719339370728, Val Acc: 68.59%\n",
      "Epoch: 9099,     Training Loss: 0.18728168308734894, Training Acc: 79.74%\n",
      "              Val Loss: 1.4487687349319458, Val Acc: 68.59%\n",
      "Epoch: 9100,     Training Loss: 0.18722429871559143, Training Acc: 79.75%\n",
      "              Val Loss: 1.4303429126739502, Val Acc: 68.59%\n",
      "Epoch: 9101,     Training Loss: 0.18886421620845795, Training Acc: 79.75%\n",
      "              Val Loss: 1.4604226350784302, Val Acc: 68.59%\n",
      "Epoch: 9102,     Training Loss: 0.1935001015663147, Training Acc: 79.75%\n",
      "              Val Loss: 1.4252876043319702, Val Acc: 68.59%\n",
      "Epoch: 9103,     Training Loss: 0.20098038017749786, Training Acc: 79.75%\n",
      "              Val Loss: 1.485510230064392, Val Acc: 68.59%\n",
      "Epoch: 9104,     Training Loss: 0.19896699488162994, Training Acc: 79.75%\n",
      "              Val Loss: 1.4165126085281372, Val Acc: 68.59%\n",
      "Epoch: 9105,     Training Loss: 0.2028554081916809, Training Acc: 79.75%\n",
      "              Val Loss: 1.4756996631622314, Val Acc: 68.59%\n",
      "Epoch: 9106,     Training Loss: 0.1996939778327942, Training Acc: 79.75%\n",
      "              Val Loss: 1.41446852684021, Val Acc: 68.59%\n",
      "Epoch: 9107,     Training Loss: 0.20103541016578674, Training Acc: 79.76%\n",
      "              Val Loss: 1.4650230407714844, Val Acc: 68.59%\n",
      "Epoch: 9108,     Training Loss: 0.19270658493041992, Training Acc: 79.76%\n",
      "              Val Loss: 1.4263111352920532, Val Acc: 68.59%\n",
      "Epoch: 9109,     Training Loss: 0.18998634815216064, Training Acc: 79.76%\n",
      "              Val Loss: 1.457746148109436, Val Acc: 68.59%\n",
      "Epoch: 9110,     Training Loss: 0.1883399784564972, Training Acc: 79.76%\n",
      "              Val Loss: 1.437474250793457, Val Acc: 68.59%\n",
      "Epoch: 9111,     Training Loss: 0.18851368129253387, Training Acc: 79.76%\n",
      "              Val Loss: 1.4590686559677124, Val Acc: 68.59%\n",
      "Epoch: 9112,     Training Loss: 0.1855519711971283, Training Acc: 79.76%\n",
      "              Val Loss: 1.4446992874145508, Val Acc: 68.59%\n",
      "Epoch: 9113,     Training Loss: 0.18497855961322784, Training Acc: 79.76%\n",
      "              Val Loss: 1.4698559045791626, Val Acc: 68.59%\n",
      "Epoch: 9114,     Training Loss: 0.18745368719100952, Training Acc: 79.77%\n",
      "              Val Loss: 1.4349077939987183, Val Acc: 68.59%\n",
      "Epoch: 9115,     Training Loss: 0.19149069488048553, Training Acc: 79.77%\n",
      "              Val Loss: 1.468785047531128, Val Acc: 68.59%\n",
      "Epoch: 9116,     Training Loss: 0.19021441042423248, Training Acc: 79.77%\n",
      "              Val Loss: 1.419405460357666, Val Acc: 68.59%\n",
      "Epoch: 9117,     Training Loss: 0.19588012993335724, Training Acc: 79.77%\n",
      "              Val Loss: 1.4877808094024658, Val Acc: 68.59%\n",
      "Epoch: 9118,     Training Loss: 0.20168732106685638, Training Acc: 79.77%\n",
      "              Val Loss: 1.4306696653366089, Val Acc: 68.59%\n",
      "Epoch: 9119,     Training Loss: 0.22066305577754974, Training Acc: 79.77%\n",
      "              Val Loss: 1.4936779737472534, Val Acc: 68.59%\n",
      "Epoch: 9120,     Training Loss: 0.20645517110824585, Training Acc: 79.77%\n",
      "              Val Loss: 1.4309371709823608, Val Acc: 68.59%\n",
      "Epoch: 9121,     Training Loss: 0.209821879863739, Training Acc: 79.78%\n",
      "              Val Loss: 1.4904295206069946, Val Acc: 68.59%\n",
      "Epoch: 9122,     Training Loss: 0.1991700679063797, Training Acc: 79.78%\n",
      "              Val Loss: 1.4375333786010742, Val Acc: 68.59%\n",
      "Epoch: 9123,     Training Loss: 0.19896507263183594, Training Acc: 79.78%\n",
      "              Val Loss: 1.4863358736038208, Val Acc: 68.59%\n",
      "Epoch: 9124,     Training Loss: 0.1905229538679123, Training Acc: 79.78%\n",
      "              Val Loss: 1.4314584732055664, Val Acc: 68.59%\n",
      "Epoch: 9125,     Training Loss: 0.19176113605499268, Training Acc: 79.78%\n",
      "              Val Loss: 1.465582013130188, Val Acc: 68.59%\n",
      "Epoch: 9126,     Training Loss: 0.18757998943328857, Training Acc: 79.78%\n",
      "              Val Loss: 1.452996850013733, Val Acc: 68.59%\n",
      "Epoch: 9127,     Training Loss: 0.19035576283931732, Training Acc: 79.78%\n",
      "              Val Loss: 1.4524438381195068, Val Acc: 68.59%\n",
      "Epoch: 9128,     Training Loss: 0.1897391527891159, Training Acc: 79.78%\n",
      "              Val Loss: 1.4537714719772339, Val Acc: 68.59%\n",
      "Epoch: 9129,     Training Loss: 0.18974122405052185, Training Acc: 79.79%\n",
      "              Val Loss: 1.483818531036377, Val Acc: 68.59%\n",
      "Epoch: 9130,     Training Loss: 0.19247519969940186, Training Acc: 79.79%\n",
      "              Val Loss: 1.4407082796096802, Val Acc: 68.59%\n",
      "Epoch: 9131,     Training Loss: 0.20641450583934784, Training Acc: 79.79%\n",
      "              Val Loss: 1.5404222011566162, Val Acc: 68.59%\n",
      "Epoch: 9132,     Training Loss: 0.2150105983018875, Training Acc: 79.79%\n",
      "              Val Loss: 1.4402046203613281, Val Acc: 68.59%\n",
      "Epoch: 9133,     Training Loss: 0.2633224129676819, Training Acc: 79.79%\n",
      "              Val Loss: 1.5286577939987183, Val Acc: 68.59%\n",
      "Epoch: 9134,     Training Loss: 0.22383268177509308, Training Acc: 79.79%\n",
      "              Val Loss: 1.423783779144287, Val Acc: 68.59%\n",
      "Epoch: 9135,     Training Loss: 0.22362220287322998, Training Acc: 79.79%\n",
      "              Val Loss: 1.452290654182434, Val Acc: 68.59%\n",
      "Epoch: 9136,     Training Loss: 0.1970842182636261, Training Acc: 79.79%\n",
      "              Val Loss: 1.4624238014221191, Val Acc: 68.59%\n",
      "Epoch: 9137,     Training Loss: 0.1908152550458908, Training Acc: 79.80%\n",
      "              Val Loss: 1.439926028251648, Val Acc: 68.59%\n",
      "Epoch: 9138,     Training Loss: 0.19724206626415253, Training Acc: 79.80%\n",
      "              Val Loss: 1.4917188882827759, Val Acc: 68.59%\n",
      "Epoch: 9139,     Training Loss: 0.19569090008735657, Training Acc: 79.80%\n",
      "              Val Loss: 1.4707696437835693, Val Acc: 68.59%\n",
      "Epoch: 9140,     Training Loss: 0.20199212431907654, Training Acc: 79.80%\n",
      "              Val Loss: 1.4998081922531128, Val Acc: 68.59%\n",
      "Epoch: 9141,     Training Loss: 0.196700781583786, Training Acc: 79.80%\n",
      "              Val Loss: 1.452620029449463, Val Acc: 68.59%\n",
      "Epoch: 9142,     Training Loss: 0.19940237700939178, Training Acc: 79.80%\n",
      "              Val Loss: 1.5214200019836426, Val Acc: 68.59%\n",
      "Epoch: 9143,     Training Loss: 0.20037603378295898, Training Acc: 79.80%\n",
      "              Val Loss: 1.443354606628418, Val Acc: 68.59%\n",
      "Epoch: 9144,     Training Loss: 0.22153151035308838, Training Acc: 79.81%\n",
      "              Val Loss: 1.5214309692382812, Val Acc: 68.59%\n",
      "Epoch: 9145,     Training Loss: 0.20816902816295624, Training Acc: 79.81%\n",
      "              Val Loss: 1.4442399740219116, Val Acc: 68.59%\n",
      "Epoch: 9146,     Training Loss: 0.21736477315425873, Training Acc: 79.81%\n",
      "              Val Loss: 1.4984498023986816, Val Acc: 68.59%\n",
      "Epoch: 9147,     Training Loss: 0.20643357932567596, Training Acc: 79.81%\n",
      "              Val Loss: 1.4607641696929932, Val Acc: 68.59%\n",
      "Epoch: 9148,     Training Loss: 0.20445509254932404, Training Acc: 79.81%\n",
      "              Val Loss: 1.4778114557266235, Val Acc: 68.59%\n",
      "Epoch: 9149,     Training Loss: 0.18749357759952545, Training Acc: 79.81%\n",
      "              Val Loss: 1.4694092273712158, Val Acc: 68.59%\n",
      "Epoch: 9150,     Training Loss: 0.18908384442329407, Training Acc: 79.81%\n",
      "              Val Loss: 1.477953314781189, Val Acc: 68.59%\n",
      "Epoch: 9151,     Training Loss: 0.1923278272151947, Training Acc: 79.81%\n",
      "              Val Loss: 1.4745209217071533, Val Acc: 68.60%\n",
      "Epoch: 9152,     Training Loss: 0.18594008684158325, Training Acc: 79.82%\n",
      "              Val Loss: 1.453459620475769, Val Acc: 68.60%\n",
      "Epoch: 9153,     Training Loss: 0.183316171169281, Training Acc: 79.82%\n",
      "              Val Loss: 1.488174557685852, Val Acc: 68.60%\n",
      "Epoch: 9154,     Training Loss: 0.18622568249702454, Training Acc: 79.82%\n",
      "              Val Loss: 1.4533005952835083, Val Acc: 68.60%\n",
      "Epoch: 9155,     Training Loss: 0.1911066174507141, Training Acc: 79.82%\n",
      "              Val Loss: 1.4951211214065552, Val Acc: 68.60%\n",
      "Epoch: 9156,     Training Loss: 0.18521465361118317, Training Acc: 79.82%\n",
      "              Val Loss: 1.4699229001998901, Val Acc: 68.60%\n",
      "Epoch: 9157,     Training Loss: 0.18459373712539673, Training Acc: 79.82%\n",
      "              Val Loss: 1.5032134056091309, Val Acc: 68.60%\n",
      "Epoch: 9158,     Training Loss: 0.19154033064842224, Training Acc: 79.82%\n",
      "              Val Loss: 1.479506015777588, Val Acc: 68.60%\n",
      "Epoch: 9159,     Training Loss: 0.20298686623573303, Training Acc: 79.83%\n",
      "              Val Loss: 1.533962368965149, Val Acc: 68.60%\n",
      "Epoch: 9160,     Training Loss: 0.20417118072509766, Training Acc: 79.83%\n",
      "              Val Loss: 1.4526724815368652, Val Acc: 68.60%\n",
      "Epoch: 9161,     Training Loss: 0.2345839887857437, Training Acc: 79.83%\n",
      "              Val Loss: 1.5818079710006714, Val Acc: 68.60%\n",
      "Epoch: 9162,     Training Loss: 0.23659434914588928, Training Acc: 79.83%\n",
      "              Val Loss: 1.4507774114608765, Val Acc: 68.60%\n",
      "Epoch: 9163,     Training Loss: 0.28404471278190613, Training Acc: 79.83%\n",
      "              Val Loss: 1.5639768838882446, Val Acc: 68.60%\n",
      "Epoch: 9164,     Training Loss: 0.2317395806312561, Training Acc: 79.83%\n",
      "              Val Loss: 1.4199801683425903, Val Acc: 68.60%\n",
      "Epoch: 9165,     Training Loss: 0.21544373035430908, Training Acc: 79.83%\n",
      "              Val Loss: 1.4681239128112793, Val Acc: 68.60%\n",
      "Epoch: 9166,     Training Loss: 0.19406232237815857, Training Acc: 79.83%\n",
      "              Val Loss: 1.5067938566207886, Val Acc: 68.60%\n",
      "Epoch: 9167,     Training Loss: 0.2015281617641449, Training Acc: 79.84%\n",
      "              Val Loss: 1.4502511024475098, Val Acc: 68.60%\n",
      "Epoch: 9168,     Training Loss: 0.20739835500717163, Training Acc: 79.84%\n",
      "              Val Loss: 1.5349717140197754, Val Acc: 68.60%\n",
      "Epoch: 9169,     Training Loss: 0.20168983936309814, Training Acc: 79.84%\n",
      "              Val Loss: 1.5298725366592407, Val Acc: 68.60%\n",
      "Epoch: 9170,     Training Loss: 0.24513790011405945, Training Acc: 79.84%\n",
      "              Val Loss: 1.5758354663848877, Val Acc: 68.60%\n",
      "Epoch: 9171,     Training Loss: 0.25402766466140747, Training Acc: 79.84%\n",
      "              Val Loss: 1.5220375061035156, Val Acc: 68.60%\n",
      "Epoch: 9172,     Training Loss: 0.2769308388233185, Training Acc: 79.84%\n",
      "              Val Loss: 1.5417735576629639, Val Acc: 68.60%\n",
      "Epoch: 9173,     Training Loss: 0.2100043147802353, Training Acc: 79.84%\n",
      "              Val Loss: 1.4712666273117065, Val Acc: 68.60%\n",
      "Epoch: 9174,     Training Loss: 0.2272646129131317, Training Acc: 79.84%\n",
      "              Val Loss: 1.5022467374801636, Val Acc: 68.60%\n",
      "Epoch: 9175,     Training Loss: 0.22153553366661072, Training Acc: 79.84%\n",
      "              Val Loss: 1.4750046730041504, Val Acc: 68.60%\n",
      "Epoch: 9176,     Training Loss: 0.19209030270576477, Training Acc: 79.85%\n",
      "              Val Loss: 1.4537246227264404, Val Acc: 68.60%\n",
      "Epoch: 9177,     Training Loss: 0.220008984208107, Training Acc: 79.85%\n",
      "              Val Loss: 1.5096355676651, Val Acc: 68.60%\n",
      "Epoch: 9178,     Training Loss: 0.21413938701152802, Training Acc: 79.85%\n",
      "              Val Loss: 1.4794987440109253, Val Acc: 68.60%\n",
      "Epoch: 9179,     Training Loss: 0.18938229978084564, Training Acc: 79.85%\n",
      "              Val Loss: 1.4431403875350952, Val Acc: 68.60%\n",
      "Epoch: 9180,     Training Loss: 0.20226384699344635, Training Acc: 79.85%\n",
      "              Val Loss: 1.5343774557113647, Val Acc: 68.60%\n",
      "Epoch: 9181,     Training Loss: 0.2027144432067871, Training Acc: 79.85%\n",
      "              Val Loss: 1.459364414215088, Val Acc: 68.60%\n",
      "Epoch: 9182,     Training Loss: 0.20916742086410522, Training Acc: 79.85%\n",
      "              Val Loss: 1.5339103937149048, Val Acc: 68.60%\n",
      "Epoch: 9183,     Training Loss: 0.20665180683135986, Training Acc: 79.85%\n",
      "              Val Loss: 1.4816151857376099, Val Acc: 68.60%\n",
      "Epoch: 9184,     Training Loss: 0.22257493436336517, Training Acc: 79.86%\n",
      "              Val Loss: 1.525822639465332, Val Acc: 68.60%\n",
      "Epoch: 9185,     Training Loss: 0.20220622420310974, Training Acc: 79.86%\n",
      "              Val Loss: 1.4742872714996338, Val Acc: 68.60%\n",
      "Epoch: 9186,     Training Loss: 0.1912955790758133, Training Acc: 79.86%\n",
      "              Val Loss: 1.521664023399353, Val Acc: 68.60%\n",
      "Epoch: 9187,     Training Loss: 0.18830032646656036, Training Acc: 79.86%\n",
      "              Val Loss: 1.5035426616668701, Val Acc: 68.60%\n",
      "Epoch: 9188,     Training Loss: 0.19424347579479218, Training Acc: 79.86%\n",
      "              Val Loss: 1.4810891151428223, Val Acc: 68.60%\n",
      "Epoch: 9189,     Training Loss: 0.18804040551185608, Training Acc: 79.86%\n",
      "              Val Loss: 1.5150562524795532, Val Acc: 68.60%\n",
      "Epoch: 9190,     Training Loss: 0.18902955949306488, Training Acc: 79.86%\n",
      "              Val Loss: 1.4495818614959717, Val Acc: 68.60%\n",
      "Epoch: 9191,     Training Loss: 0.21126653254032135, Training Acc: 79.87%\n",
      "              Val Loss: 1.5427124500274658, Val Acc: 68.60%\n",
      "Epoch: 9192,     Training Loss: 0.20666399598121643, Training Acc: 79.87%\n",
      "              Val Loss: 1.4682658910751343, Val Acc: 68.60%\n",
      "Epoch: 9193,     Training Loss: 0.24776752293109894, Training Acc: 79.87%\n",
      "              Val Loss: 1.6083557605743408, Val Acc: 68.60%\n",
      "Epoch: 9194,     Training Loss: 0.2614208161830902, Training Acc: 79.87%\n",
      "              Val Loss: 1.562779426574707, Val Acc: 68.60%\n",
      "Epoch: 9195,     Training Loss: 0.34837833046913147, Training Acc: 79.87%\n",
      "              Val Loss: 1.5671601295471191, Val Acc: 68.60%\n",
      "Epoch: 9196,     Training Loss: 0.21411944925785065, Training Acc: 79.87%\n",
      "              Val Loss: 1.527113437652588, Val Acc: 68.60%\n",
      "Epoch: 9197,     Training Loss: 0.20309263467788696, Training Acc: 79.87%\n",
      "              Val Loss: 1.4920889139175415, Val Acc: 68.60%\n",
      "Epoch: 9198,     Training Loss: 0.2465137094259262, Training Acc: 79.87%\n",
      "              Val Loss: 1.5553730726242065, Val Acc: 68.60%\n",
      "Epoch: 9199,     Training Loss: 0.21030399203300476, Training Acc: 79.87%\n",
      "              Val Loss: 1.477040410041809, Val Acc: 68.60%\n",
      "Epoch: 9200,     Training Loss: 0.2138984352350235, Training Acc: 79.88%\n",
      "              Val Loss: 1.501097559928894, Val Acc: 68.60%\n",
      "Epoch: 9201,     Training Loss: 0.20484429597854614, Training Acc: 79.88%\n",
      "              Val Loss: 1.5102375745773315, Val Acc: 68.60%\n",
      "Epoch: 9202,     Training Loss: 0.19257766008377075, Training Acc: 79.88%\n",
      "              Val Loss: 1.4544732570648193, Val Acc: 68.60%\n",
      "Epoch: 9203,     Training Loss: 0.20924213528633118, Training Acc: 79.88%\n",
      "              Val Loss: 1.5403004884719849, Val Acc: 68.60%\n",
      "Epoch: 9204,     Training Loss: 0.1996336430311203, Training Acc: 79.88%\n",
      "              Val Loss: 1.4723362922668457, Val Acc: 68.60%\n",
      "Epoch: 9205,     Training Loss: 0.19573266804218292, Training Acc: 79.88%\n",
      "              Val Loss: 1.5203521251678467, Val Acc: 68.60%\n",
      "Epoch: 9206,     Training Loss: 0.19655175507068634, Training Acc: 79.88%\n",
      "              Val Loss: 1.5044152736663818, Val Acc: 68.60%\n",
      "Epoch: 9207,     Training Loss: 0.20838794112205505, Training Acc: 79.88%\n",
      "              Val Loss: 1.5048091411590576, Val Acc: 68.60%\n",
      "Epoch: 9208,     Training Loss: 0.19904673099517822, Training Acc: 79.89%\n",
      "              Val Loss: 1.4768062829971313, Val Acc: 68.60%\n",
      "Epoch: 9209,     Training Loss: 0.18677201867103577, Training Acc: 79.89%\n",
      "              Val Loss: 1.5601844787597656, Val Acc: 68.60%\n",
      "Epoch: 9210,     Training Loss: 0.20173007249832153, Training Acc: 79.89%\n",
      "              Val Loss: 1.4738801717758179, Val Acc: 68.60%\n",
      "Epoch: 9211,     Training Loss: 0.2122320681810379, Training Acc: 79.89%\n",
      "              Val Loss: 1.5197646617889404, Val Acc: 68.60%\n",
      "Epoch: 9212,     Training Loss: 0.19434183835983276, Training Acc: 79.89%\n",
      "              Val Loss: 1.4676350355148315, Val Acc: 68.60%\n",
      "Epoch: 9213,     Training Loss: 0.20448479056358337, Training Acc: 79.89%\n",
      "              Val Loss: 1.5087193250656128, Val Acc: 68.60%\n",
      "Epoch: 9214,     Training Loss: 0.20506928861141205, Training Acc: 79.89%\n",
      "              Val Loss: 1.4731985330581665, Val Acc: 68.60%\n",
      "Epoch: 9215,     Training Loss: 0.20045533776283264, Training Acc: 79.89%\n",
      "              Val Loss: 1.5346417427062988, Val Acc: 68.60%\n",
      "Epoch: 9216,     Training Loss: 0.19187131524085999, Training Acc: 79.90%\n",
      "              Val Loss: 1.4716917276382446, Val Acc: 68.60%\n",
      "Epoch: 9217,     Training Loss: 0.20919786393642426, Training Acc: 79.90%\n",
      "              Val Loss: 1.562544345855713, Val Acc: 68.60%\n",
      "Epoch: 9218,     Training Loss: 0.2016398310661316, Training Acc: 79.90%\n",
      "              Val Loss: 1.4797254800796509, Val Acc: 68.60%\n",
      "Epoch: 9219,     Training Loss: 0.21297359466552734, Training Acc: 79.90%\n",
      "              Val Loss: 1.5583510398864746, Val Acc: 68.60%\n",
      "Epoch: 9220,     Training Loss: 0.2069065272808075, Training Acc: 79.90%\n",
      "              Val Loss: 1.502240777015686, Val Acc: 68.60%\n",
      "Epoch: 9221,     Training Loss: 0.21185263991355896, Training Acc: 79.90%\n",
      "              Val Loss: 1.5279648303985596, Val Acc: 68.60%\n",
      "Epoch: 9222,     Training Loss: 0.19104930758476257, Training Acc: 79.90%\n",
      "              Val Loss: 1.487498164176941, Val Acc: 68.60%\n",
      "Epoch: 9223,     Training Loss: 0.1817915141582489, Training Acc: 79.91%\n",
      "              Val Loss: 1.5177459716796875, Val Acc: 68.60%\n",
      "Epoch: 9224,     Training Loss: 0.18204084038734436, Training Acc: 79.91%\n",
      "              Val Loss: 1.5141899585723877, Val Acc: 68.60%\n",
      "Epoch: 9225,     Training Loss: 0.1836220920085907, Training Acc: 79.91%\n",
      "              Val Loss: 1.4886512756347656, Val Acc: 68.60%\n",
      "Epoch: 9226,     Training Loss: 0.18100740015506744, Training Acc: 79.91%\n",
      "              Val Loss: 1.5431827306747437, Val Acc: 68.60%\n",
      "Epoch: 9227,     Training Loss: 0.18778248131275177, Training Acc: 79.91%\n",
      "              Val Loss: 1.4773608446121216, Val Acc: 68.60%\n",
      "Epoch: 9228,     Training Loss: 0.20820263028144836, Training Acc: 79.91%\n",
      "              Val Loss: 1.5877691507339478, Val Acc: 68.61%\n",
      "Epoch: 9229,     Training Loss: 0.2147078961133957, Training Acc: 79.91%\n",
      "              Val Loss: 1.511110782623291, Val Acc: 68.60%\n",
      "Epoch: 9230,     Training Loss: 0.2847329080104828, Training Acc: 79.91%\n",
      "              Val Loss: 1.617533564567566, Val Acc: 68.61%\n",
      "Epoch: 9231,     Training Loss: 0.2395525723695755, Training Acc: 79.91%\n",
      "              Val Loss: 1.4793407917022705, Val Acc: 68.61%\n",
      "Epoch: 9232,     Training Loss: 0.23786239326000214, Training Acc: 79.92%\n",
      "              Val Loss: 1.5168356895446777, Val Acc: 68.61%\n",
      "Epoch: 9233,     Training Loss: 0.18776291608810425, Training Acc: 79.92%\n",
      "              Val Loss: 1.5642181634902954, Val Acc: 68.61%\n",
      "Epoch: 9234,     Training Loss: 0.21007345616817474, Training Acc: 79.92%\n",
      "              Val Loss: 1.5181045532226562, Val Acc: 68.61%\n",
      "Epoch: 9235,     Training Loss: 0.2887313961982727, Training Acc: 79.92%\n",
      "              Val Loss: 1.6039189100265503, Val Acc: 68.61%\n",
      "Epoch: 9236,     Training Loss: 0.2158537656068802, Training Acc: 79.92%\n",
      "              Val Loss: 1.4771568775177002, Val Acc: 68.61%\n",
      "Epoch: 9237,     Training Loss: 0.1975710690021515, Training Acc: 79.92%\n",
      "              Val Loss: 1.4796489477157593, Val Acc: 68.61%\n",
      "Epoch: 9238,     Training Loss: 0.20461280643939972, Training Acc: 79.92%\n",
      "              Val Loss: 1.5611283779144287, Val Acc: 68.61%\n",
      "Epoch: 9239,     Training Loss: 0.20495109260082245, Training Acc: 79.92%\n",
      "              Val Loss: 1.4996976852416992, Val Acc: 68.61%\n",
      "Epoch: 9240,     Training Loss: 0.25289666652679443, Training Acc: 79.93%\n",
      "              Val Loss: 1.6259814500808716, Val Acc: 68.61%\n",
      "Epoch: 9241,     Training Loss: 0.22873567044734955, Training Acc: 79.93%\n",
      "              Val Loss: 1.4539358615875244, Val Acc: 68.61%\n",
      "Epoch: 9242,     Training Loss: 0.21357885003089905, Training Acc: 79.93%\n",
      "              Val Loss: 1.5067601203918457, Val Acc: 68.61%\n",
      "Epoch: 9243,     Training Loss: 0.21499109268188477, Training Acc: 79.93%\n",
      "              Val Loss: 1.4975745677947998, Val Acc: 68.61%\n",
      "Epoch: 9244,     Training Loss: 0.2180812507867813, Training Acc: 79.93%\n",
      "              Val Loss: 1.5385520458221436, Val Acc: 68.61%\n",
      "Epoch: 9245,     Training Loss: 0.2185993641614914, Training Acc: 79.93%\n",
      "              Val Loss: 1.5151616334915161, Val Acc: 68.61%\n",
      "Epoch: 9246,     Training Loss: 0.1953849196434021, Training Acc: 79.93%\n",
      "              Val Loss: 1.5555058717727661, Val Acc: 68.61%\n",
      "Epoch: 9247,     Training Loss: 0.19648277759552002, Training Acc: 79.93%\n",
      "              Val Loss: 1.508918046951294, Val Acc: 68.61%\n",
      "Epoch: 9248,     Training Loss: 0.2077457755804062, Training Acc: 79.94%\n",
      "              Val Loss: 1.5243901014328003, Val Acc: 68.61%\n",
      "Epoch: 9249,     Training Loss: 0.18258853256702423, Training Acc: 79.94%\n",
      "              Val Loss: 1.5609012842178345, Val Acc: 68.61%\n",
      "Epoch: 9250,     Training Loss: 0.19922395050525665, Training Acc: 79.94%\n",
      "              Val Loss: 1.49029541015625, Val Acc: 68.61%\n",
      "Epoch: 9251,     Training Loss: 0.23620927333831787, Training Acc: 79.94%\n",
      "              Val Loss: 1.5434274673461914, Val Acc: 68.61%\n",
      "Epoch: 9252,     Training Loss: 0.20140598714351654, Training Acc: 79.94%\n",
      "              Val Loss: 1.5317844152450562, Val Acc: 68.61%\n",
      "Epoch: 9253,     Training Loss: 0.24266715347766876, Training Acc: 79.94%\n",
      "              Val Loss: 1.5746355056762695, Val Acc: 68.61%\n",
      "Epoch: 9254,     Training Loss: 0.2462560534477234, Training Acc: 79.94%\n",
      "              Val Loss: 1.5058319568634033, Val Acc: 68.61%\n",
      "Epoch: 9255,     Training Loss: 0.20918062329292297, Training Acc: 79.94%\n",
      "              Val Loss: 1.6858080625534058, Val Acc: 68.61%\n",
      "Epoch: 9256,     Training Loss: 0.26434704661369324, Training Acc: 79.94%\n",
      "              Val Loss: 1.6126500368118286, Val Acc: 68.61%\n",
      "Epoch: 9257,     Training Loss: 0.43801677227020264, Training Acc: 79.94%\n",
      "              Val Loss: 1.5245057344436646, Val Acc: 68.61%\n",
      "Epoch: 9258,     Training Loss: 0.2652355432510376, Training Acc: 79.95%\n",
      "              Val Loss: 1.7334121465682983, Val Acc: 68.61%\n",
      "Epoch: 9259,     Training Loss: 0.3929971754550934, Training Acc: 79.95%\n",
      "              Val Loss: 1.4700100421905518, Val Acc: 68.61%\n",
      "Epoch: 9260,     Training Loss: 0.2860998809337616, Training Acc: 79.95%\n",
      "              Val Loss: 1.603153109550476, Val Acc: 68.61%\n",
      "Epoch: 9261,     Training Loss: 0.38700348138809204, Training Acc: 79.95%\n",
      "              Val Loss: 1.516450047492981, Val Acc: 68.61%\n",
      "Epoch: 9262,     Training Loss: 0.39106467366218567, Training Acc: 79.95%\n",
      "              Val Loss: 1.7725486755371094, Val Acc: 68.61%\n",
      "Epoch: 9263,     Training Loss: 0.38654014468193054, Training Acc: 79.95%\n",
      "              Val Loss: 1.4143997430801392, Val Acc: 68.61%\n",
      "Epoch: 9264,     Training Loss: 0.30734145641326904, Training Acc: 79.95%\n",
      "              Val Loss: 1.4384628534317017, Val Acc: 68.61%\n",
      "Epoch: 9265,     Training Loss: 0.32319390773773193, Training Acc: 79.95%\n",
      "              Val Loss: 1.510933518409729, Val Acc: 68.61%\n",
      "Epoch: 9266,     Training Loss: 0.26727554202079773, Training Acc: 79.95%\n",
      "              Val Loss: 1.5466532707214355, Val Acc: 68.61%\n",
      "Epoch: 9267,     Training Loss: 0.3257211446762085, Training Acc: 79.95%\n",
      "              Val Loss: 1.5218373537063599, Val Acc: 68.61%\n",
      "Epoch: 9268,     Training Loss: 0.24133601784706116, Training Acc: 79.95%\n",
      "              Val Loss: 1.4801465272903442, Val Acc: 68.61%\n",
      "Epoch: 9269,     Training Loss: 0.2549993693828583, Training Acc: 79.95%\n",
      "              Val Loss: 1.4635531902313232, Val Acc: 68.61%\n",
      "Epoch: 9270,     Training Loss: 0.23315496742725372, Training Acc: 79.95%\n",
      "              Val Loss: 1.6432788372039795, Val Acc: 68.61%\n",
      "Epoch: 9271,     Training Loss: 0.28635236620903015, Training Acc: 79.96%\n",
      "              Val Loss: 1.492372989654541, Val Acc: 68.61%\n",
      "Epoch: 9272,     Training Loss: 0.3948119878768921, Training Acc: 79.96%\n",
      "              Val Loss: 1.6209745407104492, Val Acc: 68.61%\n",
      "Epoch: 9273,     Training Loss: 0.2902534604072571, Training Acc: 79.96%\n",
      "              Val Loss: 1.5752813816070557, Val Acc: 68.61%\n",
      "Epoch: 9274,     Training Loss: 0.2997928857803345, Training Acc: 79.96%\n",
      "              Val Loss: 1.4377312660217285, Val Acc: 68.61%\n",
      "Epoch: 9275,     Training Loss: 0.22493425011634827, Training Acc: 79.96%\n",
      "              Val Loss: 1.6390200853347778, Val Acc: 68.61%\n",
      "Epoch: 9276,     Training Loss: 0.3269672691822052, Training Acc: 79.96%\n",
      "              Val Loss: 1.6655830144882202, Val Acc: 68.61%\n",
      "Epoch: 9277,     Training Loss: 0.4579302966594696, Training Acc: 79.96%\n",
      "              Val Loss: 1.6796029806137085, Val Acc: 68.61%\n",
      "Epoch: 9278,     Training Loss: 0.35864928364753723, Training Acc: 79.96%\n",
      "              Val Loss: 1.5092658996582031, Val Acc: 68.61%\n",
      "Epoch: 9279,     Training Loss: 0.40920716524124146, Training Acc: 79.96%\n",
      "              Val Loss: 1.4462306499481201, Val Acc: 68.61%\n",
      "Epoch: 9280,     Training Loss: 0.4783431589603424, Training Acc: 79.96%\n",
      "              Val Loss: 1.4223414659500122, Val Acc: 68.61%\n",
      "Epoch: 9281,     Training Loss: 0.3212520182132721, Training Acc: 79.96%\n",
      "              Val Loss: 1.600723147392273, Val Acc: 68.61%\n",
      "Epoch: 9282,     Training Loss: 0.3827595114707947, Training Acc: 79.96%\n",
      "              Val Loss: 1.40494704246521, Val Acc: 68.61%\n",
      "Epoch: 9283,     Training Loss: 0.3233722448348999, Training Acc: 79.96%\n",
      "              Val Loss: 1.424731731414795, Val Acc: 68.61%\n",
      "Epoch: 9284,     Training Loss: 0.37969648838043213, Training Acc: 79.96%\n",
      "              Val Loss: 1.2853094339370728, Val Acc: 68.61%\n",
      "Epoch: 9285,     Training Loss: 0.32993385195732117, Training Acc: 79.96%\n",
      "              Val Loss: 1.3114680051803589, Val Acc: 68.61%\n",
      "Epoch: 9286,     Training Loss: 0.3104707598686218, Training Acc: 79.96%\n",
      "              Val Loss: 1.3613051176071167, Val Acc: 68.61%\n",
      "Epoch: 9287,     Training Loss: 0.2865821421146393, Training Acc: 79.96%\n",
      "              Val Loss: 1.4074358940124512, Val Acc: 68.61%\n",
      "Epoch: 9288,     Training Loss: 0.28903070092201233, Training Acc: 79.97%\n",
      "              Val Loss: 1.5284048318862915, Val Acc: 68.61%\n",
      "Epoch: 9289,     Training Loss: 0.2762632966041565, Training Acc: 79.97%\n",
      "              Val Loss: 1.6094197034835815, Val Acc: 68.61%\n",
      "Epoch: 9290,     Training Loss: 0.24380344152450562, Training Acc: 79.97%\n",
      "              Val Loss: 1.5847545862197876, Val Acc: 68.61%\n",
      "Epoch: 9291,     Training Loss: 0.2638918161392212, Training Acc: 79.97%\n",
      "              Val Loss: 1.6207002401351929, Val Acc: 68.61%\n",
      "Epoch: 9292,     Training Loss: 0.27099189162254333, Training Acc: 79.97%\n",
      "              Val Loss: 1.5546112060546875, Val Acc: 68.61%\n",
      "Epoch: 9293,     Training Loss: 0.2951781153678894, Training Acc: 79.97%\n",
      "              Val Loss: 1.7156504392623901, Val Acc: 68.61%\n",
      "Epoch: 9294,     Training Loss: 0.2539600729942322, Training Acc: 79.97%\n",
      "              Val Loss: 1.5942621231079102, Val Acc: 68.61%\n",
      "Epoch: 9295,     Training Loss: 0.21881094574928284, Training Acc: 79.97%\n",
      "              Val Loss: 1.5493522882461548, Val Acc: 68.61%\n",
      "Epoch: 9296,     Training Loss: 0.22712360322475433, Training Acc: 79.97%\n",
      "              Val Loss: 1.5915727615356445, Val Acc: 68.61%\n",
      "Epoch: 9297,     Training Loss: 0.24036723375320435, Training Acc: 79.97%\n",
      "              Val Loss: 1.4532033205032349, Val Acc: 68.61%\n",
      "Epoch: 9298,     Training Loss: 0.2670425474643707, Training Acc: 79.98%\n",
      "              Val Loss: 1.5395475625991821, Val Acc: 68.61%\n",
      "Epoch: 9299,     Training Loss: 0.22347621619701385, Training Acc: 79.98%\n",
      "              Val Loss: 1.4938734769821167, Val Acc: 68.61%\n",
      "Epoch: 9300,     Training Loss: 0.20344746112823486, Training Acc: 79.98%\n",
      "              Val Loss: 1.534926176071167, Val Acc: 68.61%\n",
      "Epoch: 9301,     Training Loss: 0.20356757938861847, Training Acc: 79.98%\n",
      "              Val Loss: 1.5805267095565796, Val Acc: 68.61%\n",
      "Epoch: 9302,     Training Loss: 0.20489473640918732, Training Acc: 79.98%\n",
      "              Val Loss: 1.528136134147644, Val Acc: 68.61%\n",
      "Epoch: 9303,     Training Loss: 0.22496549785137177, Training Acc: 79.98%\n",
      "              Val Loss: 1.589319109916687, Val Acc: 68.61%\n",
      "Epoch: 9304,     Training Loss: 0.2153209149837494, Training Acc: 79.98%\n",
      "              Val Loss: 1.4885776042938232, Val Acc: 68.61%\n",
      "Epoch: 9305,     Training Loss: 0.2072458267211914, Training Acc: 79.98%\n",
      "              Val Loss: 1.5093814134597778, Val Acc: 68.61%\n",
      "Epoch: 9306,     Training Loss: 0.20054307579994202, Training Acc: 79.99%\n",
      "              Val Loss: 1.4784654378890991, Val Acc: 68.61%\n",
      "Epoch: 9307,     Training Loss: 0.19350475072860718, Training Acc: 79.99%\n",
      "              Val Loss: 1.5094140768051147, Val Acc: 68.61%\n",
      "Epoch: 9308,     Training Loss: 0.18946100771427155, Training Acc: 79.99%\n",
      "              Val Loss: 1.522193193435669, Val Acc: 68.61%\n",
      "Epoch: 9309,     Training Loss: 0.188550665974617, Training Acc: 79.99%\n",
      "              Val Loss: 1.5078288316726685, Val Acc: 68.61%\n",
      "Epoch: 9310,     Training Loss: 0.18848007917404175, Training Acc: 79.99%\n",
      "              Val Loss: 1.5250762701034546, Val Acc: 68.61%\n",
      "Epoch: 9311,     Training Loss: 0.18648120760917664, Training Acc: 79.99%\n",
      "              Val Loss: 1.5048271417617798, Val Acc: 68.61%\n",
      "Epoch: 9312,     Training Loss: 0.18312285840511322, Training Acc: 79.99%\n",
      "              Val Loss: 1.5143734216690063, Val Acc: 68.61%\n",
      "Epoch: 9313,     Training Loss: 0.18514733016490936, Training Acc: 80.00%\n",
      "              Val Loss: 1.4976716041564941, Val Acc: 68.61%\n",
      "Epoch: 9314,     Training Loss: 0.1859104484319687, Training Acc: 80.00%\n",
      "              Val Loss: 1.5242825746536255, Val Acc: 68.61%\n",
      "Epoch: 9315,     Training Loss: 0.1895250827074051, Training Acc: 80.00%\n",
      "              Val Loss: 1.476320505142212, Val Acc: 68.61%\n",
      "Epoch: 9316,     Training Loss: 0.19446371495723724, Training Acc: 80.00%\n",
      "              Val Loss: 1.5367540121078491, Val Acc: 68.61%\n",
      "Epoch: 9317,     Training Loss: 0.19228336215019226, Training Acc: 80.00%\n",
      "              Val Loss: 1.4707874059677124, Val Acc: 68.61%\n",
      "Epoch: 9318,     Training Loss: 0.20215825736522675, Training Acc: 80.00%\n",
      "              Val Loss: 1.5327664613723755, Val Acc: 68.62%\n",
      "Epoch: 9319,     Training Loss: 0.19047307968139648, Training Acc: 80.00%\n",
      "              Val Loss: 1.466273546218872, Val Acc: 68.62%\n",
      "Epoch: 9320,     Training Loss: 0.1875641942024231, Training Acc: 80.00%\n",
      "              Val Loss: 1.5146005153656006, Val Acc: 68.62%\n",
      "Epoch: 9321,     Training Loss: 0.1835656762123108, Training Acc: 80.01%\n",
      "              Val Loss: 1.4958523511886597, Val Acc: 68.62%\n",
      "Epoch: 9322,     Training Loss: 0.17939263582229614, Training Acc: 80.01%\n",
      "              Val Loss: 1.4979004859924316, Val Acc: 68.62%\n",
      "Epoch: 9323,     Training Loss: 0.1766255497932434, Training Acc: 80.01%\n",
      "              Val Loss: 1.5114755630493164, Val Acc: 68.62%\n",
      "Epoch: 9324,     Training Loss: 0.17803330719470978, Training Acc: 80.01%\n",
      "              Val Loss: 1.4844732284545898, Val Acc: 68.62%\n",
      "Epoch: 9325,     Training Loss: 0.18340040743350983, Training Acc: 80.01%\n",
      "              Val Loss: 1.5411800146102905, Val Acc: 68.62%\n",
      "Epoch: 9326,     Training Loss: 0.18748971819877625, Training Acc: 80.01%\n",
      "              Val Loss: 1.4859920740127563, Val Acc: 68.62%\n",
      "Epoch: 9327,     Training Loss: 0.19758035242557526, Training Acc: 80.01%\n",
      "              Val Loss: 1.569166660308838, Val Acc: 68.62%\n",
      "Epoch: 9328,     Training Loss: 0.19727380573749542, Training Acc: 80.02%\n",
      "              Val Loss: 1.4740163087844849, Val Acc: 68.62%\n",
      "Epoch: 9329,     Training Loss: 0.2146405577659607, Training Acc: 80.02%\n",
      "              Val Loss: 1.5644992589950562, Val Acc: 68.62%\n",
      "Epoch: 9330,     Training Loss: 0.20273585617542267, Training Acc: 80.02%\n",
      "              Val Loss: 1.4708671569824219, Val Acc: 68.62%\n",
      "Epoch: 9331,     Training Loss: 0.20256654918193817, Training Acc: 80.02%\n",
      "              Val Loss: 1.5239530801773071, Val Acc: 68.62%\n",
      "Epoch: 9332,     Training Loss: 0.1853448897600174, Training Acc: 80.02%\n",
      "              Val Loss: 1.501157283782959, Val Acc: 68.62%\n",
      "Epoch: 9333,     Training Loss: 0.18020248413085938, Training Acc: 80.02%\n",
      "              Val Loss: 1.4807173013687134, Val Acc: 68.62%\n",
      "Epoch: 9334,     Training Loss: 0.1782372146844864, Training Acc: 80.02%\n",
      "              Val Loss: 1.5382511615753174, Val Acc: 68.62%\n",
      "Epoch: 9335,     Training Loss: 0.18225854635238647, Training Acc: 80.02%\n",
      "              Val Loss: 1.5044671297073364, Val Acc: 68.62%\n",
      "Epoch: 9336,     Training Loss: 0.19811229407787323, Training Acc: 80.03%\n",
      "              Val Loss: 1.565054178237915, Val Acc: 68.62%\n",
      "Epoch: 9337,     Training Loss: 0.19153273105621338, Training Acc: 80.03%\n",
      "              Val Loss: 1.4989101886749268, Val Acc: 68.62%\n",
      "Epoch: 9338,     Training Loss: 0.18869070708751678, Training Acc: 80.03%\n",
      "              Val Loss: 1.5521920919418335, Val Acc: 68.62%\n",
      "Epoch: 9339,     Training Loss: 0.18814903497695923, Training Acc: 80.03%\n",
      "              Val Loss: 1.4964653253555298, Val Acc: 68.62%\n",
      "Epoch: 9340,     Training Loss: 0.19721178710460663, Training Acc: 80.03%\n",
      "              Val Loss: 1.5626585483551025, Val Acc: 68.62%\n",
      "Epoch: 9341,     Training Loss: 0.186326801776886, Training Acc: 80.03%\n",
      "              Val Loss: 1.4930609464645386, Val Acc: 68.62%\n",
      "Epoch: 9342,     Training Loss: 0.179345965385437, Training Acc: 80.03%\n",
      "              Val Loss: 1.520241141319275, Val Acc: 68.62%\n",
      "Epoch: 9343,     Training Loss: 0.17732147872447968, Training Acc: 80.03%\n",
      "              Val Loss: 1.508735179901123, Val Acc: 68.62%\n",
      "Epoch: 9344,     Training Loss: 0.18077883124351501, Training Acc: 80.04%\n",
      "              Val Loss: 1.5178842544555664, Val Acc: 68.62%\n",
      "Epoch: 9345,     Training Loss: 0.17729699611663818, Training Acc: 80.04%\n",
      "              Val Loss: 1.5164196491241455, Val Acc: 68.62%\n",
      "Epoch: 9346,     Training Loss: 0.1722356081008911, Training Acc: 80.04%\n",
      "              Val Loss: 1.5246458053588867, Val Acc: 68.62%\n",
      "Epoch: 9347,     Training Loss: 0.17401641607284546, Training Acc: 80.04%\n",
      "              Val Loss: 1.5155155658721924, Val Acc: 68.62%\n",
      "Epoch: 9348,     Training Loss: 0.1776157170534134, Training Acc: 80.04%\n",
      "              Val Loss: 1.5290225744247437, Val Acc: 68.62%\n",
      "Epoch: 9349,     Training Loss: 0.17588867247104645, Training Acc: 80.04%\n",
      "              Val Loss: 1.5277564525604248, Val Acc: 68.62%\n",
      "Epoch: 9350,     Training Loss: 0.1724736988544464, Training Acc: 80.04%\n",
      "              Val Loss: 1.5268837213516235, Val Acc: 68.62%\n",
      "Epoch: 9351,     Training Loss: 0.1713804304599762, Training Acc: 80.05%\n",
      "              Val Loss: 1.5347793102264404, Val Acc: 68.62%\n",
      "Epoch: 9352,     Training Loss: 0.1729041039943695, Training Acc: 80.05%\n",
      "              Val Loss: 1.5297880172729492, Val Acc: 68.62%\n",
      "Epoch: 9353,     Training Loss: 0.1744726598262787, Training Acc: 80.05%\n",
      "              Val Loss: 1.5387628078460693, Val Acc: 68.62%\n",
      "Epoch: 9354,     Training Loss: 0.17312170565128326, Training Acc: 80.05%\n",
      "              Val Loss: 1.5216472148895264, Val Acc: 68.62%\n",
      "Epoch: 9355,     Training Loss: 0.17211326956748962, Training Acc: 80.05%\n",
      "              Val Loss: 1.5527396202087402, Val Acc: 68.62%\n",
      "Epoch: 9356,     Training Loss: 0.17598754167556763, Training Acc: 80.05%\n",
      "              Val Loss: 1.506646990776062, Val Acc: 68.62%\n",
      "Epoch: 9357,     Training Loss: 0.18800176680088043, Training Acc: 80.05%\n",
      "              Val Loss: 1.5911803245544434, Val Acc: 68.62%\n",
      "Epoch: 9358,     Training Loss: 0.19954687356948853, Training Acc: 80.06%\n",
      "              Val Loss: 1.5146996974945068, Val Acc: 68.62%\n",
      "Epoch: 9359,     Training Loss: 0.2434910535812378, Training Acc: 80.06%\n",
      "              Val Loss: 1.635891079902649, Val Acc: 68.62%\n",
      "Epoch: 9360,     Training Loss: 0.2226247936487198, Training Acc: 80.06%\n",
      "              Val Loss: 1.5148807764053345, Val Acc: 68.62%\n",
      "Epoch: 9361,     Training Loss: 0.2616799473762512, Training Acc: 80.06%\n",
      "              Val Loss: 1.5981032848358154, Val Acc: 68.62%\n",
      "Epoch: 9362,     Training Loss: 0.20707346498966217, Training Acc: 80.06%\n",
      "              Val Loss: 1.4862303733825684, Val Acc: 68.62%\n",
      "Epoch: 9363,     Training Loss: 0.19052241742610931, Training Acc: 80.06%\n",
      "              Val Loss: 1.4941611289978027, Val Acc: 68.62%\n",
      "Epoch: 9364,     Training Loss: 0.17619219422340393, Training Acc: 80.06%\n",
      "              Val Loss: 1.5709776878356934, Val Acc: 68.62%\n",
      "Epoch: 9365,     Training Loss: 0.1948685646057129, Training Acc: 80.06%\n",
      "              Val Loss: 1.477034568786621, Val Acc: 68.62%\n",
      "Epoch: 9366,     Training Loss: 0.22241488099098206, Training Acc: 80.07%\n",
      "              Val Loss: 1.5958555936813354, Val Acc: 68.62%\n",
      "Epoch: 9367,     Training Loss: 0.2023847997188568, Training Acc: 80.07%\n",
      "              Val Loss: 1.4959689378738403, Val Acc: 68.62%\n",
      "Epoch: 9368,     Training Loss: 0.21629491448402405, Training Acc: 80.07%\n",
      "              Val Loss: 1.5615578889846802, Val Acc: 68.63%\n",
      "Epoch: 9369,     Training Loss: 0.2026754766702652, Training Acc: 80.07%\n",
      "              Val Loss: 1.530350685119629, Val Acc: 68.63%\n",
      "Epoch: 9370,     Training Loss: 0.18915072083473206, Training Acc: 80.07%\n",
      "              Val Loss: 1.5264308452606201, Val Acc: 68.63%\n",
      "Epoch: 9371,     Training Loss: 0.1730317920446396, Training Acc: 80.07%\n",
      "              Val Loss: 1.5469058752059937, Val Acc: 68.63%\n",
      "Epoch: 9372,     Training Loss: 0.1822461634874344, Training Acc: 80.07%\n",
      "              Val Loss: 1.5301330089569092, Val Acc: 68.63%\n",
      "Epoch: 9373,     Training Loss: 0.20052874088287354, Training Acc: 80.07%\n",
      "              Val Loss: 1.5760324001312256, Val Acc: 68.63%\n",
      "Epoch: 9374,     Training Loss: 0.18862487375736237, Training Acc: 80.08%\n",
      "              Val Loss: 1.5044891834259033, Val Acc: 68.63%\n",
      "Epoch: 9375,     Training Loss: 0.18910476565361023, Training Acc: 80.08%\n",
      "              Val Loss: 1.5854368209838867, Val Acc: 68.63%\n",
      "Epoch: 9376,     Training Loss: 0.18756753206253052, Training Acc: 80.08%\n",
      "              Val Loss: 1.5007824897766113, Val Acc: 68.63%\n",
      "Epoch: 9377,     Training Loss: 0.1970931887626648, Training Acc: 80.08%\n",
      "              Val Loss: 1.5376166105270386, Val Acc: 68.63%\n",
      "Epoch: 9378,     Training Loss: 0.18154196441173553, Training Acc: 80.08%\n",
      "              Val Loss: 1.5162420272827148, Val Acc: 68.63%\n",
      "Epoch: 9379,     Training Loss: 0.17450210452079773, Training Acc: 80.08%\n",
      "              Val Loss: 1.5187360048294067, Val Acc: 68.63%\n",
      "Epoch: 9380,     Training Loss: 0.17832297086715698, Training Acc: 80.08%\n",
      "              Val Loss: 1.5402337312698364, Val Acc: 68.63%\n",
      "Epoch: 9381,     Training Loss: 0.17713111639022827, Training Acc: 80.09%\n",
      "              Val Loss: 1.535233497619629, Val Acc: 68.63%\n",
      "Epoch: 9382,     Training Loss: 0.17548657953739166, Training Acc: 80.09%\n",
      "              Val Loss: 1.5318621397018433, Val Acc: 68.63%\n",
      "Epoch: 9383,     Training Loss: 0.17457394301891327, Training Acc: 80.09%\n",
      "              Val Loss: 1.564286708831787, Val Acc: 68.63%\n",
      "Epoch: 9384,     Training Loss: 0.17499496042728424, Training Acc: 80.09%\n",
      "              Val Loss: 1.5643402338027954, Val Acc: 68.63%\n",
      "Epoch: 9385,     Training Loss: 0.18780571222305298, Training Acc: 80.09%\n",
      "              Val Loss: 1.553423285484314, Val Acc: 68.63%\n",
      "Epoch: 9386,     Training Loss: 0.18787220120429993, Training Acc: 80.09%\n",
      "              Val Loss: 1.540647268295288, Val Acc: 68.63%\n",
      "Epoch: 9387,     Training Loss: 0.17189496755599976, Training Acc: 80.09%\n",
      "              Val Loss: 1.5489718914031982, Val Acc: 68.63%\n",
      "Epoch: 9388,     Training Loss: 0.1781298816204071, Training Acc: 80.09%\n",
      "              Val Loss: 1.5578107833862305, Val Acc: 68.63%\n",
      "Epoch: 9389,     Training Loss: 0.19047971069812775, Training Acc: 80.10%\n",
      "              Val Loss: 1.53456711769104, Val Acc: 68.63%\n",
      "Epoch: 9390,     Training Loss: 0.1835068315267563, Training Acc: 80.10%\n",
      "              Val Loss: 1.5998190641403198, Val Acc: 68.63%\n",
      "Epoch: 9391,     Training Loss: 0.1891118437051773, Training Acc: 80.10%\n",
      "              Val Loss: 1.5087218284606934, Val Acc: 68.63%\n",
      "Epoch: 9392,     Training Loss: 0.20318590104579926, Training Acc: 80.10%\n",
      "              Val Loss: 1.6026803255081177, Val Acc: 68.63%\n",
      "Epoch: 9393,     Training Loss: 0.20251068472862244, Training Acc: 80.10%\n",
      "              Val Loss: 1.6028767824172974, Val Acc: 68.63%\n",
      "Epoch: 9394,     Training Loss: 0.28170573711395264, Training Acc: 80.10%\n",
      "              Val Loss: 1.6511198282241821, Val Acc: 68.63%\n",
      "Epoch: 9395,     Training Loss: 0.2348463237285614, Training Acc: 80.10%\n",
      "              Val Loss: 1.5225569009780884, Val Acc: 68.63%\n",
      "Epoch: 9396,     Training Loss: 0.23391368985176086, Training Acc: 80.10%\n",
      "              Val Loss: 1.6378493309020996, Val Acc: 68.63%\n",
      "Epoch: 9397,     Training Loss: 0.22096265852451324, Training Acc: 80.11%\n",
      "              Val Loss: 1.5337510108947754, Val Acc: 68.63%\n",
      "Epoch: 9398,     Training Loss: 0.24184058606624603, Training Acc: 80.11%\n",
      "              Val Loss: 1.546289086341858, Val Acc: 68.63%\n",
      "Epoch: 9399,     Training Loss: 0.1827964037656784, Training Acc: 80.11%\n",
      "              Val Loss: 1.6298304796218872, Val Acc: 68.63%\n",
      "Epoch: 9400,     Training Loss: 0.22512266039848328, Training Acc: 80.11%\n",
      "              Val Loss: 1.4799848794937134, Val Acc: 68.63%\n",
      "Epoch: 9401,     Training Loss: 0.257819265127182, Training Acc: 80.11%\n",
      "              Val Loss: 1.6160290241241455, Val Acc: 68.63%\n",
      "Epoch: 9402,     Training Loss: 0.25629380345344543, Training Acc: 80.11%\n",
      "              Val Loss: 1.7742558717727661, Val Acc: 68.63%\n",
      "Epoch: 9403,     Training Loss: 0.4767191708087921, Training Acc: 80.11%\n",
      "              Val Loss: 1.6087688207626343, Val Acc: 68.63%\n",
      "Epoch: 9404,     Training Loss: 0.2366856336593628, Training Acc: 80.11%\n",
      "              Val Loss: 1.639654517173767, Val Acc: 68.63%\n",
      "Epoch: 9405,     Training Loss: 0.2723720669746399, Training Acc: 80.11%\n",
      "              Val Loss: 1.6503344774246216, Val Acc: 68.63%\n",
      "Epoch: 9406,     Training Loss: 0.41619420051574707, Training Acc: 80.11%\n",
      "              Val Loss: 1.7805089950561523, Val Acc: 68.63%\n",
      "Epoch: 9407,     Training Loss: 0.3355363607406616, Training Acc: 80.11%\n",
      "              Val Loss: 1.6329677104949951, Val Acc: 68.63%\n",
      "Epoch: 9408,     Training Loss: 0.42013227939605713, Training Acc: 80.11%\n",
      "              Val Loss: 1.4625684022903442, Val Acc: 68.63%\n",
      "Epoch: 9409,     Training Loss: 0.32397663593292236, Training Acc: 80.11%\n",
      "              Val Loss: 1.6710952520370483, Val Acc: 68.63%\n",
      "Epoch: 9410,     Training Loss: 0.3408963680267334, Training Acc: 80.12%\n",
      "              Val Loss: 1.67522394657135, Val Acc: 68.63%\n",
      "Epoch: 9411,     Training Loss: 0.41026195883750916, Training Acc: 80.12%\n",
      "              Val Loss: 1.4616234302520752, Val Acc: 68.63%\n",
      "Epoch: 9412,     Training Loss: 0.25427374243736267, Training Acc: 80.12%\n",
      "              Val Loss: 1.6735808849334717, Val Acc: 68.63%\n",
      "Epoch: 9413,     Training Loss: 0.4222109913825989, Training Acc: 80.12%\n",
      "              Val Loss: 1.6422637701034546, Val Acc: 68.63%\n",
      "Epoch: 9414,     Training Loss: 0.5878344774246216, Training Acc: 80.12%\n",
      "              Val Loss: 1.8055378198623657, Val Acc: 68.63%\n",
      "Epoch: 9415,     Training Loss: 0.4046580493450165, Training Acc: 80.12%\n",
      "              Val Loss: 1.7774109840393066, Val Acc: 68.63%\n",
      "Epoch: 9416,     Training Loss: 0.37824416160583496, Training Acc: 80.12%\n",
      "              Val Loss: 1.5972511768341064, Val Acc: 68.63%\n",
      "Epoch: 9417,     Training Loss: 0.5346409678459167, Training Acc: 80.12%\n",
      "              Val Loss: 1.5858882665634155, Val Acc: 68.63%\n",
      "Epoch: 9418,     Training Loss: 0.3374578058719635, Training Acc: 80.12%\n",
      "              Val Loss: 1.907698631286621, Val Acc: 68.63%\n",
      "Epoch: 9419,     Training Loss: 0.49219566583633423, Training Acc: 80.12%\n",
      "              Val Loss: 2.156343936920166, Val Acc: 68.63%\n",
      "Epoch: 9420,     Training Loss: 0.9264926910400391, Training Acc: 80.12%\n",
      "              Val Loss: 1.6049314737319946, Val Acc: 68.63%\n",
      "Epoch: 9421,     Training Loss: 0.4057711064815521, Training Acc: 80.12%\n",
      "              Val Loss: 2.625718593597412, Val Acc: 68.63%\n",
      "Epoch: 9422,     Training Loss: 1.1993520259857178, Training Acc: 80.12%\n",
      "              Val Loss: 2.534369707107544, Val Acc: 68.62%\n",
      "Epoch: 9423,     Training Loss: 1.5498509407043457, Training Acc: 80.11%\n",
      "              Val Loss: 2.226228952407837, Val Acc: 68.62%\n",
      "Epoch: 9424,     Training Loss: 1.325324535369873, Training Acc: 80.11%\n",
      "              Val Loss: 2.0008575916290283, Val Acc: 68.62%\n",
      "Epoch: 9425,     Training Loss: 0.9524557590484619, Training Acc: 80.11%\n",
      "              Val Loss: 2.392686128616333, Val Acc: 68.62%\n",
      "Epoch: 9426,     Training Loss: 1.1889771223068237, Training Acc: 80.11%\n",
      "              Val Loss: 2.0087060928344727, Val Acc: 68.62%\n",
      "Epoch: 9427,     Training Loss: 0.9191962480545044, Training Acc: 80.11%\n",
      "              Val Loss: 1.7246160507202148, Val Acc: 68.62%\n",
      "Epoch: 9428,     Training Loss: 0.779666543006897, Training Acc: 80.11%\n",
      "              Val Loss: 1.7365434169769287, Val Acc: 68.62%\n",
      "Epoch: 9429,     Training Loss: 0.9253965616226196, Training Acc: 80.10%\n",
      "              Val Loss: 1.4885135889053345, Val Acc: 68.62%\n",
      "Epoch: 9430,     Training Loss: 0.8151935338973999, Training Acc: 80.10%\n",
      "              Val Loss: 1.3223060369491577, Val Acc: 68.62%\n",
      "Epoch: 9431,     Training Loss: 0.7211039662361145, Training Acc: 80.10%\n",
      "              Val Loss: 1.499571681022644, Val Acc: 68.62%\n",
      "Epoch: 9432,     Training Loss: 0.8286667466163635, Training Acc: 80.10%\n",
      "              Val Loss: 1.4825875759124756, Val Acc: 68.62%\n",
      "Epoch: 9433,     Training Loss: 0.7173759937286377, Training Acc: 80.10%\n",
      "              Val Loss: 1.376192331314087, Val Acc: 68.62%\n",
      "Epoch: 9434,     Training Loss: 0.6243254542350769, Training Acc: 80.10%\n",
      "              Val Loss: 1.3555313348770142, Val Acc: 68.62%\n",
      "Epoch: 9435,     Training Loss: 0.6456836462020874, Training Acc: 80.10%\n",
      "              Val Loss: 1.3051505088806152, Val Acc: 68.62%\n",
      "Epoch: 9436,     Training Loss: 0.6030300259590149, Training Acc: 80.10%\n",
      "              Val Loss: 1.2927149534225464, Val Acc: 68.62%\n",
      "Epoch: 9437,     Training Loss: 0.6012906432151794, Training Acc: 80.10%\n",
      "              Val Loss: 1.1660068035125732, Val Acc: 68.62%\n",
      "Epoch: 9438,     Training Loss: 0.5065427422523499, Training Acc: 80.10%\n",
      "              Val Loss: 1.1994376182556152, Val Acc: 68.62%\n",
      "Epoch: 9439,     Training Loss: 0.543235182762146, Training Acc: 80.10%\n",
      "              Val Loss: 1.2445974349975586, Val Acc: 68.62%\n",
      "Epoch: 9440,     Training Loss: 0.531703531742096, Training Acc: 80.10%\n",
      "              Val Loss: 1.2314561605453491, Val Acc: 68.62%\n",
      "Epoch: 9441,     Training Loss: 0.4935832619667053, Training Acc: 80.10%\n",
      "              Val Loss: 1.1078236103057861, Val Acc: 68.62%\n",
      "Epoch: 9442,     Training Loss: 0.44665035605430603, Training Acc: 80.10%\n",
      "              Val Loss: 1.1375784873962402, Val Acc: 68.62%\n",
      "Epoch: 9443,     Training Loss: 0.4864340126514435, Training Acc: 80.10%\n",
      "              Val Loss: 1.1196235418319702, Val Acc: 68.62%\n",
      "Epoch: 9444,     Training Loss: 0.441173791885376, Training Acc: 80.10%\n",
      "              Val Loss: 1.175171136856079, Val Acc: 68.62%\n",
      "Epoch: 9445,     Training Loss: 0.43711236119270325, Training Acc: 80.10%\n",
      "              Val Loss: 1.1425458192825317, Val Acc: 68.62%\n",
      "Epoch: 9446,     Training Loss: 0.42592474818229675, Training Acc: 80.10%\n",
      "              Val Loss: 1.171341896057129, Val Acc: 68.62%\n",
      "Epoch: 9447,     Training Loss: 0.421828955411911, Training Acc: 80.10%\n",
      "              Val Loss: 1.2243746519088745, Val Acc: 68.62%\n",
      "Epoch: 9448,     Training Loss: 0.41146400570869446, Training Acc: 80.10%\n",
      "              Val Loss: 1.1892750263214111, Val Acc: 68.62%\n",
      "Epoch: 9449,     Training Loss: 0.3924560546875, Training Acc: 80.10%\n",
      "              Val Loss: 1.157352089881897, Val Acc: 68.62%\n",
      "Epoch: 9450,     Training Loss: 0.39367181062698364, Training Acc: 80.10%\n",
      "              Val Loss: 1.1837059259414673, Val Acc: 68.62%\n",
      "Epoch: 9451,     Training Loss: 0.3822500705718994, Training Acc: 80.10%\n",
      "              Val Loss: 1.2276939153671265, Val Acc: 68.62%\n",
      "Epoch: 9452,     Training Loss: 0.3808990716934204, Training Acc: 80.10%\n",
      "              Val Loss: 1.2093689441680908, Val Acc: 68.62%\n",
      "Epoch: 9453,     Training Loss: 0.37548545002937317, Training Acc: 80.10%\n",
      "              Val Loss: 1.2391904592514038, Val Acc: 68.62%\n",
      "Epoch: 9454,     Training Loss: 0.35999637842178345, Training Acc: 80.10%\n",
      "              Val Loss: 1.293141484260559, Val Acc: 68.62%\n",
      "Epoch: 9455,     Training Loss: 0.36058157682418823, Training Acc: 80.10%\n",
      "              Val Loss: 1.2609599828720093, Val Acc: 68.62%\n",
      "Epoch: 9456,     Training Loss: 0.35832449793815613, Training Acc: 80.10%\n",
      "              Val Loss: 1.27166748046875, Val Acc: 68.62%\n",
      "Epoch: 9457,     Training Loss: 0.3469756841659546, Training Acc: 80.10%\n",
      "              Val Loss: 1.2996662855148315, Val Acc: 68.62%\n",
      "Epoch: 9458,     Training Loss: 0.3497820198535919, Training Acc: 80.10%\n",
      "              Val Loss: 1.251878261566162, Val Acc: 68.62%\n",
      "Epoch: 9459,     Training Loss: 0.3388725221157074, Training Acc: 80.10%\n",
      "              Val Loss: 1.2499290704727173, Val Acc: 68.62%\n",
      "Epoch: 9460,     Training Loss: 0.3278646171092987, Training Acc: 80.11%\n",
      "              Val Loss: 1.283974051475525, Val Acc: 68.62%\n",
      "Epoch: 9461,     Training Loss: 0.3352278470993042, Training Acc: 80.11%\n",
      "              Val Loss: 1.2337530851364136, Val Acc: 68.62%\n",
      "Epoch: 9462,     Training Loss: 0.32872146368026733, Training Acc: 80.11%\n",
      "              Val Loss: 1.2494481801986694, Val Acc: 68.62%\n",
      "Epoch: 9463,     Training Loss: 0.3177903890609741, Training Acc: 80.11%\n",
      "              Val Loss: 1.2844269275665283, Val Acc: 68.62%\n",
      "Epoch: 9464,     Training Loss: 0.3218018710613251, Training Acc: 80.11%\n",
      "              Val Loss: 1.2595815658569336, Val Acc: 68.62%\n",
      "Epoch: 9465,     Training Loss: 0.31382760405540466, Training Acc: 80.11%\n",
      "              Val Loss: 1.2828612327575684, Val Acc: 68.62%\n",
      "Epoch: 9466,     Training Loss: 0.30692702531814575, Training Acc: 80.11%\n",
      "              Val Loss: 1.3196507692337036, Val Acc: 68.62%\n",
      "Epoch: 9467,     Training Loss: 0.3082299530506134, Training Acc: 80.11%\n",
      "              Val Loss: 1.3036688566207886, Val Acc: 68.62%\n",
      "Epoch: 9468,     Training Loss: 0.3028339743614197, Training Acc: 80.11%\n",
      "              Val Loss: 1.3061928749084473, Val Acc: 68.62%\n",
      "Epoch: 9469,     Training Loss: 0.297697514295578, Training Acc: 80.11%\n",
      "              Val Loss: 1.3254977464675903, Val Acc: 68.63%\n",
      "Epoch: 9470,     Training Loss: 0.29780977964401245, Training Acc: 80.11%\n",
      "              Val Loss: 1.3002846240997314, Val Acc: 68.63%\n",
      "Epoch: 9471,     Training Loss: 0.2906031310558319, Training Acc: 80.11%\n",
      "              Val Loss: 1.3060513734817505, Val Acc: 68.63%\n",
      "Epoch: 9472,     Training Loss: 0.28638526797294617, Training Acc: 80.11%\n",
      "              Val Loss: 1.3332209587097168, Val Acc: 68.63%\n",
      "Epoch: 9473,     Training Loss: 0.2849579453468323, Training Acc: 80.12%\n",
      "              Val Loss: 1.3171786069869995, Val Acc: 68.63%\n",
      "Epoch: 9474,     Training Loss: 0.2780839800834656, Training Acc: 80.12%\n",
      "              Val Loss: 1.3239526748657227, Val Acc: 68.63%\n",
      "Epoch: 9475,     Training Loss: 0.2751043438911438, Training Acc: 80.12%\n",
      "              Val Loss: 1.3580459356307983, Val Acc: 68.63%\n",
      "Epoch: 9476,     Training Loss: 0.2719402313232422, Training Acc: 80.12%\n",
      "              Val Loss: 1.359371542930603, Val Acc: 68.63%\n",
      "Epoch: 9477,     Training Loss: 0.26631978154182434, Training Acc: 80.12%\n",
      "              Val Loss: 1.3701122999191284, Val Acc: 68.63%\n",
      "Epoch: 9478,     Training Loss: 0.26254579424858093, Training Acc: 80.12%\n",
      "              Val Loss: 1.38895583152771, Val Acc: 68.63%\n",
      "Epoch: 9479,     Training Loss: 0.25922828912734985, Training Acc: 80.12%\n",
      "              Val Loss: 1.3804608583450317, Val Acc: 68.63%\n",
      "Epoch: 9480,     Training Loss: 0.25496166944503784, Training Acc: 80.12%\n",
      "              Val Loss: 1.388558030128479, Val Acc: 68.63%\n",
      "Epoch: 9481,     Training Loss: 0.2512827217578888, Training Acc: 80.12%\n",
      "              Val Loss: 1.400290846824646, Val Acc: 68.63%\n",
      "Epoch: 9482,     Training Loss: 0.24898523092269897, Training Acc: 80.12%\n",
      "              Val Loss: 1.3838677406311035, Val Acc: 68.63%\n",
      "Epoch: 9483,     Training Loss: 0.24575649201869965, Training Acc: 80.12%\n",
      "              Val Loss: 1.3946908712387085, Val Acc: 68.63%\n",
      "Epoch: 9484,     Training Loss: 0.24178437888622284, Training Acc: 80.13%\n",
      "              Val Loss: 1.403257131576538, Val Acc: 68.63%\n",
      "Epoch: 9485,     Training Loss: 0.23926416039466858, Training Acc: 80.13%\n",
      "              Val Loss: 1.4034730195999146, Val Acc: 68.63%\n",
      "Epoch: 9486,     Training Loss: 0.2384043186903, Training Acc: 80.13%\n",
      "              Val Loss: 1.4267158508300781, Val Acc: 68.63%\n",
      "Epoch: 9487,     Training Loss: 0.23675380647182465, Training Acc: 80.13%\n",
      "              Val Loss: 1.423179030418396, Val Acc: 68.63%\n",
      "Epoch: 9488,     Training Loss: 0.23455576598644257, Training Acc: 80.13%\n",
      "              Val Loss: 1.4189873933792114, Val Acc: 68.63%\n",
      "Epoch: 9489,     Training Loss: 0.23322910070419312, Training Acc: 80.13%\n",
      "              Val Loss: 1.4286093711853027, Val Acc: 68.63%\n",
      "Epoch: 9490,     Training Loss: 0.2318786084651947, Training Acc: 80.13%\n",
      "              Val Loss: 1.4184528589248657, Val Acc: 68.63%\n",
      "Epoch: 9491,     Training Loss: 0.22943618893623352, Training Acc: 80.13%\n",
      "              Val Loss: 1.4205952882766724, Val Acc: 68.63%\n",
      "Epoch: 9492,     Training Loss: 0.22753696143627167, Training Acc: 80.13%\n",
      "              Val Loss: 1.4314743280410767, Val Acc: 68.63%\n",
      "Epoch: 9493,     Training Loss: 0.22652886807918549, Training Acc: 80.14%\n",
      "              Val Loss: 1.4230128526687622, Val Acc: 68.63%\n",
      "Epoch: 9494,     Training Loss: 0.22476965188980103, Training Acc: 80.14%\n",
      "              Val Loss: 1.4296988248825073, Val Acc: 68.63%\n",
      "Epoch: 9495,     Training Loss: 0.2224978506565094, Training Acc: 80.14%\n",
      "              Val Loss: 1.425422191619873, Val Acc: 68.63%\n",
      "Epoch: 9496,     Training Loss: 0.22069740295410156, Training Acc: 80.14%\n",
      "              Val Loss: 1.4221683740615845, Val Acc: 68.63%\n",
      "Epoch: 9497,     Training Loss: 0.21895290911197662, Training Acc: 80.14%\n",
      "              Val Loss: 1.4385199546813965, Val Acc: 68.63%\n",
      "Epoch: 9498,     Training Loss: 0.21763162314891815, Training Acc: 80.14%\n",
      "              Val Loss: 1.4314181804656982, Val Acc: 68.63%\n",
      "Epoch: 9499,     Training Loss: 0.2155575156211853, Training Acc: 80.14%\n",
      "              Val Loss: 1.4310635328292847, Val Acc: 68.63%\n",
      "Epoch: 9500,     Training Loss: 0.21408310532569885, Training Acc: 80.14%\n",
      "              Val Loss: 1.4389513731002808, Val Acc: 68.63%\n",
      "Epoch: 9501,     Training Loss: 0.21249936521053314, Training Acc: 80.14%\n",
      "              Val Loss: 1.4356416463851929, Val Acc: 68.63%\n",
      "Epoch: 9502,     Training Loss: 0.21150261163711548, Training Acc: 80.15%\n",
      "              Val Loss: 1.4430102109909058, Val Acc: 68.63%\n",
      "Epoch: 9503,     Training Loss: 0.20979946851730347, Training Acc: 80.15%\n",
      "              Val Loss: 1.4514012336730957, Val Acc: 68.63%\n",
      "Epoch: 9504,     Training Loss: 0.209049791097641, Training Acc: 80.15%\n",
      "              Val Loss: 1.4563331604003906, Val Acc: 68.63%\n",
      "Epoch: 9505,     Training Loss: 0.20818711817264557, Training Acc: 80.15%\n",
      "              Val Loss: 1.462052583694458, Val Acc: 68.63%\n",
      "Epoch: 9506,     Training Loss: 0.2068372666835785, Training Acc: 80.15%\n",
      "              Val Loss: 1.4616332054138184, Val Acc: 68.63%\n",
      "Epoch: 9507,     Training Loss: 0.2059565931558609, Training Acc: 80.15%\n",
      "              Val Loss: 1.46498703956604, Val Acc: 68.63%\n",
      "Epoch: 9508,     Training Loss: 0.20515865087509155, Training Acc: 80.15%\n",
      "              Val Loss: 1.4717320203781128, Val Acc: 68.63%\n",
      "Epoch: 9509,     Training Loss: 0.20428813993930817, Training Acc: 80.15%\n",
      "              Val Loss: 1.472710371017456, Val Acc: 68.63%\n",
      "Epoch: 9510,     Training Loss: 0.20343603193759918, Training Acc: 80.16%\n",
      "              Val Loss: 1.4707156419754028, Val Acc: 68.63%\n",
      "Epoch: 9511,     Training Loss: 0.20255640149116516, Training Acc: 80.16%\n",
      "              Val Loss: 1.4768714904785156, Val Acc: 68.63%\n",
      "Epoch: 9512,     Training Loss: 0.20206399261951447, Training Acc: 80.16%\n",
      "              Val Loss: 1.463463544845581, Val Acc: 68.63%\n",
      "Epoch: 9513,     Training Loss: 0.20163381099700928, Training Acc: 80.16%\n",
      "              Val Loss: 1.4736356735229492, Val Acc: 68.63%\n",
      "Epoch: 9514,     Training Loss: 0.20042812824249268, Training Acc: 80.16%\n",
      "              Val Loss: 1.4735321998596191, Val Acc: 68.63%\n",
      "Epoch: 9515,     Training Loss: 0.1993284970521927, Training Acc: 80.16%\n",
      "              Val Loss: 1.4770492315292358, Val Acc: 68.63%\n",
      "Epoch: 9516,     Training Loss: 0.19879668951034546, Training Acc: 80.16%\n",
      "              Val Loss: 1.4870424270629883, Val Acc: 68.63%\n",
      "Epoch: 9517,     Training Loss: 0.19799169898033142, Training Acc: 80.17%\n",
      "              Val Loss: 1.4825944900512695, Val Acc: 68.63%\n",
      "Epoch: 9518,     Training Loss: 0.19731010496616364, Training Acc: 80.17%\n",
      "              Val Loss: 1.4918999671936035, Val Acc: 68.63%\n",
      "Epoch: 9519,     Training Loss: 0.1964280903339386, Training Acc: 80.17%\n",
      "              Val Loss: 1.4954229593276978, Val Acc: 68.63%\n",
      "Epoch: 9520,     Training Loss: 0.1955776810646057, Training Acc: 80.17%\n",
      "              Val Loss: 1.4992457628250122, Val Acc: 68.63%\n",
      "Epoch: 9521,     Training Loss: 0.19502218067646027, Training Acc: 80.17%\n",
      "              Val Loss: 1.5063761472702026, Val Acc: 68.63%\n",
      "Epoch: 9522,     Training Loss: 0.19456681609153748, Training Acc: 80.17%\n",
      "              Val Loss: 1.5030723810195923, Val Acc: 68.63%\n",
      "Epoch: 9523,     Training Loss: 0.19401143491268158, Training Acc: 80.17%\n",
      "              Val Loss: 1.5101356506347656, Val Acc: 68.63%\n",
      "Epoch: 9524,     Training Loss: 0.19326838850975037, Training Acc: 80.17%\n",
      "              Val Loss: 1.503921389579773, Val Acc: 68.63%\n",
      "Epoch: 9525,     Training Loss: 0.1924731284379959, Training Acc: 80.18%\n",
      "              Val Loss: 1.5101306438446045, Val Acc: 68.64%\n",
      "Epoch: 9526,     Training Loss: 0.19188661873340607, Training Acc: 80.18%\n",
      "              Val Loss: 1.5065363645553589, Val Acc: 68.64%\n",
      "Epoch: 9527,     Training Loss: 0.19140270352363586, Training Acc: 80.18%\n",
      "              Val Loss: 1.5058262348175049, Val Acc: 68.64%\n",
      "Epoch: 9528,     Training Loss: 0.19076348841190338, Training Acc: 80.18%\n",
      "              Val Loss: 1.508743166923523, Val Acc: 68.64%\n",
      "Epoch: 9529,     Training Loss: 0.190398707985878, Training Acc: 80.18%\n",
      "              Val Loss: 1.506363034248352, Val Acc: 68.64%\n",
      "Epoch: 9530,     Training Loss: 0.19027963280677795, Training Acc: 80.18%\n",
      "              Val Loss: 1.5153776407241821, Val Acc: 68.64%\n",
      "Epoch: 9531,     Training Loss: 0.1899341344833374, Training Acc: 80.18%\n",
      "              Val Loss: 1.5058684349060059, Val Acc: 68.64%\n",
      "Epoch: 9532,     Training Loss: 0.18958908319473267, Training Acc: 80.18%\n",
      "              Val Loss: 1.5146468877792358, Val Acc: 68.64%\n",
      "Epoch: 9533,     Training Loss: 0.18869701027870178, Training Acc: 80.19%\n",
      "              Val Loss: 1.5054434537887573, Val Acc: 68.64%\n",
      "Epoch: 9534,     Training Loss: 0.1886574923992157, Training Acc: 80.19%\n",
      "              Val Loss: 1.5131232738494873, Val Acc: 68.64%\n",
      "Epoch: 9535,     Training Loss: 0.1882183849811554, Training Acc: 80.19%\n",
      "              Val Loss: 1.5082528591156006, Val Acc: 68.64%\n",
      "Epoch: 9536,     Training Loss: 0.18757450580596924, Training Acc: 80.19%\n",
      "              Val Loss: 1.510237455368042, Val Acc: 68.64%\n",
      "Epoch: 9537,     Training Loss: 0.18681852519512177, Training Acc: 80.19%\n",
      "              Val Loss: 1.5196254253387451, Val Acc: 68.64%\n",
      "Epoch: 9538,     Training Loss: 0.18680335581302643, Training Acc: 80.19%\n",
      "              Val Loss: 1.5031529664993286, Val Acc: 68.64%\n",
      "Epoch: 9539,     Training Loss: 0.18752634525299072, Training Acc: 80.19%\n",
      "              Val Loss: 1.5289595127105713, Val Acc: 68.64%\n",
      "Epoch: 9540,     Training Loss: 0.18783973157405853, Training Acc: 80.19%\n",
      "              Val Loss: 1.5038260221481323, Val Acc: 68.64%\n",
      "Epoch: 9541,     Training Loss: 0.18812812864780426, Training Acc: 80.20%\n",
      "              Val Loss: 1.5303254127502441, Val Acc: 68.64%\n",
      "Epoch: 9542,     Training Loss: 0.18712396919727325, Training Acc: 80.20%\n",
      "              Val Loss: 1.5025821924209595, Val Acc: 68.64%\n",
      "Epoch: 9543,     Training Loss: 0.18652082979679108, Training Acc: 80.20%\n",
      "              Val Loss: 1.5225356817245483, Val Acc: 68.64%\n",
      "Epoch: 9544,     Training Loss: 0.18535774946212769, Training Acc: 80.20%\n",
      "              Val Loss: 1.5074095726013184, Val Acc: 68.64%\n",
      "Epoch: 9545,     Training Loss: 0.18472720682621002, Training Acc: 80.20%\n",
      "              Val Loss: 1.5216915607452393, Val Acc: 68.64%\n",
      "Epoch: 9546,     Training Loss: 0.18376392126083374, Training Acc: 80.20%\n",
      "              Val Loss: 1.518581748008728, Val Acc: 68.64%\n",
      "Epoch: 9547,     Training Loss: 0.18347805738449097, Training Acc: 80.20%\n",
      "              Val Loss: 1.511252760887146, Val Acc: 68.64%\n",
      "Epoch: 9548,     Training Loss: 0.18435819447040558, Training Acc: 80.21%\n",
      "              Val Loss: 1.525297999382019, Val Acc: 68.64%\n",
      "Epoch: 9549,     Training Loss: 0.1838386505842209, Training Acc: 80.21%\n",
      "              Val Loss: 1.5112725496292114, Val Acc: 68.64%\n",
      "Epoch: 9550,     Training Loss: 0.18351325392723083, Training Acc: 80.21%\n",
      "              Val Loss: 1.527706265449524, Val Acc: 68.64%\n",
      "Epoch: 9551,     Training Loss: 0.18300984799861908, Training Acc: 80.21%\n",
      "              Val Loss: 1.5088059902191162, Val Acc: 68.64%\n",
      "Epoch: 9552,     Training Loss: 0.18519096076488495, Training Acc: 80.21%\n",
      "              Val Loss: 1.5342618227005005, Val Acc: 68.64%\n",
      "Epoch: 9553,     Training Loss: 0.18543864786624908, Training Acc: 80.21%\n",
      "              Val Loss: 1.4989349842071533, Val Acc: 68.64%\n",
      "Epoch: 9554,     Training Loss: 0.18898078799247742, Training Acc: 80.21%\n",
      "              Val Loss: 1.546988844871521, Val Acc: 68.64%\n",
      "Epoch: 9555,     Training Loss: 0.1893300563097, Training Acc: 80.22%\n",
      "              Val Loss: 1.4969497919082642, Val Acc: 68.64%\n",
      "Epoch: 9556,     Training Loss: 0.19401313364505768, Training Acc: 80.22%\n",
      "              Val Loss: 1.5488024950027466, Val Acc: 68.64%\n",
      "Epoch: 9557,     Training Loss: 0.18760938942432404, Training Acc: 80.22%\n",
      "              Val Loss: 1.5094294548034668, Val Acc: 68.64%\n",
      "Epoch: 9558,     Training Loss: 0.1838713139295578, Training Acc: 80.22%\n",
      "              Val Loss: 1.531103253364563, Val Acc: 68.64%\n",
      "Epoch: 9559,     Training Loss: 0.18056391179561615, Training Acc: 80.22%\n",
      "              Val Loss: 1.5383458137512207, Val Acc: 68.64%\n",
      "Epoch: 9560,     Training Loss: 0.18087714910507202, Training Acc: 80.22%\n",
      "              Val Loss: 1.5186951160430908, Val Acc: 68.64%\n",
      "Epoch: 9561,     Training Loss: 0.18341463804244995, Training Acc: 80.22%\n",
      "              Val Loss: 1.5574482679367065, Val Acc: 68.64%\n",
      "Epoch: 9562,     Training Loss: 0.1840038150548935, Training Acc: 80.22%\n",
      "              Val Loss: 1.5126205682754517, Val Acc: 68.64%\n",
      "Epoch: 9563,     Training Loss: 0.1896149069070816, Training Acc: 80.23%\n",
      "              Val Loss: 1.5612062215805054, Val Acc: 68.64%\n",
      "Epoch: 9564,     Training Loss: 0.18975627422332764, Training Acc: 80.23%\n",
      "              Val Loss: 1.5042555332183838, Val Acc: 68.64%\n",
      "Epoch: 9565,     Training Loss: 0.19754734635353088, Training Acc: 80.23%\n",
      "              Val Loss: 1.5597503185272217, Val Acc: 68.64%\n",
      "Epoch: 9566,     Training Loss: 0.19124330580234528, Training Acc: 80.23%\n",
      "              Val Loss: 1.500272274017334, Val Acc: 68.64%\n",
      "Epoch: 9567,     Training Loss: 0.1894584596157074, Training Acc: 80.23%\n",
      "              Val Loss: 1.5478405952453613, Val Acc: 68.64%\n",
      "Epoch: 9568,     Training Loss: 0.18457992374897003, Training Acc: 80.23%\n",
      "              Val Loss: 1.523250937461853, Val Acc: 68.64%\n",
      "Epoch: 9569,     Training Loss: 0.18419887125492096, Training Acc: 80.23%\n",
      "              Val Loss: 1.5305442810058594, Val Acc: 68.64%\n",
      "Epoch: 9570,     Training Loss: 0.17961597442626953, Training Acc: 80.24%\n",
      "              Val Loss: 1.5571900606155396, Val Acc: 68.64%\n",
      "Epoch: 9571,     Training Loss: 0.18229198455810547, Training Acc: 80.24%\n",
      "              Val Loss: 1.5233163833618164, Val Acc: 68.64%\n",
      "Epoch: 9572,     Training Loss: 0.1925562024116516, Training Acc: 80.24%\n",
      "              Val Loss: 1.5595734119415283, Val Acc: 68.64%\n",
      "Epoch: 9573,     Training Loss: 0.1829451322555542, Training Acc: 80.24%\n",
      "              Val Loss: 1.533483624458313, Val Acc: 68.64%\n",
      "Epoch: 9574,     Training Loss: 0.18188545107841492, Training Acc: 80.24%\n",
      "              Val Loss: 1.5412410497665405, Val Acc: 68.64%\n",
      "Epoch: 9575,     Training Loss: 0.18540389835834503, Training Acc: 80.24%\n",
      "              Val Loss: 1.534443974494934, Val Acc: 68.64%\n",
      "Epoch: 9576,     Training Loss: 0.1919589787721634, Training Acc: 80.24%\n",
      "              Val Loss: 1.5543720722198486, Val Acc: 68.64%\n",
      "Epoch: 9577,     Training Loss: 0.18699003756046295, Training Acc: 80.24%\n",
      "              Val Loss: 1.5204123258590698, Val Acc: 68.64%\n",
      "Epoch: 9578,     Training Loss: 0.17950056493282318, Training Acc: 80.25%\n",
      "              Val Loss: 1.5436797142028809, Val Acc: 68.64%\n",
      "Epoch: 9579,     Training Loss: 0.18363162875175476, Training Acc: 80.25%\n",
      "              Val Loss: 1.5336112976074219, Val Acc: 68.64%\n",
      "Epoch: 9580,     Training Loss: 0.19301439821720123, Training Acc: 80.25%\n",
      "              Val Loss: 1.5592952966690063, Val Acc: 68.64%\n",
      "Epoch: 9581,     Training Loss: 0.18322379887104034, Training Acc: 80.25%\n",
      "              Val Loss: 1.52463698387146, Val Acc: 68.64%\n",
      "Epoch: 9582,     Training Loss: 0.18500873446464539, Training Acc: 80.25%\n",
      "              Val Loss: 1.5731821060180664, Val Acc: 68.64%\n",
      "Epoch: 9583,     Training Loss: 0.1842000037431717, Training Acc: 80.25%\n",
      "              Val Loss: 1.5341206789016724, Val Acc: 68.64%\n",
      "Epoch: 9584,     Training Loss: 0.19643886387348175, Training Acc: 80.25%\n",
      "              Val Loss: 1.5627425909042358, Val Acc: 68.64%\n",
      "Epoch: 9585,     Training Loss: 0.19389930367469788, Training Acc: 80.25%\n",
      "              Val Loss: 1.5105445384979248, Val Acc: 68.64%\n",
      "Epoch: 9586,     Training Loss: 0.1912516951560974, Training Acc: 80.26%\n",
      "              Val Loss: 1.5885231494903564, Val Acc: 68.64%\n",
      "Epoch: 9587,     Training Loss: 0.19753389060497284, Training Acc: 80.26%\n",
      "              Val Loss: 1.5230435132980347, Val Acc: 68.64%\n",
      "Epoch: 9588,     Training Loss: 0.23130641877651215, Training Acc: 80.26%\n",
      "              Val Loss: 1.5733331441879272, Val Acc: 68.64%\n",
      "Epoch: 9589,     Training Loss: 0.19171808660030365, Training Acc: 80.26%\n",
      "              Val Loss: 1.5706270933151245, Val Acc: 68.64%\n",
      "Epoch: 9590,     Training Loss: 0.2061605602502823, Training Acc: 80.26%\n",
      "              Val Loss: 1.5202618837356567, Val Acc: 68.65%\n",
      "Epoch: 9591,     Training Loss: 0.20290063321590424, Training Acc: 80.26%\n",
      "              Val Loss: 1.5468628406524658, Val Acc: 68.65%\n",
      "Epoch: 9592,     Training Loss: 0.20654340088367462, Training Acc: 80.26%\n",
      "              Val Loss: 1.5712238550186157, Val Acc: 68.65%\n",
      "Epoch: 9593,     Training Loss: 0.22618374228477478, Training Acc: 80.26%\n",
      "              Val Loss: 1.5398024320602417, Val Acc: 68.65%\n",
      "Epoch: 9594,     Training Loss: 0.18502958118915558, Training Acc: 80.27%\n",
      "              Val Loss: 1.5677913427352905, Val Acc: 68.65%\n",
      "Epoch: 9595,     Training Loss: 0.22745127975940704, Training Acc: 80.27%\n",
      "              Val Loss: 1.5465949773788452, Val Acc: 68.65%\n",
      "Epoch: 9596,     Training Loss: 0.2319335788488388, Training Acc: 80.27%\n",
      "              Val Loss: 1.6285548210144043, Val Acc: 68.65%\n",
      "Epoch: 9597,     Training Loss: 0.22292660176753998, Training Acc: 80.27%\n",
      "              Val Loss: 1.5555649995803833, Val Acc: 68.65%\n",
      "Epoch: 9598,     Training Loss: 0.29884961247444153, Training Acc: 80.27%\n",
      "              Val Loss: 1.6256605386734009, Val Acc: 68.65%\n",
      "Epoch: 9599,     Training Loss: 0.25407662987709045, Training Acc: 80.27%\n",
      "              Val Loss: 1.71763277053833, Val Acc: 68.65%\n",
      "Epoch: 9600,     Training Loss: 0.4137178659439087, Training Acc: 80.27%\n",
      "              Val Loss: 1.4765266180038452, Val Acc: 68.65%\n",
      "Epoch: 9601,     Training Loss: 0.22118015587329865, Training Acc: 80.27%\n",
      "              Val Loss: 1.5778874158859253, Val Acc: 68.65%\n",
      "Epoch: 9602,     Training Loss: 0.32697781920433044, Training Acc: 80.27%\n",
      "              Val Loss: 1.6358603239059448, Val Acc: 68.65%\n",
      "Epoch: 9603,     Training Loss: 0.47801509499549866, Training Acc: 80.27%\n",
      "              Val Loss: 1.8722405433654785, Val Acc: 68.65%\n",
      "Epoch: 9604,     Training Loss: 0.4606333076953888, Training Acc: 80.27%\n",
      "              Val Loss: 1.7431814670562744, Val Acc: 68.64%\n",
      "Epoch: 9605,     Training Loss: 0.5852094888687134, Training Acc: 80.27%\n",
      "              Val Loss: 1.879135012626648, Val Acc: 68.64%\n",
      "Epoch: 9606,     Training Loss: 0.8005406856536865, Training Acc: 80.27%\n",
      "              Val Loss: 1.6058965921401978, Val Acc: 68.64%\n",
      "Epoch: 9607,     Training Loss: 0.48785194754600525, Training Acc: 80.27%\n",
      "              Val Loss: 1.6416822671890259, Val Acc: 68.64%\n",
      "Epoch: 9608,     Training Loss: 0.5772902965545654, Training Acc: 80.27%\n",
      "              Val Loss: 1.6464217901229858, Val Acc: 68.64%\n",
      "Epoch: 9609,     Training Loss: 0.6250030398368835, Training Acc: 80.27%\n",
      "              Val Loss: 1.4639816284179688, Val Acc: 68.64%\n",
      "Epoch: 9610,     Training Loss: 0.42330801486968994, Training Acc: 80.27%\n",
      "              Val Loss: 1.6693257093429565, Val Acc: 68.64%\n",
      "Epoch: 9611,     Training Loss: 0.6024531722068787, Training Acc: 80.27%\n",
      "              Val Loss: 1.5584408044815063, Val Acc: 68.64%\n",
      "Epoch: 9612,     Training Loss: 0.6370452046394348, Training Acc: 80.27%\n",
      "              Val Loss: 1.4222004413604736, Val Acc: 68.64%\n",
      "Epoch: 9613,     Training Loss: 0.6285673379898071, Training Acc: 80.27%\n",
      "              Val Loss: 1.474953293800354, Val Acc: 68.64%\n",
      "Epoch: 9614,     Training Loss: 0.6027488112449646, Training Acc: 80.27%\n",
      "              Val Loss: 1.3375390768051147, Val Acc: 68.64%\n",
      "Epoch: 9615,     Training Loss: 0.49212658405303955, Training Acc: 80.27%\n",
      "              Val Loss: 1.4257136583328247, Val Acc: 68.64%\n",
      "Epoch: 9616,     Training Loss: 0.503197968006134, Training Acc: 80.27%\n",
      "              Val Loss: 1.5316667556762695, Val Acc: 68.64%\n",
      "Epoch: 9617,     Training Loss: 0.4988667368888855, Training Acc: 80.27%\n",
      "              Val Loss: 1.5020499229431152, Val Acc: 68.64%\n",
      "Epoch: 9618,     Training Loss: 0.4940735101699829, Training Acc: 80.27%\n",
      "              Val Loss: 1.3061524629592896, Val Acc: 68.64%\n",
      "Epoch: 9619,     Training Loss: 0.43108561635017395, Training Acc: 80.27%\n",
      "              Val Loss: 1.2689597606658936, Val Acc: 68.64%\n",
      "Epoch: 9620,     Training Loss: 0.4113370478153229, Training Acc: 80.27%\n",
      "              Val Loss: 1.2812010049819946, Val Acc: 68.64%\n",
      "Epoch: 9621,     Training Loss: 0.4080820381641388, Training Acc: 80.27%\n",
      "              Val Loss: 1.2259411811828613, Val Acc: 68.64%\n",
      "Epoch: 9622,     Training Loss: 0.4241420328617096, Training Acc: 80.27%\n",
      "              Val Loss: 1.1686522960662842, Val Acc: 68.64%\n",
      "Epoch: 9623,     Training Loss: 0.3629247546195984, Training Acc: 80.27%\n",
      "              Val Loss: 1.3087055683135986, Val Acc: 68.64%\n",
      "Epoch: 9624,     Training Loss: 0.4061141908168793, Training Acc: 80.27%\n",
      "              Val Loss: 1.234354853630066, Val Acc: 68.64%\n",
      "Epoch: 9625,     Training Loss: 0.35922446846961975, Training Acc: 80.27%\n",
      "              Val Loss: 1.2443734407424927, Val Acc: 68.64%\n",
      "Epoch: 9626,     Training Loss: 0.3497962951660156, Training Acc: 80.27%\n",
      "              Val Loss: 1.3325390815734863, Val Acc: 68.65%\n",
      "Epoch: 9627,     Training Loss: 0.37326741218566895, Training Acc: 80.27%\n",
      "              Val Loss: 1.2232184410095215, Val Acc: 68.65%\n",
      "Epoch: 9628,     Training Loss: 0.3579944670200348, Training Acc: 80.27%\n",
      "              Val Loss: 1.2149977684020996, Val Acc: 68.65%\n",
      "Epoch: 9629,     Training Loss: 0.32824069261550903, Training Acc: 80.27%\n",
      "              Val Loss: 1.3309905529022217, Val Acc: 68.65%\n",
      "Epoch: 9630,     Training Loss: 0.3461323082447052, Training Acc: 80.27%\n",
      "              Val Loss: 1.2516822814941406, Val Acc: 68.65%\n",
      "Epoch: 9631,     Training Loss: 0.34821030497550964, Training Acc: 80.27%\n",
      "              Val Loss: 1.2501224279403687, Val Acc: 68.65%\n",
      "Epoch: 9632,     Training Loss: 0.29160168766975403, Training Acc: 80.27%\n",
      "              Val Loss: 1.3989490270614624, Val Acc: 68.65%\n",
      "Epoch: 9633,     Training Loss: 0.3562431335449219, Training Acc: 80.28%\n",
      "              Val Loss: 1.332249402999878, Val Acc: 68.65%\n",
      "Epoch: 9634,     Training Loss: 0.40911656618118286, Training Acc: 80.28%\n",
      "              Val Loss: 1.2778476476669312, Val Acc: 68.65%\n",
      "Epoch: 9635,     Training Loss: 0.30149349570274353, Training Acc: 80.28%\n",
      "              Val Loss: 1.602708339691162, Val Acc: 68.65%\n",
      "Epoch: 9636,     Training Loss: 0.45258763432502747, Training Acc: 80.28%\n",
      "              Val Loss: 1.4732682704925537, Val Acc: 68.65%\n",
      "Epoch: 9637,     Training Loss: 0.5307897329330444, Training Acc: 80.28%\n",
      "              Val Loss: 1.3661683797836304, Val Acc: 68.65%\n",
      "Epoch: 9638,     Training Loss: 0.3644504249095917, Training Acc: 80.28%\n",
      "              Val Loss: 1.8845131397247314, Val Acc: 68.65%\n",
      "Epoch: 9639,     Training Loss: 0.6150119304656982, Training Acc: 80.28%\n",
      "              Val Loss: 1.6700760126113892, Val Acc: 68.65%\n",
      "Epoch: 9640,     Training Loss: 0.6790545582771301, Training Acc: 80.28%\n",
      "              Val Loss: 1.5761077404022217, Val Acc: 68.65%\n",
      "Epoch: 9641,     Training Loss: 0.6215024590492249, Training Acc: 80.28%\n",
      "              Val Loss: 1.6160824298858643, Val Acc: 68.65%\n",
      "Epoch: 9642,     Training Loss: 0.5006362795829773, Training Acc: 80.27%\n",
      "              Val Loss: 1.5419065952301025, Val Acc: 68.65%\n",
      "Epoch: 9643,     Training Loss: 0.42764025926589966, Training Acc: 80.28%\n",
      "              Val Loss: 1.5290790796279907, Val Acc: 68.65%\n",
      "Epoch: 9644,     Training Loss: 0.4766567647457123, Training Acc: 80.28%\n",
      "              Val Loss: 1.4577133655548096, Val Acc: 68.65%\n",
      "Epoch: 9645,     Training Loss: 0.4656635522842407, Training Acc: 80.28%\n",
      "              Val Loss: 1.3633296489715576, Val Acc: 68.65%\n",
      "Epoch: 9646,     Training Loss: 0.36061105132102966, Training Acc: 80.28%\n",
      "              Val Loss: 1.4257686138153076, Val Acc: 68.65%\n",
      "Epoch: 9647,     Training Loss: 0.4258768856525421, Training Acc: 80.28%\n",
      "              Val Loss: 1.2236509323120117, Val Acc: 68.65%\n",
      "Epoch: 9648,     Training Loss: 0.39466243982315063, Training Acc: 80.28%\n",
      "              Val Loss: 1.286229133605957, Val Acc: 68.65%\n",
      "Epoch: 9649,     Training Loss: 0.40913689136505127, Training Acc: 80.28%\n",
      "              Val Loss: 1.4269250631332397, Val Acc: 68.65%\n",
      "Epoch: 9650,     Training Loss: 0.35873955488204956, Training Acc: 80.28%\n",
      "              Val Loss: 1.4446799755096436, Val Acc: 68.64%\n",
      "Epoch: 9651,     Training Loss: 0.3860173523426056, Training Acc: 80.28%\n",
      "              Val Loss: 1.2762469053268433, Val Acc: 68.64%\n",
      "Epoch: 9652,     Training Loss: 0.3445674777030945, Training Acc: 80.28%\n",
      "              Val Loss: 1.3192881345748901, Val Acc: 68.64%\n",
      "Epoch: 9653,     Training Loss: 0.3339218497276306, Training Acc: 80.28%\n",
      "              Val Loss: 1.4623985290527344, Val Acc: 68.65%\n",
      "Epoch: 9654,     Training Loss: 0.3530062437057495, Training Acc: 80.28%\n",
      "              Val Loss: 1.324741244316101, Val Acc: 68.64%\n",
      "Epoch: 9655,     Training Loss: 0.3330233693122864, Training Acc: 80.28%\n",
      "              Val Loss: 1.3032101392745972, Val Acc: 68.64%\n",
      "Epoch: 9656,     Training Loss: 0.33638110756874084, Training Acc: 80.28%\n",
      "              Val Loss: 1.3852152824401855, Val Acc: 68.64%\n",
      "Epoch: 9657,     Training Loss: 0.30696991086006165, Training Acc: 80.28%\n",
      "              Val Loss: 1.396651029586792, Val Acc: 68.65%\n",
      "Epoch: 9658,     Training Loss: 0.2765980660915375, Training Acc: 80.28%\n",
      "              Val Loss: 1.4128440618515015, Val Acc: 68.65%\n",
      "Epoch: 9659,     Training Loss: 0.3025059401988983, Training Acc: 80.28%\n",
      "              Val Loss: 1.4557844400405884, Val Acc: 68.65%\n",
      "Epoch: 9660,     Training Loss: 0.28635862469673157, Training Acc: 80.28%\n",
      "              Val Loss: 1.514824390411377, Val Acc: 68.65%\n",
      "Epoch: 9661,     Training Loss: 0.2855035066604614, Training Acc: 80.28%\n",
      "              Val Loss: 1.384248971939087, Val Acc: 68.65%\n",
      "Epoch: 9662,     Training Loss: 0.25893929600715637, Training Acc: 80.28%\n",
      "              Val Loss: 1.3846969604492188, Val Acc: 68.64%\n",
      "Epoch: 9663,     Training Loss: 0.27228325605392456, Training Acc: 80.29%\n",
      "              Val Loss: 1.4446238279342651, Val Acc: 68.65%\n",
      "Epoch: 9664,     Training Loss: 0.24473215639591217, Training Acc: 80.29%\n",
      "              Val Loss: 1.453299880027771, Val Acc: 68.65%\n",
      "Epoch: 9665,     Training Loss: 0.24847355484962463, Training Acc: 80.29%\n",
      "              Val Loss: 1.3944233655929565, Val Acc: 68.65%\n",
      "Epoch: 9666,     Training Loss: 0.24078285694122314, Training Acc: 80.29%\n",
      "              Val Loss: 1.4629707336425781, Val Acc: 68.65%\n",
      "Epoch: 9667,     Training Loss: 0.24633623659610748, Training Acc: 80.29%\n",
      "              Val Loss: 1.4516607522964478, Val Acc: 68.65%\n",
      "Epoch: 9668,     Training Loss: 0.22356736660003662, Training Acc: 80.29%\n",
      "              Val Loss: 1.4214637279510498, Val Acc: 68.65%\n",
      "Epoch: 9669,     Training Loss: 0.23421503603458405, Training Acc: 80.29%\n",
      "              Val Loss: 1.4202824831008911, Val Acc: 68.65%\n",
      "Epoch: 9670,     Training Loss: 0.21454744040966034, Training Acc: 80.29%\n",
      "              Val Loss: 1.45589017868042, Val Acc: 68.65%\n",
      "Epoch: 9671,     Training Loss: 0.2227116972208023, Training Acc: 80.29%\n",
      "              Val Loss: 1.4263168573379517, Val Acc: 68.65%\n",
      "Epoch: 9672,     Training Loss: 0.2225022166967392, Training Acc: 80.29%\n",
      "              Val Loss: 1.4835906028747559, Val Acc: 68.65%\n",
      "Epoch: 9673,     Training Loss: 0.21156863868236542, Training Acc: 80.30%\n",
      "              Val Loss: 1.4719270467758179, Val Acc: 68.65%\n",
      "Epoch: 9674,     Training Loss: 0.21540546417236328, Training Acc: 80.30%\n",
      "              Val Loss: 1.4154032468795776, Val Acc: 68.65%\n",
      "Epoch: 9675,     Training Loss: 0.21187803149223328, Training Acc: 80.30%\n",
      "              Val Loss: 1.4547815322875977, Val Acc: 68.65%\n",
      "Epoch: 9676,     Training Loss: 0.20835793018341064, Training Acc: 80.30%\n",
      "              Val Loss: 1.4571592807769775, Val Acc: 68.65%\n",
      "Epoch: 9677,     Training Loss: 0.20506928861141205, Training Acc: 80.30%\n",
      "              Val Loss: 1.4473044872283936, Val Acc: 68.65%\n",
      "Epoch: 9678,     Training Loss: 0.19853177666664124, Training Acc: 80.30%\n",
      "              Val Loss: 1.4896736145019531, Val Acc: 68.65%\n",
      "Epoch: 9679,     Training Loss: 0.2049654722213745, Training Acc: 80.30%\n",
      "              Val Loss: 1.4794096946716309, Val Acc: 68.65%\n",
      "Epoch: 9680,     Training Loss: 0.19700293242931366, Training Acc: 80.30%\n",
      "              Val Loss: 1.4891546964645386, Val Acc: 68.65%\n",
      "Epoch: 9681,     Training Loss: 0.1944759339094162, Training Acc: 80.31%\n",
      "              Val Loss: 1.4918866157531738, Val Acc: 68.65%\n",
      "Epoch: 9682,     Training Loss: 0.1988898664712906, Training Acc: 80.31%\n",
      "              Val Loss: 1.4750880002975464, Val Acc: 68.65%\n",
      "Epoch: 9683,     Training Loss: 0.19383519887924194, Training Acc: 80.31%\n",
      "              Val Loss: 1.5234724283218384, Val Acc: 68.65%\n",
      "Epoch: 9684,     Training Loss: 0.19587963819503784, Training Acc: 80.31%\n",
      "              Val Loss: 1.481055498123169, Val Acc: 68.65%\n",
      "Epoch: 9685,     Training Loss: 0.19407054781913757, Training Acc: 80.31%\n",
      "              Val Loss: 1.4922027587890625, Val Acc: 68.65%\n",
      "Epoch: 9686,     Training Loss: 0.18850177526474, Training Acc: 80.31%\n",
      "              Val Loss: 1.5173447132110596, Val Acc: 68.65%\n",
      "Epoch: 9687,     Training Loss: 0.1921364963054657, Training Acc: 80.31%\n",
      "              Val Loss: 1.482737421989441, Val Acc: 68.65%\n",
      "Epoch: 9688,     Training Loss: 0.18835845589637756, Training Acc: 80.31%\n",
      "              Val Loss: 1.490931510925293, Val Acc: 68.65%\n",
      "Epoch: 9689,     Training Loss: 0.18874847888946533, Training Acc: 80.32%\n",
      "              Val Loss: 1.49558687210083, Val Acc: 68.65%\n",
      "Epoch: 9690,     Training Loss: 0.18800801038742065, Training Acc: 80.32%\n",
      "              Val Loss: 1.4953938722610474, Val Acc: 68.65%\n",
      "Epoch: 9691,     Training Loss: 0.1831466555595398, Training Acc: 80.32%\n",
      "              Val Loss: 1.5135949850082397, Val Acc: 68.65%\n",
      "Epoch: 9692,     Training Loss: 0.18668638169765472, Training Acc: 80.32%\n",
      "              Val Loss: 1.4874736070632935, Val Acc: 68.65%\n",
      "Epoch: 9693,     Training Loss: 0.18725982308387756, Training Acc: 80.32%\n",
      "              Val Loss: 1.512132167816162, Val Acc: 68.65%\n",
      "Epoch: 9694,     Training Loss: 0.18377642333507538, Training Acc: 80.32%\n",
      "              Val Loss: 1.4889808893203735, Val Acc: 68.65%\n",
      "Epoch: 9695,     Training Loss: 0.18433105945587158, Training Acc: 80.32%\n",
      "              Val Loss: 1.522119164466858, Val Acc: 68.65%\n",
      "Epoch: 9696,     Training Loss: 0.1817367672920227, Training Acc: 80.32%\n",
      "              Val Loss: 1.5150024890899658, Val Acc: 68.65%\n",
      "Epoch: 9697,     Training Loss: 0.18136900663375854, Training Acc: 80.33%\n",
      "              Val Loss: 1.528721570968628, Val Acc: 68.65%\n",
      "Epoch: 9698,     Training Loss: 0.18095283210277557, Training Acc: 80.33%\n",
      "              Val Loss: 1.5181241035461426, Val Acc: 68.65%\n",
      "Epoch: 9699,     Training Loss: 0.1792663335800171, Training Acc: 80.33%\n",
      "              Val Loss: 1.5189117193222046, Val Acc: 68.65%\n",
      "Epoch: 9700,     Training Loss: 0.17920368909835815, Training Acc: 80.33%\n",
      "              Val Loss: 1.5159553289413452, Val Acc: 68.65%\n",
      "Epoch: 9701,     Training Loss: 0.17876467108726501, Training Acc: 80.33%\n",
      "              Val Loss: 1.5202511548995972, Val Acc: 68.65%\n",
      "Epoch: 9702,     Training Loss: 0.17847591638565063, Training Acc: 80.33%\n",
      "              Val Loss: 1.529334306716919, Val Acc: 68.65%\n",
      "Epoch: 9703,     Training Loss: 0.1779555082321167, Training Acc: 80.33%\n",
      "              Val Loss: 1.5199302434921265, Val Acc: 68.65%\n",
      "Epoch: 9704,     Training Loss: 0.17743933200836182, Training Acc: 80.33%\n",
      "              Val Loss: 1.521888017654419, Val Acc: 68.65%\n",
      "Epoch: 9705,     Training Loss: 0.1772897094488144, Training Acc: 80.34%\n",
      "              Val Loss: 1.5292108058929443, Val Acc: 68.65%\n",
      "Epoch: 9706,     Training Loss: 0.1770235300064087, Training Acc: 80.34%\n",
      "              Val Loss: 1.5156316757202148, Val Acc: 68.65%\n",
      "Epoch: 9707,     Training Loss: 0.17779354751110077, Training Acc: 80.34%\n",
      "              Val Loss: 1.5365214347839355, Val Acc: 68.65%\n",
      "Epoch: 9708,     Training Loss: 0.1782211810350418, Training Acc: 80.34%\n",
      "              Val Loss: 1.504644751548767, Val Acc: 68.65%\n",
      "Epoch: 9709,     Training Loss: 0.1808684915304184, Training Acc: 80.34%\n",
      "              Val Loss: 1.5472912788391113, Val Acc: 68.65%\n",
      "Epoch: 9710,     Training Loss: 0.18243947625160217, Training Acc: 80.34%\n",
      "              Val Loss: 1.498294711112976, Val Acc: 68.65%\n",
      "Epoch: 9711,     Training Loss: 0.1860274076461792, Training Acc: 80.34%\n",
      "              Val Loss: 1.558347225189209, Val Acc: 68.65%\n",
      "Epoch: 9712,     Training Loss: 0.18384811282157898, Training Acc: 80.35%\n",
      "              Val Loss: 1.495571494102478, Val Acc: 68.65%\n",
      "Epoch: 9713,     Training Loss: 0.1858077198266983, Training Acc: 80.35%\n",
      "              Val Loss: 1.5501154661178589, Val Acc: 68.65%\n",
      "Epoch: 9714,     Training Loss: 0.18184499442577362, Training Acc: 80.35%\n",
      "              Val Loss: 1.4996455907821655, Val Acc: 68.65%\n",
      "Epoch: 9715,     Training Loss: 0.1801939606666565, Training Acc: 80.35%\n",
      "              Val Loss: 1.5266953706741333, Val Acc: 68.65%\n",
      "Epoch: 9716,     Training Loss: 0.17609253525733948, Training Acc: 80.35%\n",
      "              Val Loss: 1.518625020980835, Val Acc: 68.65%\n",
      "Epoch: 9717,     Training Loss: 0.1745859533548355, Training Acc: 80.35%\n",
      "              Val Loss: 1.5041042566299438, Val Acc: 68.65%\n",
      "Epoch: 9718,     Training Loss: 0.1765650510787964, Training Acc: 80.35%\n",
      "              Val Loss: 1.5390846729278564, Val Acc: 68.65%\n",
      "Epoch: 9719,     Training Loss: 0.17897291481494904, Training Acc: 80.35%\n",
      "              Val Loss: 1.4918437004089355, Val Acc: 68.65%\n",
      "Epoch: 9720,     Training Loss: 0.18588727712631226, Training Acc: 80.36%\n",
      "              Val Loss: 1.5668655633926392, Val Acc: 68.65%\n",
      "Epoch: 9721,     Training Loss: 0.18825797736644745, Training Acc: 80.36%\n",
      "              Val Loss: 1.493156909942627, Val Acc: 68.65%\n",
      "Epoch: 9722,     Training Loss: 0.19622273743152618, Training Acc: 80.36%\n",
      "              Val Loss: 1.5665888786315918, Val Acc: 68.65%\n",
      "Epoch: 9723,     Training Loss: 0.18724653124809265, Training Acc: 80.36%\n",
      "              Val Loss: 1.4955030679702759, Val Acc: 68.65%\n",
      "Epoch: 9724,     Training Loss: 0.18420061469078064, Training Acc: 80.36%\n",
      "              Val Loss: 1.5351643562316895, Val Acc: 68.65%\n",
      "Epoch: 9725,     Training Loss: 0.175824373960495, Training Acc: 80.36%\n",
      "              Val Loss: 1.526283621788025, Val Acc: 68.65%\n",
      "Epoch: 9726,     Training Loss: 0.1741124987602234, Training Acc: 80.36%\n",
      "              Val Loss: 1.499348759651184, Val Acc: 68.65%\n",
      "Epoch: 9727,     Training Loss: 0.17815373837947845, Training Acc: 80.36%\n",
      "              Val Loss: 1.554315209388733, Val Acc: 68.65%\n",
      "Epoch: 9728,     Training Loss: 0.18059392273426056, Training Acc: 80.37%\n",
      "              Val Loss: 1.4995907545089722, Val Acc: 68.65%\n",
      "Epoch: 9729,     Training Loss: 0.18743745982646942, Training Acc: 80.37%\n",
      "              Val Loss: 1.5700050592422485, Val Acc: 68.66%\n",
      "Epoch: 9730,     Training Loss: 0.1833728849887848, Training Acc: 80.37%\n",
      "              Val Loss: 1.5034172534942627, Val Acc: 68.66%\n",
      "Epoch: 9731,     Training Loss: 0.18455225229263306, Training Acc: 80.37%\n",
      "              Val Loss: 1.5546296834945679, Val Acc: 68.66%\n",
      "Epoch: 9732,     Training Loss: 0.17738232016563416, Training Acc: 80.37%\n",
      "              Val Loss: 1.5116760730743408, Val Acc: 68.66%\n",
      "Epoch: 9733,     Training Loss: 0.1747293919324875, Training Acc: 80.37%\n",
      "              Val Loss: 1.530838966369629, Val Acc: 68.66%\n",
      "Epoch: 9734,     Training Loss: 0.17232881486415863, Training Acc: 80.37%\n",
      "              Val Loss: 1.5328158140182495, Val Acc: 68.66%\n",
      "Epoch: 9735,     Training Loss: 0.1723175197839737, Training Acc: 80.38%\n",
      "              Val Loss: 1.5085231065750122, Val Acc: 68.66%\n",
      "Epoch: 9736,     Training Loss: 0.17452138662338257, Training Acc: 80.38%\n",
      "              Val Loss: 1.5525453090667725, Val Acc: 68.66%\n",
      "Epoch: 9737,     Training Loss: 0.17696668207645416, Training Acc: 80.38%\n",
      "              Val Loss: 1.5071349143981934, Val Acc: 68.66%\n",
      "Epoch: 9738,     Training Loss: 0.18466834723949432, Training Acc: 80.38%\n",
      "              Val Loss: 1.5844961404800415, Val Acc: 68.66%\n",
      "Epoch: 9739,     Training Loss: 0.18529756367206573, Training Acc: 80.38%\n",
      "              Val Loss: 1.5005685091018677, Val Acc: 68.66%\n",
      "Epoch: 9740,     Training Loss: 0.1935896873474121, Training Acc: 80.38%\n",
      "              Val Loss: 1.5735529661178589, Val Acc: 68.66%\n",
      "Epoch: 9741,     Training Loss: 0.18221338093280792, Training Acc: 80.38%\n",
      "              Val Loss: 1.5078444480895996, Val Acc: 68.66%\n",
      "Epoch: 9742,     Training Loss: 0.17838041484355927, Training Acc: 80.38%\n",
      "              Val Loss: 1.5320725440979004, Val Acc: 68.66%\n",
      "Epoch: 9743,     Training Loss: 0.1719590127468109, Training Acc: 80.39%\n",
      "              Val Loss: 1.5357110500335693, Val Acc: 68.66%\n",
      "Epoch: 9744,     Training Loss: 0.1720910221338272, Training Acc: 80.39%\n",
      "              Val Loss: 1.5113698244094849, Val Acc: 68.66%\n",
      "Epoch: 9745,     Training Loss: 0.1775650978088379, Training Acc: 80.39%\n",
      "              Val Loss: 1.5717146396636963, Val Acc: 68.66%\n",
      "Epoch: 9746,     Training Loss: 0.18080513179302216, Training Acc: 80.39%\n",
      "              Val Loss: 1.502008080482483, Val Acc: 68.66%\n",
      "Epoch: 9747,     Training Loss: 0.19195249676704407, Training Acc: 80.39%\n",
      "              Val Loss: 1.5846213102340698, Val Acc: 68.66%\n",
      "Epoch: 9748,     Training Loss: 0.18419067561626434, Training Acc: 80.39%\n",
      "              Val Loss: 1.5113215446472168, Val Acc: 68.66%\n",
      "Epoch: 9749,     Training Loss: 0.18647366762161255, Training Acc: 80.39%\n",
      "              Val Loss: 1.5598846673965454, Val Acc: 68.66%\n",
      "Epoch: 9750,     Training Loss: 0.17536035180091858, Training Acc: 80.39%\n",
      "              Val Loss: 1.5207594633102417, Val Acc: 68.66%\n",
      "Epoch: 9751,     Training Loss: 0.17112623155117035, Training Acc: 80.40%\n",
      "              Val Loss: 1.5279957056045532, Val Acc: 68.66%\n",
      "Epoch: 9752,     Training Loss: 0.17056848108768463, Training Acc: 80.40%\n",
      "              Val Loss: 1.556994915008545, Val Acc: 68.66%\n",
      "Epoch: 9753,     Training Loss: 0.17281000316143036, Training Acc: 80.40%\n",
      "              Val Loss: 1.5119900703430176, Val Acc: 68.66%\n",
      "Epoch: 9754,     Training Loss: 0.179438054561615, Training Acc: 80.40%\n",
      "              Val Loss: 1.5805020332336426, Val Acc: 68.66%\n",
      "Epoch: 9755,     Training Loss: 0.17969506978988647, Training Acc: 80.40%\n",
      "              Val Loss: 1.5095622539520264, Val Acc: 68.66%\n",
      "Epoch: 9756,     Training Loss: 0.18662267923355103, Training Acc: 80.40%\n",
      "              Val Loss: 1.5767548084259033, Val Acc: 68.66%\n",
      "Epoch: 9757,     Training Loss: 0.181178480386734, Training Acc: 80.40%\n",
      "              Val Loss: 1.506889820098877, Val Acc: 68.66%\n",
      "Epoch: 9758,     Training Loss: 0.18274852633476257, Training Acc: 80.40%\n",
      "              Val Loss: 1.5641728639602661, Val Acc: 68.66%\n",
      "Epoch: 9759,     Training Loss: 0.17444640398025513, Training Acc: 80.41%\n",
      "              Val Loss: 1.5208908319473267, Val Acc: 68.66%\n",
      "Epoch: 9760,     Training Loss: 0.1706206500530243, Training Acc: 80.41%\n",
      "              Val Loss: 1.5300848484039307, Val Acc: 68.66%\n",
      "Epoch: 9761,     Training Loss: 0.16918733716011047, Training Acc: 80.41%\n",
      "              Val Loss: 1.5523930788040161, Val Acc: 68.66%\n",
      "Epoch: 9762,     Training Loss: 0.17038221657276154, Training Acc: 80.41%\n",
      "              Val Loss: 1.519984483718872, Val Acc: 68.66%\n",
      "Epoch: 9763,     Training Loss: 0.17525266110897064, Training Acc: 80.41%\n",
      "              Val Loss: 1.5786651372909546, Val Acc: 68.66%\n",
      "Epoch: 9764,     Training Loss: 0.1766868531703949, Training Acc: 80.41%\n",
      "              Val Loss: 1.5165884494781494, Val Acc: 68.66%\n",
      "Epoch: 9765,     Training Loss: 0.18568561971187592, Training Acc: 80.41%\n",
      "              Val Loss: 1.5939230918884277, Val Acc: 68.66%\n",
      "Epoch: 9766,     Training Loss: 0.18253222107887268, Training Acc: 80.42%\n",
      "              Val Loss: 1.512549638748169, Val Acc: 68.66%\n",
      "Epoch: 9767,     Training Loss: 0.19409595429897308, Training Acc: 80.42%\n",
      "              Val Loss: 1.5893728733062744, Val Acc: 68.66%\n",
      "Epoch: 9768,     Training Loss: 0.1810949742794037, Training Acc: 80.42%\n",
      "              Val Loss: 1.5124098062515259, Val Acc: 68.66%\n",
      "Epoch: 9769,     Training Loss: 0.17746110260486603, Training Acc: 80.42%\n",
      "              Val Loss: 1.5342808961868286, Val Acc: 68.66%\n",
      "Epoch: 9770,     Training Loss: 0.17038345336914062, Training Acc: 80.42%\n",
      "              Val Loss: 1.5432953834533691, Val Acc: 68.66%\n",
      "Epoch: 9771,     Training Loss: 0.170317605137825, Training Acc: 80.42%\n",
      "              Val Loss: 1.51677668094635, Val Acc: 68.66%\n",
      "Epoch: 9772,     Training Loss: 0.18009214103221893, Training Acc: 80.42%\n",
      "              Val Loss: 1.5973947048187256, Val Acc: 68.66%\n",
      "Epoch: 9773,     Training Loss: 0.18197883665561676, Training Acc: 80.42%\n",
      "              Val Loss: 1.5149171352386475, Val Acc: 68.66%\n",
      "Epoch: 9774,     Training Loss: 0.18977823853492737, Training Acc: 80.43%\n",
      "              Val Loss: 1.5936819314956665, Val Acc: 68.66%\n",
      "Epoch: 9775,     Training Loss: 0.18245337903499603, Training Acc: 80.43%\n",
      "              Val Loss: 1.5182499885559082, Val Acc: 68.66%\n",
      "Epoch: 9776,     Training Loss: 0.18618667125701904, Training Acc: 80.43%\n",
      "              Val Loss: 1.5835663080215454, Val Acc: 68.66%\n",
      "Epoch: 9777,     Training Loss: 0.1772078573703766, Training Acc: 80.43%\n",
      "              Val Loss: 1.5247067213058472, Val Acc: 68.66%\n",
      "Epoch: 9778,     Training Loss: 0.17268520593643188, Training Acc: 80.43%\n",
      "              Val Loss: 1.5437345504760742, Val Acc: 68.66%\n",
      "Epoch: 9779,     Training Loss: 0.1681867390871048, Training Acc: 80.43%\n",
      "              Val Loss: 1.5550624132156372, Val Acc: 68.66%\n",
      "Epoch: 9780,     Training Loss: 0.16961286962032318, Training Acc: 80.43%\n",
      "              Val Loss: 1.5238035917282104, Val Acc: 68.66%\n",
      "Epoch: 9781,     Training Loss: 0.1771783083677292, Training Acc: 80.43%\n",
      "              Val Loss: 1.6028945446014404, Val Acc: 68.66%\n",
      "Epoch: 9782,     Training Loss: 0.17957396805286407, Training Acc: 80.44%\n",
      "              Val Loss: 1.519749641418457, Val Acc: 68.66%\n",
      "Epoch: 9783,     Training Loss: 0.18830737471580505, Training Acc: 80.44%\n",
      "              Val Loss: 1.594398021697998, Val Acc: 68.67%\n",
      "Epoch: 9784,     Training Loss: 0.1806049942970276, Training Acc: 80.44%\n",
      "              Val Loss: 1.514915108680725, Val Acc: 68.67%\n",
      "Epoch: 9785,     Training Loss: 0.18566283583641052, Training Acc: 80.44%\n",
      "              Val Loss: 1.5791406631469727, Val Acc: 68.67%\n",
      "Epoch: 9786,     Training Loss: 0.17714720964431763, Training Acc: 80.44%\n",
      "              Val Loss: 1.5196512937545776, Val Acc: 68.67%\n",
      "Epoch: 9787,     Training Loss: 0.1758631467819214, Training Acc: 80.44%\n",
      "              Val Loss: 1.5662213563919067, Val Acc: 68.67%\n",
      "Epoch: 9788,     Training Loss: 0.16910164058208466, Training Acc: 80.44%\n",
      "              Val Loss: 1.555474877357483, Val Acc: 68.67%\n",
      "Epoch: 9789,     Training Loss: 0.1676955372095108, Training Acc: 80.45%\n",
      "              Val Loss: 1.527957797050476, Val Acc: 68.67%\n",
      "Epoch: 9790,     Training Loss: 0.17300842702388763, Training Acc: 80.45%\n",
      "              Val Loss: 1.6013882160186768, Val Acc: 68.67%\n",
      "Epoch: 9791,     Training Loss: 0.17666776478290558, Training Acc: 80.45%\n",
      "              Val Loss: 1.5234912633895874, Val Acc: 68.67%\n",
      "Epoch: 9792,     Training Loss: 0.18603460490703583, Training Acc: 80.45%\n",
      "              Val Loss: 1.595654010772705, Val Acc: 68.67%\n",
      "Epoch: 9793,     Training Loss: 0.1785895973443985, Training Acc: 80.45%\n",
      "              Val Loss: 1.5224720239639282, Val Acc: 68.67%\n",
      "Epoch: 9794,     Training Loss: 0.1870630979537964, Training Acc: 80.45%\n",
      "              Val Loss: 1.5734387636184692, Val Acc: 68.67%\n",
      "Epoch: 9795,     Training Loss: 0.173662468791008, Training Acc: 80.45%\n",
      "              Val Loss: 1.524373173713684, Val Acc: 68.67%\n",
      "Epoch: 9796,     Training Loss: 0.17012359201908112, Training Acc: 80.45%\n",
      "              Val Loss: 1.5589312314987183, Val Acc: 68.67%\n",
      "Epoch: 9797,     Training Loss: 0.16854004561901093, Training Acc: 80.46%\n",
      "              Val Loss: 1.560133695602417, Val Acc: 68.67%\n",
      "Epoch: 9798,     Training Loss: 0.16700133681297302, Training Acc: 80.46%\n",
      "              Val Loss: 1.5346790552139282, Val Acc: 68.67%\n",
      "Epoch: 9799,     Training Loss: 0.16898974776268005, Training Acc: 80.46%\n",
      "              Val Loss: 1.5914922952651978, Val Acc: 68.67%\n",
      "Epoch: 9800,     Training Loss: 0.17331640422344208, Training Acc: 80.46%\n",
      "              Val Loss: 1.5320842266082764, Val Acc: 68.67%\n",
      "Epoch: 9801,     Training Loss: 0.18086853623390198, Training Acc: 80.46%\n",
      "              Val Loss: 1.6026819944381714, Val Acc: 68.67%\n",
      "Epoch: 9802,     Training Loss: 0.1790902465581894, Training Acc: 80.46%\n",
      "              Val Loss: 1.5331007242202759, Val Acc: 68.67%\n",
      "Epoch: 9803,     Training Loss: 0.19091443717479706, Training Acc: 80.46%\n",
      "              Val Loss: 1.6016556024551392, Val Acc: 68.67%\n",
      "Epoch: 9804,     Training Loss: 0.17982988059520721, Training Acc: 80.46%\n",
      "              Val Loss: 1.518381953239441, Val Acc: 68.67%\n",
      "Epoch: 9805,     Training Loss: 0.1800176054239273, Training Acc: 80.47%\n",
      "              Val Loss: 1.5775238275527954, Val Acc: 68.67%\n",
      "Epoch: 9806,     Training Loss: 0.17061994969844818, Training Acc: 80.47%\n",
      "              Val Loss: 1.5468558073043823, Val Acc: 68.67%\n",
      "Epoch: 9807,     Training Loss: 0.16832181811332703, Training Acc: 80.47%\n",
      "              Val Loss: 1.5420936346054077, Val Acc: 68.67%\n",
      "Epoch: 9808,     Training Loss: 0.16788524389266968, Training Acc: 80.47%\n",
      "              Val Loss: 1.5782455205917358, Val Acc: 68.67%\n",
      "Epoch: 9809,     Training Loss: 0.16975532472133636, Training Acc: 80.47%\n",
      "              Val Loss: 1.5237232446670532, Val Acc: 68.67%\n",
      "Epoch: 9810,     Training Loss: 0.17751269042491913, Training Acc: 80.47%\n",
      "              Val Loss: 1.5983985662460327, Val Acc: 68.67%\n",
      "Epoch: 9811,     Training Loss: 0.18136772513389587, Training Acc: 80.47%\n",
      "              Val Loss: 1.546742558479309, Val Acc: 68.67%\n",
      "Epoch: 9812,     Training Loss: 0.20373447239398956, Training Acc: 80.48%\n",
      "              Val Loss: 1.6327853202819824, Val Acc: 68.67%\n",
      "Epoch: 9813,     Training Loss: 0.18835251033306122, Training Acc: 80.48%\n",
      "              Val Loss: 1.5288805961608887, Val Acc: 68.67%\n",
      "Epoch: 9814,     Training Loss: 0.1989712119102478, Training Acc: 80.48%\n",
      "              Val Loss: 1.609429121017456, Val Acc: 68.67%\n",
      "Epoch: 9815,     Training Loss: 0.18071134388446808, Training Acc: 80.48%\n",
      "              Val Loss: 1.5322251319885254, Val Acc: 68.67%\n",
      "Epoch: 9816,     Training Loss: 0.16810590028762817, Training Acc: 80.48%\n",
      "              Val Loss: 1.5340981483459473, Val Acc: 68.67%\n",
      "Epoch: 9817,     Training Loss: 0.16910643875598907, Training Acc: 80.48%\n",
      "              Val Loss: 1.590946912765503, Val Acc: 68.67%\n",
      "Epoch: 9818,     Training Loss: 0.1757429540157318, Training Acc: 80.48%\n",
      "              Val Loss: 1.5116586685180664, Val Acc: 68.67%\n",
      "Epoch: 9819,     Training Loss: 0.18127727508544922, Training Acc: 80.48%\n",
      "              Val Loss: 1.591447353363037, Val Acc: 68.67%\n",
      "Epoch: 9820,     Training Loss: 0.18105334043502808, Training Acc: 80.49%\n",
      "              Val Loss: 1.550774097442627, Val Acc: 68.67%\n",
      "Epoch: 9821,     Training Loss: 0.1962234377861023, Training Acc: 80.49%\n",
      "              Val Loss: 1.6103674173355103, Val Acc: 68.67%\n",
      "Epoch: 9822,     Training Loss: 0.17885304987430573, Training Acc: 80.49%\n",
      "              Val Loss: 1.543588399887085, Val Acc: 68.67%\n",
      "Epoch: 9823,     Training Loss: 0.17333509027957916, Training Acc: 80.49%\n",
      "              Val Loss: 1.5841383934020996, Val Acc: 68.67%\n",
      "Epoch: 9824,     Training Loss: 0.17090673744678497, Training Acc: 80.49%\n",
      "              Val Loss: 1.5572148561477661, Val Acc: 68.67%\n",
      "Epoch: 9825,     Training Loss: 0.16723944246768951, Training Acc: 80.49%\n",
      "              Val Loss: 1.5500283241271973, Val Acc: 68.67%\n",
      "Epoch: 9826,     Training Loss: 0.1660575121641159, Training Acc: 80.49%\n",
      "              Val Loss: 1.6036436557769775, Val Acc: 68.67%\n",
      "Epoch: 9827,     Training Loss: 0.17176416516304016, Training Acc: 80.49%\n",
      "              Val Loss: 1.5343130826950073, Val Acc: 68.67%\n",
      "Epoch: 9828,     Training Loss: 0.18158966302871704, Training Acc: 80.50%\n",
      "              Val Loss: 1.612383246421814, Val Acc: 68.67%\n",
      "Epoch: 9829,     Training Loss: 0.18087661266326904, Training Acc: 80.50%\n",
      "              Val Loss: 1.5360020399093628, Val Acc: 68.67%\n",
      "Epoch: 9830,     Training Loss: 0.19874653220176697, Training Acc: 80.50%\n",
      "              Val Loss: 1.6442794799804688, Val Acc: 68.67%\n",
      "Epoch: 9831,     Training Loss: 0.1989201009273529, Training Acc: 80.50%\n",
      "              Val Loss: 1.5502920150756836, Val Acc: 68.67%\n",
      "Epoch: 9832,     Training Loss: 0.22995899617671967, Training Acc: 80.50%\n",
      "              Val Loss: 1.614607572555542, Val Acc: 68.67%\n",
      "Epoch: 9833,     Training Loss: 0.1769244223833084, Training Acc: 80.50%\n",
      "              Val Loss: 1.5806384086608887, Val Acc: 68.67%\n",
      "Epoch: 9834,     Training Loss: 0.18388082087039948, Training Acc: 80.50%\n",
      "              Val Loss: 1.5388702154159546, Val Acc: 68.67%\n",
      "Epoch: 9835,     Training Loss: 0.19753926992416382, Training Acc: 80.50%\n",
      "              Val Loss: 1.585435390472412, Val Acc: 68.67%\n",
      "Epoch: 9836,     Training Loss: 0.17633678019046783, Training Acc: 80.51%\n",
      "              Val Loss: 1.5768183469772339, Val Acc: 68.67%\n",
      "Epoch: 9837,     Training Loss: 0.20561109483242035, Training Acc: 80.51%\n",
      "              Val Loss: 1.5746737718582153, Val Acc: 68.67%\n",
      "Epoch: 9838,     Training Loss: 0.18830183148384094, Training Acc: 80.51%\n",
      "              Val Loss: 1.569636583328247, Val Acc: 68.67%\n",
      "Epoch: 9839,     Training Loss: 0.17433738708496094, Training Acc: 80.51%\n",
      "              Val Loss: 1.562056541442871, Val Acc: 68.67%\n",
      "Epoch: 9840,     Training Loss: 0.18496915698051453, Training Acc: 80.51%\n",
      "              Val Loss: 1.6041359901428223, Val Acc: 68.67%\n",
      "Epoch: 9841,     Training Loss: 0.1783483922481537, Training Acc: 80.51%\n",
      "              Val Loss: 1.5496776103973389, Val Acc: 68.67%\n",
      "Epoch: 9842,     Training Loss: 0.1787104606628418, Training Acc: 80.51%\n",
      "              Val Loss: 1.583431601524353, Val Acc: 68.67%\n",
      "Epoch: 9843,     Training Loss: 0.1713382750749588, Training Acc: 80.51%\n",
      "              Val Loss: 1.5522247552871704, Val Acc: 68.67%\n",
      "Epoch: 9844,     Training Loss: 0.17272791266441345, Training Acc: 80.52%\n",
      "              Val Loss: 1.5548008680343628, Val Acc: 68.67%\n",
      "Epoch: 9845,     Training Loss: 0.17583943903446198, Training Acc: 80.52%\n",
      "              Val Loss: 1.5938100814819336, Val Acc: 68.67%\n",
      "Epoch: 9846,     Training Loss: 0.17240682244300842, Training Acc: 80.52%\n",
      "              Val Loss: 1.5800596475601196, Val Acc: 68.67%\n",
      "Epoch: 9847,     Training Loss: 0.1668825000524521, Training Acc: 80.52%\n",
      "              Val Loss: 1.57771635055542, Val Acc: 68.67%\n",
      "Epoch: 9848,     Training Loss: 0.17242565751075745, Training Acc: 80.52%\n",
      "              Val Loss: 1.599533200263977, Val Acc: 68.67%\n",
      "Epoch: 9849,     Training Loss: 0.1725894957780838, Training Acc: 80.52%\n",
      "              Val Loss: 1.562231183052063, Val Acc: 68.67%\n",
      "Epoch: 9850,     Training Loss: 0.1646977961063385, Training Acc: 80.52%\n",
      "              Val Loss: 1.5701953172683716, Val Acc: 68.68%\n",
      "Epoch: 9851,     Training Loss: 0.16988767683506012, Training Acc: 80.52%\n",
      "              Val Loss: 1.5724105834960938, Val Acc: 68.68%\n",
      "Epoch: 9852,     Training Loss: 0.17868995666503906, Training Acc: 80.53%\n",
      "              Val Loss: 1.5650229454040527, Val Acc: 68.68%\n",
      "Epoch: 9853,     Training Loss: 0.16583985090255737, Training Acc: 80.53%\n",
      "              Val Loss: 1.5376771688461304, Val Acc: 68.68%\n",
      "Epoch: 9854,     Training Loss: 0.16769760847091675, Training Acc: 80.53%\n",
      "              Val Loss: 1.5900341272354126, Val Acc: 68.68%\n",
      "Epoch: 9855,     Training Loss: 0.17090538144111633, Training Acc: 80.53%\n",
      "              Val Loss: 1.557308554649353, Val Acc: 68.68%\n",
      "Epoch: 9856,     Training Loss: 0.16714449226856232, Training Acc: 80.53%\n",
      "              Val Loss: 1.6020088195800781, Val Acc: 68.68%\n",
      "Epoch: 9857,     Training Loss: 0.16585174202919006, Training Acc: 80.53%\n",
      "              Val Loss: 1.5808018445968628, Val Acc: 68.68%\n",
      "Epoch: 9858,     Training Loss: 0.1722157895565033, Training Acc: 80.53%\n",
      "              Val Loss: 1.6097358465194702, Val Acc: 68.68%\n",
      "Epoch: 9859,     Training Loss: 0.17014530301094055, Training Acc: 80.53%\n",
      "              Val Loss: 1.5578029155731201, Val Acc: 68.68%\n",
      "Epoch: 9860,     Training Loss: 0.17968325316905975, Training Acc: 80.54%\n",
      "              Val Loss: 1.667966604232788, Val Acc: 68.68%\n",
      "Epoch: 9861,     Training Loss: 0.1884763389825821, Training Acc: 80.54%\n",
      "              Val Loss: 1.5528559684753418, Val Acc: 68.68%\n",
      "Epoch: 9862,     Training Loss: 0.23737487196922302, Training Acc: 80.54%\n",
      "              Val Loss: 1.6737667322158813, Val Acc: 68.68%\n",
      "Epoch: 9863,     Training Loss: 0.20739759504795074, Training Acc: 80.54%\n",
      "              Val Loss: 1.5294451713562012, Val Acc: 68.68%\n",
      "Epoch: 9864,     Training Loss: 0.2271021604537964, Training Acc: 80.54%\n",
      "              Val Loss: 1.6126350164413452, Val Acc: 68.68%\n",
      "Epoch: 9865,     Training Loss: 0.18240122497081757, Training Acc: 80.54%\n",
      "              Val Loss: 1.5683541297912598, Val Acc: 68.68%\n",
      "Epoch: 9866,     Training Loss: 0.1724264919757843, Training Acc: 80.54%\n",
      "              Val Loss: 1.5221742391586304, Val Acc: 68.68%\n",
      "Epoch: 9867,     Training Loss: 0.17818611860275269, Training Acc: 80.54%\n",
      "              Val Loss: 1.614630937576294, Val Acc: 68.68%\n",
      "Epoch: 9868,     Training Loss: 0.18415893614292145, Training Acc: 80.55%\n",
      "              Val Loss: 1.555317997932434, Val Acc: 68.68%\n",
      "Epoch: 9869,     Training Loss: 0.21037715673446655, Training Acc: 80.55%\n",
      "              Val Loss: 1.6230347156524658, Val Acc: 68.68%\n",
      "Epoch: 9870,     Training Loss: 0.18007542192935944, Training Acc: 80.55%\n",
      "              Val Loss: 1.5778692960739136, Val Acc: 68.68%\n",
      "Epoch: 9871,     Training Loss: 0.1696682572364807, Training Acc: 80.55%\n",
      "              Val Loss: 1.5706459283828735, Val Acc: 68.68%\n",
      "Epoch: 9872,     Training Loss: 0.18138130009174347, Training Acc: 80.55%\n",
      "              Val Loss: 1.584344744682312, Val Acc: 68.68%\n",
      "Epoch: 9873,     Training Loss: 0.17744934558868408, Training Acc: 80.55%\n",
      "              Val Loss: 1.5914500951766968, Val Acc: 68.68%\n",
      "Epoch: 9874,     Training Loss: 0.17814281582832336, Training Acc: 80.55%\n",
      "              Val Loss: 1.6150623559951782, Val Acc: 68.68%\n",
      "Epoch: 9875,     Training Loss: 0.1788225769996643, Training Acc: 80.55%\n",
      "              Val Loss: 1.5565451383590698, Val Acc: 68.68%\n",
      "Epoch: 9876,     Training Loss: 0.19518247246742249, Training Acc: 80.56%\n",
      "              Val Loss: 1.6167356967926025, Val Acc: 68.68%\n",
      "Epoch: 9877,     Training Loss: 0.1835993230342865, Training Acc: 80.56%\n",
      "              Val Loss: 1.5347691774368286, Val Acc: 68.68%\n",
      "Epoch: 9878,     Training Loss: 0.17848049104213715, Training Acc: 80.56%\n",
      "              Val Loss: 1.6236053705215454, Val Acc: 68.68%\n",
      "Epoch: 9879,     Training Loss: 0.18890488147735596, Training Acc: 80.56%\n",
      "              Val Loss: 1.557844877243042, Val Acc: 68.68%\n",
      "Epoch: 9880,     Training Loss: 0.20280709862709045, Training Acc: 80.56%\n",
      "              Val Loss: 1.6117825508117676, Val Acc: 68.68%\n",
      "Epoch: 9881,     Training Loss: 0.18103022873401642, Training Acc: 80.56%\n",
      "              Val Loss: 1.5473805665969849, Val Acc: 68.68%\n",
      "Epoch: 9882,     Training Loss: 0.17063026130199432, Training Acc: 80.56%\n",
      "              Val Loss: 1.6033356189727783, Val Acc: 68.68%\n",
      "Epoch: 9883,     Training Loss: 0.1739448606967926, Training Acc: 80.56%\n",
      "              Val Loss: 1.5846688747406006, Val Acc: 68.68%\n",
      "Epoch: 9884,     Training Loss: 0.17094726860523224, Training Acc: 80.57%\n",
      "              Val Loss: 1.5826263427734375, Val Acc: 68.68%\n",
      "Epoch: 9885,     Training Loss: 0.1638532280921936, Training Acc: 80.57%\n",
      "              Val Loss: 1.5932819843292236, Val Acc: 68.68%\n",
      "Epoch: 9886,     Training Loss: 0.1655503213405609, Training Acc: 80.57%\n",
      "              Val Loss: 1.5744543075561523, Val Acc: 68.68%\n",
      "Epoch: 9887,     Training Loss: 0.170697420835495, Training Acc: 80.57%\n",
      "              Val Loss: 1.6000767946243286, Val Acc: 68.68%\n",
      "Epoch: 9888,     Training Loss: 0.16620424389839172, Training Acc: 80.57%\n",
      "              Val Loss: 1.5986469984054565, Val Acc: 68.68%\n",
      "Epoch: 9889,     Training Loss: 0.16129615902900696, Training Acc: 80.57%\n",
      "              Val Loss: 1.6007498502731323, Val Acc: 68.68%\n",
      "Epoch: 9890,     Training Loss: 0.16756290197372437, Training Acc: 80.57%\n",
      "              Val Loss: 1.5828458070755005, Val Acc: 68.68%\n",
      "Epoch: 9891,     Training Loss: 0.1664724349975586, Training Acc: 80.57%\n",
      "              Val Loss: 1.6117315292358398, Val Acc: 68.68%\n",
      "Epoch: 9892,     Training Loss: 0.1667049378156662, Training Acc: 80.58%\n",
      "              Val Loss: 1.568820834159851, Val Acc: 68.68%\n",
      "Epoch: 9893,     Training Loss: 0.17214591801166534, Training Acc: 80.58%\n",
      "              Val Loss: 1.6369242668151855, Val Acc: 68.68%\n",
      "Epoch: 9894,     Training Loss: 0.1717768907546997, Training Acc: 80.58%\n",
      "              Val Loss: 1.5596840381622314, Val Acc: 68.68%\n",
      "Epoch: 9895,     Training Loss: 0.185427725315094, Training Acc: 80.58%\n",
      "              Val Loss: 1.6221556663513184, Val Acc: 68.68%\n",
      "Epoch: 9896,     Training Loss: 0.18048349022865295, Training Acc: 80.58%\n",
      "              Val Loss: 1.5486828088760376, Val Acc: 68.68%\n",
      "Epoch: 9897,     Training Loss: 0.19280298054218292, Training Acc: 80.58%\n",
      "              Val Loss: 1.6785565614700317, Val Acc: 68.68%\n",
      "Epoch: 9898,     Training Loss: 0.20392362773418427, Training Acc: 80.58%\n",
      "              Val Loss: 1.569217562675476, Val Acc: 68.68%\n",
      "Epoch: 9899,     Training Loss: 0.26304391026496887, Training Acc: 80.58%\n",
      "              Val Loss: 1.6920379400253296, Val Acc: 68.68%\n",
      "Epoch: 9900,     Training Loss: 0.19915497303009033, Training Acc: 80.58%\n",
      "              Val Loss: 1.5716629028320312, Val Acc: 68.68%\n",
      "Epoch: 9901,     Training Loss: 0.20720010995864868, Training Acc: 80.59%\n",
      "              Val Loss: 1.615861415863037, Val Acc: 68.68%\n",
      "Epoch: 9902,     Training Loss: 0.1895577609539032, Training Acc: 80.59%\n",
      "              Val Loss: 1.5486434698104858, Val Acc: 68.68%\n",
      "Epoch: 9903,     Training Loss: 0.17645861208438873, Training Acc: 80.59%\n",
      "              Val Loss: 1.5849498510360718, Val Acc: 68.68%\n",
      "Epoch: 9904,     Training Loss: 0.17381563782691956, Training Acc: 80.59%\n",
      "              Val Loss: 1.5863473415374756, Val Acc: 68.68%\n",
      "Epoch: 9905,     Training Loss: 0.17934399843215942, Training Acc: 80.59%\n",
      "              Val Loss: 1.5661693811416626, Val Acc: 68.68%\n",
      "Epoch: 9906,     Training Loss: 0.1836986541748047, Training Acc: 80.59%\n",
      "              Val Loss: 1.636167049407959, Val Acc: 68.68%\n",
      "Epoch: 9907,     Training Loss: 0.17625243961811066, Training Acc: 80.59%\n",
      "              Val Loss: 1.5750807523727417, Val Acc: 68.68%\n",
      "Epoch: 9908,     Training Loss: 0.17652316391468048, Training Acc: 80.59%\n",
      "              Val Loss: 1.6267024278640747, Val Acc: 68.68%\n",
      "Epoch: 9909,     Training Loss: 0.18741963803768158, Training Acc: 80.60%\n",
      "              Val Loss: 1.6212356090545654, Val Acc: 68.68%\n",
      "Epoch: 9910,     Training Loss: 0.21573838591575623, Training Acc: 80.60%\n",
      "              Val Loss: 1.631661057472229, Val Acc: 68.68%\n",
      "Epoch: 9911,     Training Loss: 0.1858842968940735, Training Acc: 80.60%\n",
      "              Val Loss: 1.5669997930526733, Val Acc: 68.68%\n",
      "Epoch: 9912,     Training Loss: 0.19830697774887085, Training Acc: 80.60%\n",
      "              Val Loss: 1.6918827295303345, Val Acc: 68.68%\n",
      "Epoch: 9913,     Training Loss: 0.20333455502986908, Training Acc: 80.60%\n",
      "              Val Loss: 1.5650542974472046, Val Acc: 68.68%\n",
      "Epoch: 9914,     Training Loss: 0.20676857233047485, Training Acc: 80.60%\n",
      "              Val Loss: 1.6565601825714111, Val Acc: 68.68%\n",
      "Epoch: 9915,     Training Loss: 0.19427713751792908, Training Acc: 80.60%\n",
      "              Val Loss: 1.581681489944458, Val Acc: 68.68%\n",
      "Epoch: 9916,     Training Loss: 0.24884216487407684, Training Acc: 80.60%\n",
      "              Val Loss: 1.6435203552246094, Val Acc: 68.68%\n",
      "Epoch: 9917,     Training Loss: 0.2068716585636139, Training Acc: 80.60%\n",
      "              Val Loss: 1.560875415802002, Val Acc: 68.68%\n",
      "Epoch: 9918,     Training Loss: 0.20022183656692505, Training Acc: 80.61%\n",
      "              Val Loss: 1.6368671655654907, Val Acc: 68.68%\n",
      "Epoch: 9919,     Training Loss: 0.18634982407093048, Training Acc: 80.61%\n",
      "              Val Loss: 1.646519660949707, Val Acc: 68.68%\n",
      "Epoch: 9920,     Training Loss: 0.20836761593818665, Training Acc: 80.61%\n",
      "              Val Loss: 1.572930097579956, Val Acc: 68.68%\n",
      "Epoch: 9921,     Training Loss: 0.19269955158233643, Training Acc: 80.61%\n",
      "              Val Loss: 1.629755973815918, Val Acc: 68.68%\n",
      "Epoch: 9922,     Training Loss: 0.18711866438388824, Training Acc: 80.61%\n",
      "              Val Loss: 1.6794836521148682, Val Acc: 68.68%\n",
      "Epoch: 9923,     Training Loss: 0.2887956500053406, Training Acc: 80.61%\n",
      "              Val Loss: 1.7027019262313843, Val Acc: 68.68%\n",
      "Epoch: 9924,     Training Loss: 0.27406546473503113, Training Acc: 80.61%\n",
      "              Val Loss: 1.55535888671875, Val Acc: 68.68%\n",
      "Epoch: 9925,     Training Loss: 0.19880478084087372, Training Acc: 80.61%\n",
      "              Val Loss: 1.737548828125, Val Acc: 68.68%\n",
      "Epoch: 9926,     Training Loss: 0.2693552076816559, Training Acc: 80.61%\n",
      "              Val Loss: 1.631223201751709, Val Acc: 68.68%\n",
      "Epoch: 9927,     Training Loss: 0.44632217288017273, Training Acc: 80.61%\n",
      "              Val Loss: 1.6637372970581055, Val Acc: 68.68%\n",
      "Epoch: 9928,     Training Loss: 0.272687703371048, Training Acc: 80.61%\n",
      "              Val Loss: 1.8172053098678589, Val Acc: 68.68%\n",
      "Epoch: 9929,     Training Loss: 0.3488878905773163, Training Acc: 80.62%\n",
      "              Val Loss: 1.527193546295166, Val Acc: 68.68%\n",
      "Epoch: 9930,     Training Loss: 0.2596636414527893, Training Acc: 80.62%\n",
      "              Val Loss: 1.7572355270385742, Val Acc: 68.68%\n",
      "Epoch: 9931,     Training Loss: 0.41990718245506287, Training Acc: 80.62%\n",
      "              Val Loss: 1.9415959119796753, Val Acc: 68.68%\n",
      "Epoch: 9932,     Training Loss: 0.7555931210517883, Training Acc: 80.62%\n",
      "              Val Loss: 1.700734257698059, Val Acc: 68.68%\n",
      "Epoch: 9933,     Training Loss: 0.3982490301132202, Training Acc: 80.62%\n",
      "              Val Loss: 1.9955472946166992, Val Acc: 68.68%\n",
      "Epoch: 9934,     Training Loss: 0.8236732482910156, Training Acc: 80.62%\n",
      "              Val Loss: 2.2554852962493896, Val Acc: 68.68%\n",
      "Epoch: 9935,     Training Loss: 1.280137062072754, Training Acc: 80.61%\n",
      "              Val Loss: 1.7065004110336304, Val Acc: 68.68%\n",
      "Epoch: 9936,     Training Loss: 0.6223312020301819, Training Acc: 80.61%\n",
      "              Val Loss: 2.5027692317962646, Val Acc: 68.68%\n",
      "Epoch: 9937,     Training Loss: 1.1072977781295776, Training Acc: 80.61%\n",
      "              Val Loss: 1.8637028932571411, Val Acc: 68.68%\n",
      "Epoch: 9938,     Training Loss: 0.806926965713501, Training Acc: 80.61%\n",
      "              Val Loss: 1.7674775123596191, Val Acc: 68.68%\n",
      "Epoch: 9939,     Training Loss: 0.8121084570884705, Training Acc: 80.61%\n",
      "              Val Loss: 1.8222432136535645, Val Acc: 68.68%\n",
      "Epoch: 9940,     Training Loss: 0.9927754402160645, Training Acc: 80.61%\n",
      "              Val Loss: 1.3393478393554688, Val Acc: 68.68%\n",
      "Epoch: 9941,     Training Loss: 0.5124624371528625, Training Acc: 80.61%\n",
      "              Val Loss: 1.5324110984802246, Val Acc: 68.68%\n",
      "Epoch: 9942,     Training Loss: 0.717119574546814, Training Acc: 80.61%\n",
      "              Val Loss: 1.4985507726669312, Val Acc: 68.68%\n",
      "Epoch: 9943,     Training Loss: 0.693083643913269, Training Acc: 80.61%\n",
      "              Val Loss: 1.3852462768554688, Val Acc: 68.68%\n",
      "Epoch: 9944,     Training Loss: 0.5410286784172058, Training Acc: 80.61%\n",
      "              Val Loss: 1.4844818115234375, Val Acc: 68.68%\n",
      "Epoch: 9945,     Training Loss: 0.5793933868408203, Training Acc: 80.61%\n",
      "              Val Loss: 1.5175224542617798, Val Acc: 68.68%\n",
      "Epoch: 9946,     Training Loss: 0.5879911780357361, Training Acc: 80.61%\n",
      "              Val Loss: 1.4533820152282715, Val Acc: 68.68%\n",
      "Epoch: 9947,     Training Loss: 0.5179288983345032, Training Acc: 80.61%\n",
      "              Val Loss: 1.3978776931762695, Val Acc: 68.68%\n",
      "Epoch: 9948,     Training Loss: 0.49240192770957947, Training Acc: 80.61%\n",
      "              Val Loss: 1.3470244407653809, Val Acc: 68.68%\n",
      "Epoch: 9949,     Training Loss: 0.505450963973999, Training Acc: 80.61%\n",
      "              Val Loss: 1.2917789220809937, Val Acc: 68.68%\n",
      "Epoch: 9950,     Training Loss: 0.4805847108364105, Training Acc: 80.61%\n",
      "              Val Loss: 1.2799417972564697, Val Acc: 68.68%\n",
      "Epoch: 9951,     Training Loss: 0.4465910792350769, Training Acc: 80.61%\n",
      "              Val Loss: 1.3197396993637085, Val Acc: 68.68%\n",
      "Epoch: 9952,     Training Loss: 0.48631978034973145, Training Acc: 80.61%\n",
      "              Val Loss: 1.2238852977752686, Val Acc: 68.68%\n",
      "Epoch: 9953,     Training Loss: 0.41074129939079285, Training Acc: 80.61%\n",
      "              Val Loss: 1.2601830959320068, Val Acc: 68.68%\n",
      "Epoch: 9954,     Training Loss: 0.41997280716896057, Training Acc: 80.61%\n",
      "              Val Loss: 1.324162483215332, Val Acc: 68.68%\n",
      "Epoch: 9955,     Training Loss: 0.44353431463241577, Training Acc: 80.61%\n",
      "              Val Loss: 1.29463791847229, Val Acc: 68.68%\n",
      "Epoch: 9956,     Training Loss: 0.3755910396575928, Training Acc: 80.61%\n",
      "              Val Loss: 1.280917763710022, Val Acc: 68.68%\n",
      "Epoch: 9957,     Training Loss: 0.3868766725063324, Training Acc: 80.61%\n",
      "              Val Loss: 1.293156623840332, Val Acc: 68.68%\n",
      "Epoch: 9958,     Training Loss: 0.3716168701648712, Training Acc: 80.61%\n",
      "              Val Loss: 1.2734191417694092, Val Acc: 68.68%\n",
      "Epoch: 9959,     Training Loss: 0.3553464114665985, Training Acc: 80.61%\n",
      "              Val Loss: 1.2710469961166382, Val Acc: 68.68%\n",
      "Epoch: 9960,     Training Loss: 0.3605482876300812, Training Acc: 80.61%\n",
      "              Val Loss: 1.2683768272399902, Val Acc: 68.68%\n",
      "Epoch: 9961,     Training Loss: 0.35233038663864136, Training Acc: 80.61%\n",
      "              Val Loss: 1.2602767944335938, Val Acc: 68.68%\n",
      "Epoch: 9962,     Training Loss: 0.34599825739860535, Training Acc: 80.61%\n",
      "              Val Loss: 1.224246859550476, Val Acc: 68.68%\n",
      "Epoch: 9963,     Training Loss: 0.32676613330841064, Training Acc: 80.61%\n",
      "              Val Loss: 1.232067584991455, Val Acc: 68.68%\n",
      "Epoch: 9964,     Training Loss: 0.3255871832370758, Training Acc: 80.61%\n",
      "              Val Loss: 1.227402687072754, Val Acc: 68.68%\n",
      "Epoch: 9965,     Training Loss: 0.31780779361724854, Training Acc: 80.61%\n",
      "              Val Loss: 1.252323865890503, Val Acc: 68.68%\n",
      "Epoch: 9966,     Training Loss: 0.32755932211875916, Training Acc: 80.61%\n",
      "              Val Loss: 1.2769428491592407, Val Acc: 68.68%\n",
      "Epoch: 9967,     Training Loss: 0.3204408884048462, Training Acc: 80.61%\n",
      "              Val Loss: 1.282862901687622, Val Acc: 68.68%\n",
      "Epoch: 9968,     Training Loss: 0.3132098317146301, Training Acc: 80.61%\n",
      "              Val Loss: 1.276625633239746, Val Acc: 68.68%\n",
      "Epoch: 9969,     Training Loss: 0.29930540919303894, Training Acc: 80.61%\n",
      "              Val Loss: 1.270013689994812, Val Acc: 68.68%\n",
      "Epoch: 9970,     Training Loss: 0.2977525293827057, Training Acc: 80.61%\n",
      "              Val Loss: 1.267141580581665, Val Acc: 68.68%\n",
      "Epoch: 9971,     Training Loss: 0.29664015769958496, Training Acc: 80.62%\n",
      "              Val Loss: 1.2809174060821533, Val Acc: 68.68%\n",
      "Epoch: 9972,     Training Loss: 0.2941749095916748, Training Acc: 80.62%\n",
      "              Val Loss: 1.2818617820739746, Val Acc: 68.68%\n",
      "Epoch: 9973,     Training Loss: 0.2838866710662842, Training Acc: 80.62%\n",
      "              Val Loss: 1.2807971239089966, Val Acc: 68.68%\n",
      "Epoch: 9974,     Training Loss: 0.2820517420768738, Training Acc: 80.62%\n",
      "              Val Loss: 1.2960457801818848, Val Acc: 68.68%\n",
      "Epoch: 9975,     Training Loss: 0.2805597186088562, Training Acc: 80.62%\n",
      "              Val Loss: 1.2988723516464233, Val Acc: 68.68%\n",
      "Epoch: 9976,     Training Loss: 0.27835404872894287, Training Acc: 80.62%\n",
      "              Val Loss: 1.288863182067871, Val Acc: 68.68%\n",
      "Epoch: 9977,     Training Loss: 0.2712835371494293, Training Acc: 80.62%\n",
      "              Val Loss: 1.2988460063934326, Val Acc: 68.68%\n",
      "Epoch: 9978,     Training Loss: 0.2695640027523041, Training Acc: 80.62%\n",
      "              Val Loss: 1.3177505731582642, Val Acc: 68.68%\n",
      "Epoch: 9979,     Training Loss: 0.26607441902160645, Training Acc: 80.62%\n",
      "              Val Loss: 1.3428137302398682, Val Acc: 68.68%\n",
      "Epoch: 9980,     Training Loss: 0.26306796073913574, Training Acc: 80.62%\n",
      "              Val Loss: 1.3566420078277588, Val Acc: 68.69%\n",
      "Epoch: 9981,     Training Loss: 0.2592354118824005, Training Acc: 80.62%\n",
      "              Val Loss: 1.3616992235183716, Val Acc: 68.69%\n",
      "Epoch: 9982,     Training Loss: 0.2556358873844147, Training Acc: 80.62%\n",
      "              Val Loss: 1.3838082551956177, Val Acc: 68.69%\n",
      "Epoch: 9983,     Training Loss: 0.25417250394821167, Training Acc: 80.63%\n",
      "              Val Loss: 1.3732813596725464, Val Acc: 68.69%\n",
      "Epoch: 9984,     Training Loss: 0.2502478361129761, Training Acc: 80.63%\n",
      "              Val Loss: 1.3833415508270264, Val Acc: 68.69%\n",
      "Epoch: 9985,     Training Loss: 0.24809665977954865, Training Acc: 80.63%\n",
      "              Val Loss: 1.3927030563354492, Val Acc: 68.69%\n",
      "Epoch: 9986,     Training Loss: 0.24498553574085236, Training Acc: 80.63%\n",
      "              Val Loss: 1.4003896713256836, Val Acc: 68.69%\n",
      "Epoch: 9987,     Training Loss: 0.24213138222694397, Training Acc: 80.63%\n",
      "              Val Loss: 1.4233225584030151, Val Acc: 68.69%\n",
      "Epoch: 9988,     Training Loss: 0.24140864610671997, Training Acc: 80.63%\n",
      "              Val Loss: 1.4250646829605103, Val Acc: 68.69%\n",
      "Epoch: 9989,     Training Loss: 0.24506278336048126, Training Acc: 80.63%\n",
      "              Val Loss: 1.465012550354004, Val Acc: 68.69%\n",
      "Epoch: 9990,     Training Loss: 0.2477942705154419, Training Acc: 80.63%\n",
      "              Val Loss: 1.429383397102356, Val Acc: 68.69%\n",
      "Epoch: 9991,     Training Loss: 0.260397344827652, Training Acc: 80.63%\n",
      "              Val Loss: 1.4732815027236938, Val Acc: 68.69%\n",
      "Epoch: 9992,     Training Loss: 0.25071725249290466, Training Acc: 80.63%\n",
      "              Val Loss: 1.4215883016586304, Val Acc: 68.69%\n",
      "Epoch: 9993,     Training Loss: 0.25110846757888794, Training Acc: 80.64%\n",
      "              Val Loss: 1.456529140472412, Val Acc: 68.69%\n",
      "Epoch: 9994,     Training Loss: 0.23395317792892456, Training Acc: 80.64%\n",
      "              Val Loss: 1.4355567693710327, Val Acc: 68.69%\n",
      "Epoch: 9995,     Training Loss: 0.22596031427383423, Training Acc: 80.64%\n",
      "              Val Loss: 1.439276933670044, Val Acc: 68.69%\n",
      "Epoch: 9996,     Training Loss: 0.22636419534683228, Training Acc: 80.64%\n",
      "              Val Loss: 1.480627179145813, Val Acc: 68.69%\n",
      "Epoch: 9997,     Training Loss: 0.23126256465911865, Training Acc: 80.64%\n",
      "              Val Loss: 1.4412879943847656, Val Acc: 68.69%\n",
      "Epoch: 9998,     Training Loss: 0.2347879856824875, Training Acc: 80.64%\n",
      "              Val Loss: 1.4820544719696045, Val Acc: 68.69%\n",
      "Epoch: 9999,     Training Loss: 0.22409400343894958, Training Acc: 80.64%\n",
      "              Val Loss: 1.4772322177886963, Val Acc: 68.69%\n",
      "Epoch: 10000,     Training Loss: 0.21722668409347534, Training Acc: 80.64%\n",
      "              Val Loss: 1.4799602031707764, Val Acc: 68.69%\n"
     ]
    }
   ],
   "source": [
    "# Curves list\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "accuracies_train = []\n",
    "accuracies_val = []\n",
    "\n",
    "epochs = []\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "correct_val = 0\n",
    "total_val = 0\n",
    "\n",
    "# hyperparameter\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    y_pred_train = model(train_features)\n",
    "    loss_train = loss_fn(y_pred_train, train_labels)\n",
    "    losses_train.append(loss_train.item())\n",
    "    epochs.append(epoch + 1)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_val = model(val_features)\n",
    "        loss_val = loss_fn(y_pred_val, val_labels)\n",
    "        losses_val.append(loss_val.item())\n",
    "\n",
    "\n",
    "    # Reference: https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch/63271002#63271002\n",
    "    # Calculate accuracy on validation set\n",
    "    _, predicted_val = torch.max(y_pred_val, 1)\n",
    "    correct_val += (predicted_val == val_labels).sum().item()\n",
    "    total_val += val_labels.size(0)\n",
    "    accuracy_val = correct_val / total_val * 100\n",
    "\n",
    "    \n",
    "    # Calculate accuracy on training set\n",
    "    _, predicted_train = torch.max(y_pred_train, 1)\n",
    "    correct_train += (predicted_train == train_labels).sum().item()\n",
    "    total_train += train_labels.size(0)\n",
    "    accuracy_train = correct_train / total_train * 100\n",
    "    \n",
    "    accuracies_train.append(accuracy_train)\n",
    "    accuracies_val.append(accuracy_val)\n",
    "\n",
    "    # output epoch, Training Loss, Training Accuracy, Validation Loss, Validation Accuracy\n",
    "    print(f\"Epoch: {epoch + 1},     Training Loss: {loss_train}, Training Acc: {accuracy_train:.2f}%\") \n",
    "    print(f\"              Val Loss: {loss_val}, Val Acc: {accuracy_val:.2f}%\")   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between loss and accuracy Reference: \n",
    "# https://www.zhihu.com/question/264892967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs[:300], losses_train[:300], label=\"Training Loss\")\n",
    "plt.plot(epochs[:300], losses_val[:300], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Losses\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(0, 300)\n",
    "\n",
    "plt.savefig('pic/loss_' + str(num_epochs) +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, accuracies_train, label=\"Training Accuracy\")\n",
    "plt.plot(epochs, accuracies_val, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracies\")\n",
    "plt.legend()\n",
    "plt.savefig('pic/acc_' + str(num_epochs) +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'model/nn_' + str(num_epochs) + '.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/Test_Data_final.csv\")\n",
    "\n",
    "test_features = torch.tensor(test_data.values, dtype=torch.float).to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Cancel gradient to use model\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(test_features)\n",
    "\n",
    "_, predicted_labels = torch.max(y_pred_test, 1)\n",
    "\n",
    "predicted_labels_np = predicted_labels.cpu().numpy()\n",
    "\n",
    "raw_Test_Data = pd.read_csv(\"data/Test_Data.csv\")\n",
    "\n",
    "raw_Test_Data['total cost'] = predicted_labels_np + 1\n",
    "\n",
    "raw_Test_Data.to_csv(\"result/prediction_\" + str(num_epochs) + \".csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
